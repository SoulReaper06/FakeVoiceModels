{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 11:19:21.683322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-27 11:19:21.805905: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-27 11:19:21.805926: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-10-27 11:19:21.829986: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-27 11:19:22.339115: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-27 11:19:22.339188: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-27 11:19:22.339195: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from audiomentations import Compose, TimeStretch, PitchShift, AddGaussianNoise\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define paths and parameters\n",
    "DATASET_PATH_TRAIN = \"/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/flac\"\n",
    "DATASET_PATH_DEV = \"/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_dev/flac\"\n",
    "DATASET_PATH_EVAL = \"/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_eval/flac\"\n",
    "LABEL_FILE_PATH_TRAIN = \"/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\"\n",
    "LABEL_FILE_PATH_DEV = \"/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\"\n",
    "LABEL_FILE_PATH_EVAL = \"/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\"\n",
    "NUM_CLASSES = 2  # Number of classes (bonafide and spoof)\n",
    "SAMPLE_RATE = 16000  # Sample rate of your audio files\n",
    "DURATION = 5  # Duration of audio clips in seconds\n",
    "N_MFCC = 13  # Number of MFCC coefficients\n",
    "HOP_LENGTH = 512  # Hop length for MFCC extraction\n",
    "WIN_LENGTH = 1024  # Window length for MFCC extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the training data\n",
    "labels = {}\n",
    "with open(LABEL_FILE_PATH_TRAIN, 'r') as label_file_train:\n",
    "    lines = label_file_train.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split()\n",
    "    file_name = parts[1]\n",
    "    label = 1 if parts[-1] == \"bonafide\" else 0 #positive class is spoof\n",
    "    labels[file_name] = label\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "max_time_steps = 109  # Define the maximum time steps for your model\n",
    "\n",
    "for file_name, label in labels.items():\n",
    "    file_path = os.path.join(DATASET_PATH_TRAIN, file_name + \".flac\")\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "\n",
    "    # Extract MFCC features using librosa\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=N_MFCC, hop_length=HOP_LENGTH, n_fft=WIN_LENGTH)\n",
    "\n",
    "    # Ensure all MFCC features have the same width (time steps)\n",
    "    if mfcc.shape[1] < max_time_steps:\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, max_time_steps - mfcc.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_time_steps]\n",
    "\n",
    "    X_train.append(mfcc)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the development data\n",
    "labels = {}\n",
    "with open(LABEL_FILE_PATH_DEV, 'r') as label_file_dev:\n",
    "    lines = label_file_dev.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split()\n",
    "    file_name = parts[1]\n",
    "    label = 1 if parts[-1] == \"bonafide\" else 0 #positive class is spoof\n",
    "    labels[file_name] = label\n",
    "\n",
    "X_dev = []\n",
    "y_dev = []\n",
    "\n",
    "max_time_steps = 109  # Define the maximum time steps for your model\n",
    "\n",
    "for file_name, label in labels.items():\n",
    "    file_path = os.path.join(DATASET_PATH_DEV, file_name + \".flac\")\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "\n",
    "    # Extract MFCC features using librosa\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=N_MFCC, hop_length=HOP_LENGTH, n_fft=WIN_LENGTH)\n",
    "\n",
    "    # Ensure all MFCC features have the same width (time steps)\n",
    "    if mfcc.shape[1] < max_time_steps:\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, max_time_steps - mfcc.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_time_steps]\n",
    "\n",
    "    X_dev.append(mfcc)\n",
    "    y_dev.append(label)\n",
    "\n",
    "X_dev = np.array(X_dev)\n",
    "y_dev = np.array(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the evaluation data\n",
    "labels = {}\n",
    "with open(LABEL_FILE_PATH_EVAL, 'r') as label_file_eval:\n",
    "    lines = label_file_eval.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split()\n",
    "    file_name = parts[1]\n",
    "    label = 1 if parts[-1] == \"bonafide\" else 0 #positive class is spoof\n",
    "    labels[file_name] = label\n",
    "\n",
    "X_eval = []\n",
    "y_eval = []\n",
    "\n",
    "max_time_steps = 109  # Define the maximum time steps for your model\n",
    "\n",
    "for file_name, label in labels.items():\n",
    "    file_path = os.path.join(DATASET_PATH_EVAL, file_name + \".flac\")\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "\n",
    "    # Extract MFCC features using librosa\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=N_MFCC, hop_length=HOP_LENGTH, n_fft=WIN_LENGTH)\n",
    "\n",
    "    # Ensure all MFCC features have the same width (time steps)\n",
    "    if mfcc.shape[1] < max_time_steps:\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, max_time_steps - mfcc.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_time_steps]\n",
    "\n",
    "    X_eval.append(mfcc)\n",
    "    y_eval.append(label)\n",
    "\n",
    "X_eval = np.array(X_eval)\n",
    "y_eval = np.array(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m y_train_save_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39my_train.npy\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39m# Save X_train and y_train as .npy files\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m np\u001b[39m.\u001b[39msave(X_train_save_path, X_train)\n\u001b[1;32m      9\u001b[0m np\u001b[39m.\u001b[39msave(y_train_save_path, y_train)\n\u001b[1;32m     12\u001b[0m \u001b[39m# Specify the file paths where you want to save the data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Saving dava before data agumentation/normalization\n",
    "\n",
    "# Specify the file paths where you want to save the data\n",
    "X_train_save_path = 'X_train.npy'\n",
    "y_train_save_path = 'y_train.npy'\n",
    "\n",
    "# Save X_train and y_train as .npy files\n",
    "np.save(X_train_save_path, X_train)\n",
    "np.save(y_train_save_path, y_train)\n",
    "\n",
    "\n",
    "# Specify the file paths where you want to save the data\n",
    "X_train_save_path = 'X_dev.npy'\n",
    "y_train_save_path = 'y_dev.npy'\n",
    "\n",
    "# Save X_train and y_train as .npy files\n",
    "np.save(X_train_save_path, X_dev)\n",
    "np.save(y_train_save_path, y_dev)\n",
    "\n",
    "\n",
    "# Specify the file paths where you want to save the data\n",
    "X_train_save_path = 'X_eval.npy'\n",
    "y_train_save_path = 'y_eval.npy'\n",
    "\n",
    "# Save X_train and y_train as .npy files\n",
    "np.save(X_train_save_path, X_eval)\n",
    "np.save(y_train_save_path, y_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to NumPy arrays\n",
    "X_train = np.load('X_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_dev = np.load('y_dev.npy')\n",
    "y_eval = np.load('y_eval.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Define agumentation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Data augmentation using audiomentations\u001b[39;00m\n\u001b[1;32m      3\u001b[0m augment \u001b[39m=\u001b[39m Compose([\n\u001b[1;32m      4\u001b[0m     TimeStretch(min_rate\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m, max_rate\u001b[39m=\u001b[39m\u001b[39m1.2\u001b[39m, p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m),\n\u001b[1;32m      5\u001b[0m     PitchShift(min_semitones\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, max_semitones\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m),\n\u001b[1;32m      6\u001b[0m     AddGaussianNoise(min_amplitude\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, max_amplitude\u001b[39m=\u001b[39m\u001b[39m0.015\u001b[39m, p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m),\n\u001b[1;32m      7\u001b[0m ])\n\u001b[0;32m----> 9\u001b[0m X_train_augmented \u001b[39m=\u001b[39m [augment(samples\u001b[39m=\u001b[39mx, sample_rate\u001b[39m=\u001b[39mSAMPLE_RATE) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X_train]\n\u001b[1;32m     10\u001b[0m X_dev_augmented \u001b[39m=\u001b[39m [augment(samples\u001b[39m=\u001b[39mx, sample_rate\u001b[39m=\u001b[39mSAMPLE_RATE) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X_dev]\n\u001b[1;32m     11\u001b[0m X_eval_augmented \u001b[39m=\u001b[39m [augment(samples\u001b[39m=\u001b[39mx, sample_rate\u001b[39m=\u001b[39mSAMPLE_RATE) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X_eval]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Define agumentation\n",
    "# Data augmentation using audiomentations\n",
    "augment = Compose([\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.2, p=0.5),\n",
    "    PitchShift(min_semitones=-2, max_semitones=2, p=0.5),\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "])\n",
    "\n",
    "X_train_augmented = [augment(samples=x, sample_rate=SAMPLE_RATE) for x in X_train]\n",
    "X_dev_augmented = [augment(samples=x, sample_rate=SAMPLE_RATE) for x in X_dev]\n",
    "X_eval_augmented = [augment(samples=x, sample_rate=SAMPLE_RATE) for x in X_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_augmented' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Convert lists to NumPy arrays\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train_augmented_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X_train_augmented)\n\u001b[1;32m      3\u001b[0m X_dev_augmented_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X_dev_augmented)\n\u001b[1;32m      4\u001b[0m X_eval_augmented_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X_eval_augmented)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_augmented' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train_augmented_array = np.array(X_train_augmented)\n",
    "X_dev_augmented_array = np.array(X_dev_augmented)\n",
    "X_eval_augmented_array = np.array(X_eval_augmented)\n",
    "\n",
    "# Save the NumPy arrays as .npy files\n",
    "np.save('X_train_augmented.npy', X_train_augmented_array)\n",
    "np.save('X_dev_augmented.npy', X_dev_augmented_array)\n",
    "np.save('X_eval_augmented.npy', X_eval_augmented_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Convert the class weights to a dictionary\n",
    "class_weight_dict = {i: class_weights[i] for i in range(NUM_CLASSES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "X_train_augmented = np.load('X_train_augmented.npy')\n",
    "X_dev_augmented = np.load('X_dev_augmented.npy')\n",
    "X_eval_augmented = np.load('X_eval_augmented.npy')\n",
    "\n",
    "# Reshape the 3D data to 2D\n",
    "X_train_2d = X_train_augmented.reshape(-1, X_train_augmented.shape[-1])\n",
    "X_dev_2d = X_dev_augmented.reshape(-1, X_dev_augmented.shape[-1])\n",
    "X_val_2d = X_eval_augmented.reshape(-1, X_eval_augmented.shape[-1])\n",
    "\n",
    "# Fit the scaler to your training data and transform it\n",
    "X_train_normalized = scaler.fit_transform(X_train_2d)\n",
    "\n",
    "# Transform the validation and test data using the same scaler\n",
    "X_val_normalized = scaler.transform(X_val_2d)\n",
    "X_dev_normalized = scaler.transform(X_dev_2d)\n",
    "\n",
    "# Reshape the normalized data back to 3D\n",
    "X_train_normalized = X_train_normalized.reshape(X_train_augmented.shape)\n",
    "X_val_normalized = X_val_normalized.reshape(X_eval_augmented.shape)\n",
    "X_dev_normalized = X_dev_normalized.reshape(X_dev_augmented.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data\n",
    "from sklearn.utils import shuffle\n",
    "# Shuffle the training data\n",
    "X_train_normalized, y_train = shuffle(X_train_normalized, y_train, random_state=42)\n",
    "\n",
    "# Shuffle the validation data (if needed)\n",
    "X_val_normalized, y_eval = shuffle(X_val_normalized, y_eval, random_state=42)\n",
    "\n",
    "# Shuffle the development data\n",
    "X_dev_normalized, y_dev = shuffle(X_dev_normalized, y_dev, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary stuff for learning rate scheduler\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "\n",
    "# Attach a callback to save learning rates to the list\n",
    "class LearningRateCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        optimizer = self.model.optimizer\n",
    "        lr = tf.keras.backend.get_value(optimizer.lr)\n",
    "        learning_rates.append(lr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the learning rate schedule function\n",
    "def exponential_decay(epoch, initial_learning_rate):\n",
    "    k = 0.1\n",
    "    lr = initial_learning_rate * math.exp(-k*epoch)\n",
    "    return lr\n",
    "\n",
    "# Create a learning rate scheduler callback\n",
    "lr_scheduler = LearningRateScheduler(\n",
    "    lambda epoch: exponential_decay(epoch, 0.05),\n",
    "    verbose=1  # This will print the learning rate at each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate scheduler - time based decay\n",
    "decay = 0.01/100\n",
    "\n",
    "# Define a learning rate schedule function\n",
    "def time_based_decay(epoch, lr, intial_learning_rate):\n",
    "    if (epoch == 0):\n",
    "        return intial_learning_rate\n",
    "    else:\n",
    "        #decay = intial_learning_rate/epochs\n",
    "        print(\"epoch\", epoch)\n",
    "        print(\"lr\", lr)\n",
    "        lr = lr * 1/(1+decay*epoch)\n",
    "        learning_rates.append(lr)\n",
    "        return lr\n",
    "\n",
    "# Create a learning rate scheduler callback\n",
    "lr_scheduler = LearningRateScheduler(\n",
    "    lambda epoch, lr: time_based_decay(epoch, lr, 0.01),\n",
    "    verbose=1  # This will print the learning rate at each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learing rate scheduler - linear decay\n",
    "# Define a custom learning rate scheduler\n",
    "def linear_decay(epoch, initial_lr, num_epochs):\n",
    "    # Calculate the decayed learning rate\n",
    "    decayed_lr = initial_lr * (1.0 - epoch / float(num_epochs))\n",
    "    learning_rates.append(decayed_lr)\n",
    "    return decayed_lr\n",
    "\n",
    "\n",
    "# Total number of epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Create a learning rate scheduler\n",
    "lr_scheduler = LearningRateScheduler(\n",
    "    lambda epoch: linear_decay(epoch, initial_learning_rate, num_epochs),\n",
    "    verbose=1  # This will print the learning rate at each epoch\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 11:23:05.126873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-27 11:23:05.126964: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-10-27 11:23:05.127009: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-10-27 11:23:05.127052: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-10-27 11:23:05.164599: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-10-27 11:23:05.164673: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-10-27 11:23:05.164681: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-10-27 11:23:05.165331: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 3.4294 - accuracy: 0.8052 - val_loss: 2.4583 - val_accuracy: 0.5511 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 1.2865 - accuracy: 0.8099 - val_loss: 1.0664 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.9785 - accuracy: 0.8255 - val_loss: 1.6829 - val_accuracy: 0.6314 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.6283 - accuracy: 0.8288 - val_loss: 0.6232 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.5584 - accuracy: 0.8338 - val_loss: 1.4699 - val_accuracy: 0.6408 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.4862 - accuracy: 0.8386 - val_loss: 1.9905 - val_accuracy: 0.6824 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.4732 - accuracy: 0.8368 - val_loss: 0.6668 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.4512 - accuracy: 0.8425 - val_loss: 0.2581 - val_accuracy: 0.9212 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.4233 - accuracy: 0.8479 - val_loss: 0.6241 - val_accuracy: 0.8974 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.4523 - accuracy: 0.8394 - val_loss: 0.6269 - val_accuracy: 0.8974 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.4079 - accuracy: 0.8545 - val_loss: 0.5589 - val_accuracy: 0.7891 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.3874 - accuracy: 0.8588 - val_loss: 0.3200 - val_accuracy: 0.8999 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.3781 - accuracy: 0.8589 - val_loss: 0.4656 - val_accuracy: 0.8192 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.3556 - accuracy: 0.8651 - val_loss: 0.2392 - val_accuracy: 0.9297 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "397/397 [==============================] - 13s 33ms/step - loss: 0.3430 - accuracy: 0.8694 - val_loss: 0.2902 - val_accuracy: 0.9084 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.3315 - accuracy: 0.8762 - val_loss: 0.2192 - val_accuracy: 0.9342 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.3095 - accuracy: 0.8811 - val_loss: 0.3236 - val_accuracy: 0.8786 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.3013 - accuracy: 0.8853 - val_loss: 0.2043 - val_accuracy: 0.9375 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2959 - accuracy: 0.8879 - val_loss: 0.2128 - val_accuracy: 0.9224 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2930 - accuracy: 0.8874 - val_loss: 0.3444 - val_accuracy: 0.8698 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2758 - accuracy: 0.8916 - val_loss: 0.2457 - val_accuracy: 0.9178 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2776 - accuracy: 0.8961 - val_loss: 0.2196 - val_accuracy: 0.9339 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2755 - accuracy: 0.8974 - val_loss: 0.3530 - val_accuracy: 0.8711 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2692 - accuracy: 0.8997 - val_loss: 0.2663 - val_accuracy: 0.9049 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2593 - accuracy: 0.9028 - val_loss: 0.2078 - val_accuracy: 0.9256 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2477 - accuracy: 0.9067 - val_loss: 0.1819 - val_accuracy: 0.9397 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2440 - accuracy: 0.9037 - val_loss: 0.2121 - val_accuracy: 0.9201 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2356 - accuracy: 0.9084 - val_loss: 0.3602 - val_accuracy: 0.8739 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2284 - accuracy: 0.9156 - val_loss: 0.1588 - val_accuracy: 0.9538 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2300 - accuracy: 0.9174 - val_loss: 0.2326 - val_accuracy: 0.9173 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2114 - accuracy: 0.9250 - val_loss: 0.2549 - val_accuracy: 0.9083 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2093 - accuracy: 0.9266 - val_loss: 0.1661 - val_accuracy: 0.9525 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1933 - accuracy: 0.9314 - val_loss: 0.1501 - val_accuracy: 0.9569 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1831 - accuracy: 0.9368 - val_loss: 0.1534 - val_accuracy: 0.9560 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1870 - accuracy: 0.9370 - val_loss: 0.2699 - val_accuracy: 0.9109 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1784 - accuracy: 0.9364 - val_loss: 0.1547 - val_accuracy: 0.9538 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1674 - accuracy: 0.9433 - val_loss: 0.1425 - val_accuracy: 0.9600 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1601 - accuracy: 0.9465 - val_loss: 0.1461 - val_accuracy: 0.9569 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.1515 - accuracy: 0.9513 - val_loss: 0.1842 - val_accuracy: 0.9424 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1390 - accuracy: 0.9561 - val_loss: 0.1471 - val_accuracy: 0.9597 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1368 - accuracy: 0.9588 - val_loss: 0.1422 - val_accuracy: 0.9613 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1429 - accuracy: 0.9568 - val_loss: 0.1595 - val_accuracy: 0.9533 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1270 - accuracy: 0.9615 - val_loss: 0.1456 - val_accuracy: 0.9577 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1282 - accuracy: 0.9595 - val_loss: 0.1449 - val_accuracy: 0.9572 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1213 - accuracy: 0.9632 - val_loss: 0.1271 - val_accuracy: 0.9659 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1155 - accuracy: 0.9661 - val_loss: 0.1314 - val_accuracy: 0.9662 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1077 - accuracy: 0.9682 - val_loss: 0.1745 - val_accuracy: 0.9474 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.1104 - accuracy: 0.9675 - val_loss: 0.1334 - val_accuracy: 0.9665 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1058 - accuracy: 0.9693 - val_loss: 0.1485 - val_accuracy: 0.9657 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1013 - accuracy: 0.9690 - val_loss: 0.1316 - val_accuracy: 0.9674 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.1038 - accuracy: 0.9692 - val_loss: 0.1367 - val_accuracy: 0.9621 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0987 - accuracy: 0.9702 - val_loss: 0.1354 - val_accuracy: 0.9612 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0973 - accuracy: 0.9716 - val_loss: 0.1688 - val_accuracy: 0.9525 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0974 - accuracy: 0.9712 - val_loss: 0.1287 - val_accuracy: 0.9678 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0952 - accuracy: 0.9725 - val_loss: 0.1297 - val_accuracy: 0.9654 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0966 - accuracy: 0.9712 - val_loss: 0.1250 - val_accuracy: 0.9691 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0900 - accuracy: 0.9750 - val_loss: 0.1237 - val_accuracy: 0.9679 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0886 - accuracy: 0.9740 - val_loss: 0.1310 - val_accuracy: 0.9644 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0861 - accuracy: 0.9757 - val_loss: 0.1703 - val_accuracy: 0.9532 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0886 - accuracy: 0.9749 - val_loss: 0.1456 - val_accuracy: 0.9588 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0853 - accuracy: 0.9758 - val_loss: 0.1561 - val_accuracy: 0.9566 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0862 - accuracy: 0.9742 - val_loss: 0.1331 - val_accuracy: 0.9633 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0850 - accuracy: 0.9764 - val_loss: 0.1232 - val_accuracy: 0.9672 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0835 - accuracy: 0.9753 - val_loss: 0.1276 - val_accuracy: 0.9668 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0826 - accuracy: 0.9762 - val_loss: 0.1341 - val_accuracy: 0.9632 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "397/397 [==============================] - 13s 31ms/step - loss: 0.0829 - accuracy: 0.9750 - val_loss: 0.1266 - val_accuracy: 0.9682 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0843 - accuracy: 0.9754 - val_loss: 0.1246 - val_accuracy: 0.9693 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0807 - accuracy: 0.9767 - val_loss: 0.1246 - val_accuracy: 0.9676 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0787 - accuracy: 0.9775 - val_loss: 0.1301 - val_accuracy: 0.9657 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0802 - accuracy: 0.9779 - val_loss: 0.1232 - val_accuracy: 0.9684 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0784 - accuracy: 0.9783 - val_loss: 0.1321 - val_accuracy: 0.9644 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0760 - accuracy: 0.9787 - val_loss: 0.1250 - val_accuracy: 0.9684 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0805 - accuracy: 0.9765 - val_loss: 0.1295 - val_accuracy: 0.9663 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0765 - accuracy: 0.9789 - val_loss: 0.1280 - val_accuracy: 0.9661 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0782 - accuracy: 0.9783 - val_loss: 0.1262 - val_accuracy: 0.9680 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0765 - accuracy: 0.9773 - val_loss: 0.1293 - val_accuracy: 0.9656 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0763 - accuracy: 0.9783 - val_loss: 0.1256 - val_accuracy: 0.9679 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0776 - accuracy: 0.9775 - val_loss: 0.1288 - val_accuracy: 0.9656 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0807 - accuracy: 0.9763 - val_loss: 0.1269 - val_accuracy: 0.9669 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0758 - accuracy: 0.9790 - val_loss: 0.1292 - val_accuracy: 0.9658 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0794 - accuracy: 0.9784 - val_loss: 0.1270 - val_accuracy: 0.9672 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0782 - accuracy: 0.9781 - val_loss: 0.1256 - val_accuracy: 0.9677 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0758 - accuracy: 0.9782 - val_loss: 0.1258 - val_accuracy: 0.9679 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0769 - accuracy: 0.9771 - val_loss: 0.1282 - val_accuracy: 0.9664 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0729 - accuracy: 0.9793 - val_loss: 0.1267 - val_accuracy: 0.9669 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0787 - accuracy: 0.9769 - val_loss: 0.1257 - val_accuracy: 0.9678 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0747 - accuracy: 0.9780 - val_loss: 0.1266 - val_accuracy: 0.9672 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0815 - accuracy: 0.9771 - val_loss: 0.1256 - val_accuracy: 0.9676 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0776 - accuracy: 0.9767 - val_loss: 0.1260 - val_accuracy: 0.9674 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0770 - accuracy: 0.9777 - val_loss: 0.1279 - val_accuracy: 0.9670 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "397/397 [==============================] - 13s 31ms/step - loss: 0.0776 - accuracy: 0.9778 - val_loss: 0.1261 - val_accuracy: 0.9676 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0775 - accuracy: 0.9779 - val_loss: 0.1267 - val_accuracy: 0.9675 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0732 - accuracy: 0.9786 - val_loss: 0.1263 - val_accuracy: 0.9675 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0753 - accuracy: 0.9788 - val_loss: 0.1256 - val_accuracy: 0.9675 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0775 - accuracy: 0.9788 - val_loss: 0.1259 - val_accuracy: 0.9677 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0743 - accuracy: 0.9797 - val_loss: 0.1254 - val_accuracy: 0.9677 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0766 - accuracy: 0.9780 - val_loss: 0.1256 - val_accuracy: 0.9678 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0756 - accuracy: 0.9788 - val_loss: 0.1256 - val_accuracy: 0.9677 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.0765 - accuracy: 0.9777 - val_loss: 0.1259 - val_accuracy: 0.9676 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.0764 - accuracy: 0.9784 - val_loss: 0.1258 - val_accuracy: 0.9677 - lr: 2.5087e-06\n",
      "2227/2227 [==============================] - 17s 7ms/step - loss: 0.6365 - accuracy: 0.8643\n",
      "Test Loss: 0.6365137100219727\n",
      "Test Accuracy: 0.8643121123313904\n",
      "2227/2227 [==============================] - 16s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "#final pick\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# reduce_lr = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 5, min_lr = 0.00001)\n",
    "\n",
    "#{'batch_size': 64, 'kernel_size': (4, 4), 'num_filters': 64, 'reg_strength': 0.001}\n",
    "\n",
    "#Intial learning rate\n",
    "initial_learning_rate = 0.05\n",
    "max_time_steps = 109\n",
    "\n",
    "# Define and compile a CNN model with L2 regularization and other improvements\n",
    "model = tf.keras.Sequential([\n",
    "    Conv2D(64, kernel_size=(4, 4), activation='relu', input_shape=(N_MFCC, max_time_steps, 1),\n",
    "           kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(4, 4), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "learning_rates = []\n",
    "\n",
    "# Train the model using class weights\n",
    "history = model.fit(np.expand_dims(X_train_normalized, -1), y_train, batch_size=64, epochs=100,\n",
    "                validation_data=(np.expand_dims(X_dev_normalized, -1), y_dev), class_weight=class_weight_dict, callbacks = [lr_scheduler])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(np.expand_dims(X_val_normalized, -1), y_eval)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "\n",
    "# Make predictions on the evaluation set\n",
    "y_test_pred = model.predict(X_val_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21073/4199446376.py:34: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=100, verbose=1)\n",
      "2023-10-24 10:18:05.804883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-24 10:18:05.804954: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-10-24 10:18:05.804997: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-10-24 10:18:05.805036: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-10-24 10:18:05.837654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-10-24 10:18:05.837717: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-10-24 10:18:05.837726: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-10-24 10:18:05.838142: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 16s 29ms/step - loss: 7.4055 - accuracy: 0.7108 - val_loss: 6.3535 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 5.4263 - accuracy: 0.7212 - val_loss: 3.4522 - val_accuracy: 0.1026 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 6.0845 - accuracy: 0.7128 - val_loss: 2.8443 - val_accuracy: 0.8611 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 3.1544 - accuracy: 0.7504 - val_loss: 2.8989 - val_accuracy: 0.5817 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 2.4942 - accuracy: 0.7605 - val_loss: 13.9740 - val_accuracy: 0.1026 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.3465 - accuracy: 0.7843 - val_loss: 0.6205 - val_accuracy: 0.8983 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.1090 - accuracy: 0.7971 - val_loss: 2.4605 - val_accuracy: 0.3802 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 1.0185 - accuracy: 0.8021 - val_loss: 3.4953 - val_accuracy: 0.1937 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.8309 - accuracy: 0.8077 - val_loss: 0.8058 - val_accuracy: 0.8161 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.7507 - accuracy: 0.8127 - val_loss: 0.5128 - val_accuracy: 0.8976 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.0578 - accuracy: 0.8044 - val_loss: 1.7537 - val_accuracy: 0.8974 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.0791 - accuracy: 0.7959 - val_loss: 0.6616 - val_accuracy: 0.8992 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.7608 - accuracy: 0.8087 - val_loss: 0.5740 - val_accuracy: 0.8901 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.8222 - accuracy: 0.8035 - val_loss: 1.3197 - val_accuracy: 0.6559 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.6195 - accuracy: 0.8051 - val_loss: 0.3404 - val_accuracy: 0.9066 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.6332 - accuracy: 0.8201 - val_loss: 1.6013 - val_accuracy: 0.4848 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5668 - accuracy: 0.8156 - val_loss: 0.4305 - val_accuracy: 0.8585 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5560 - accuracy: 0.8238 - val_loss: 0.8386 - val_accuracy: 0.7622 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5378 - accuracy: 0.8270 - val_loss: 0.7562 - val_accuracy: 0.7463 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5046 - accuracy: 0.8198 - val_loss: 0.2972 - val_accuracy: 0.9041 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4744 - accuracy: 0.8333 - val_loss: 0.3030 - val_accuracy: 0.8953 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4723 - accuracy: 0.8350 - val_loss: 0.3323 - val_accuracy: 0.8961 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4603 - accuracy: 0.8375 - val_loss: 0.3766 - val_accuracy: 0.8687 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4462 - accuracy: 0.8395 - val_loss: 0.6572 - val_accuracy: 0.7890 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4285 - accuracy: 0.8395 - val_loss: 0.2912 - val_accuracy: 0.9222 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4399 - accuracy: 0.8505 - val_loss: 0.3708 - val_accuracy: 0.9016 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4049 - accuracy: 0.8546 - val_loss: 0.2321 - val_accuracy: 0.9363 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3796 - accuracy: 0.8601 - val_loss: 0.2738 - val_accuracy: 0.9065 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3759 - accuracy: 0.8635 - val_loss: 0.2449 - val_accuracy: 0.9259 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3600 - accuracy: 0.8664 - val_loss: 0.4762 - val_accuracy: 0.8190 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3474 - accuracy: 0.8730 - val_loss: 0.3611 - val_accuracy: 0.8689 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3315 - accuracy: 0.8772 - val_loss: 0.2012 - val_accuracy: 0.9394 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3209 - accuracy: 0.8855 - val_loss: 0.6440 - val_accuracy: 0.7834 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3293 - accuracy: 0.8808 - val_loss: 0.2636 - val_accuracy: 0.9168 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3289 - accuracy: 0.8836 - val_loss: 0.3067 - val_accuracy: 0.8904 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3097 - accuracy: 0.8908 - val_loss: 0.6709 - val_accuracy: 0.7962 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3025 - accuracy: 0.8841 - val_loss: 0.6239 - val_accuracy: 0.7902 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2883 - accuracy: 0.8924 - val_loss: 0.1885 - val_accuracy: 0.9405 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2680 - accuracy: 0.9010 - val_loss: 0.1951 - val_accuracy: 0.9359 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2807 - accuracy: 0.8969 - val_loss: 0.2505 - val_accuracy: 0.9133 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2695 - accuracy: 0.8992 - val_loss: 0.1985 - val_accuracy: 0.9335 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2653 - accuracy: 0.9018 - val_loss: 0.2147 - val_accuracy: 0.9256 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2591 - accuracy: 0.9056 - val_loss: 0.5244 - val_accuracy: 0.8183 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2560 - accuracy: 0.9022 - val_loss: 0.1843 - val_accuracy: 0.9366 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2568 - accuracy: 0.9054 - val_loss: 0.3203 - val_accuracy: 0.8820 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2444 - accuracy: 0.9104 - val_loss: 0.2775 - val_accuracy: 0.8999 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2453 - accuracy: 0.9089 - val_loss: 0.2732 - val_accuracy: 0.8967 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2400 - accuracy: 0.9091 - val_loss: 0.2906 - val_accuracy: 0.8955 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2377 - accuracy: 0.9101 - val_loss: 0.4180 - val_accuracy: 0.8466 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2332 - accuracy: 0.9139 - val_loss: 0.2573 - val_accuracy: 0.9052 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2355 - accuracy: 0.9135 - val_loss: 0.2059 - val_accuracy: 0.9262 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2294 - accuracy: 0.9189 - val_loss: 0.2364 - val_accuracy: 0.9146 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2265 - accuracy: 0.9155 - val_loss: 0.2294 - val_accuracy: 0.9164 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2249 - accuracy: 0.9178 - val_loss: 0.3236 - val_accuracy: 0.8831 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2174 - accuracy: 0.9203 - val_loss: 0.2413 - val_accuracy: 0.9152 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2120 - accuracy: 0.9257 - val_loss: 0.2691 - val_accuracy: 0.9051 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2193 - accuracy: 0.9230 - val_loss: 0.2814 - val_accuracy: 0.9042 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2142 - accuracy: 0.9219 - val_loss: 0.2247 - val_accuracy: 0.9197 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2140 - accuracy: 0.9209 - val_loss: 0.2048 - val_accuracy: 0.9273 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2082 - accuracy: 0.9240 - val_loss: 0.2869 - val_accuracy: 0.8984 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2143 - accuracy: 0.9233 - val_loss: 0.1713 - val_accuracy: 0.9390 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2004 - accuracy: 0.9233 - val_loss: 0.2864 - val_accuracy: 0.8989 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2146 - accuracy: 0.9237 - val_loss: 0.1878 - val_accuracy: 0.9331 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2129 - accuracy: 0.9228 - val_loss: 0.3155 - val_accuracy: 0.8887 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1995 - accuracy: 0.9255 - val_loss: 0.2467 - val_accuracy: 0.9134 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2043 - accuracy: 0.9260 - val_loss: 0.2112 - val_accuracy: 0.9252 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2005 - accuracy: 0.9281 - val_loss: 0.2121 - val_accuracy: 0.9261 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1982 - accuracy: 0.9259 - val_loss: 0.2422 - val_accuracy: 0.9163 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2126 - accuracy: 0.9283 - val_loss: 0.2029 - val_accuracy: 0.9289 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1965 - accuracy: 0.9307 - val_loss: 0.1911 - val_accuracy: 0.9329 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2013 - accuracy: 0.9279 - val_loss: 0.2477 - val_accuracy: 0.9150 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1969 - accuracy: 0.9300 - val_loss: 0.2353 - val_accuracy: 0.9185 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1968 - accuracy: 0.9301 - val_loss: 0.2025 - val_accuracy: 0.9293 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2053 - accuracy: 0.9284 - val_loss: 0.2752 - val_accuracy: 0.9061 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2009 - accuracy: 0.9276 - val_loss: 0.2164 - val_accuracy: 0.9242 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1995 - accuracy: 0.9304 - val_loss: 0.2182 - val_accuracy: 0.9240 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1964 - accuracy: 0.9268 - val_loss: 0.2316 - val_accuracy: 0.9202 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1986 - accuracy: 0.9311 - val_loss: 0.2246 - val_accuracy: 0.9227 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2038 - accuracy: 0.9299 - val_loss: 0.2211 - val_accuracy: 0.9231 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1981 - accuracy: 0.9277 - val_loss: 0.2122 - val_accuracy: 0.9259 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2009 - accuracy: 0.9277 - val_loss: 0.2215 - val_accuracy: 0.9238 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1968 - accuracy: 0.9287 - val_loss: 0.2113 - val_accuracy: 0.9263 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2047 - accuracy: 0.9295 - val_loss: 0.2166 - val_accuracy: 0.9251 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1907 - accuracy: 0.9313 - val_loss: 0.2203 - val_accuracy: 0.9241 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1983 - accuracy: 0.9304 - val_loss: 0.2217 - val_accuracy: 0.9232 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2008 - accuracy: 0.9287 - val_loss: 0.2164 - val_accuracy: 0.9252 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2004 - accuracy: 0.9281 - val_loss: 0.2191 - val_accuracy: 0.9243 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1898 - accuracy: 0.9324 - val_loss: 0.2124 - val_accuracy: 0.9263 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1914 - accuracy: 0.9330 - val_loss: 0.2163 - val_accuracy: 0.9244 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1888 - accuracy: 0.9326 - val_loss: 0.2154 - val_accuracy: 0.9253 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1923 - accuracy: 0.9305 - val_loss: 0.2185 - val_accuracy: 0.9248 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1972 - accuracy: 0.9326 - val_loss: 0.2205 - val_accuracy: 0.9247 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1906 - accuracy: 0.9327 - val_loss: 0.2187 - val_accuracy: 0.9247 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1907 - accuracy: 0.9312 - val_loss: 0.2176 - val_accuracy: 0.9250 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1903 - accuracy: 0.9300 - val_loss: 0.2245 - val_accuracy: 0.9237 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1947 - accuracy: 0.9332 - val_loss: 0.2142 - val_accuracy: 0.9261 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2014 - accuracy: 0.9300 - val_loss: 0.2237 - val_accuracy: 0.9245 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1974 - accuracy: 0.9317 - val_loss: 0.2214 - val_accuracy: 0.9245 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1896 - accuracy: 0.9332 - val_loss: 0.2161 - val_accuracy: 0.9260 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1982 - accuracy: 0.9320 - val_loss: 0.2148 - val_accuracy: 0.9263 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 18s 32ms/step - loss: 6.2243 - accuracy: 0.7240 - val_loss: 4.3599 - val_accuracy: 0.5974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 4.4595 - accuracy: 0.7420 - val_loss: 2.0880 - val_accuracy: 0.8380 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 2.4108 - accuracy: 0.7794 - val_loss: 6.0771 - val_accuracy: 0.1170 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.2169 - accuracy: 0.7956 - val_loss: 1.1693 - val_accuracy: 0.8398 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.9817 - accuracy: 0.7864 - val_loss: 0.6777 - val_accuracy: 0.8688 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.0543 - accuracy: 0.7975 - val_loss: 1.0996 - val_accuracy: 0.8925 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.8152 - accuracy: 0.8053 - val_loss: 0.6708 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.9938 - accuracy: 0.7962 - val_loss: 0.5113 - val_accuracy: 0.8974 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.7662 - accuracy: 0.8000 - val_loss: 0.4506 - val_accuracy: 0.9135 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.7181 - accuracy: 0.8072 - val_loss: 0.5519 - val_accuracy: 0.9160 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.6646 - accuracy: 0.8002 - val_loss: 0.5913 - val_accuracy: 0.8974 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.6711 - accuracy: 0.8046 - val_loss: 0.5213 - val_accuracy: 0.8449 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5830 - accuracy: 0.8064 - val_loss: 0.4557 - val_accuracy: 0.8880 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.6080 - accuracy: 0.8163 - val_loss: 0.7269 - val_accuracy: 0.7766 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5262 - accuracy: 0.8178 - val_loss: 1.9596 - val_accuracy: 0.5007 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5033 - accuracy: 0.8183 - val_loss: 0.3478 - val_accuracy: 0.8777 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.5251 - accuracy: 0.8220 - val_loss: 1.9968 - val_accuracy: 0.5628 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5121 - accuracy: 0.8210 - val_loss: 0.6489 - val_accuracy: 0.7911 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4839 - accuracy: 0.8264 - val_loss: 0.3112 - val_accuracy: 0.9210 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5010 - accuracy: 0.8271 - val_loss: 0.3350 - val_accuracy: 0.8980 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4893 - accuracy: 0.8339 - val_loss: 0.3959 - val_accuracy: 0.9164 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5045 - accuracy: 0.8387 - val_loss: 0.3029 - val_accuracy: 0.9325 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4667 - accuracy: 0.8430 - val_loss: 0.3110 - val_accuracy: 0.9300 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4463 - accuracy: 0.8441 - val_loss: 0.2800 - val_accuracy: 0.9287 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4526 - accuracy: 0.8433 - val_loss: 0.4350 - val_accuracy: 0.8640 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4286 - accuracy: 0.8504 - val_loss: 0.4777 - val_accuracy: 0.8386 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4107 - accuracy: 0.8540 - val_loss: 0.3994 - val_accuracy: 0.8634 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3810 - accuracy: 0.8598 - val_loss: 0.3231 - val_accuracy: 0.8964 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3688 - accuracy: 0.8646 - val_loss: 0.2267 - val_accuracy: 0.9389 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3762 - accuracy: 0.8666 - val_loss: 0.3124 - val_accuracy: 0.8939 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3425 - accuracy: 0.8716 - val_loss: 0.2437 - val_accuracy: 0.9221 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3318 - accuracy: 0.8767 - val_loss: 0.2017 - val_accuracy: 0.9442 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3216 - accuracy: 0.8826 - val_loss: 0.2241 - val_accuracy: 0.9327 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3212 - accuracy: 0.8820 - val_loss: 0.2131 - val_accuracy: 0.9382 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3047 - accuracy: 0.8885 - val_loss: 0.3257 - val_accuracy: 0.8930 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3080 - accuracy: 0.8846 - val_loss: 0.2594 - val_accuracy: 0.9048 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2940 - accuracy: 0.8917 - val_loss: 0.2601 - val_accuracy: 0.9062 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2830 - accuracy: 0.8980 - val_loss: 0.3059 - val_accuracy: 0.8892 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2886 - accuracy: 0.8942 - val_loss: 0.3672 - val_accuracy: 0.8582 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2683 - accuracy: 0.8991 - val_loss: 0.3063 - val_accuracy: 0.8834 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2671 - accuracy: 0.8988 - val_loss: 0.2352 - val_accuracy: 0.9112 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2597 - accuracy: 0.9011 - val_loss: 0.2820 - val_accuracy: 0.8903 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2548 - accuracy: 0.9063 - val_loss: 0.2054 - val_accuracy: 0.9300 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2607 - accuracy: 0.9060 - val_loss: 0.2073 - val_accuracy: 0.9309 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2554 - accuracy: 0.9049 - val_loss: 0.2379 - val_accuracy: 0.9107 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2406 - accuracy: 0.9073 - val_loss: 0.1749 - val_accuracy: 0.9433 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2481 - accuracy: 0.9108 - val_loss: 0.2168 - val_accuracy: 0.9199 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2318 - accuracy: 0.9144 - val_loss: 0.1659 - val_accuracy: 0.9470 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2313 - accuracy: 0.9114 - val_loss: 0.2726 - val_accuracy: 0.8955 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.2253 - accuracy: 0.9158 - val_loss: 0.2112 - val_accuracy: 0.9219 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2280 - accuracy: 0.9163 - val_loss: 0.1588 - val_accuracy: 0.9490 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2265 - accuracy: 0.9168 - val_loss: 0.1651 - val_accuracy: 0.9443 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2143 - accuracy: 0.9183 - val_loss: 0.1971 - val_accuracy: 0.9288 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2183 - accuracy: 0.9202 - val_loss: 0.1963 - val_accuracy: 0.9285 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2193 - accuracy: 0.9194 - val_loss: 0.2156 - val_accuracy: 0.9185 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1995 - accuracy: 0.9267 - val_loss: 0.1924 - val_accuracy: 0.9293 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2085 - accuracy: 0.9232 - val_loss: 0.1639 - val_accuracy: 0.9448 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2045 - accuracy: 0.9219 - val_loss: 0.1675 - val_accuracy: 0.9408 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2010 - accuracy: 0.9244 - val_loss: 0.1674 - val_accuracy: 0.9415 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2006 - accuracy: 0.9240 - val_loss: 0.1634 - val_accuracy: 0.9421 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1994 - accuracy: 0.9262 - val_loss: 0.1814 - val_accuracy: 0.9337 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1989 - accuracy: 0.9270 - val_loss: 0.1613 - val_accuracy: 0.9445 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1957 - accuracy: 0.9279 - val_loss: 0.2010 - val_accuracy: 0.9245 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1930 - accuracy: 0.9245 - val_loss: 0.1780 - val_accuracy: 0.9356 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1952 - accuracy: 0.9279 - val_loss: 0.1650 - val_accuracy: 0.9421 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1910 - accuracy: 0.9288 - val_loss: 0.1539 - val_accuracy: 0.9483 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1835 - accuracy: 0.9326 - val_loss: 0.1761 - val_accuracy: 0.9362 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1866 - accuracy: 0.9313 - val_loss: 0.1787 - val_accuracy: 0.9352 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1892 - accuracy: 0.9314 - val_loss: 0.1677 - val_accuracy: 0.9399 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1838 - accuracy: 0.9304 - val_loss: 0.1774 - val_accuracy: 0.9360 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1880 - accuracy: 0.9318 - val_loss: 0.1666 - val_accuracy: 0.9406 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1820 - accuracy: 0.9316 - val_loss: 0.1661 - val_accuracy: 0.9416 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1878 - accuracy: 0.9325 - val_loss: 0.1691 - val_accuracy: 0.9389 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1872 - accuracy: 0.9316 - val_loss: 0.1699 - val_accuracy: 0.9390 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1820 - accuracy: 0.9301 - val_loss: 0.1654 - val_accuracy: 0.9416 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1832 - accuracy: 0.9337 - val_loss: 0.1662 - val_accuracy: 0.9399 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1805 - accuracy: 0.9317 - val_loss: 0.1680 - val_accuracy: 0.9400 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1816 - accuracy: 0.9337 - val_loss: 0.1642 - val_accuracy: 0.9422 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1826 - accuracy: 0.9339 - val_loss: 0.1656 - val_accuracy: 0.9405 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1854 - accuracy: 0.9305 - val_loss: 0.1656 - val_accuracy: 0.9410 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1809 - accuracy: 0.9324 - val_loss: 0.1672 - val_accuracy: 0.9401 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1841 - accuracy: 0.9324 - val_loss: 0.1646 - val_accuracy: 0.9417 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1870 - accuracy: 0.9326 - val_loss: 0.1651 - val_accuracy: 0.9415 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1800 - accuracy: 0.9319 - val_loss: 0.1653 - val_accuracy: 0.9416 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1804 - accuracy: 0.9322 - val_loss: 0.1664 - val_accuracy: 0.9402 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1726 - accuracy: 0.9344 - val_loss: 0.1654 - val_accuracy: 0.9406 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1833 - accuracy: 0.9323 - val_loss: 0.1653 - val_accuracy: 0.9409 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1813 - accuracy: 0.9332 - val_loss: 0.1651 - val_accuracy: 0.9410 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1836 - accuracy: 0.9335 - val_loss: 0.1664 - val_accuracy: 0.9403 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1834 - accuracy: 0.9332 - val_loss: 0.1608 - val_accuracy: 0.9435 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1840 - accuracy: 0.9319 - val_loss: 0.1642 - val_accuracy: 0.9417 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1851 - accuracy: 0.9313 - val_loss: 0.1632 - val_accuracy: 0.9420 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1813 - accuracy: 0.9335 - val_loss: 0.1651 - val_accuracy: 0.9410 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1762 - accuracy: 0.9320 - val_loss: 0.1647 - val_accuracy: 0.9414 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1808 - accuracy: 0.9351 - val_loss: 0.1636 - val_accuracy: 0.9416 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1778 - accuracy: 0.9310 - val_loss: 0.1650 - val_accuracy: 0.9410 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1805 - accuracy: 0.9328 - val_loss: 0.1636 - val_accuracy: 0.9418 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1823 - accuracy: 0.9311 - val_loss: 0.1657 - val_accuracy: 0.9405 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1752 - accuracy: 0.9341 - val_loss: 0.1607 - val_accuracy: 0.9435 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1775 - accuracy: 0.9354 - val_loss: 0.1617 - val_accuracy: 0.9430 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 18s 32ms/step - loss: 6.8529 - accuracy: 0.7239 - val_loss: 5.7564 - val_accuracy: 0.5460 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 6.3232 - accuracy: 0.7146 - val_loss: 3.4760 - val_accuracy: 0.8989 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 5.3529 - accuracy: 0.7396 - val_loss: 12.5731 - val_accuracy: 0.1026 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 3.3524 - accuracy: 0.7736 - val_loss: 3.2737 - val_accuracy: 0.1989 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 2.7697 - accuracy: 0.7803 - val_loss: 3.1974 - val_accuracy: 0.8976 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 2.0302 - accuracy: 0.7926 - val_loss: 0.8622 - val_accuracy: 0.9003 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 2.2027 - accuracy: 0.7947 - val_loss: 5.2930 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 1.5328 - accuracy: 0.8037 - val_loss: 1.1745 - val_accuracy: 0.8974 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.7481 - accuracy: 0.8046 - val_loss: 1.4506 - val_accuracy: 0.5621 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.4837 - accuracy: 0.8093 - val_loss: 3.9722 - val_accuracy: 0.2499 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 1.3736 - accuracy: 0.8128 - val_loss: 4.9600 - val_accuracy: 0.1064 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.4091 - accuracy: 0.8105 - val_loss: 1.4678 - val_accuracy: 0.7110 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.9449 - accuracy: 0.8133 - val_loss: 0.4616 - val_accuracy: 0.9073 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.8213 - accuracy: 0.8167 - val_loss: 0.5215 - val_accuracy: 0.9019 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.9054 - accuracy: 0.8222 - val_loss: 8.1952 - val_accuracy: 0.1026 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.8121 - accuracy: 0.8219 - val_loss: 0.6401 - val_accuracy: 0.9114 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.8086 - accuracy: 0.8248 - val_loss: 3.5145 - val_accuracy: 0.1166 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.6242 - accuracy: 0.8281 - val_loss: 0.4784 - val_accuracy: 0.8997 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.6127 - accuracy: 0.8297 - val_loss: 0.7858 - val_accuracy: 0.8084 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.6421 - accuracy: 0.8298 - val_loss: 0.5579 - val_accuracy: 0.8636 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.5988 - accuracy: 0.8335 - val_loss: 0.4121 - val_accuracy: 0.9030 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.6077 - accuracy: 0.8322 - val_loss: 0.9664 - val_accuracy: 0.6870 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5817 - accuracy: 0.8333 - val_loss: 0.4197 - val_accuracy: 0.8796 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5781 - accuracy: 0.8327 - val_loss: 0.4920 - val_accuracy: 0.8435 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.5174 - accuracy: 0.8361 - val_loss: 0.8210 - val_accuracy: 0.7393 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4724 - accuracy: 0.8400 - val_loss: 0.3160 - val_accuracy: 0.9057 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4320 - accuracy: 0.8403 - val_loss: 0.2682 - val_accuracy: 0.9051 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4293 - accuracy: 0.8467 - val_loss: 0.3679 - val_accuracy: 0.8687 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4333 - accuracy: 0.8486 - val_loss: 0.2714 - val_accuracy: 0.9200 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4163 - accuracy: 0.8533 - val_loss: 0.3967 - val_accuracy: 0.8568 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4074 - accuracy: 0.8549 - val_loss: 0.7955 - val_accuracy: 0.8974 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.4072 - accuracy: 0.8535 - val_loss: 0.2713 - val_accuracy: 0.9193 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3968 - accuracy: 0.8542 - val_loss: 1.9725 - val_accuracy: 0.2987 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3844 - accuracy: 0.8635 - val_loss: 1.3034 - val_accuracy: 0.5834 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3754 - accuracy: 0.8630 - val_loss: 0.2769 - val_accuracy: 0.9041 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3522 - accuracy: 0.8660 - val_loss: 0.4018 - val_accuracy: 0.8440 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3302 - accuracy: 0.8752 - val_loss: 0.3241 - val_accuracy: 0.8796 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3313 - accuracy: 0.8730 - val_loss: 0.1967 - val_accuracy: 0.9360 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3120 - accuracy: 0.8830 - val_loss: 0.9804 - val_accuracy: 0.6243 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3022 - accuracy: 0.8866 - val_loss: 0.6014 - val_accuracy: 0.8131 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2987 - accuracy: 0.8801 - val_loss: 0.3577 - val_accuracy: 0.8635 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2808 - accuracy: 0.8940 - val_loss: 0.2754 - val_accuracy: 0.8945 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2776 - accuracy: 0.8950 - val_loss: 0.1800 - val_accuracy: 0.9414 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2734 - accuracy: 0.8944 - val_loss: 0.3631 - val_accuracy: 0.8590 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2554 - accuracy: 0.8995 - val_loss: 0.2842 - val_accuracy: 0.8909 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2589 - accuracy: 0.9005 - val_loss: 0.2706 - val_accuracy: 0.9157 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2540 - accuracy: 0.9015 - val_loss: 0.3305 - val_accuracy: 0.8706 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2575 - accuracy: 0.9029 - val_loss: 0.2831 - val_accuracy: 0.8879 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2494 - accuracy: 0.9030 - val_loss: 0.2397 - val_accuracy: 0.9075 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2423 - accuracy: 0.9052 - val_loss: 0.2139 - val_accuracy: 0.9214 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2407 - accuracy: 0.9054 - val_loss: 0.1993 - val_accuracy: 0.9274 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2393 - accuracy: 0.9106 - val_loss: 0.7194 - val_accuracy: 0.7556 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2351 - accuracy: 0.9110 - val_loss: 0.2085 - val_accuracy: 0.9204 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2325 - accuracy: 0.9117 - val_loss: 0.6469 - val_accuracy: 0.7614 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2287 - accuracy: 0.9116 - val_loss: 0.2494 - val_accuracy: 0.9029 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2228 - accuracy: 0.9133 - val_loss: 0.3124 - val_accuracy: 0.8784 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2223 - accuracy: 0.9144 - val_loss: 0.2005 - val_accuracy: 0.9227 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2118 - accuracy: 0.9153 - val_loss: 0.2035 - val_accuracy: 0.9240 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2086 - accuracy: 0.9155 - val_loss: 0.2376 - val_accuracy: 0.9063 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2095 - accuracy: 0.9154 - val_loss: 0.2222 - val_accuracy: 0.9158 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2085 - accuracy: 0.9160 - val_loss: 0.4867 - val_accuracy: 0.8301 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2055 - accuracy: 0.9176 - val_loss: 0.2358 - val_accuracy: 0.9079 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2072 - accuracy: 0.9151 - val_loss: 0.2557 - val_accuracy: 0.8992 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2111 - accuracy: 0.9174 - val_loss: 0.2099 - val_accuracy: 0.9197 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2043 - accuracy: 0.9236 - val_loss: 0.2862 - val_accuracy: 0.8871 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2007 - accuracy: 0.9197 - val_loss: 0.2213 - val_accuracy: 0.9139 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2044 - accuracy: 0.9194 - val_loss: 0.1862 - val_accuracy: 0.9300 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1991 - accuracy: 0.9186 - val_loss: 0.2330 - val_accuracy: 0.9091 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1959 - accuracy: 0.9234 - val_loss: 0.2089 - val_accuracy: 0.9198 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2015 - accuracy: 0.9210 - val_loss: 0.1981 - val_accuracy: 0.9248 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2013 - accuracy: 0.9187 - val_loss: 0.2583 - val_accuracy: 0.8976 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1881 - accuracy: 0.9196 - val_loss: 0.2104 - val_accuracy: 0.9191 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1966 - accuracy: 0.9215 - val_loss: 0.2169 - val_accuracy: 0.9167 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1917 - accuracy: 0.9219 - val_loss: 0.1830 - val_accuracy: 0.9314 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1972 - accuracy: 0.9217 - val_loss: 0.2046 - val_accuracy: 0.9222 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1972 - accuracy: 0.9209 - val_loss: 0.2082 - val_accuracy: 0.9204 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2001 - accuracy: 0.9217 - val_loss: 0.2271 - val_accuracy: 0.9118 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1899 - accuracy: 0.9212 - val_loss: 0.2261 - val_accuracy: 0.9128 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1925 - accuracy: 0.9223 - val_loss: 0.2175 - val_accuracy: 0.9162 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1920 - accuracy: 0.9246 - val_loss: 0.2058 - val_accuracy: 0.9216 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1905 - accuracy: 0.9219 - val_loss: 0.2148 - val_accuracy: 0.9172 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2022 - accuracy: 0.9204 - val_loss: 0.2112 - val_accuracy: 0.9194 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1903 - accuracy: 0.9235 - val_loss: 0.2107 - val_accuracy: 0.9197 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1975 - accuracy: 0.9222 - val_loss: 0.2129 - val_accuracy: 0.9184 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1911 - accuracy: 0.9230 - val_loss: 0.2124 - val_accuracy: 0.9190 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1913 - accuracy: 0.9259 - val_loss: 0.2068 - val_accuracy: 0.9206 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1970 - accuracy: 0.9227 - val_loss: 0.1974 - val_accuracy: 0.9247 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1931 - accuracy: 0.9234 - val_loss: 0.2024 - val_accuracy: 0.9228 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1938 - accuracy: 0.9246 - val_loss: 0.2055 - val_accuracy: 0.9214 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1962 - accuracy: 0.9229 - val_loss: 0.1992 - val_accuracy: 0.9239 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1899 - accuracy: 0.9245 - val_loss: 0.2002 - val_accuracy: 0.9238 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1915 - accuracy: 0.9242 - val_loss: 0.2060 - val_accuracy: 0.9216 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1890 - accuracy: 0.9241 - val_loss: 0.2042 - val_accuracy: 0.9223 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1868 - accuracy: 0.9264 - val_loss: 0.2048 - val_accuracy: 0.9222 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1937 - accuracy: 0.9238 - val_loss: 0.2070 - val_accuracy: 0.9216 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1874 - accuracy: 0.9237 - val_loss: 0.2036 - val_accuracy: 0.9221 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1873 - accuracy: 0.9252 - val_loss: 0.2017 - val_accuracy: 0.9232 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1972 - accuracy: 0.9230 - val_loss: 0.1986 - val_accuracy: 0.9249 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1915 - accuracy: 0.9236 - val_loss: 0.2052 - val_accuracy: 0.9225 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1925 - accuracy: 0.9234 - val_loss: 0.2136 - val_accuracy: 0.9189 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 18s 32ms/step - loss: 2.8676 - accuracy: 0.7530 - val_loss: 3.8865 - val_accuracy: 0.5675 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.3687 - accuracy: 0.7830 - val_loss: 1.7558 - val_accuracy: 0.7692 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 1.1620 - accuracy: 0.8015 - val_loss: 0.8932 - val_accuracy: 0.9046 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.8167 - accuracy: 0.8027 - val_loss: 1.3009 - val_accuracy: 0.4367 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.3513 - accuracy: 0.7966 - val_loss: 0.9841 - val_accuracy: 0.9017 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.9543 - accuracy: 0.8105 - val_loss: 0.9228 - val_accuracy: 0.8325 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.7097 - accuracy: 0.8133 - val_loss: 0.7811 - val_accuracy: 0.8156 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.7079 - accuracy: 0.8151 - val_loss: 0.4096 - val_accuracy: 0.8944 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5769 - accuracy: 0.8297 - val_loss: 0.5282 - val_accuracy: 0.9204 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5262 - accuracy: 0.8337 - val_loss: 0.5524 - val_accuracy: 0.8977 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.5484 - accuracy: 0.8377 - val_loss: 1.1506 - val_accuracy: 0.6860 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4749 - accuracy: 0.8468 - val_loss: 0.2784 - val_accuracy: 0.9195 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4386 - accuracy: 0.8532 - val_loss: 0.3618 - val_accuracy: 0.8883 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4120 - accuracy: 0.8608 - val_loss: 0.6082 - val_accuracy: 0.8061 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3876 - accuracy: 0.8750 - val_loss: 0.3047 - val_accuracy: 0.9156 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3884 - accuracy: 0.8677 - val_loss: 0.5731 - val_accuracy: 0.7945 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3578 - accuracy: 0.8836 - val_loss: 0.2923 - val_accuracy: 0.9215 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3487 - accuracy: 0.8869 - val_loss: 0.4224 - val_accuracy: 0.8590 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3223 - accuracy: 0.8905 - val_loss: 0.5057 - val_accuracy: 0.8215 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3260 - accuracy: 0.8949 - val_loss: 0.2324 - val_accuracy: 0.9345 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3131 - accuracy: 0.9029 - val_loss: 0.3703 - val_accuracy: 0.8745 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2803 - accuracy: 0.9094 - val_loss: 0.2362 - val_accuracy: 0.9270 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2864 - accuracy: 0.9062 - val_loss: 0.2585 - val_accuracy: 0.9263 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2779 - accuracy: 0.9089 - val_loss: 0.3192 - val_accuracy: 0.8943 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2643 - accuracy: 0.9170 - val_loss: 0.1991 - val_accuracy: 0.9428 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2605 - accuracy: 0.9143 - val_loss: 0.3322 - val_accuracy: 0.8939 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2521 - accuracy: 0.9154 - val_loss: 0.2331 - val_accuracy: 0.9372 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2361 - accuracy: 0.9209 - val_loss: 0.1983 - val_accuracy: 0.9393 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2369 - accuracy: 0.9231 - val_loss: 0.1866 - val_accuracy: 0.9428 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2190 - accuracy: 0.9221 - val_loss: 0.7444 - val_accuracy: 0.7717 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2297 - accuracy: 0.9235 - val_loss: 0.1863 - val_accuracy: 0.9438 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2200 - accuracy: 0.9272 - val_loss: 0.4090 - val_accuracy: 0.8745 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2199 - accuracy: 0.9250 - val_loss: 0.2994 - val_accuracy: 0.9012 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.2104 - accuracy: 0.9299 - val_loss: 0.1995 - val_accuracy: 0.9360 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 0.2040 - accuracy: 0.9298 - val_loss: 0.2768 - val_accuracy: 0.9115 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1975 - accuracy: 0.9337 - val_loss: 0.2616 - val_accuracy: 0.9116 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1891 - accuracy: 0.9350 - val_loss: 0.1523 - val_accuracy: 0.9548 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1945 - accuracy: 0.9343 - val_loss: 0.3784 - val_accuracy: 0.8732 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1924 - accuracy: 0.9337 - val_loss: 0.1531 - val_accuracy: 0.9540 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1876 - accuracy: 0.9376 - val_loss: 0.1832 - val_accuracy: 0.9407 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1832 - accuracy: 0.9372 - val_loss: 0.1821 - val_accuracy: 0.9418 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1833 - accuracy: 0.9372 - val_loss: 0.1874 - val_accuracy: 0.9402 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1819 - accuracy: 0.9367 - val_loss: 0.1526 - val_accuracy: 0.9524 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1803 - accuracy: 0.9371 - val_loss: 0.2078 - val_accuracy: 0.9321 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1711 - accuracy: 0.9389 - val_loss: 0.1944 - val_accuracy: 0.9372 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1751 - accuracy: 0.9401 - val_loss: 0.2401 - val_accuracy: 0.9226 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1708 - accuracy: 0.9404 - val_loss: 0.1862 - val_accuracy: 0.9399 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1731 - accuracy: 0.9391 - val_loss: 0.2206 - val_accuracy: 0.9271 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1782 - accuracy: 0.9381 - val_loss: 0.1793 - val_accuracy: 0.9420 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1681 - accuracy: 0.9417 - val_loss: 0.1610 - val_accuracy: 0.9475 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1684 - accuracy: 0.9420 - val_loss: 0.1860 - val_accuracy: 0.9393 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1726 - accuracy: 0.9401 - val_loss: 0.1766 - val_accuracy: 0.9415 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1642 - accuracy: 0.9418 - val_loss: 0.1750 - val_accuracy: 0.9421 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1701 - accuracy: 0.9402 - val_loss: 0.1740 - val_accuracy: 0.9436 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1567 - accuracy: 0.9453 - val_loss: 0.1891 - val_accuracy: 0.9381 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1651 - accuracy: 0.9394 - val_loss: 0.1593 - val_accuracy: 0.9481 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1607 - accuracy: 0.9434 - val_loss: 0.1809 - val_accuracy: 0.9408 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1577 - accuracy: 0.9444 - val_loss: 0.1990 - val_accuracy: 0.9353 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1655 - accuracy: 0.9411 - val_loss: 0.1761 - val_accuracy: 0.9426 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1653 - accuracy: 0.9418 - val_loss: 0.1852 - val_accuracy: 0.9400 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1649 - accuracy: 0.9418 - val_loss: 0.1878 - val_accuracy: 0.9382 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1663 - accuracy: 0.9418 - val_loss: 0.1754 - val_accuracy: 0.9421 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1543 - accuracy: 0.9434 - val_loss: 0.1768 - val_accuracy: 0.9422 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1600 - accuracy: 0.9444 - val_loss: 0.1843 - val_accuracy: 0.9392 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1607 - accuracy: 0.9447 - val_loss: 0.1759 - val_accuracy: 0.9417 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1601 - accuracy: 0.9444 - val_loss: 0.1814 - val_accuracy: 0.9400 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1604 - accuracy: 0.9460 - val_loss: 0.1667 - val_accuracy: 0.9451 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1599 - accuracy: 0.9443 - val_loss: 0.1751 - val_accuracy: 0.9424 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1541 - accuracy: 0.9468 - val_loss: 0.1738 - val_accuracy: 0.9428 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1561 - accuracy: 0.9454 - val_loss: 0.1818 - val_accuracy: 0.9400 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1556 - accuracy: 0.9473 - val_loss: 0.1762 - val_accuracy: 0.9413 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1627 - accuracy: 0.9456 - val_loss: 0.1778 - val_accuracy: 0.9404 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1620 - accuracy: 0.9444 - val_loss: 0.1696 - val_accuracy: 0.9439 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1571 - accuracy: 0.9447 - val_loss: 0.1763 - val_accuracy: 0.9412 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1591 - accuracy: 0.9430 - val_loss: 0.1738 - val_accuracy: 0.9425 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1578 - accuracy: 0.9449 - val_loss: 0.1814 - val_accuracy: 0.9401 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1592 - accuracy: 0.9425 - val_loss: 0.1826 - val_accuracy: 0.9399 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1598 - accuracy: 0.9420 - val_loss: 0.1744 - val_accuracy: 0.9423 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1553 - accuracy: 0.9452 - val_loss: 0.1777 - val_accuracy: 0.9408 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1575 - accuracy: 0.9436 - val_loss: 0.1752 - val_accuracy: 0.9418 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1515 - accuracy: 0.9433 - val_loss: 0.1756 - val_accuracy: 0.9419 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1592 - accuracy: 0.9449 - val_loss: 0.1746 - val_accuracy: 0.9420 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1647 - accuracy: 0.9416 - val_loss: 0.1698 - val_accuracy: 0.9442 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1580 - accuracy: 0.9453 - val_loss: 0.1743 - val_accuracy: 0.9428 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1564 - accuracy: 0.9451 - val_loss: 0.1784 - val_accuracy: 0.9410 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 16s 29ms/step - loss: 0.1574 - accuracy: 0.9445 - val_loss: 0.1812 - val_accuracy: 0.9403 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1604 - accuracy: 0.9436 - val_loss: 0.1780 - val_accuracy: 0.9410 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1546 - accuracy: 0.9446 - val_loss: 0.1782 - val_accuracy: 0.9408 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1564 - accuracy: 0.9450 - val_loss: 0.1761 - val_accuracy: 0.9413 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1552 - accuracy: 0.9449 - val_loss: 0.1771 - val_accuracy: 0.9410 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1566 - accuracy: 0.9456 - val_loss: 0.1793 - val_accuracy: 0.9407 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1565 - accuracy: 0.9428 - val_loss: 0.1752 - val_accuracy: 0.9414 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1538 - accuracy: 0.9444 - val_loss: 0.1789 - val_accuracy: 0.9407 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1517 - accuracy: 0.9459 - val_loss: 0.1780 - val_accuracy: 0.9409 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1553 - accuracy: 0.9443 - val_loss: 0.1790 - val_accuracy: 0.9408 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1535 - accuracy: 0.9465 - val_loss: 0.1772 - val_accuracy: 0.9411 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1548 - accuracy: 0.9458 - val_loss: 0.1777 - val_accuracy: 0.9410 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1540 - accuracy: 0.9447 - val_loss: 0.1725 - val_accuracy: 0.9432 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1526 - accuracy: 0.9460 - val_loss: 0.1752 - val_accuracy: 0.9416 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1609 - accuracy: 0.9433 - val_loss: 0.1742 - val_accuracy: 0.9422 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 2.3072 - accuracy: 0.7518 - val_loss: 1.5938 - val_accuracy: 0.8627 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.4131 - accuracy: 0.7698 - val_loss: 1.7425 - val_accuracy: 0.5501 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 1.0223 - accuracy: 0.7969 - val_loss: 0.9950 - val_accuracy: 0.8984 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.7706 - accuracy: 0.8047 - val_loss: 1.4654 - val_accuracy: 0.6096 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.2036 - accuracy: 0.7855 - val_loss: 1.6143 - val_accuracy: 0.7381 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.8698 - accuracy: 0.8020 - val_loss: 4.3816 - val_accuracy: 0.1790 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.7070 - accuracy: 0.8064 - val_loss: 0.8880 - val_accuracy: 0.7079 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.5827 - accuracy: 0.8135 - val_loss: 0.3933 - val_accuracy: 0.9014 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.6257 - accuracy: 0.8159 - val_loss: 0.5911 - val_accuracy: 0.8462 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.5533 - accuracy: 0.8172 - val_loss: 0.3771 - val_accuracy: 0.8681 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.5002 - accuracy: 0.8177 - val_loss: 0.4503 - val_accuracy: 0.8554 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4929 - accuracy: 0.8233 - val_loss: 0.6294 - val_accuracy: 0.8191 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5108 - accuracy: 0.8350 - val_loss: 0.4168 - val_accuracy: 0.8693 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5270 - accuracy: 0.8339 - val_loss: 0.3648 - val_accuracy: 0.8933 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.5238 - accuracy: 0.8352 - val_loss: 0.9570 - val_accuracy: 0.7469 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4657 - accuracy: 0.8428 - val_loss: 0.5152 - val_accuracy: 0.8239 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4239 - accuracy: 0.8511 - val_loss: 0.3700 - val_accuracy: 0.8690 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4111 - accuracy: 0.8543 - val_loss: 0.3969 - val_accuracy: 0.8516 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4345 - accuracy: 0.8391 - val_loss: 0.4012 - val_accuracy: 0.8547 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3794 - accuracy: 0.8572 - val_loss: 0.3201 - val_accuracy: 0.8768 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3675 - accuracy: 0.8644 - val_loss: 0.4431 - val_accuracy: 0.8332 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3520 - accuracy: 0.8739 - val_loss: 0.3199 - val_accuracy: 0.9133 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3458 - accuracy: 0.8832 - val_loss: 0.2849 - val_accuracy: 0.9106 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.3160 - accuracy: 0.8920 - val_loss: 0.2456 - val_accuracy: 0.9264 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2986 - accuracy: 0.9006 - val_loss: 0.2593 - val_accuracy: 0.9200 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2841 - accuracy: 0.9043 - val_loss: 0.2575 - val_accuracy: 0.9196 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2687 - accuracy: 0.9110 - val_loss: 0.5375 - val_accuracy: 0.8421 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2757 - accuracy: 0.9048 - val_loss: 0.2303 - val_accuracy: 0.9271 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2551 - accuracy: 0.9157 - val_loss: 0.3419 - val_accuracy: 0.8890 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2524 - accuracy: 0.9153 - val_loss: 0.2512 - val_accuracy: 0.9211 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2491 - accuracy: 0.9159 - val_loss: 0.2648 - val_accuracy: 0.9115 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2374 - accuracy: 0.9191 - val_loss: 0.2081 - val_accuracy: 0.9363 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2356 - accuracy: 0.9207 - val_loss: 0.2156 - val_accuracy: 0.9308 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2317 - accuracy: 0.9231 - val_loss: 0.1838 - val_accuracy: 0.9453 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2246 - accuracy: 0.9264 - val_loss: 0.2342 - val_accuracy: 0.9254 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2213 - accuracy: 0.9256 - val_loss: 0.2520 - val_accuracy: 0.9190 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2175 - accuracy: 0.9292 - val_loss: 0.3451 - val_accuracy: 0.8906 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2070 - accuracy: 0.9313 - val_loss: 0.2132 - val_accuracy: 0.9321 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1955 - accuracy: 0.9365 - val_loss: 0.1828 - val_accuracy: 0.9463 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1917 - accuracy: 0.9373 - val_loss: 0.1917 - val_accuracy: 0.9412 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1900 - accuracy: 0.9363 - val_loss: 0.3025 - val_accuracy: 0.9055 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1868 - accuracy: 0.9387 - val_loss: 0.2902 - val_accuracy: 0.9086 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1841 - accuracy: 0.9382 - val_loss: 0.2353 - val_accuracy: 0.9254 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1812 - accuracy: 0.9402 - val_loss: 0.2828 - val_accuracy: 0.9101 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1857 - accuracy: 0.9373 - val_loss: 0.2346 - val_accuracy: 0.9252 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1756 - accuracy: 0.9397 - val_loss: 0.2239 - val_accuracy: 0.9287 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1732 - accuracy: 0.9417 - val_loss: 0.2864 - val_accuracy: 0.9111 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1754 - accuracy: 0.9416 - val_loss: 0.2285 - val_accuracy: 0.9285 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1699 - accuracy: 0.9439 - val_loss: 0.2004 - val_accuracy: 0.9364 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1648 - accuracy: 0.9438 - val_loss: 0.2242 - val_accuracy: 0.9284 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1682 - accuracy: 0.9407 - val_loss: 0.1939 - val_accuracy: 0.9383 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1675 - accuracy: 0.9444 - val_loss: 0.3389 - val_accuracy: 0.8994 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1621 - accuracy: 0.9434 - val_loss: 0.2116 - val_accuracy: 0.9331 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1543 - accuracy: 0.9462 - val_loss: 0.1910 - val_accuracy: 0.9392 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1593 - accuracy: 0.9463 - val_loss: 0.1950 - val_accuracy: 0.9393 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1597 - accuracy: 0.9441 - val_loss: 0.2157 - val_accuracy: 0.9320 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1575 - accuracy: 0.9467 - val_loss: 0.1952 - val_accuracy: 0.9397 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1559 - accuracy: 0.9488 - val_loss: 0.2163 - val_accuracy: 0.9327 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1600 - accuracy: 0.9469 - val_loss: 0.2605 - val_accuracy: 0.9177 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1512 - accuracy: 0.9478 - val_loss: 0.2036 - val_accuracy: 0.9364 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1503 - accuracy: 0.9472 - val_loss: 0.2195 - val_accuracy: 0.9306 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1520 - accuracy: 0.9492 - val_loss: 0.2113 - val_accuracy: 0.9337 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1537 - accuracy: 0.9470 - val_loss: 0.2166 - val_accuracy: 0.9325 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1532 - accuracy: 0.9500 - val_loss: 0.2202 - val_accuracy: 0.9305 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1531 - accuracy: 0.9491 - val_loss: 0.2125 - val_accuracy: 0.9335 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1562 - accuracy: 0.9487 - val_loss: 0.2059 - val_accuracy: 0.9351 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1582 - accuracy: 0.9470 - val_loss: 0.2001 - val_accuracy: 0.9370 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1536 - accuracy: 0.9466 - val_loss: 0.2127 - val_accuracy: 0.9332 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1438 - accuracy: 0.9488 - val_loss: 0.2094 - val_accuracy: 0.9345 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1552 - accuracy: 0.9487 - val_loss: 0.2034 - val_accuracy: 0.9358 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1486 - accuracy: 0.9501 - val_loss: 0.2069 - val_accuracy: 0.9346 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1460 - accuracy: 0.9501 - val_loss: 0.2028 - val_accuracy: 0.9362 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1521 - accuracy: 0.9494 - val_loss: 0.2073 - val_accuracy: 0.9350 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1444 - accuracy: 0.9488 - val_loss: 0.2101 - val_accuracy: 0.9341 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1477 - accuracy: 0.9476 - val_loss: 0.2029 - val_accuracy: 0.9359 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1532 - accuracy: 0.9504 - val_loss: 0.2029 - val_accuracy: 0.9362 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1434 - accuracy: 0.9511 - val_loss: 0.2043 - val_accuracy: 0.9359 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1491 - accuracy: 0.9495 - val_loss: 0.2069 - val_accuracy: 0.9354 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1464 - accuracy: 0.9488 - val_loss: 0.2066 - val_accuracy: 0.9356 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1479 - accuracy: 0.9494 - val_loss: 0.2038 - val_accuracy: 0.9362 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1431 - accuracy: 0.9483 - val_loss: 0.2035 - val_accuracy: 0.9365 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1472 - accuracy: 0.9486 - val_loss: 0.2088 - val_accuracy: 0.9352 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1472 - accuracy: 0.9495 - val_loss: 0.2075 - val_accuracy: 0.9352 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1480 - accuracy: 0.9499 - val_loss: 0.2065 - val_accuracy: 0.9355 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1451 - accuracy: 0.9520 - val_loss: 0.2036 - val_accuracy: 0.9362 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1489 - accuracy: 0.9480 - val_loss: 0.2056 - val_accuracy: 0.9356 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1431 - accuracy: 0.9513 - val_loss: 0.2048 - val_accuracy: 0.9358 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1420 - accuracy: 0.9524 - val_loss: 0.2069 - val_accuracy: 0.9357 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1472 - accuracy: 0.9512 - val_loss: 0.2029 - val_accuracy: 0.9365 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1508 - accuracy: 0.9489 - val_loss: 0.2034 - val_accuracy: 0.9363 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1544 - accuracy: 0.9472 - val_loss: 0.2020 - val_accuracy: 0.9366 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1489 - accuracy: 0.9498 - val_loss: 0.2049 - val_accuracy: 0.9360 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1431 - accuracy: 0.9515 - val_loss: 0.2038 - val_accuracy: 0.9362 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1485 - accuracy: 0.9502 - val_loss: 0.2055 - val_accuracy: 0.9358 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1463 - accuracy: 0.9508 - val_loss: 0.2064 - val_accuracy: 0.9358 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1447 - accuracy: 0.9509 - val_loss: 0.2079 - val_accuracy: 0.9352 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1505 - accuracy: 0.9501 - val_loss: 0.2055 - val_accuracy: 0.9358 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1398 - accuracy: 0.9515 - val_loss: 0.2068 - val_accuracy: 0.9360 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1530 - accuracy: 0.9502 - val_loss: 0.2064 - val_accuracy: 0.9356 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1466 - accuracy: 0.9501 - val_loss: 0.2072 - val_accuracy: 0.9352 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 2.8900 - accuracy: 0.7809 - val_loss: 10.3115 - val_accuracy: 0.1154 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 1.2998 - accuracy: 0.8035 - val_loss: 1.3130 - val_accuracy: 0.7593 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.1243 - accuracy: 0.8059 - val_loss: 0.9714 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.3129 - accuracy: 0.8067 - val_loss: 1.1157 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 1.4525 - accuracy: 0.8109 - val_loss: 0.9911 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.9198 - accuracy: 0.8259 - val_loss: 1.1176 - val_accuracy: 0.8976 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 1.0521 - accuracy: 0.8298 - val_loss: 2.5334 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.7416 - accuracy: 0.8288 - val_loss: 0.7437 - val_accuracy: 0.8974 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.8458 - accuracy: 0.8355 - val_loss: 0.4672 - val_accuracy: 0.8726 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.5226 - accuracy: 0.8423 - val_loss: 0.5610 - val_accuracy: 0.8988 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.4432 - accuracy: 0.8526 - val_loss: 0.4607 - val_accuracy: 0.8991 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4378 - accuracy: 0.8579 - val_loss: 1.2377 - val_accuracy: 0.6559 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4808 - accuracy: 0.8517 - val_loss: 0.2674 - val_accuracy: 0.9270 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4430 - accuracy: 0.8677 - val_loss: 1.1410 - val_accuracy: 0.6248 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.4217 - accuracy: 0.8726 - val_loss: 0.2836 - val_accuracy: 0.9337 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3776 - accuracy: 0.8791 - val_loss: 0.4330 - val_accuracy: 0.8549 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3864 - accuracy: 0.8817 - val_loss: 0.6278 - val_accuracy: 0.7919 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3679 - accuracy: 0.8863 - val_loss: 0.7441 - val_accuracy: 0.7676 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3464 - accuracy: 0.8907 - val_loss: 1.2951 - val_accuracy: 0.6219 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3317 - accuracy: 0.8927 - val_loss: 0.3385 - val_accuracy: 0.8900 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.3389 - accuracy: 0.8949 - val_loss: 0.6054 - val_accuracy: 0.7995 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.3115 - accuracy: 0.9002 - val_loss: 0.2309 - val_accuracy: 0.9319 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2998 - accuracy: 0.9067 - val_loss: 0.2567 - val_accuracy: 0.9177 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2918 - accuracy: 0.9074 - val_loss: 0.2946 - val_accuracy: 0.9022 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.2872 - accuracy: 0.9093 - val_loss: 0.5007 - val_accuracy: 0.8202 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2664 - accuracy: 0.9132 - val_loss: 0.2531 - val_accuracy: 0.9200 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2578 - accuracy: 0.9147 - val_loss: 1.2521 - val_accuracy: 0.6406 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2582 - accuracy: 0.9191 - val_loss: 0.2197 - val_accuracy: 0.9317 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2392 - accuracy: 0.9211 - val_loss: 0.3750 - val_accuracy: 0.8765 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2458 - accuracy: 0.9208 - val_loss: 0.2348 - val_accuracy: 0.9192 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2325 - accuracy: 0.9204 - val_loss: 0.3329 - val_accuracy: 0.8831 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2383 - accuracy: 0.9212 - val_loss: 0.2814 - val_accuracy: 0.9242 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2305 - accuracy: 0.9230 - val_loss: 0.1927 - val_accuracy: 0.9394 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2241 - accuracy: 0.9255 - val_loss: 0.1699 - val_accuracy: 0.9504 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2122 - accuracy: 0.9284 - val_loss: 0.2347 - val_accuracy: 0.9182 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.2117 - accuracy: 0.9290 - val_loss: 0.2451 - val_accuracy: 0.9133 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2052 - accuracy: 0.9319 - val_loss: 0.1554 - val_accuracy: 0.9510 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2114 - accuracy: 0.9297 - val_loss: 0.2425 - val_accuracy: 0.9152 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1968 - accuracy: 0.9339 - val_loss: 0.6490 - val_accuracy: 0.8060 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1996 - accuracy: 0.9301 - val_loss: 0.1826 - val_accuracy: 0.9385 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1874 - accuracy: 0.9350 - val_loss: 0.2642 - val_accuracy: 0.9086 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1965 - accuracy: 0.9337 - val_loss: 0.1833 - val_accuracy: 0.9385 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1912 - accuracy: 0.9352 - val_loss: 0.1615 - val_accuracy: 0.9478 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1798 - accuracy: 0.9366 - val_loss: 0.1739 - val_accuracy: 0.9418 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1846 - accuracy: 0.9333 - val_loss: 0.1567 - val_accuracy: 0.9488 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1783 - accuracy: 0.9382 - val_loss: 0.1835 - val_accuracy: 0.9390 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1820 - accuracy: 0.9356 - val_loss: 0.1982 - val_accuracy: 0.9319 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1874 - accuracy: 0.9356 - val_loss: 0.2340 - val_accuracy: 0.9179 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1759 - accuracy: 0.9382 - val_loss: 0.1707 - val_accuracy: 0.9428 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1792 - accuracy: 0.9365 - val_loss: 0.2056 - val_accuracy: 0.9275 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1738 - accuracy: 0.9392 - val_loss: 0.1600 - val_accuracy: 0.9468 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1712 - accuracy: 0.9400 - val_loss: 0.1957 - val_accuracy: 0.9322 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1621 - accuracy: 0.9396 - val_loss: 0.2046 - val_accuracy: 0.9294 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1673 - accuracy: 0.9417 - val_loss: 0.1815 - val_accuracy: 0.9389 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1731 - accuracy: 0.9409 - val_loss: 0.1902 - val_accuracy: 0.9348 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1708 - accuracy: 0.9411 - val_loss: 0.1978 - val_accuracy: 0.9314 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1611 - accuracy: 0.9430 - val_loss: 0.1765 - val_accuracy: 0.9407 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1595 - accuracy: 0.9433 - val_loss: 0.1933 - val_accuracy: 0.9354 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1666 - accuracy: 0.9440 - val_loss: 0.1870 - val_accuracy: 0.9376 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1525 - accuracy: 0.9452 - val_loss: 0.1675 - val_accuracy: 0.9436 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1624 - accuracy: 0.9453 - val_loss: 0.1831 - val_accuracy: 0.9387 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1597 - accuracy: 0.9453 - val_loss: 0.1865 - val_accuracy: 0.9372 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1528 - accuracy: 0.9471 - val_loss: 0.1741 - val_accuracy: 0.9418 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1590 - accuracy: 0.9457 - val_loss: 0.1751 - val_accuracy: 0.9413 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1585 - accuracy: 0.9465 - val_loss: 0.1829 - val_accuracy: 0.9386 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1514 - accuracy: 0.9487 - val_loss: 0.1816 - val_accuracy: 0.9395 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1570 - accuracy: 0.9466 - val_loss: 0.1836 - val_accuracy: 0.9386 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1485 - accuracy: 0.9475 - val_loss: 0.1709 - val_accuracy: 0.9426 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1582 - accuracy: 0.9444 - val_loss: 0.1834 - val_accuracy: 0.9385 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1560 - accuracy: 0.9456 - val_loss: 0.1764 - val_accuracy: 0.9411 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1524 - accuracy: 0.9464 - val_loss: 0.1731 - val_accuracy: 0.9417 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1516 - accuracy: 0.9475 - val_loss: 0.1803 - val_accuracy: 0.9396 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1588 - accuracy: 0.9452 - val_loss: 0.1791 - val_accuracy: 0.9401 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1581 - accuracy: 0.9462 - val_loss: 0.1735 - val_accuracy: 0.9418 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1564 - accuracy: 0.9480 - val_loss: 0.1771 - val_accuracy: 0.9409 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1542 - accuracy: 0.9474 - val_loss: 0.1794 - val_accuracy: 0.9402 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1500 - accuracy: 0.9472 - val_loss: 0.1840 - val_accuracy: 0.9386 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1477 - accuracy: 0.9488 - val_loss: 0.1857 - val_accuracy: 0.9382 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1517 - accuracy: 0.9476 - val_loss: 0.1795 - val_accuracy: 0.9401 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1491 - accuracy: 0.9478 - val_loss: 0.1835 - val_accuracy: 0.9389 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1534 - accuracy: 0.9457 - val_loss: 0.1805 - val_accuracy: 0.9398 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1480 - accuracy: 0.9483 - val_loss: 0.1767 - val_accuracy: 0.9411 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1525 - accuracy: 0.9465 - val_loss: 0.1771 - val_accuracy: 0.9410 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1564 - accuracy: 0.9480 - val_loss: 0.1763 - val_accuracy: 0.9412 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1534 - accuracy: 0.9480 - val_loss: 0.1786 - val_accuracy: 0.9402 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1541 - accuracy: 0.9472 - val_loss: 0.1754 - val_accuracy: 0.9415 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1575 - accuracy: 0.9485 - val_loss: 0.1798 - val_accuracy: 0.9401 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1442 - accuracy: 0.9498 - val_loss: 0.1887 - val_accuracy: 0.9373 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1550 - accuracy: 0.9476 - val_loss: 0.1771 - val_accuracy: 0.9412 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1473 - accuracy: 0.9477 - val_loss: 0.1750 - val_accuracy: 0.9416 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1527 - accuracy: 0.9474 - val_loss: 0.1773 - val_accuracy: 0.9408 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1509 - accuracy: 0.9488 - val_loss: 0.1768 - val_accuracy: 0.9411 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1492 - accuracy: 0.9483 - val_loss: 0.1826 - val_accuracy: 0.9387 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1511 - accuracy: 0.9475 - val_loss: 0.1764 - val_accuracy: 0.9412 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1556 - accuracy: 0.9456 - val_loss: 0.1790 - val_accuracy: 0.9401 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1539 - accuracy: 0.9482 - val_loss: 0.1774 - val_accuracy: 0.9409 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1541 - accuracy: 0.9456 - val_loss: 0.1750 - val_accuracy: 0.9415 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1445 - accuracy: 0.9496 - val_loss: 0.1797 - val_accuracy: 0.9398 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1505 - accuracy: 0.9489 - val_loss: 0.1789 - val_accuracy: 0.9401 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1499 - accuracy: 0.9465 - val_loss: 0.1784 - val_accuracy: 0.9404 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 16s 27ms/step - loss: 13.0460 - accuracy: 0.6921 - val_loss: 4.5254 - val_accuracy: 0.7720 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 7.1554 - accuracy: 0.7175 - val_loss: 5.4407 - val_accuracy: 0.5471 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 6.1322 - accuracy: 0.7199 - val_loss: 2.7002 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 3.7160 - accuracy: 0.7510 - val_loss: 1.8503 - val_accuracy: 0.4623 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 2.3897 - accuracy: 0.7551 - val_loss: 10.2546 - val_accuracy: 0.7983 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 3.3008 - accuracy: 0.7454 - val_loss: 1.3135 - val_accuracy: 0.8987 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.1678 - accuracy: 0.7858 - val_loss: 1.8736 - val_accuracy: 0.8161 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.1357 - accuracy: 0.7949 - val_loss: 0.6238 - val_accuracy: 0.9038 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 1.2750 - accuracy: 0.7923 - val_loss: 1.1086 - val_accuracy: 0.6868 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.6709 - accuracy: 0.7833 - val_loss: 4.8565 - val_accuracy: 0.1031 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 1.0892 - accuracy: 0.7973 - val_loss: 0.6339 - val_accuracy: 0.9022 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.8292 - accuracy: 0.8063 - val_loss: 1.4621 - val_accuracy: 0.5095 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.6915 - accuracy: 0.8143 - val_loss: 0.6104 - val_accuracy: 0.8159 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.8103 - accuracy: 0.8131 - val_loss: 1.5252 - val_accuracy: 0.6769 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.8992 - accuracy: 0.8164 - val_loss: 0.9966 - val_accuracy: 0.8977 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.8681 - accuracy: 0.8171 - val_loss: 0.9350 - val_accuracy: 0.8372 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6669 - accuracy: 0.8220 - val_loss: 0.5448 - val_accuracy: 0.9103 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5666 - accuracy: 0.8281 - val_loss: 2.4426 - val_accuracy: 0.2266 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.5432 - accuracy: 0.8297 - val_loss: 0.4348 - val_accuracy: 0.9054 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.5327 - accuracy: 0.8269 - val_loss: 1.0166 - val_accuracy: 0.6909 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4830 - accuracy: 0.8303 - val_loss: 0.6822 - val_accuracy: 0.7893 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4820 - accuracy: 0.8290 - val_loss: 0.4836 - val_accuracy: 0.8489 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4832 - accuracy: 0.8268 - val_loss: 1.0721 - val_accuracy: 0.6532 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4587 - accuracy: 0.8337 - val_loss: 0.3599 - val_accuracy: 0.8625 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4245 - accuracy: 0.8378 - val_loss: 1.5688 - val_accuracy: 0.6171 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4340 - accuracy: 0.8321 - val_loss: 0.3193 - val_accuracy: 0.8687 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3978 - accuracy: 0.8496 - val_loss: 0.4174 - val_accuracy: 0.8366 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3744 - accuracy: 0.8601 - val_loss: 0.7999 - val_accuracy: 0.7659 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3700 - accuracy: 0.8612 - val_loss: 0.3435 - val_accuracy: 0.9035 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3561 - accuracy: 0.8683 - val_loss: 0.6789 - val_accuracy: 0.7646 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3471 - accuracy: 0.8746 - val_loss: 1.3880 - val_accuracy: 0.4705 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3407 - accuracy: 0.8797 - val_loss: 1.1056 - val_accuracy: 0.6830 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3237 - accuracy: 0.8787 - val_loss: 0.2762 - val_accuracy: 0.9064 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3610 - accuracy: 0.8782 - val_loss: 0.2067 - val_accuracy: 0.9432 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3070 - accuracy: 0.8895 - val_loss: 0.2566 - val_accuracy: 0.9132 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3053 - accuracy: 0.8918 - val_loss: 0.2260 - val_accuracy: 0.9292 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2855 - accuracy: 0.8978 - val_loss: 0.3251 - val_accuracy: 0.8833 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2794 - accuracy: 0.8995 - val_loss: 0.3295 - val_accuracy: 0.8855 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2870 - accuracy: 0.8998 - val_loss: 0.4203 - val_accuracy: 0.8420 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2675 - accuracy: 0.9037 - val_loss: 0.2805 - val_accuracy: 0.8997 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2689 - accuracy: 0.9020 - val_loss: 0.1869 - val_accuracy: 0.9405 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2516 - accuracy: 0.9102 - val_loss: 0.2046 - val_accuracy: 0.9309 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2527 - accuracy: 0.9096 - val_loss: 0.1895 - val_accuracy: 0.9425 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2451 - accuracy: 0.9154 - val_loss: 0.2988 - val_accuracy: 0.8951 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2450 - accuracy: 0.9118 - val_loss: 0.1763 - val_accuracy: 0.9422 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2412 - accuracy: 0.9128 - val_loss: 0.2440 - val_accuracy: 0.9173 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2374 - accuracy: 0.9129 - val_loss: 0.2643 - val_accuracy: 0.9083 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2324 - accuracy: 0.9168 - val_loss: 0.2131 - val_accuracy: 0.9263 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2189 - accuracy: 0.9209 - val_loss: 0.1909 - val_accuracy: 0.9349 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2286 - accuracy: 0.9150 - val_loss: 0.1860 - val_accuracy: 0.9370 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2170 - accuracy: 0.9227 - val_loss: 0.2093 - val_accuracy: 0.9279 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2173 - accuracy: 0.9209 - val_loss: 0.1963 - val_accuracy: 0.9327 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2094 - accuracy: 0.9255 - val_loss: 0.1720 - val_accuracy: 0.9433 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2059 - accuracy: 0.9247 - val_loss: 0.2241 - val_accuracy: 0.9240 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2069 - accuracy: 0.9271 - val_loss: 0.1672 - val_accuracy: 0.9441 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2024 - accuracy: 0.9276 - val_loss: 0.2108 - val_accuracy: 0.9292 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1991 - accuracy: 0.9305 - val_loss: 0.1911 - val_accuracy: 0.9360 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1999 - accuracy: 0.9287 - val_loss: 0.1945 - val_accuracy: 0.9337 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1894 - accuracy: 0.9292 - val_loss: 0.2456 - val_accuracy: 0.9158 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1976 - accuracy: 0.9305 - val_loss: 0.1945 - val_accuracy: 0.9335 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1929 - accuracy: 0.9298 - val_loss: 0.1728 - val_accuracy: 0.9414 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1836 - accuracy: 0.9326 - val_loss: 0.2059 - val_accuracy: 0.9302 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1878 - accuracy: 0.9306 - val_loss: 0.1991 - val_accuracy: 0.9329 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1876 - accuracy: 0.9293 - val_loss: 0.1781 - val_accuracy: 0.9408 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1809 - accuracy: 0.9326 - val_loss: 0.1913 - val_accuracy: 0.9355 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1896 - accuracy: 0.9311 - val_loss: 0.1974 - val_accuracy: 0.9333 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1868 - accuracy: 0.9298 - val_loss: 0.2003 - val_accuracy: 0.9324 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1794 - accuracy: 0.9329 - val_loss: 0.1795 - val_accuracy: 0.9396 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1883 - accuracy: 0.9310 - val_loss: 0.1775 - val_accuracy: 0.9409 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1888 - accuracy: 0.9309 - val_loss: 0.1908 - val_accuracy: 0.9353 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1794 - accuracy: 0.9341 - val_loss: 0.1745 - val_accuracy: 0.9414 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1738 - accuracy: 0.9372 - val_loss: 0.1884 - val_accuracy: 0.9377 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1792 - accuracy: 0.9352 - val_loss: 0.1895 - val_accuracy: 0.9364 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1786 - accuracy: 0.9352 - val_loss: 0.1742 - val_accuracy: 0.9418 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1771 - accuracy: 0.9347 - val_loss: 0.1840 - val_accuracy: 0.9383 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1797 - accuracy: 0.9349 - val_loss: 0.1785 - val_accuracy: 0.9404 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1769 - accuracy: 0.9340 - val_loss: 0.1882 - val_accuracy: 0.9376 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1795 - accuracy: 0.9364 - val_loss: 0.1850 - val_accuracy: 0.9383 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1768 - accuracy: 0.9366 - val_loss: 0.1784 - val_accuracy: 0.9401 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1750 - accuracy: 0.9336 - val_loss: 0.1766 - val_accuracy: 0.9409 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1781 - accuracy: 0.9369 - val_loss: 0.1821 - val_accuracy: 0.9393 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1748 - accuracy: 0.9342 - val_loss: 0.1784 - val_accuracy: 0.9409 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1809 - accuracy: 0.9364 - val_loss: 0.1816 - val_accuracy: 0.9393 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1755 - accuracy: 0.9361 - val_loss: 0.1856 - val_accuracy: 0.9377 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1780 - accuracy: 0.9370 - val_loss: 0.1779 - val_accuracy: 0.9406 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1733 - accuracy: 0.9367 - val_loss: 0.1794 - val_accuracy: 0.9402 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1705 - accuracy: 0.9387 - val_loss: 0.1829 - val_accuracy: 0.9395 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1740 - accuracy: 0.9366 - val_loss: 0.1781 - val_accuracy: 0.9407 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1663 - accuracy: 0.9392 - val_loss: 0.1816 - val_accuracy: 0.9398 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1797 - accuracy: 0.9351 - val_loss: 0.1711 - val_accuracy: 0.9426 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1667 - accuracy: 0.9399 - val_loss: 0.1789 - val_accuracy: 0.9406 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1759 - accuracy: 0.9359 - val_loss: 0.1806 - val_accuracy: 0.9403 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1735 - accuracy: 0.9371 - val_loss: 0.1815 - val_accuracy: 0.9399 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1785 - accuracy: 0.9357 - val_loss: 0.1827 - val_accuracy: 0.9396 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1728 - accuracy: 0.9380 - val_loss: 0.1814 - val_accuracy: 0.9399 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1687 - accuracy: 0.9377 - val_loss: 0.1773 - val_accuracy: 0.9412 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1748 - accuracy: 0.9385 - val_loss: 0.1863 - val_accuracy: 0.9381 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1735 - accuracy: 0.9385 - val_loss: 0.1827 - val_accuracy: 0.9398 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1729 - accuracy: 0.9392 - val_loss: 0.1783 - val_accuracy: 0.9408 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1758 - accuracy: 0.9361 - val_loss: 0.1745 - val_accuracy: 0.9416 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 13.3088 - accuracy: 0.6911 - val_loss: 7.7413 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 10.0390 - accuracy: 0.6818 - val_loss: 24.3786 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 8.8673 - accuracy: 0.7061 - val_loss: 5.5611 - val_accuracy: 0.8977 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 8.2017 - accuracy: 0.7174 - val_loss: 3.8154 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 3.6375 - accuracy: 0.7784 - val_loss: 3.1247 - val_accuracy: 0.8988 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 6.0464 - accuracy: 0.7579 - val_loss: 6.0161 - val_accuracy: 0.8974 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 5.8926 - accuracy: 0.7731 - val_loss: 3.7952 - val_accuracy: 0.8976 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 3.2300 - accuracy: 0.8001 - val_loss: 2.8505 - val_accuracy: 0.4636 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 2.2147 - accuracy: 0.8011 - val_loss: 1.4424 - val_accuracy: 0.9054 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.4031 - accuracy: 0.8008 - val_loss: 1.5832 - val_accuracy: 0.5718 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 1.5667 - accuracy: 0.8103 - val_loss: 1.3886 - val_accuracy: 0.5829 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 2.5471 - accuracy: 0.7917 - val_loss: 1.9489 - val_accuracy: 0.8974 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 1.2677 - accuracy: 0.8079 - val_loss: 1.7072 - val_accuracy: 0.4663 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 1.5626 - accuracy: 0.8109 - val_loss: 2.1619 - val_accuracy: 0.8485 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.9125 - accuracy: 0.8216 - val_loss: 0.8282 - val_accuracy: 0.8363 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.9681 - accuracy: 0.8262 - val_loss: 1.0249 - val_accuracy: 0.8974 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7401 - accuracy: 0.8321 - val_loss: 1.6091 - val_accuracy: 0.8974 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.8826 - accuracy: 0.8420 - val_loss: 0.7238 - val_accuracy: 0.7990 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6540 - accuracy: 0.8433 - val_loss: 0.3842 - val_accuracy: 0.9213 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5560 - accuracy: 0.8499 - val_loss: 1.2503 - val_accuracy: 0.5931 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.5706 - accuracy: 0.8498 - val_loss: 0.7532 - val_accuracy: 0.8974 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5158 - accuracy: 0.8600 - val_loss: 0.3172 - val_accuracy: 0.9220 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4987 - accuracy: 0.8651 - val_loss: 1.3359 - val_accuracy: 0.6376 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4547 - accuracy: 0.8752 - val_loss: 0.4304 - val_accuracy: 0.9144 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4138 - accuracy: 0.8750 - val_loss: 0.9549 - val_accuracy: 0.6425 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4208 - accuracy: 0.8775 - val_loss: 0.2368 - val_accuracy: 0.9422 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3786 - accuracy: 0.8843 - val_loss: 0.6314 - val_accuracy: 0.8186 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3663 - accuracy: 0.8867 - val_loss: 0.4139 - val_accuracy: 0.8548 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3387 - accuracy: 0.8932 - val_loss: 0.2396 - val_accuracy: 0.9339 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3352 - accuracy: 0.8982 - val_loss: 0.2667 - val_accuracy: 0.9368 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3293 - accuracy: 0.8974 - val_loss: 0.2617 - val_accuracy: 0.9184 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3186 - accuracy: 0.8971 - val_loss: 0.2568 - val_accuracy: 0.9303 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3021 - accuracy: 0.8980 - val_loss: 0.2037 - val_accuracy: 0.9414 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2925 - accuracy: 0.9045 - val_loss: 0.2178 - val_accuracy: 0.9435 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2869 - accuracy: 0.9082 - val_loss: 0.2188 - val_accuracy: 0.9396 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2876 - accuracy: 0.9059 - val_loss: 0.4023 - val_accuracy: 0.9088 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2790 - accuracy: 0.9065 - val_loss: 0.2630 - val_accuracy: 0.9125 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2591 - accuracy: 0.9131 - val_loss: 0.2857 - val_accuracy: 0.9003 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2620 - accuracy: 0.9087 - val_loss: 0.2093 - val_accuracy: 0.9298 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2468 - accuracy: 0.9187 - val_loss: 0.9134 - val_accuracy: 0.7181 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2418 - accuracy: 0.9126 - val_loss: 0.2734 - val_accuracy: 0.9055 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2367 - accuracy: 0.9222 - val_loss: 0.3915 - val_accuracy: 0.8664 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2410 - accuracy: 0.9171 - val_loss: 0.1515 - val_accuracy: 0.9553 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2318 - accuracy: 0.9189 - val_loss: 0.3236 - val_accuracy: 0.8884 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2308 - accuracy: 0.9204 - val_loss: 0.1581 - val_accuracy: 0.9515 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2335 - accuracy: 0.9220 - val_loss: 0.2139 - val_accuracy: 0.9294 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2254 - accuracy: 0.9202 - val_loss: 0.1571 - val_accuracy: 0.9501 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2139 - accuracy: 0.9241 - val_loss: 0.2048 - val_accuracy: 0.9293 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2127 - accuracy: 0.9236 - val_loss: 0.1821 - val_accuracy: 0.9393 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2189 - accuracy: 0.9233 - val_loss: 0.1453 - val_accuracy: 0.9546 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2104 - accuracy: 0.9261 - val_loss: 0.2241 - val_accuracy: 0.9206 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2141 - accuracy: 0.9246 - val_loss: 0.1696 - val_accuracy: 0.9424 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 0.2086 - accuracy: 0.9259 - val_loss: 0.1584 - val_accuracy: 0.9482 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2019 - accuracy: 0.9277 - val_loss: 0.2245 - val_accuracy: 0.9216 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2021 - accuracy: 0.9251 - val_loss: 0.1943 - val_accuracy: 0.9321 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2002 - accuracy: 0.9277 - val_loss: 0.1583 - val_accuracy: 0.9475 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1942 - accuracy: 0.9324 - val_loss: 0.1710 - val_accuracy: 0.9418 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1910 - accuracy: 0.9305 - val_loss: 0.1428 - val_accuracy: 0.9541 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1998 - accuracy: 0.9319 - val_loss: 0.2315 - val_accuracy: 0.9193 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1916 - accuracy: 0.9301 - val_loss: 0.1635 - val_accuracy: 0.9449 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2033 - accuracy: 0.9281 - val_loss: 0.2946 - val_accuracy: 0.8986 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1896 - accuracy: 0.9308 - val_loss: 0.1747 - val_accuracy: 0.9404 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1890 - accuracy: 0.9348 - val_loss: 0.1696 - val_accuracy: 0.9426 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1947 - accuracy: 0.9294 - val_loss: 0.1611 - val_accuracy: 0.9453 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1920 - accuracy: 0.9339 - val_loss: 0.1711 - val_accuracy: 0.9399 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1862 - accuracy: 0.9333 - val_loss: 0.1905 - val_accuracy: 0.9333 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1854 - accuracy: 0.9316 - val_loss: 0.1716 - val_accuracy: 0.9410 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1846 - accuracy: 0.9344 - val_loss: 0.1668 - val_accuracy: 0.9430 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1910 - accuracy: 0.9329 - val_loss: 0.1665 - val_accuracy: 0.9432 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1871 - accuracy: 0.9335 - val_loss: 0.1551 - val_accuracy: 0.9476 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1762 - accuracy: 0.9352 - val_loss: 0.1632 - val_accuracy: 0.9446 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1825 - accuracy: 0.9346 - val_loss: 0.1702 - val_accuracy: 0.9414 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1787 - accuracy: 0.9395 - val_loss: 0.1643 - val_accuracy: 0.9445 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1864 - accuracy: 0.9354 - val_loss: 0.1648 - val_accuracy: 0.9438 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1811 - accuracy: 0.9351 - val_loss: 0.1699 - val_accuracy: 0.9422 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1813 - accuracy: 0.9345 - val_loss: 0.1550 - val_accuracy: 0.9475 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1830 - accuracy: 0.9349 - val_loss: 0.1502 - val_accuracy: 0.9493 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1834 - accuracy: 0.9349 - val_loss: 0.1573 - val_accuracy: 0.9468 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1837 - accuracy: 0.9362 - val_loss: 0.1610 - val_accuracy: 0.9455 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1769 - accuracy: 0.9386 - val_loss: 0.1610 - val_accuracy: 0.9456 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1759 - accuracy: 0.9361 - val_loss: 0.1589 - val_accuracy: 0.9469 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1810 - accuracy: 0.9335 - val_loss: 0.1586 - val_accuracy: 0.9465 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 0.1792 - accuracy: 0.9339 - val_loss: 0.1563 - val_accuracy: 0.9468 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1751 - accuracy: 0.9345 - val_loss: 0.1613 - val_accuracy: 0.9457 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1790 - accuracy: 0.9363 - val_loss: 0.1654 - val_accuracy: 0.9442 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1799 - accuracy: 0.9345 - val_loss: 0.1637 - val_accuracy: 0.9449 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1781 - accuracy: 0.9332 - val_loss: 0.1653 - val_accuracy: 0.9438 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1730 - accuracy: 0.9355 - val_loss: 0.1563 - val_accuracy: 0.9469 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1741 - accuracy: 0.9363 - val_loss: 0.1601 - val_accuracy: 0.9459 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1748 - accuracy: 0.9365 - val_loss: 0.1622 - val_accuracy: 0.9454 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1749 - accuracy: 0.9353 - val_loss: 0.1591 - val_accuracy: 0.9464 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1789 - accuracy: 0.9345 - val_loss: 0.1663 - val_accuracy: 0.9439 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1780 - accuracy: 0.9349 - val_loss: 0.1616 - val_accuracy: 0.9454 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1731 - accuracy: 0.9358 - val_loss: 0.1594 - val_accuracy: 0.9461 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1761 - accuracy: 0.9376 - val_loss: 0.1571 - val_accuracy: 0.9474 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1707 - accuracy: 0.9373 - val_loss: 0.1600 - val_accuracy: 0.9463 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1690 - accuracy: 0.9397 - val_loss: 0.1626 - val_accuracy: 0.9457 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1713 - accuracy: 0.9363 - val_loss: 0.1522 - val_accuracy: 0.9494 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1751 - accuracy: 0.9373 - val_loss: 0.1628 - val_accuracy: 0.9456 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1764 - accuracy: 0.9382 - val_loss: 0.1608 - val_accuracy: 0.9461 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 8ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 14.5479 - accuracy: 0.7146 - val_loss: 13.7467 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 7.4793 - accuracy: 0.7190 - val_loss: 7.2300 - val_accuracy: 0.8274 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 8.5267 - accuracy: 0.7241 - val_loss: 7.6635 - val_accuracy: 0.2942 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 7.2790 - accuracy: 0.7420 - val_loss: 5.5808 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 4.4350 - accuracy: 0.7814 - val_loss: 2.6745 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 3.7503 - accuracy: 0.7801 - val_loss: 3.8758 - val_accuracy: 0.9044 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 2.3553 - accuracy: 0.7951 - val_loss: 1.7605 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 2.2358 - accuracy: 0.7823 - val_loss: 3.0220 - val_accuracy: 0.8829 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 2.1078 - accuracy: 0.7845 - val_loss: 3.1444 - val_accuracy: 0.3975 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.1574 - accuracy: 0.7863 - val_loss: 1.1376 - val_accuracy: 0.7380 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.3591 - accuracy: 0.7947 - val_loss: 0.7365 - val_accuracy: 0.8965 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.8525 - accuracy: 0.8077 - val_loss: 1.4662 - val_accuracy: 0.8711 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.9951 - accuracy: 0.8121 - val_loss: 0.5983 - val_accuracy: 0.8463 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5805 - accuracy: 0.8240 - val_loss: 0.5510 - val_accuracy: 0.8263 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5990 - accuracy: 0.8238 - val_loss: 2.0684 - val_accuracy: 0.2291 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.6455 - accuracy: 0.8303 - val_loss: 0.9760 - val_accuracy: 0.8974 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6870 - accuracy: 0.8214 - val_loss: 1.3916 - val_accuracy: 0.4618 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.5711 - accuracy: 0.8300 - val_loss: 0.3621 - val_accuracy: 0.9041 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.5713 - accuracy: 0.8424 - val_loss: 0.3850 - val_accuracy: 0.9077 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.5074 - accuracy: 0.8501 - val_loss: 0.3082 - val_accuracy: 0.9220 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4932 - accuracy: 0.8527 - val_loss: 0.2844 - val_accuracy: 0.9197 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4656 - accuracy: 0.8576 - val_loss: 0.3156 - val_accuracy: 0.9281 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.4319 - accuracy: 0.8595 - val_loss: 0.3733 - val_accuracy: 0.9088 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4794 - accuracy: 0.8674 - val_loss: 0.3633 - val_accuracy: 0.8885 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3919 - accuracy: 0.8709 - val_loss: 0.7747 - val_accuracy: 0.7372 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3927 - accuracy: 0.8721 - val_loss: 0.2578 - val_accuracy: 0.9367 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3757 - accuracy: 0.8739 - val_loss: 0.2292 - val_accuracy: 0.9420 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.3530 - accuracy: 0.8767 - val_loss: 0.4299 - val_accuracy: 0.8498 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3468 - accuracy: 0.8760 - val_loss: 0.2547 - val_accuracy: 0.9336 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 0.3395 - accuracy: 0.8846 - val_loss: 0.2182 - val_accuracy: 0.9422 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3336 - accuracy: 0.8831 - val_loss: 0.3095 - val_accuracy: 0.8863 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3138 - accuracy: 0.8895 - val_loss: 0.2598 - val_accuracy: 0.9201 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3053 - accuracy: 0.8939 - val_loss: 0.2368 - val_accuracy: 0.9225 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3101 - accuracy: 0.8894 - val_loss: 0.2954 - val_accuracy: 0.8962 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3022 - accuracy: 0.8939 - val_loss: 0.2173 - val_accuracy: 0.9319 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2856 - accuracy: 0.8983 - val_loss: 0.2363 - val_accuracy: 0.9350 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2913 - accuracy: 0.8977 - val_loss: 0.2113 - val_accuracy: 0.9302 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2671 - accuracy: 0.9051 - val_loss: 0.2719 - val_accuracy: 0.9054 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2687 - accuracy: 0.9059 - val_loss: 0.1998 - val_accuracy: 0.9368 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2642 - accuracy: 0.9069 - val_loss: 0.3477 - val_accuracy: 0.8699 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2644 - accuracy: 0.9072 - val_loss: 0.1895 - val_accuracy: 0.9423 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2481 - accuracy: 0.9089 - val_loss: 0.2333 - val_accuracy: 0.9165 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2383 - accuracy: 0.9157 - val_loss: 0.2650 - val_accuracy: 0.9040 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2499 - accuracy: 0.9121 - val_loss: 0.2009 - val_accuracy: 0.9323 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2372 - accuracy: 0.9122 - val_loss: 0.1751 - val_accuracy: 0.9447 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2331 - accuracy: 0.9155 - val_loss: 0.2146 - val_accuracy: 0.9243 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2345 - accuracy: 0.9125 - val_loss: 0.2244 - val_accuracy: 0.9211 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2358 - accuracy: 0.9164 - val_loss: 0.3407 - val_accuracy: 0.8734 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2211 - accuracy: 0.9175 - val_loss: 0.2781 - val_accuracy: 0.8957 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2160 - accuracy: 0.9239 - val_loss: 0.1737 - val_accuracy: 0.9418 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2086 - accuracy: 0.9209 - val_loss: 0.2325 - val_accuracy: 0.9171 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2087 - accuracy: 0.9242 - val_loss: 0.1629 - val_accuracy: 0.9456 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2026 - accuracy: 0.9250 - val_loss: 0.2102 - val_accuracy: 0.9244 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2002 - accuracy: 0.9247 - val_loss: 0.2408 - val_accuracy: 0.9126 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1942 - accuracy: 0.9286 - val_loss: 0.1669 - val_accuracy: 0.9432 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2008 - accuracy: 0.9265 - val_loss: 0.1967 - val_accuracy: 0.9295 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1908 - accuracy: 0.9300 - val_loss: 0.1725 - val_accuracy: 0.9400 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1880 - accuracy: 0.9329 - val_loss: 0.2209 - val_accuracy: 0.9193 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1946 - accuracy: 0.9291 - val_loss: 0.2226 - val_accuracy: 0.9188 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1929 - accuracy: 0.9297 - val_loss: 0.1838 - val_accuracy: 0.9354 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1858 - accuracy: 0.9334 - val_loss: 0.2688 - val_accuracy: 0.9024 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1849 - accuracy: 0.9329 - val_loss: 0.1781 - val_accuracy: 0.9364 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1912 - accuracy: 0.9295 - val_loss: 0.1755 - val_accuracy: 0.9379 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1836 - accuracy: 0.9348 - val_loss: 0.1679 - val_accuracy: 0.9405 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1865 - accuracy: 0.9298 - val_loss: 0.1772 - val_accuracy: 0.9379 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1806 - accuracy: 0.9332 - val_loss: 0.1876 - val_accuracy: 0.9316 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1807 - accuracy: 0.9312 - val_loss: 0.2092 - val_accuracy: 0.9230 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1856 - accuracy: 0.9339 - val_loss: 0.1929 - val_accuracy: 0.9296 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1830 - accuracy: 0.9346 - val_loss: 0.1823 - val_accuracy: 0.9327 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1759 - accuracy: 0.9340 - val_loss: 0.1770 - val_accuracy: 0.9356 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1814 - accuracy: 0.9307 - val_loss: 0.1946 - val_accuracy: 0.9292 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1744 - accuracy: 0.9353 - val_loss: 0.1931 - val_accuracy: 0.9295 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1798 - accuracy: 0.9355 - val_loss: 0.1810 - val_accuracy: 0.9344 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1804 - accuracy: 0.9311 - val_loss: 0.1989 - val_accuracy: 0.9273 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1807 - accuracy: 0.9332 - val_loss: 0.1902 - val_accuracy: 0.9313 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1772 - accuracy: 0.9324 - val_loss: 0.1795 - val_accuracy: 0.9336 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1795 - accuracy: 0.9310 - val_loss: 0.1900 - val_accuracy: 0.9302 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1777 - accuracy: 0.9326 - val_loss: 0.1895 - val_accuracy: 0.9301 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1748 - accuracy: 0.9350 - val_loss: 0.1863 - val_accuracy: 0.9322 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1672 - accuracy: 0.9368 - val_loss: 0.1918 - val_accuracy: 0.9302 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1766 - accuracy: 0.9337 - val_loss: 0.1824 - val_accuracy: 0.9344 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1757 - accuracy: 0.9345 - val_loss: 0.1849 - val_accuracy: 0.9336 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1767 - accuracy: 0.9325 - val_loss: 0.1847 - val_accuracy: 0.9332 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1745 - accuracy: 0.9363 - val_loss: 0.1863 - val_accuracy: 0.9322 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1752 - accuracy: 0.9346 - val_loss: 0.1907 - val_accuracy: 0.9310 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1777 - accuracy: 0.9313 - val_loss: 0.1809 - val_accuracy: 0.9341 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1718 - accuracy: 0.9340 - val_loss: 0.1858 - val_accuracy: 0.9319 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1723 - accuracy: 0.9345 - val_loss: 0.1835 - val_accuracy: 0.9331 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1686 - accuracy: 0.9364 - val_loss: 0.1827 - val_accuracy: 0.9338 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1741 - accuracy: 0.9349 - val_loss: 0.1833 - val_accuracy: 0.9334 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1736 - accuracy: 0.9345 - val_loss: 0.1860 - val_accuracy: 0.9323 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1715 - accuracy: 0.9350 - val_loss: 0.1873 - val_accuracy: 0.9317 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1733 - accuracy: 0.9363 - val_loss: 0.1880 - val_accuracy: 0.9312 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1751 - accuracy: 0.9325 - val_loss: 0.1836 - val_accuracy: 0.9334 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1736 - accuracy: 0.9335 - val_loss: 0.1806 - val_accuracy: 0.9346 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1723 - accuracy: 0.9369 - val_loss: 0.1916 - val_accuracy: 0.9297 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1664 - accuracy: 0.9379 - val_loss: 0.1797 - val_accuracy: 0.9349 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1763 - accuracy: 0.9355 - val_loss: 0.1829 - val_accuracy: 0.9336 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1701 - accuracy: 0.9356 - val_loss: 0.1843 - val_accuracy: 0.9331 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1742 - accuracy: 0.9371 - val_loss: 0.1865 - val_accuracy: 0.9325 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 8ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 4.5650 - accuracy: 0.7397 - val_loss: 3.9536 - val_accuracy: 0.3565 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 3.2830 - accuracy: 0.7822 - val_loss: 2.3979 - val_accuracy: 0.8329 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 2.3463 - accuracy: 0.7900 - val_loss: 3.2863 - val_accuracy: 0.5199 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.5322 - accuracy: 0.8074 - val_loss: 10.3015 - val_accuracy: 0.1026 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 1.6783 - accuracy: 0.7991 - val_loss: 1.3949 - val_accuracy: 0.9101 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.1446 - accuracy: 0.8087 - val_loss: 0.6500 - val_accuracy: 0.9108 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 1.1484 - accuracy: 0.8089 - val_loss: 3.8010 - val_accuracy: 0.1355 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.1002 - accuracy: 0.8129 - val_loss: 0.7155 - val_accuracy: 0.8563 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7406 - accuracy: 0.8211 - val_loss: 0.3684 - val_accuracy: 0.9272 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7572 - accuracy: 0.8194 - val_loss: 0.4652 - val_accuracy: 0.9078 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6728 - accuracy: 0.8262 - val_loss: 0.5843 - val_accuracy: 0.8278 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4874 - accuracy: 0.8413 - val_loss: 0.8810 - val_accuracy: 0.7847 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4845 - accuracy: 0.8524 - val_loss: 0.5456 - val_accuracy: 0.8419 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4347 - accuracy: 0.8568 - val_loss: 0.4077 - val_accuracy: 0.8678 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4094 - accuracy: 0.8611 - val_loss: 0.2908 - val_accuracy: 0.9158 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3777 - accuracy: 0.8659 - val_loss: 0.2247 - val_accuracy: 0.9385 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3762 - accuracy: 0.8736 - val_loss: 0.2931 - val_accuracy: 0.8986 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3647 - accuracy: 0.8738 - val_loss: 0.2324 - val_accuracy: 0.9398 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3460 - accuracy: 0.8800 - val_loss: 0.3812 - val_accuracy: 0.8664 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3464 - accuracy: 0.8804 - val_loss: 0.3515 - val_accuracy: 0.8695 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3146 - accuracy: 0.8888 - val_loss: 0.2473 - val_accuracy: 0.9161 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3212 - accuracy: 0.8874 - val_loss: 0.2210 - val_accuracy: 0.9316 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3015 - accuracy: 0.8928 - val_loss: 0.5708 - val_accuracy: 0.7866 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3025 - accuracy: 0.8898 - val_loss: 0.2264 - val_accuracy: 0.9233 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2800 - accuracy: 0.9031 - val_loss: 0.5059 - val_accuracy: 0.8463 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2686 - accuracy: 0.9063 - val_loss: 0.2751 - val_accuracy: 0.8987 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2714 - accuracy: 0.9024 - val_loss: 0.3955 - val_accuracy: 0.8503 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2570 - accuracy: 0.9074 - val_loss: 0.1814 - val_accuracy: 0.9432 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2561 - accuracy: 0.9105 - val_loss: 0.3405 - val_accuracy: 0.8744 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2431 - accuracy: 0.9152 - val_loss: 0.1670 - val_accuracy: 0.9500 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2395 - accuracy: 0.9166 - val_loss: 0.2460 - val_accuracy: 0.9123 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2334 - accuracy: 0.9181 - val_loss: 0.1685 - val_accuracy: 0.9436 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2344 - accuracy: 0.9176 - val_loss: 0.3473 - val_accuracy: 0.8721 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2261 - accuracy: 0.9186 - val_loss: 0.2938 - val_accuracy: 0.8920 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2189 - accuracy: 0.9219 - val_loss: 0.1574 - val_accuracy: 0.9523 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2191 - accuracy: 0.9246 - val_loss: 0.3190 - val_accuracy: 0.8862 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2218 - accuracy: 0.9222 - val_loss: 0.1632 - val_accuracy: 0.9470 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2088 - accuracy: 0.9228 - val_loss: 0.2252 - val_accuracy: 0.9215 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.2168 - accuracy: 0.9246 - val_loss: 0.4789 - val_accuracy: 0.8408 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2081 - accuracy: 0.9254 - val_loss: 0.1603 - val_accuracy: 0.9482 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2070 - accuracy: 0.9271 - val_loss: 0.1716 - val_accuracy: 0.9421 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2009 - accuracy: 0.9283 - val_loss: 0.2007 - val_accuracy: 0.9285 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2035 - accuracy: 0.9287 - val_loss: 0.2464 - val_accuracy: 0.9108 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1966 - accuracy: 0.9308 - val_loss: 0.2809 - val_accuracy: 0.9012 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1956 - accuracy: 0.9310 - val_loss: 0.1880 - val_accuracy: 0.9345 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1977 - accuracy: 0.9293 - val_loss: 0.1787 - val_accuracy: 0.9383 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1932 - accuracy: 0.9280 - val_loss: 0.3052 - val_accuracy: 0.8915 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1946 - accuracy: 0.9302 - val_loss: 0.1980 - val_accuracy: 0.9300 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1895 - accuracy: 0.9315 - val_loss: 0.2161 - val_accuracy: 0.9234 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1858 - accuracy: 0.9325 - val_loss: 0.1773 - val_accuracy: 0.9403 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1862 - accuracy: 0.9346 - val_loss: 0.1916 - val_accuracy: 0.9325 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1799 - accuracy: 0.9336 - val_loss: 0.2541 - val_accuracy: 0.9097 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 0.1808 - accuracy: 0.9339 - val_loss: 0.1878 - val_accuracy: 0.9340 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1814 - accuracy: 0.9352 - val_loss: 0.2469 - val_accuracy: 0.9136 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1877 - accuracy: 0.9343 - val_loss: 0.1762 - val_accuracy: 0.9385 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1696 - accuracy: 0.9366 - val_loss: 0.1976 - val_accuracy: 0.9317 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1788 - accuracy: 0.9350 - val_loss: 0.1957 - val_accuracy: 0.9317 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1706 - accuracy: 0.9396 - val_loss: 0.2020 - val_accuracy: 0.9300 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.1769 - accuracy: 0.9401 - val_loss: 0.1949 - val_accuracy: 0.9325 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1715 - accuracy: 0.9379 - val_loss: 0.1717 - val_accuracy: 0.9420 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1791 - accuracy: 0.9362 - val_loss: 0.1793 - val_accuracy: 0.9380 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1689 - accuracy: 0.9423 - val_loss: 0.1860 - val_accuracy: 0.9364 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1734 - accuracy: 0.9388 - val_loss: 0.1917 - val_accuracy: 0.9346 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1673 - accuracy: 0.9385 - val_loss: 0.1867 - val_accuracy: 0.9362 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1723 - accuracy: 0.9398 - val_loss: 0.1892 - val_accuracy: 0.9354 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1648 - accuracy: 0.9410 - val_loss: 0.1848 - val_accuracy: 0.9370 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1750 - accuracy: 0.9385 - val_loss: 0.2007 - val_accuracy: 0.9310 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1701 - accuracy: 0.9402 - val_loss: 0.1889 - val_accuracy: 0.9354 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1610 - accuracy: 0.9400 - val_loss: 0.1802 - val_accuracy: 0.9389 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1675 - accuracy: 0.9391 - val_loss: 0.1807 - val_accuracy: 0.9387 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1711 - accuracy: 0.9400 - val_loss: 0.1765 - val_accuracy: 0.9401 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1627 - accuracy: 0.9411 - val_loss: 0.1840 - val_accuracy: 0.9375 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1604 - accuracy: 0.9418 - val_loss: 0.1789 - val_accuracy: 0.9396 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 0.1641 - accuracy: 0.9441 - val_loss: 0.1768 - val_accuracy: 0.9405 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1615 - accuracy: 0.9413 - val_loss: 0.1801 - val_accuracy: 0.9394 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.1620 - accuracy: 0.9436 - val_loss: 0.1732 - val_accuracy: 0.9411 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1736 - accuracy: 0.9417 - val_loss: 0.1757 - val_accuracy: 0.9398 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1565 - accuracy: 0.9437 - val_loss: 0.1793 - val_accuracy: 0.9394 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1646 - accuracy: 0.9426 - val_loss: 0.1783 - val_accuracy: 0.9398 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1617 - accuracy: 0.9430 - val_loss: 0.1775 - val_accuracy: 0.9401 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1656 - accuracy: 0.9427 - val_loss: 0.1774 - val_accuracy: 0.9400 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 0.1599 - accuracy: 0.9447 - val_loss: 0.1759 - val_accuracy: 0.9408 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1629 - accuracy: 0.9439 - val_loss: 0.1871 - val_accuracy: 0.9364 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1723 - accuracy: 0.9411 - val_loss: 0.1847 - val_accuracy: 0.9376 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1667 - accuracy: 0.9432 - val_loss: 0.1761 - val_accuracy: 0.9408 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1702 - accuracy: 0.9424 - val_loss: 0.1758 - val_accuracy: 0.9402 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1615 - accuracy: 0.9421 - val_loss: 0.1838 - val_accuracy: 0.9379 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1606 - accuracy: 0.9413 - val_loss: 0.1760 - val_accuracy: 0.9408 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1667 - accuracy: 0.9411 - val_loss: 0.1785 - val_accuracy: 0.9398 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1605 - accuracy: 0.9434 - val_loss: 0.1784 - val_accuracy: 0.9399 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1619 - accuracy: 0.9407 - val_loss: 0.1798 - val_accuracy: 0.9395 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1604 - accuracy: 0.9445 - val_loss: 0.1857 - val_accuracy: 0.9371 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1623 - accuracy: 0.9399 - val_loss: 0.1785 - val_accuracy: 0.9397 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1619 - accuracy: 0.9424 - val_loss: 0.1777 - val_accuracy: 0.9400 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1617 - accuracy: 0.9417 - val_loss: 0.1767 - val_accuracy: 0.9402 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1623 - accuracy: 0.9432 - val_loss: 0.1792 - val_accuracy: 0.9390 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1616 - accuracy: 0.9429 - val_loss: 0.1752 - val_accuracy: 0.9407 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1620 - accuracy: 0.9431 - val_loss: 0.1790 - val_accuracy: 0.9393 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1660 - accuracy: 0.9423 - val_loss: 0.1779 - val_accuracy: 0.9397 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1643 - accuracy: 0.9403 - val_loss: 0.1787 - val_accuracy: 0.9395 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 8ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 3.6906 - accuracy: 0.7586 - val_loss: 1.3067 - val_accuracy: 0.7694 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 2.2129 - accuracy: 0.7862 - val_loss: 4.1262 - val_accuracy: 0.2422 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 2.7986 - accuracy: 0.7829 - val_loss: 8.0423 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 3.1583 - accuracy: 0.7927 - val_loss: 6.3236 - val_accuracy: 0.8879 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 3.8944 - accuracy: 0.7978 - val_loss: 6.4684 - val_accuracy: 0.1026 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 4.2172 - accuracy: 0.7886 - val_loss: 6.3871 - val_accuracy: 0.1936 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 2.1699 - accuracy: 0.8060 - val_loss: 1.9319 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.1750 - accuracy: 0.8168 - val_loss: 6.0157 - val_accuracy: 0.1026 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.1576 - accuracy: 0.8265 - val_loss: 4.1844 - val_accuracy: 0.8974 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.3261 - accuracy: 0.8365 - val_loss: 7.5099 - val_accuracy: 0.1026 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.8700 - accuracy: 0.8449 - val_loss: 0.7883 - val_accuracy: 0.9220 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6962 - accuracy: 0.8521 - val_loss: 1.1916 - val_accuracy: 0.8974 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.8051 - accuracy: 0.8591 - val_loss: 18.2123 - val_accuracy: 0.1026 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.7972 - accuracy: 0.8596 - val_loss: 2.0911 - val_accuracy: 0.8974 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.6024 - accuracy: 0.8785 - val_loss: 2.2839 - val_accuracy: 0.2798 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.5428 - accuracy: 0.8784 - val_loss: 0.8135 - val_accuracy: 0.8982 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.5691 - accuracy: 0.8858 - val_loss: 5.8637 - val_accuracy: 0.1070 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4772 - accuracy: 0.8937 - val_loss: 1.0558 - val_accuracy: 0.7619 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4686 - accuracy: 0.9051 - val_loss: 3.1856 - val_accuracy: 0.3485 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4952 - accuracy: 0.8944 - val_loss: 0.6737 - val_accuracy: 0.9108 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5449 - accuracy: 0.9017 - val_loss: 0.6942 - val_accuracy: 0.9114 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.5165 - accuracy: 0.9077 - val_loss: 1.9403 - val_accuracy: 0.4664 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4238 - accuracy: 0.9171 - val_loss: 0.3254 - val_accuracy: 0.9542 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4442 - accuracy: 0.9201 - val_loss: 0.3373 - val_accuracy: 0.9587 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4104 - accuracy: 0.9222 - val_loss: 0.3176 - val_accuracy: 0.9502 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3555 - accuracy: 0.9226 - val_loss: 0.6508 - val_accuracy: 0.8043 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.3205 - accuracy: 0.9223 - val_loss: 1.7128 - val_accuracy: 0.4078 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 0.2967 - accuracy: 0.9246 - val_loss: 0.2564 - val_accuracy: 0.9436 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.2566 - accuracy: 0.9333 - val_loss: 0.3374 - val_accuracy: 0.9288 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2515 - accuracy: 0.9320 - val_loss: 1.3990 - val_accuracy: 0.6069 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2614 - accuracy: 0.9329 - val_loss: 0.2357 - val_accuracy: 0.9471 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2560 - accuracy: 0.9334 - val_loss: 0.2294 - val_accuracy: 0.9463 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2281 - accuracy: 0.9372 - val_loss: 0.3501 - val_accuracy: 0.8954 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2263 - accuracy: 0.9317 - val_loss: 0.1889 - val_accuracy: 0.9496 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2104 - accuracy: 0.9385 - val_loss: 0.2628 - val_accuracy: 0.9220 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2142 - accuracy: 0.9366 - val_loss: 0.2108 - val_accuracy: 0.9370 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1899 - accuracy: 0.9439 - val_loss: 0.6668 - val_accuracy: 0.7981 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1959 - accuracy: 0.9407 - val_loss: 0.1461 - val_accuracy: 0.9602 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1804 - accuracy: 0.9434 - val_loss: 0.7083 - val_accuracy: 0.8024 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1857 - accuracy: 0.9403 - val_loss: 0.1559 - val_accuracy: 0.9565 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1675 - accuracy: 0.9466 - val_loss: 0.1906 - val_accuracy: 0.9497 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1828 - accuracy: 0.9453 - val_loss: 0.1819 - val_accuracy: 0.9463 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1748 - accuracy: 0.9457 - val_loss: 0.2557 - val_accuracy: 0.9201 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1729 - accuracy: 0.9460 - val_loss: 7.6419 - val_accuracy: 0.1332 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1688 - accuracy: 0.9463 - val_loss: 0.2783 - val_accuracy: 0.9169 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1573 - accuracy: 0.9492 - val_loss: 0.2263 - val_accuracy: 0.9330 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1576 - accuracy: 0.9554 - val_loss: 0.1399 - val_accuracy: 0.9594 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1672 - accuracy: 0.9456 - val_loss: 0.2284 - val_accuracy: 0.9311 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1649 - accuracy: 0.9476 - val_loss: 0.1407 - val_accuracy: 0.9602 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1592 - accuracy: 0.9502 - val_loss: 0.1417 - val_accuracy: 0.9583 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1577 - accuracy: 0.9530 - val_loss: 0.2266 - val_accuracy: 0.9308 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1616 - accuracy: 0.9459 - val_loss: 0.1747 - val_accuracy: 0.9489 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1598 - accuracy: 0.9457 - val_loss: 0.1775 - val_accuracy: 0.9461 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1582 - accuracy: 0.9485 - val_loss: 0.1660 - val_accuracy: 0.9496 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1574 - accuracy: 0.9483 - val_loss: 0.2017 - val_accuracy: 0.9379 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1509 - accuracy: 0.9498 - val_loss: 0.1495 - val_accuracy: 0.9551 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1500 - accuracy: 0.9529 - val_loss: 0.1933 - val_accuracy: 0.9393 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1466 - accuracy: 0.9489 - val_loss: 0.1661 - val_accuracy: 0.9507 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1600 - accuracy: 0.9476 - val_loss: 0.2090 - val_accuracy: 0.9356 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1447 - accuracy: 0.9538 - val_loss: 0.1656 - val_accuracy: 0.9494 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1503 - accuracy: 0.9511 - val_loss: 0.1606 - val_accuracy: 0.9504 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1462 - accuracy: 0.9537 - val_loss: 0.1674 - val_accuracy: 0.9490 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1477 - accuracy: 0.9514 - val_loss: 0.5217 - val_accuracy: 0.8507 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1459 - accuracy: 0.9521 - val_loss: 0.1871 - val_accuracy: 0.9421 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1455 - accuracy: 0.9537 - val_loss: 0.1695 - val_accuracy: 0.9484 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1412 - accuracy: 0.9546 - val_loss: 0.1766 - val_accuracy: 0.9455 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1400 - accuracy: 0.9526 - val_loss: 0.1631 - val_accuracy: 0.9500 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1393 - accuracy: 0.9546 - val_loss: 0.1543 - val_accuracy: 0.9527 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1402 - accuracy: 0.9518 - val_loss: 0.1685 - val_accuracy: 0.9491 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1463 - accuracy: 0.9541 - val_loss: 0.1731 - val_accuracy: 0.9463 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1396 - accuracy: 0.9521 - val_loss: 0.1704 - val_accuracy: 0.9489 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1413 - accuracy: 0.9530 - val_loss: 0.1749 - val_accuracy: 0.9462 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1384 - accuracy: 0.9553 - val_loss: 0.1554 - val_accuracy: 0.9528 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1346 - accuracy: 0.9557 - val_loss: 0.1701 - val_accuracy: 0.9480 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1354 - accuracy: 0.9554 - val_loss: 0.1736 - val_accuracy: 0.9466 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1376 - accuracy: 0.9537 - val_loss: 0.1570 - val_accuracy: 0.9526 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1323 - accuracy: 0.9546 - val_loss: 0.1605 - val_accuracy: 0.9523 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1421 - accuracy: 0.9530 - val_loss: 0.1696 - val_accuracy: 0.9483 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1434 - accuracy: 0.9543 - val_loss: 0.1607 - val_accuracy: 0.9523 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1349 - accuracy: 0.9546 - val_loss: 0.1701 - val_accuracy: 0.9490 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1392 - accuracy: 0.9554 - val_loss: 0.1671 - val_accuracy: 0.9493 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1344 - accuracy: 0.9565 - val_loss: 0.1614 - val_accuracy: 0.9517 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1365 - accuracy: 0.9559 - val_loss: 0.1637 - val_accuracy: 0.9513 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1419 - accuracy: 0.9548 - val_loss: 0.1656 - val_accuracy: 0.9506 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1402 - accuracy: 0.9538 - val_loss: 0.1711 - val_accuracy: 0.9488 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1377 - accuracy: 0.9544 - val_loss: 0.1669 - val_accuracy: 0.9502 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1353 - accuracy: 0.9569 - val_loss: 0.1720 - val_accuracy: 0.9484 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1422 - accuracy: 0.9533 - val_loss: 0.1721 - val_accuracy: 0.9484 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1373 - accuracy: 0.9536 - val_loss: 0.1687 - val_accuracy: 0.9492 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1352 - accuracy: 0.9543 - val_loss: 0.1677 - val_accuracy: 0.9504 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1328 - accuracy: 0.9553 - val_loss: 0.1679 - val_accuracy: 0.9499 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1384 - accuracy: 0.9556 - val_loss: 0.1655 - val_accuracy: 0.9506 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1353 - accuracy: 0.9545 - val_loss: 0.1685 - val_accuracy: 0.9497 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1389 - accuracy: 0.9562 - val_loss: 0.1680 - val_accuracy: 0.9498 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1325 - accuracy: 0.9570 - val_loss: 0.1601 - val_accuracy: 0.9522 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1338 - accuracy: 0.9569 - val_loss: 0.1625 - val_accuracy: 0.9518 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1389 - accuracy: 0.9550 - val_loss: 0.1678 - val_accuracy: 0.9493 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1339 - accuracy: 0.9541 - val_loss: 0.1606 - val_accuracy: 0.9521 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1317 - accuracy: 0.9561 - val_loss: 0.1640 - val_accuracy: 0.9508 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1339 - accuracy: 0.9560 - val_loss: 0.1623 - val_accuracy: 0.9517 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 8ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 15s 27ms/step - loss: 4.0060 - accuracy: 0.7673 - val_loss: 1.9403 - val_accuracy: 0.7963 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.9470 - accuracy: 0.7843 - val_loss: 1.3334 - val_accuracy: 0.8014 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 2.4999 - accuracy: 0.7690 - val_loss: 3.1037 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.8358 - accuracy: 0.7863 - val_loss: 1.3484 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.2444 - accuracy: 0.8197 - val_loss: 1.2053 - val_accuracy: 0.8363 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.1885 - accuracy: 0.8134 - val_loss: 0.5550 - val_accuracy: 0.8874 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.0497 - accuracy: 0.8270 - val_loss: 1.3946 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.9935 - accuracy: 0.8185 - val_loss: 0.9460 - val_accuracy: 0.8974 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7759 - accuracy: 0.8210 - val_loss: 0.4555 - val_accuracy: 0.9292 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.8140 - accuracy: 0.8289 - val_loss: 0.8125 - val_accuracy: 0.9006 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.9100 - accuracy: 0.8293 - val_loss: 14.9044 - val_accuracy: 0.1026 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.9550 - accuracy: 0.8356 - val_loss: 1.0977 - val_accuracy: 0.7314 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7331 - accuracy: 0.8356 - val_loss: 0.5508 - val_accuracy: 0.8982 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6242 - accuracy: 0.8556 - val_loss: 0.3623 - val_accuracy: 0.9356 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.4792 - accuracy: 0.8707 - val_loss: 0.4547 - val_accuracy: 0.8774 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4177 - accuracy: 0.8793 - val_loss: 0.4833 - val_accuracy: 0.8492 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.4028 - accuracy: 0.8801 - val_loss: 0.2891 - val_accuracy: 0.9291 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3761 - accuracy: 0.8932 - val_loss: 0.4304 - val_accuracy: 0.8609 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3773 - accuracy: 0.8882 - val_loss: 0.2730 - val_accuracy: 0.9339 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3567 - accuracy: 0.8939 - val_loss: 1.5522 - val_accuracy: 0.5674 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3643 - accuracy: 0.8924 - val_loss: 0.2482 - val_accuracy: 0.9468 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3432 - accuracy: 0.9064 - val_loss: 0.3258 - val_accuracy: 0.9035 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3174 - accuracy: 0.9061 - val_loss: 0.3413 - val_accuracy: 0.8947 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2859 - accuracy: 0.9189 - val_loss: 0.2108 - val_accuracy: 0.9461 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2759 - accuracy: 0.9174 - val_loss: 0.2682 - val_accuracy: 0.9195 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2735 - accuracy: 0.9132 - val_loss: 0.2043 - val_accuracy: 0.9474 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2618 - accuracy: 0.9193 - val_loss: 0.1872 - val_accuracy: 0.9533 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2442 - accuracy: 0.9241 - val_loss: 0.3144 - val_accuracy: 0.9025 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2256 - accuracy: 0.9339 - val_loss: 0.3243 - val_accuracy: 0.9068 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2307 - accuracy: 0.9300 - val_loss: 0.2493 - val_accuracy: 0.9247 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2147 - accuracy: 0.9344 - val_loss: 0.1690 - val_accuracy: 0.9573 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2101 - accuracy: 0.9372 - val_loss: 0.2606 - val_accuracy: 0.9169 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2012 - accuracy: 0.9395 - val_loss: 0.2134 - val_accuracy: 0.9372 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1991 - accuracy: 0.9379 - val_loss: 0.1716 - val_accuracy: 0.9527 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.1942 - accuracy: 0.9420 - val_loss: 0.1765 - val_accuracy: 0.9490 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1905 - accuracy: 0.9428 - val_loss: 0.1517 - val_accuracy: 0.9588 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1857 - accuracy: 0.9439 - val_loss: 0.2349 - val_accuracy: 0.9284 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1716 - accuracy: 0.9496 - val_loss: 0.1527 - val_accuracy: 0.9581 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1787 - accuracy: 0.9462 - val_loss: 0.1549 - val_accuracy: 0.9568 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1713 - accuracy: 0.9468 - val_loss: 0.1466 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1624 - accuracy: 0.9502 - val_loss: 0.1507 - val_accuracy: 0.9570 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1557 - accuracy: 0.9535 - val_loss: 0.1600 - val_accuracy: 0.9525 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1523 - accuracy: 0.9532 - val_loss: 0.1452 - val_accuracy: 0.9602 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1482 - accuracy: 0.9564 - val_loss: 0.1848 - val_accuracy: 0.9438 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1442 - accuracy: 0.9541 - val_loss: 0.1699 - val_accuracy: 0.9474 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1438 - accuracy: 0.9563 - val_loss: 0.1660 - val_accuracy: 0.9501 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1393 - accuracy: 0.9565 - val_loss: 0.1618 - val_accuracy: 0.9515 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1393 - accuracy: 0.9563 - val_loss: 0.1670 - val_accuracy: 0.9512 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1430 - accuracy: 0.9559 - val_loss: 0.1591 - val_accuracy: 0.9531 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1322 - accuracy: 0.9585 - val_loss: 0.1573 - val_accuracy: 0.9535 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1356 - accuracy: 0.9583 - val_loss: 0.1646 - val_accuracy: 0.9505 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1361 - accuracy: 0.9577 - val_loss: 0.1612 - val_accuracy: 0.9522 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1303 - accuracy: 0.9595 - val_loss: 0.1608 - val_accuracy: 0.9511 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1262 - accuracy: 0.9586 - val_loss: 0.1617 - val_accuracy: 0.9503 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1328 - accuracy: 0.9573 - val_loss: 0.1555 - val_accuracy: 0.9521 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1240 - accuracy: 0.9606 - val_loss: 0.1492 - val_accuracy: 0.9563 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1232 - accuracy: 0.9631 - val_loss: 0.1606 - val_accuracy: 0.9510 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1188 - accuracy: 0.9638 - val_loss: 0.1561 - val_accuracy: 0.9523 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1232 - accuracy: 0.9638 - val_loss: 0.1635 - val_accuracy: 0.9512 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1211 - accuracy: 0.9632 - val_loss: 0.1571 - val_accuracy: 0.9527 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1172 - accuracy: 0.9637 - val_loss: 0.1536 - val_accuracy: 0.9544 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1146 - accuracy: 0.9641 - val_loss: 0.1527 - val_accuracy: 0.9539 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1137 - accuracy: 0.9665 - val_loss: 0.1546 - val_accuracy: 0.9541 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1158 - accuracy: 0.9651 - val_loss: 0.1632 - val_accuracy: 0.9517 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1213 - accuracy: 0.9638 - val_loss: 0.1600 - val_accuracy: 0.9519 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1193 - accuracy: 0.9622 - val_loss: 0.1552 - val_accuracy: 0.9529 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1122 - accuracy: 0.9635 - val_loss: 0.1583 - val_accuracy: 0.9522 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1086 - accuracy: 0.9659 - val_loss: 0.1500 - val_accuracy: 0.9557 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1117 - accuracy: 0.9646 - val_loss: 0.1532 - val_accuracy: 0.9542 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1110 - accuracy: 0.9652 - val_loss: 0.1530 - val_accuracy: 0.9542 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1139 - accuracy: 0.9649 - val_loss: 0.1520 - val_accuracy: 0.9548 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1122 - accuracy: 0.9639 - val_loss: 0.1561 - val_accuracy: 0.9531 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1142 - accuracy: 0.9665 - val_loss: 0.1482 - val_accuracy: 0.9562 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1108 - accuracy: 0.9633 - val_loss: 0.1533 - val_accuracy: 0.9544 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1085 - accuracy: 0.9676 - val_loss: 0.1525 - val_accuracy: 0.9546 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1097 - accuracy: 0.9638 - val_loss: 0.1517 - val_accuracy: 0.9548 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1135 - accuracy: 0.9646 - val_loss: 0.1554 - val_accuracy: 0.9538 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1175 - accuracy: 0.9643 - val_loss: 0.1490 - val_accuracy: 0.9554 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1099 - accuracy: 0.9642 - val_loss: 0.1546 - val_accuracy: 0.9541 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1134 - accuracy: 0.9642 - val_loss: 0.1544 - val_accuracy: 0.9542 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1109 - accuracy: 0.9623 - val_loss: 0.1543 - val_accuracy: 0.9541 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1119 - accuracy: 0.9638 - val_loss: 0.1518 - val_accuracy: 0.9551 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1113 - accuracy: 0.9668 - val_loss: 0.1526 - val_accuracy: 0.9545 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1108 - accuracy: 0.9647 - val_loss: 0.1537 - val_accuracy: 0.9546 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1113 - accuracy: 0.9651 - val_loss: 0.1480 - val_accuracy: 0.9559 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1128 - accuracy: 0.9635 - val_loss: 0.1528 - val_accuracy: 0.9546 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1146 - accuracy: 0.9644 - val_loss: 0.1520 - val_accuracy: 0.9548 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1121 - accuracy: 0.9641 - val_loss: 0.1487 - val_accuracy: 0.9560 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1107 - accuracy: 0.9648 - val_loss: 0.1523 - val_accuracy: 0.9546 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1088 - accuracy: 0.9658 - val_loss: 0.1546 - val_accuracy: 0.9540 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1084 - accuracy: 0.9667 - val_loss: 0.1533 - val_accuracy: 0.9546 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1078 - accuracy: 0.9677 - val_loss: 0.1545 - val_accuracy: 0.9546 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1112 - accuracy: 0.9657 - val_loss: 0.1512 - val_accuracy: 0.9554 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1141 - accuracy: 0.9658 - val_loss: 0.1506 - val_accuracy: 0.9556 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1125 - accuracy: 0.9658 - val_loss: 0.1549 - val_accuracy: 0.9544 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1137 - accuracy: 0.9647 - val_loss: 0.1524 - val_accuracy: 0.9549 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1130 - accuracy: 0.9638 - val_loss: 0.1508 - val_accuracy: 0.9555 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1093 - accuracy: 0.9646 - val_loss: 0.1546 - val_accuracy: 0.9543 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.1119 - accuracy: 0.9649 - val_loss: 0.1573 - val_accuracy: 0.9537 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1101 - accuracy: 0.9655 - val_loss: 0.1529 - val_accuracy: 0.9545 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 8ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 17s 30ms/step - loss: 6.2850 - accuracy: 0.7358 - val_loss: 9.1674 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 5.0281 - accuracy: 0.7589 - val_loss: 4.7171 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 2.7854 - accuracy: 0.7867 - val_loss: 8.4052 - val_accuracy: 0.1027 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 3.5384 - accuracy: 0.7431 - val_loss: 39.4499 - val_accuracy: 0.1026 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 2.4822 - accuracy: 0.7686 - val_loss: 1.0503 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.3666 - accuracy: 0.7940 - val_loss: 4.3297 - val_accuracy: 0.3320 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 1.9894 - accuracy: 0.8043 - val_loss: 3.5383 - val_accuracy: 0.4339 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.9072 - accuracy: 0.8121 - val_loss: 0.5115 - val_accuracy: 0.8929 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.8714 - accuracy: 0.8181 - val_loss: 0.7375 - val_accuracy: 0.9014 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.1969 - accuracy: 0.8166 - val_loss: 1.9585 - val_accuracy: 0.8974 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 1.1625 - accuracy: 0.8213 - val_loss: 1.0172 - val_accuracy: 0.9052 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.8025 - accuracy: 0.8300 - val_loss: 1.9946 - val_accuracy: 0.6631 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.6614 - accuracy: 0.8299 - val_loss: 0.4806 - val_accuracy: 0.8984 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.6021 - accuracy: 0.8348 - val_loss: 1.0695 - val_accuracy: 0.6314 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.6454 - accuracy: 0.8332 - val_loss: 3.4669 - val_accuracy: 0.2120 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.6675 - accuracy: 0.8340 - val_loss: 0.8886 - val_accuracy: 0.6833 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5532 - accuracy: 0.8329 - val_loss: 0.6718 - val_accuracy: 0.8977 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5813 - accuracy: 0.8394 - val_loss: 0.5226 - val_accuracy: 0.9152 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.5359 - accuracy: 0.8460 - val_loss: 0.4956 - val_accuracy: 0.8992 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5310 - accuracy: 0.8493 - val_loss: 0.7448 - val_accuracy: 0.8974 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5845 - accuracy: 0.8476 - val_loss: 1.9395 - val_accuracy: 0.2653 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4867 - accuracy: 0.8490 - val_loss: 4.0117 - val_accuracy: 0.1026 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5384 - accuracy: 0.8587 - val_loss: 0.7464 - val_accuracy: 0.7593 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4460 - accuracy: 0.8633 - val_loss: 0.5197 - val_accuracy: 0.8980 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4264 - accuracy: 0.8626 - val_loss: 0.9872 - val_accuracy: 0.8974 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4527 - accuracy: 0.8667 - val_loss: 0.7200 - val_accuracy: 0.7755 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3947 - accuracy: 0.8729 - val_loss: 0.3206 - val_accuracy: 0.9155 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3803 - accuracy: 0.8792 - val_loss: 0.9168 - val_accuracy: 0.8975 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3607 - accuracy: 0.8844 - val_loss: 0.5780 - val_accuracy: 0.8282 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3372 - accuracy: 0.8895 - val_loss: 1.5505 - val_accuracy: 0.6646 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3403 - accuracy: 0.8872 - val_loss: 0.2543 - val_accuracy: 0.9104 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3295 - accuracy: 0.8913 - val_loss: 0.2252 - val_accuracy: 0.9302 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3094 - accuracy: 0.8922 - val_loss: 0.2821 - val_accuracy: 0.9172 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2989 - accuracy: 0.8984 - val_loss: 0.4668 - val_accuracy: 0.8419 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3064 - accuracy: 0.8943 - val_loss: 0.8295 - val_accuracy: 0.8975 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2916 - accuracy: 0.8969 - val_loss: 0.4742 - val_accuracy: 0.8451 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2909 - accuracy: 0.8962 - val_loss: 0.8018 - val_accuracy: 0.7916 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2758 - accuracy: 0.9030 - val_loss: 0.2658 - val_accuracy: 0.9067 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2692 - accuracy: 0.9070 - val_loss: 0.2069 - val_accuracy: 0.9298 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2614 - accuracy: 0.9080 - val_loss: 0.1881 - val_accuracy: 0.9419 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2412 - accuracy: 0.9147 - val_loss: 0.2138 - val_accuracy: 0.9257 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2401 - accuracy: 0.9161 - val_loss: 0.3861 - val_accuracy: 0.8699 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2414 - accuracy: 0.9187 - val_loss: 0.2289 - val_accuracy: 0.9215 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2313 - accuracy: 0.9183 - val_loss: 0.2456 - val_accuracy: 0.9154 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2252 - accuracy: 0.9250 - val_loss: 0.2042 - val_accuracy: 0.9296 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2279 - accuracy: 0.9289 - val_loss: 0.2696 - val_accuracy: 0.9062 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2178 - accuracy: 0.9251 - val_loss: 0.2012 - val_accuracy: 0.9308 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2173 - accuracy: 0.9230 - val_loss: 0.1753 - val_accuracy: 0.9450 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2083 - accuracy: 0.9247 - val_loss: 0.2392 - val_accuracy: 0.9174 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2054 - accuracy: 0.9288 - val_loss: 0.3118 - val_accuracy: 0.8972 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1980 - accuracy: 0.9313 - val_loss: 0.1979 - val_accuracy: 0.9342 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2082 - accuracy: 0.9305 - val_loss: 0.2161 - val_accuracy: 0.9231 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1916 - accuracy: 0.9353 - val_loss: 0.2013 - val_accuracy: 0.9311 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1996 - accuracy: 0.9323 - val_loss: 0.1959 - val_accuracy: 0.9333 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1904 - accuracy: 0.9362 - val_loss: 0.2300 - val_accuracy: 0.9240 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1871 - accuracy: 0.9339 - val_loss: 0.9250 - val_accuracy: 0.6949 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1890 - accuracy: 0.9365 - val_loss: 0.1870 - val_accuracy: 0.9390 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1843 - accuracy: 0.9358 - val_loss: 0.2097 - val_accuracy: 0.9282 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1805 - accuracy: 0.9367 - val_loss: 0.2416 - val_accuracy: 0.9188 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1814 - accuracy: 0.9323 - val_loss: 0.1884 - val_accuracy: 0.9381 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1842 - accuracy: 0.9371 - val_loss: 0.1936 - val_accuracy: 0.9357 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1737 - accuracy: 0.9394 - val_loss: 0.3053 - val_accuracy: 0.8985 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1753 - accuracy: 0.9385 - val_loss: 0.2044 - val_accuracy: 0.9325 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1731 - accuracy: 0.9421 - val_loss: 0.2035 - val_accuracy: 0.9323 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1678 - accuracy: 0.9398 - val_loss: 0.1841 - val_accuracy: 0.9406 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1664 - accuracy: 0.9441 - val_loss: 0.2242 - val_accuracy: 0.9253 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1707 - accuracy: 0.9425 - val_loss: 0.2284 - val_accuracy: 0.9252 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1652 - accuracy: 0.9413 - val_loss: 0.1905 - val_accuracy: 0.9370 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1627 - accuracy: 0.9414 - val_loss: 0.2240 - val_accuracy: 0.9263 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1636 - accuracy: 0.9418 - val_loss: 0.1879 - val_accuracy: 0.9391 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1643 - accuracy: 0.9426 - val_loss: 0.2011 - val_accuracy: 0.9344 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1626 - accuracy: 0.9443 - val_loss: 0.1959 - val_accuracy: 0.9354 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1691 - accuracy: 0.9415 - val_loss: 0.2038 - val_accuracy: 0.9322 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1652 - accuracy: 0.9417 - val_loss: 0.1949 - val_accuracy: 0.9356 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1645 - accuracy: 0.9426 - val_loss: 0.1938 - val_accuracy: 0.9351 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1596 - accuracy: 0.9437 - val_loss: 0.1961 - val_accuracy: 0.9352 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1646 - accuracy: 0.9435 - val_loss: 0.1986 - val_accuracy: 0.9344 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1628 - accuracy: 0.9437 - val_loss: 0.1866 - val_accuracy: 0.9385 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1591 - accuracy: 0.9456 - val_loss: 0.1905 - val_accuracy: 0.9372 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1582 - accuracy: 0.9465 - val_loss: 0.1906 - val_accuracy: 0.9369 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1586 - accuracy: 0.9431 - val_loss: 0.1981 - val_accuracy: 0.9343 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1571 - accuracy: 0.9450 - val_loss: 0.1949 - val_accuracy: 0.9362 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1553 - accuracy: 0.9436 - val_loss: 0.2006 - val_accuracy: 0.9335 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1588 - accuracy: 0.9468 - val_loss: 0.1902 - val_accuracy: 0.9372 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1573 - accuracy: 0.9466 - val_loss: 0.1914 - val_accuracy: 0.9378 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1568 - accuracy: 0.9462 - val_loss: 0.1931 - val_accuracy: 0.9366 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1620 - accuracy: 0.9439 - val_loss: 0.1903 - val_accuracy: 0.9382 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1568 - accuracy: 0.9464 - val_loss: 0.1941 - val_accuracy: 0.9366 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1611 - accuracy: 0.9447 - val_loss: 0.1973 - val_accuracy: 0.9353 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1634 - accuracy: 0.9461 - val_loss: 0.1906 - val_accuracy: 0.9380 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1593 - accuracy: 0.9465 - val_loss: 0.1908 - val_accuracy: 0.9378 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1575 - accuracy: 0.9475 - val_loss: 0.1947 - val_accuracy: 0.9361 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1494 - accuracy: 0.9476 - val_loss: 0.1927 - val_accuracy: 0.9370 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1562 - accuracy: 0.9463 - val_loss: 0.1900 - val_accuracy: 0.9379 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1572 - accuracy: 0.9464 - val_loss: 0.1908 - val_accuracy: 0.9373 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1650 - accuracy: 0.9432 - val_loss: 0.1914 - val_accuracy: 0.9367 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1558 - accuracy: 0.9472 - val_loss: 0.1918 - val_accuracy: 0.9368 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1565 - accuracy: 0.9463 - val_loss: 0.1899 - val_accuracy: 0.9379 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1549 - accuracy: 0.9475 - val_loss: 0.1888 - val_accuracy: 0.9383 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1547 - accuracy: 0.9457 - val_loss: 0.1911 - val_accuracy: 0.9374 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 7.1905 - accuracy: 0.7382 - val_loss: 3.9177 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 4.3064 - accuracy: 0.7524 - val_loss: 2.5427 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 2.9281 - accuracy: 0.7706 - val_loss: 2.8953 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 3.1884 - accuracy: 0.7712 - val_loss: 1.9968 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.7897 - accuracy: 0.7819 - val_loss: 1.5870 - val_accuracy: 0.7271 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.6943 - accuracy: 0.8020 - val_loss: 4.7169 - val_accuracy: 0.1026 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.6829 - accuracy: 0.8012 - val_loss: 1.0299 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.3624 - accuracy: 0.8017 - val_loss: 3.8310 - val_accuracy: 0.2448 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.0325 - accuracy: 0.8089 - val_loss: 3.5695 - val_accuracy: 0.1869 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.9142 - accuracy: 0.8104 - val_loss: 0.5016 - val_accuracy: 0.8994 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.1653 - accuracy: 0.8188 - val_loss: 2.6381 - val_accuracy: 0.3875 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.9825 - accuracy: 0.8254 - val_loss: 0.8072 - val_accuracy: 0.8998 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.0074 - accuracy: 0.8234 - val_loss: 4.2558 - val_accuracy: 0.1944 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.0267 - accuracy: 0.8278 - val_loss: 3.4798 - val_accuracy: 0.3094 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.7051 - accuracy: 0.8332 - val_loss: 0.3986 - val_accuracy: 0.9038 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.7487 - accuracy: 0.8340 - val_loss: 7.7857 - val_accuracy: 0.8974 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.8351 - accuracy: 0.8366 - val_loss: 0.2668 - val_accuracy: 0.9186 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.6026 - accuracy: 0.8369 - val_loss: 0.4437 - val_accuracy: 0.8997 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.7583 - accuracy: 0.8383 - val_loss: 2.7561 - val_accuracy: 0.1026 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5234 - accuracy: 0.8449 - val_loss: 0.4443 - val_accuracy: 0.8981 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4664 - accuracy: 0.8435 - val_loss: 0.5655 - val_accuracy: 0.7966 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4880 - accuracy: 0.8483 - val_loss: 0.8936 - val_accuracy: 0.7952 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4993 - accuracy: 0.8541 - val_loss: 0.5662 - val_accuracy: 0.8163 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4337 - accuracy: 0.8533 - val_loss: 0.2739 - val_accuracy: 0.9229 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4148 - accuracy: 0.8528 - val_loss: 2.9756 - val_accuracy: 0.2102 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.4028 - accuracy: 0.8534 - val_loss: 0.4190 - val_accuracy: 0.8405 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3762 - accuracy: 0.8554 - val_loss: 0.9825 - val_accuracy: 0.7190 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.3875 - accuracy: 0.8550 - val_loss: 0.2340 - val_accuracy: 0.9276 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3857 - accuracy: 0.8587 - val_loss: 0.7627 - val_accuracy: 0.8025 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3579 - accuracy: 0.8621 - val_loss: 1.2273 - val_accuracy: 0.6533 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.3475 - accuracy: 0.8603 - val_loss: 0.3298 - val_accuracy: 0.8602 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3406 - accuracy: 0.8706 - val_loss: 0.3311 - val_accuracy: 0.8726 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3268 - accuracy: 0.8639 - val_loss: 0.2750 - val_accuracy: 0.8957 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3185 - accuracy: 0.8763 - val_loss: 0.2429 - val_accuracy: 0.9100 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.3181 - accuracy: 0.8712 - val_loss: 0.1908 - val_accuracy: 0.9313 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3088 - accuracy: 0.8741 - val_loss: 0.3261 - val_accuracy: 0.8604 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2997 - accuracy: 0.8780 - val_loss: 0.4101 - val_accuracy: 0.8365 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2868 - accuracy: 0.8830 - val_loss: 0.1959 - val_accuracy: 0.9340 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2844 - accuracy: 0.8897 - val_loss: 0.6421 - val_accuracy: 0.7677 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2873 - accuracy: 0.8882 - val_loss: 0.1902 - val_accuracy: 0.9347 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.2803 - accuracy: 0.8921 - val_loss: 0.4097 - val_accuracy: 0.8387 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 15s 28ms/step - loss: 0.2749 - accuracy: 0.8918 - val_loss: 0.2805 - val_accuracy: 0.8916 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.2681 - accuracy: 0.8938 - val_loss: 0.1772 - val_accuracy: 0.9405 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.2655 - accuracy: 0.8972 - val_loss: 0.1754 - val_accuracy: 0.9432 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 14s 27ms/step - loss: 0.2557 - accuracy: 0.8987 - val_loss: 0.1820 - val_accuracy: 0.9388 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2494 - accuracy: 0.9062 - val_loss: 0.3491 - val_accuracy: 0.8692 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2440 - accuracy: 0.9063 - val_loss: 0.1947 - val_accuracy: 0.9356 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2426 - accuracy: 0.9076 - val_loss: 0.2107 - val_accuracy: 0.9224 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2397 - accuracy: 0.9090 - val_loss: 0.2349 - val_accuracy: 0.9164 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2337 - accuracy: 0.9101 - val_loss: 0.1904 - val_accuracy: 0.9356 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 16s 29ms/step - loss: 0.2271 - accuracy: 0.9183 - val_loss: 0.3518 - val_accuracy: 0.8683 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2251 - accuracy: 0.9169 - val_loss: 0.1891 - val_accuracy: 0.9337 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2229 - accuracy: 0.9206 - val_loss: 0.4396 - val_accuracy: 0.8468 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2115 - accuracy: 0.9209 - val_loss: 0.3864 - val_accuracy: 0.8638 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2094 - accuracy: 0.9199 - val_loss: 0.1920 - val_accuracy: 0.9302 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2112 - accuracy: 0.9213 - val_loss: 0.2740 - val_accuracy: 0.9003 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2064 - accuracy: 0.9259 - val_loss: 0.2040 - val_accuracy: 0.9279 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2029 - accuracy: 0.9241 - val_loss: 0.2549 - val_accuracy: 0.9091 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1987 - accuracy: 0.9245 - val_loss: 0.1950 - val_accuracy: 0.9308 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1989 - accuracy: 0.9273 - val_loss: 0.2052 - val_accuracy: 0.9279 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2049 - accuracy: 0.9261 - val_loss: 0.1945 - val_accuracy: 0.9327 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1986 - accuracy: 0.9275 - val_loss: 0.2146 - val_accuracy: 0.9245 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2049 - accuracy: 0.9239 - val_loss: 0.1889 - val_accuracy: 0.9355 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1928 - accuracy: 0.9245 - val_loss: 0.2765 - val_accuracy: 0.9013 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1897 - accuracy: 0.9284 - val_loss: 0.1932 - val_accuracy: 0.9332 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1888 - accuracy: 0.9282 - val_loss: 0.1760 - val_accuracy: 0.9408 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1921 - accuracy: 0.9314 - val_loss: 0.1612 - val_accuracy: 0.9453 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1901 - accuracy: 0.9323 - val_loss: 0.2072 - val_accuracy: 0.9270 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1845 - accuracy: 0.9338 - val_loss: 0.1950 - val_accuracy: 0.9315 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1944 - accuracy: 0.9299 - val_loss: 0.1763 - val_accuracy: 0.9395 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1892 - accuracy: 0.9264 - val_loss: 0.2762 - val_accuracy: 0.9001 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1803 - accuracy: 0.9313 - val_loss: 0.1871 - val_accuracy: 0.9350 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1872 - accuracy: 0.9280 - val_loss: 0.1709 - val_accuracy: 0.9420 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1858 - accuracy: 0.9293 - val_loss: 0.2639 - val_accuracy: 0.9065 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1751 - accuracy: 0.9312 - val_loss: 0.1812 - val_accuracy: 0.9389 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1786 - accuracy: 0.9330 - val_loss: 0.1836 - val_accuracy: 0.9370 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1759 - accuracy: 0.9309 - val_loss: 0.1892 - val_accuracy: 0.9352 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1734 - accuracy: 0.9330 - val_loss: 0.1813 - val_accuracy: 0.9380 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1770 - accuracy: 0.9318 - val_loss: 0.1791 - val_accuracy: 0.9391 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1801 - accuracy: 0.9303 - val_loss: 0.1966 - val_accuracy: 0.9311 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1835 - accuracy: 0.9331 - val_loss: 0.1650 - val_accuracy: 0.9443 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1778 - accuracy: 0.9356 - val_loss: 0.1879 - val_accuracy: 0.9342 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1789 - accuracy: 0.9333 - val_loss: 0.1824 - val_accuracy: 0.9371 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1724 - accuracy: 0.9359 - val_loss: 0.1826 - val_accuracy: 0.9367 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1773 - accuracy: 0.9360 - val_loss: 0.1788 - val_accuracy: 0.9385 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1762 - accuracy: 0.9331 - val_loss: 0.1874 - val_accuracy: 0.9353 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1687 - accuracy: 0.9375 - val_loss: 0.1820 - val_accuracy: 0.9372 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1793 - accuracy: 0.9358 - val_loss: 0.1810 - val_accuracy: 0.9375 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1807 - accuracy: 0.9343 - val_loss: 0.1838 - val_accuracy: 0.9366 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1756 - accuracy: 0.9363 - val_loss: 0.1819 - val_accuracy: 0.9380 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1754 - accuracy: 0.9353 - val_loss: 0.1863 - val_accuracy: 0.9356 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1767 - accuracy: 0.9339 - val_loss: 0.1869 - val_accuracy: 0.9358 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1782 - accuracy: 0.9347 - val_loss: 0.1891 - val_accuracy: 0.9344 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1808 - accuracy: 0.9325 - val_loss: 0.1808 - val_accuracy: 0.9377 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1829 - accuracy: 0.9332 - val_loss: 0.1858 - val_accuracy: 0.9360 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1772 - accuracy: 0.9348 - val_loss: 0.1816 - val_accuracy: 0.9376 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1734 - accuracy: 0.9346 - val_loss: 0.1828 - val_accuracy: 0.9374 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1757 - accuracy: 0.9361 - val_loss: 0.1831 - val_accuracy: 0.9371 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1777 - accuracy: 0.9331 - val_loss: 0.1864 - val_accuracy: 0.9356 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1796 - accuracy: 0.9337 - val_loss: 0.1887 - val_accuracy: 0.9351 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 6.6508 - accuracy: 0.7461 - val_loss: 3.2909 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 3.9825 - accuracy: 0.7702 - val_loss: 3.4278 - val_accuracy: 0.5612 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 3.3046 - accuracy: 0.7787 - val_loss: 2.1863 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 3.3186 - accuracy: 0.7395 - val_loss: 5.4732 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 2.8868 - accuracy: 0.7801 - val_loss: 0.8377 - val_accuracy: 0.9058 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.1780 - accuracy: 0.8101 - val_loss: 0.9597 - val_accuracy: 0.8974 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.8771 - accuracy: 0.8138 - val_loss: 0.6160 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.7262 - accuracy: 0.8112 - val_loss: 0.6179 - val_accuracy: 0.8974 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.7256 - accuracy: 0.8093 - val_loss: 0.6222 - val_accuracy: 0.8329 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.6490 - accuracy: 0.8218 - val_loss: 0.5086 - val_accuracy: 0.8976 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5952 - accuracy: 0.8274 - val_loss: 0.4579 - val_accuracy: 0.8493 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5448 - accuracy: 0.8252 - val_loss: 2.5656 - val_accuracy: 0.3702 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4863 - accuracy: 0.8316 - val_loss: 0.5580 - val_accuracy: 0.8974 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4928 - accuracy: 0.8274 - val_loss: 0.3485 - val_accuracy: 0.8959 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4699 - accuracy: 0.8342 - val_loss: 0.2955 - val_accuracy: 0.9062 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4542 - accuracy: 0.8331 - val_loss: 2.7911 - val_accuracy: 0.3703 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4336 - accuracy: 0.8374 - val_loss: 0.4258 - val_accuracy: 0.8974 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4870 - accuracy: 0.8298 - val_loss: 0.4240 - val_accuracy: 0.8974 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4391 - accuracy: 0.8388 - val_loss: 0.2624 - val_accuracy: 0.9103 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4320 - accuracy: 0.8407 - val_loss: 2.1064 - val_accuracy: 0.5066 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4210 - accuracy: 0.8334 - val_loss: 0.4055 - val_accuracy: 0.8379 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4093 - accuracy: 0.8408 - val_loss: 0.3246 - val_accuracy: 0.8982 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3930 - accuracy: 0.8492 - val_loss: 0.8370 - val_accuracy: 0.7490 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3847 - accuracy: 0.8485 - val_loss: 0.6265 - val_accuracy: 0.7801 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3709 - accuracy: 0.8579 - val_loss: 0.3527 - val_accuracy: 0.8681 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3488 - accuracy: 0.8648 - val_loss: 0.2274 - val_accuracy: 0.9266 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3539 - accuracy: 0.8634 - val_loss: 0.2571 - val_accuracy: 0.8976 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3298 - accuracy: 0.8707 - val_loss: 0.2092 - val_accuracy: 0.9322 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3345 - accuracy: 0.8699 - val_loss: 0.2251 - val_accuracy: 0.9209 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3329 - accuracy: 0.8673 - val_loss: 0.2081 - val_accuracy: 0.9263 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3268 - accuracy: 0.8710 - val_loss: 0.1962 - val_accuracy: 0.9320 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3092 - accuracy: 0.8755 - val_loss: 0.7530 - val_accuracy: 0.7329 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3063 - accuracy: 0.8740 - val_loss: 0.2363 - val_accuracy: 0.9075 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2961 - accuracy: 0.8824 - val_loss: 0.1884 - val_accuracy: 0.9350 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3061 - accuracy: 0.8804 - val_loss: 0.4034 - val_accuracy: 0.8366 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2932 - accuracy: 0.8832 - val_loss: 1.1591 - val_accuracy: 0.6437 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2807 - accuracy: 0.8809 - val_loss: 0.2127 - val_accuracy: 0.9154 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2871 - accuracy: 0.8852 - val_loss: 0.2420 - val_accuracy: 0.8936 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2733 - accuracy: 0.8848 - val_loss: 0.1705 - val_accuracy: 0.9410 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2754 - accuracy: 0.8847 - val_loss: 0.2831 - val_accuracy: 0.8765 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2680 - accuracy: 0.8865 - val_loss: 0.3283 - val_accuracy: 0.8634 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2590 - accuracy: 0.8911 - val_loss: 0.2304 - val_accuracy: 0.9063 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2549 - accuracy: 0.8979 - val_loss: 0.2848 - val_accuracy: 0.8814 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2580 - accuracy: 0.8910 - val_loss: 0.1673 - val_accuracy: 0.9403 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2483 - accuracy: 0.8947 - val_loss: 0.2602 - val_accuracy: 0.8918 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2506 - accuracy: 0.8966 - val_loss: 0.1741 - val_accuracy: 0.9311 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2510 - accuracy: 0.8910 - val_loss: 0.2253 - val_accuracy: 0.9027 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2415 - accuracy: 0.8978 - val_loss: 0.3057 - val_accuracy: 0.8723 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2425 - accuracy: 0.8954 - val_loss: 0.2289 - val_accuracy: 0.9043 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2443 - accuracy: 0.8968 - val_loss: 0.2465 - val_accuracy: 0.8970 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2412 - accuracy: 0.8988 - val_loss: 0.2599 - val_accuracy: 0.8899 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2344 - accuracy: 0.8987 - val_loss: 0.1919 - val_accuracy: 0.9231 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2336 - accuracy: 0.9000 - val_loss: 0.2173 - val_accuracy: 0.9059 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2347 - accuracy: 0.9002 - val_loss: 0.1795 - val_accuracy: 0.9290 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2239 - accuracy: 0.9036 - val_loss: 0.1887 - val_accuracy: 0.9229 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2250 - accuracy: 0.9041 - val_loss: 0.1811 - val_accuracy: 0.9281 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2280 - accuracy: 0.9015 - val_loss: 0.2057 - val_accuracy: 0.9157 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2185 - accuracy: 0.9060 - val_loss: 0.1711 - val_accuracy: 0.9321 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2245 - accuracy: 0.9033 - val_loss: 0.1796 - val_accuracy: 0.9275 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2228 - accuracy: 0.9076 - val_loss: 0.1717 - val_accuracy: 0.9317 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2120 - accuracy: 0.9082 - val_loss: 0.2124 - val_accuracy: 0.9143 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2235 - accuracy: 0.9056 - val_loss: 0.1783 - val_accuracy: 0.9297 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2172 - accuracy: 0.9064 - val_loss: 0.1835 - val_accuracy: 0.9273 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2074 - accuracy: 0.9128 - val_loss: 0.1862 - val_accuracy: 0.9269 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2113 - accuracy: 0.9152 - val_loss: 0.1890 - val_accuracy: 0.9260 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2119 - accuracy: 0.9142 - val_loss: 0.2050 - val_accuracy: 0.9168 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2156 - accuracy: 0.9118 - val_loss: 0.1987 - val_accuracy: 0.9193 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2121 - accuracy: 0.9125 - val_loss: 0.2044 - val_accuracy: 0.9168 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2052 - accuracy: 0.9124 - val_loss: 0.1825 - val_accuracy: 0.9289 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2022 - accuracy: 0.9167 - val_loss: 0.1991 - val_accuracy: 0.9202 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2059 - accuracy: 0.9151 - val_loss: 0.1823 - val_accuracy: 0.9286 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2076 - accuracy: 0.9180 - val_loss: 0.1780 - val_accuracy: 0.9314 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2012 - accuracy: 0.9184 - val_loss: 0.1756 - val_accuracy: 0.9307 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2095 - accuracy: 0.9148 - val_loss: 0.1825 - val_accuracy: 0.9296 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1947 - accuracy: 0.9193 - val_loss: 0.1768 - val_accuracy: 0.9319 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2005 - accuracy: 0.9201 - val_loss: 0.1831 - val_accuracy: 0.9281 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2003 - accuracy: 0.9209 - val_loss: 0.1850 - val_accuracy: 0.9271 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1990 - accuracy: 0.9166 - val_loss: 0.1925 - val_accuracy: 0.9244 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2008 - accuracy: 0.9189 - val_loss: 0.1834 - val_accuracy: 0.9280 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2040 - accuracy: 0.9198 - val_loss: 0.1857 - val_accuracy: 0.9271 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1995 - accuracy: 0.9177 - val_loss: 0.1881 - val_accuracy: 0.9262 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2001 - accuracy: 0.9168 - val_loss: 0.1863 - val_accuracy: 0.9267 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2008 - accuracy: 0.9174 - val_loss: 0.1793 - val_accuracy: 0.9293 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1928 - accuracy: 0.9187 - val_loss: 0.1771 - val_accuracy: 0.9313 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1955 - accuracy: 0.9207 - val_loss: 0.1807 - val_accuracy: 0.9301 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1948 - accuracy: 0.9193 - val_loss: 0.1892 - val_accuracy: 0.9259 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1951 - accuracy: 0.9191 - val_loss: 0.1863 - val_accuracy: 0.9269 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1991 - accuracy: 0.9199 - val_loss: 0.1810 - val_accuracy: 0.9294 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2005 - accuracy: 0.9187 - val_loss: 0.1838 - val_accuracy: 0.9279 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2014 - accuracy: 0.9173 - val_loss: 0.1838 - val_accuracy: 0.9285 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1966 - accuracy: 0.9209 - val_loss: 0.1863 - val_accuracy: 0.9266 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2016 - accuracy: 0.9199 - val_loss: 0.1815 - val_accuracy: 0.9291 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1955 - accuracy: 0.9178 - val_loss: 0.1859 - val_accuracy: 0.9267 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1953 - accuracy: 0.9205 - val_loss: 0.1815 - val_accuracy: 0.9289 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1935 - accuracy: 0.9204 - val_loss: 0.1833 - val_accuracy: 0.9282 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2016 - accuracy: 0.9185 - val_loss: 0.1874 - val_accuracy: 0.9260 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1905 - accuracy: 0.9178 - val_loss: 0.1809 - val_accuracy: 0.9294 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1958 - accuracy: 0.9196 - val_loss: 0.1858 - val_accuracy: 0.9269 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2027 - accuracy: 0.9201 - val_loss: 0.1829 - val_accuracy: 0.9285 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1977 - accuracy: 0.9203 - val_loss: 0.1877 - val_accuracy: 0.9263 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 2.4809 - accuracy: 0.7791 - val_loss: 2.1136 - val_accuracy: 0.7555 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.8117 - accuracy: 0.8159 - val_loss: 1.9974 - val_accuracy: 0.1761 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.3617 - accuracy: 0.8209 - val_loss: 1.4875 - val_accuracy: 0.9100 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.2630 - accuracy: 0.8057 - val_loss: 1.0825 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.7523 - accuracy: 0.8176 - val_loss: 0.8036 - val_accuracy: 0.8318 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.8536 - accuracy: 0.8265 - val_loss: 0.6939 - val_accuracy: 0.8974 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.6188 - accuracy: 0.8398 - val_loss: 0.9469 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.9086 - accuracy: 0.8125 - val_loss: 1.0880 - val_accuracy: 0.8167 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.9705 - accuracy: 0.8392 - val_loss: 3.4513 - val_accuracy: 0.3758 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.9266 - accuracy: 0.8456 - val_loss: 0.8588 - val_accuracy: 0.9161 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.7512 - accuracy: 0.8513 - val_loss: 1.5321 - val_accuracy: 0.6829 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5597 - accuracy: 0.8635 - val_loss: 4.4796 - val_accuracy: 0.1026 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5049 - accuracy: 0.8761 - val_loss: 5.7670 - val_accuracy: 0.3781 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.6459 - accuracy: 0.8691 - val_loss: 5.2686 - val_accuracy: 0.1060 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4862 - accuracy: 0.8868 - val_loss: 0.5182 - val_accuracy: 0.9007 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4418 - accuracy: 0.8979 - val_loss: 1.9671 - val_accuracy: 0.8974 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4632 - accuracy: 0.9055 - val_loss: 1.1642 - val_accuracy: 0.6598 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4649 - accuracy: 0.8965 - val_loss: 0.3448 - val_accuracy: 0.9331 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4414 - accuracy: 0.9051 - val_loss: 1.0614 - val_accuracy: 0.7137 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4026 - accuracy: 0.9164 - val_loss: 4.1276 - val_accuracy: 0.2389 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3539 - accuracy: 0.9226 - val_loss: 0.2790 - val_accuracy: 0.9396 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3325 - accuracy: 0.9249 - val_loss: 0.2663 - val_accuracy: 0.9434 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2884 - accuracy: 0.9285 - val_loss: 0.2649 - val_accuracy: 0.9463 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2799 - accuracy: 0.9339 - val_loss: 0.5084 - val_accuracy: 0.8554 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2882 - accuracy: 0.9358 - val_loss: 0.4374 - val_accuracy: 0.9145 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2549 - accuracy: 0.9335 - val_loss: 0.5440 - val_accuracy: 0.9113 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2426 - accuracy: 0.9420 - val_loss: 0.2025 - val_accuracy: 0.9549 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2585 - accuracy: 0.9394 - val_loss: 0.2466 - val_accuracy: 0.9424 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2326 - accuracy: 0.9423 - val_loss: 0.1990 - val_accuracy: 0.9522 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2050 - accuracy: 0.9478 - val_loss: 0.3239 - val_accuracy: 0.9316 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2200 - accuracy: 0.9469 - val_loss: 0.2283 - val_accuracy: 0.9433 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1948 - accuracy: 0.9514 - val_loss: 0.4325 - val_accuracy: 0.9221 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2171 - accuracy: 0.9488 - val_loss: 0.6532 - val_accuracy: 0.8101 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2103 - accuracy: 0.9459 - val_loss: 0.2351 - val_accuracy: 0.9384 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1970 - accuracy: 0.9479 - val_loss: 0.2392 - val_accuracy: 0.9322 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1881 - accuracy: 0.9495 - val_loss: 0.2281 - val_accuracy: 0.9386 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1979 - accuracy: 0.9433 - val_loss: 0.2261 - val_accuracy: 0.9513 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1772 - accuracy: 0.9535 - val_loss: 0.2682 - val_accuracy: 0.9293 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1704 - accuracy: 0.9564 - val_loss: 0.1898 - val_accuracy: 0.9568 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1691 - accuracy: 0.9535 - val_loss: 0.1837 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1631 - accuracy: 0.9547 - val_loss: 6.1637 - val_accuracy: 0.2077 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1608 - accuracy: 0.9562 - val_loss: 0.5060 - val_accuracy: 0.8592 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1532 - accuracy: 0.9577 - val_loss: 0.2051 - val_accuracy: 0.9547 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1686 - accuracy: 0.9559 - val_loss: 0.3033 - val_accuracy: 0.9424 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1598 - accuracy: 0.9527 - val_loss: 0.1867 - val_accuracy: 0.9551 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1511 - accuracy: 0.9572 - val_loss: 0.1888 - val_accuracy: 0.9540 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1487 - accuracy: 0.9595 - val_loss: 0.4964 - val_accuracy: 0.8583 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1479 - accuracy: 0.9622 - val_loss: 0.1845 - val_accuracy: 0.9563 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1457 - accuracy: 0.9571 - val_loss: 0.1902 - val_accuracy: 0.9518 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1325 - accuracy: 0.9624 - val_loss: 0.2076 - val_accuracy: 0.9515 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1427 - accuracy: 0.9630 - val_loss: 0.3792 - val_accuracy: 0.9013 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1441 - accuracy: 0.9609 - val_loss: 0.2219 - val_accuracy: 0.9498 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1319 - accuracy: 0.9656 - val_loss: 0.1831 - val_accuracy: 0.9558 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1409 - accuracy: 0.9602 - val_loss: 0.3630 - val_accuracy: 0.8992 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1332 - accuracy: 0.9621 - val_loss: 0.1971 - val_accuracy: 0.9564 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1372 - accuracy: 0.9629 - val_loss: 0.3006 - val_accuracy: 0.9230 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1244 - accuracy: 0.9623 - val_loss: 0.1882 - val_accuracy: 0.9537 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1238 - accuracy: 0.9615 - val_loss: 0.1961 - val_accuracy: 0.9551 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1253 - accuracy: 0.9630 - val_loss: 0.1952 - val_accuracy: 0.9556 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1163 - accuracy: 0.9661 - val_loss: 0.2002 - val_accuracy: 0.9554 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1133 - accuracy: 0.9666 - val_loss: 0.1988 - val_accuracy: 0.9510 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1173 - accuracy: 0.9676 - val_loss: 0.1913 - val_accuracy: 0.9559 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1185 - accuracy: 0.9677 - val_loss: 0.1914 - val_accuracy: 0.9548 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1150 - accuracy: 0.9682 - val_loss: 0.1966 - val_accuracy: 0.9523 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1140 - accuracy: 0.9680 - val_loss: 0.1870 - val_accuracy: 0.9562 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1168 - accuracy: 0.9661 - val_loss: 0.1990 - val_accuracy: 0.9520 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1128 - accuracy: 0.9685 - val_loss: 0.1896 - val_accuracy: 0.9538 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1100 - accuracy: 0.9689 - val_loss: 0.2059 - val_accuracy: 0.9492 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1119 - accuracy: 0.9670 - val_loss: 0.1819 - val_accuracy: 0.9566 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1133 - accuracy: 0.9689 - val_loss: 0.1875 - val_accuracy: 0.9556 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1050 - accuracy: 0.9686 - val_loss: 0.1923 - val_accuracy: 0.9537 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1143 - accuracy: 0.9690 - val_loss: 0.1939 - val_accuracy: 0.9532 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1146 - accuracy: 0.9679 - val_loss: 0.1947 - val_accuracy: 0.9533 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1062 - accuracy: 0.9689 - val_loss: 0.1924 - val_accuracy: 0.9549 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1108 - accuracy: 0.9700 - val_loss: 0.1857 - val_accuracy: 0.9558 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1140 - accuracy: 0.9690 - val_loss: 0.1905 - val_accuracy: 0.9552 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1028 - accuracy: 0.9704 - val_loss: 0.1897 - val_accuracy: 0.9553 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1138 - accuracy: 0.9698 - val_loss: 0.1913 - val_accuracy: 0.9558 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1039 - accuracy: 0.9702 - val_loss: 0.1896 - val_accuracy: 0.9551 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1061 - accuracy: 0.9699 - val_loss: 0.1943 - val_accuracy: 0.9537 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1045 - accuracy: 0.9703 - val_loss: 0.1911 - val_accuracy: 0.9551 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1100 - accuracy: 0.9706 - val_loss: 0.1916 - val_accuracy: 0.9556 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1121 - accuracy: 0.9687 - val_loss: 0.1986 - val_accuracy: 0.9529 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1035 - accuracy: 0.9699 - val_loss: 0.1932 - val_accuracy: 0.9546 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1036 - accuracy: 0.9700 - val_loss: 0.1931 - val_accuracy: 0.9557 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1041 - accuracy: 0.9704 - val_loss: 0.1948 - val_accuracy: 0.9539 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1063 - accuracy: 0.9701 - val_loss: 0.1936 - val_accuracy: 0.9548 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1073 - accuracy: 0.9710 - val_loss: 0.1910 - val_accuracy: 0.9554 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1064 - accuracy: 0.9698 - val_loss: 0.1921 - val_accuracy: 0.9555 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1096 - accuracy: 0.9702 - val_loss: 0.1946 - val_accuracy: 0.9546 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1005 - accuracy: 0.9705 - val_loss: 0.1931 - val_accuracy: 0.9549 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1051 - accuracy: 0.9694 - val_loss: 0.1946 - val_accuracy: 0.9546 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1015 - accuracy: 0.9716 - val_loss: 0.1935 - val_accuracy: 0.9546 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1043 - accuracy: 0.9708 - val_loss: 0.1954 - val_accuracy: 0.9538 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1058 - accuracy: 0.9702 - val_loss: 0.1925 - val_accuracy: 0.9547 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1014 - accuracy: 0.9722 - val_loss: 0.1924 - val_accuracy: 0.9548 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1091 - accuracy: 0.9699 - val_loss: 0.1950 - val_accuracy: 0.9543 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1033 - accuracy: 0.9700 - val_loss: 0.1946 - val_accuracy: 0.9540 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1067 - accuracy: 0.9694 - val_loss: 0.1927 - val_accuracy: 0.9555 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1104 - accuracy: 0.9697 - val_loss: 0.1972 - val_accuracy: 0.9536 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 2.8110 - accuracy: 0.7843 - val_loss: 2.1309 - val_accuracy: 0.9011 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.3086 - accuracy: 0.8124 - val_loss: 0.5355 - val_accuracy: 0.8980 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.7492 - accuracy: 0.8211 - val_loss: 1.7885 - val_accuracy: 0.6092 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.6489 - accuracy: 0.8139 - val_loss: 0.5857 - val_accuracy: 0.8174 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.8834 - accuracy: 0.8158 - val_loss: 3.8032 - val_accuracy: 0.1902 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.7693 - accuracy: 0.8339 - val_loss: 2.1159 - val_accuracy: 0.4607 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5504 - accuracy: 0.8353 - val_loss: 0.4746 - val_accuracy: 0.8975 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5001 - accuracy: 0.8365 - val_loss: 0.4040 - val_accuracy: 0.9127 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4739 - accuracy: 0.8468 - val_loss: 1.1154 - val_accuracy: 0.7291 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.5260 - accuracy: 0.8358 - val_loss: 0.3005 - val_accuracy: 0.9144 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4258 - accuracy: 0.8519 - val_loss: 0.2672 - val_accuracy: 0.9185 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4237 - accuracy: 0.8584 - val_loss: 1.4840 - val_accuracy: 0.5849 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4148 - accuracy: 0.8544 - val_loss: 2.5670 - val_accuracy: 0.4187 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3784 - accuracy: 0.8629 - val_loss: 0.4859 - val_accuracy: 0.8456 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3886 - accuracy: 0.8626 - val_loss: 0.6423 - val_accuracy: 0.8173 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3483 - accuracy: 0.8712 - val_loss: 0.8163 - val_accuracy: 0.7477 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3490 - accuracy: 0.8778 - val_loss: 0.2700 - val_accuracy: 0.9144 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3451 - accuracy: 0.8762 - val_loss: 0.2293 - val_accuracy: 0.9325 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3250 - accuracy: 0.8820 - val_loss: 0.3561 - val_accuracy: 0.9020 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3359 - accuracy: 0.8837 - val_loss: 0.2684 - val_accuracy: 0.9191 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3197 - accuracy: 0.8898 - val_loss: 0.2818 - val_accuracy: 0.8997 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3073 - accuracy: 0.8876 - val_loss: 0.2082 - val_accuracy: 0.9373 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2901 - accuracy: 0.8979 - val_loss: 0.3972 - val_accuracy: 0.8658 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2990 - accuracy: 0.8909 - val_loss: 0.2229 - val_accuracy: 0.9267 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2667 - accuracy: 0.9005 - val_loss: 0.1903 - val_accuracy: 0.9410 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2688 - accuracy: 0.8996 - val_loss: 0.2318 - val_accuracy: 0.9199 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2719 - accuracy: 0.9030 - val_loss: 0.5471 - val_accuracy: 0.8124 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2675 - accuracy: 0.9005 - val_loss: 0.2262 - val_accuracy: 0.9188 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2510 - accuracy: 0.9087 - val_loss: 0.2516 - val_accuracy: 0.9067 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2453 - accuracy: 0.9106 - val_loss: 0.8617 - val_accuracy: 0.7401 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2386 - accuracy: 0.9107 - val_loss: 0.1923 - val_accuracy: 0.9356 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2460 - accuracy: 0.9074 - val_loss: 0.2289 - val_accuracy: 0.9280 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2281 - accuracy: 0.9150 - val_loss: 0.1916 - val_accuracy: 0.9356 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2305 - accuracy: 0.9112 - val_loss: 0.1784 - val_accuracy: 0.9375 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2279 - accuracy: 0.9143 - val_loss: 0.1836 - val_accuracy: 0.9408 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2153 - accuracy: 0.9176 - val_loss: 0.1919 - val_accuracy: 0.9307 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2031 - accuracy: 0.9241 - val_loss: 0.1941 - val_accuracy: 0.9315 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2168 - accuracy: 0.9220 - val_loss: 0.1662 - val_accuracy: 0.9465 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2088 - accuracy: 0.9222 - val_loss: 0.1761 - val_accuracy: 0.9427 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2065 - accuracy: 0.9199 - val_loss: 0.1750 - val_accuracy: 0.9439 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2012 - accuracy: 0.9239 - val_loss: 0.1768 - val_accuracy: 0.9421 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1992 - accuracy: 0.9257 - val_loss: 0.2052 - val_accuracy: 0.9277 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1956 - accuracy: 0.9271 - val_loss: 0.1740 - val_accuracy: 0.9392 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1897 - accuracy: 0.9305 - val_loss: 0.1907 - val_accuracy: 0.9326 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1912 - accuracy: 0.9284 - val_loss: 0.4818 - val_accuracy: 0.8370 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1969 - accuracy: 0.9288 - val_loss: 0.1971 - val_accuracy: 0.9280 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1859 - accuracy: 0.9312 - val_loss: 0.2272 - val_accuracy: 0.9176 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1815 - accuracy: 0.9310 - val_loss: 0.2531 - val_accuracy: 0.9083 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1853 - accuracy: 0.9320 - val_loss: 0.2100 - val_accuracy: 0.9233 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1794 - accuracy: 0.9339 - val_loss: 0.1787 - val_accuracy: 0.9369 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1807 - accuracy: 0.9366 - val_loss: 0.2458 - val_accuracy: 0.9113 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1799 - accuracy: 0.9327 - val_loss: 0.2184 - val_accuracy: 0.9209 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1759 - accuracy: 0.9329 - val_loss: 0.2240 - val_accuracy: 0.9181 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1736 - accuracy: 0.9371 - val_loss: 0.1889 - val_accuracy: 0.9333 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1721 - accuracy: 0.9352 - val_loss: 0.1939 - val_accuracy: 0.9306 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1767 - accuracy: 0.9363 - val_loss: 0.1920 - val_accuracy: 0.9319 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1748 - accuracy: 0.9358 - val_loss: 0.1939 - val_accuracy: 0.9302 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1699 - accuracy: 0.9377 - val_loss: 0.1823 - val_accuracy: 0.9357 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1705 - accuracy: 0.9383 - val_loss: 0.1946 - val_accuracy: 0.9305 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1665 - accuracy: 0.9379 - val_loss: 0.1823 - val_accuracy: 0.9356 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1725 - accuracy: 0.9376 - val_loss: 0.1840 - val_accuracy: 0.9341 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1719 - accuracy: 0.9393 - val_loss: 0.1866 - val_accuracy: 0.9338 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1704 - accuracy: 0.9357 - val_loss: 0.1949 - val_accuracy: 0.9306 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1669 - accuracy: 0.9400 - val_loss: 0.1758 - val_accuracy: 0.9376 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1716 - accuracy: 0.9355 - val_loss: 0.1891 - val_accuracy: 0.9315 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1691 - accuracy: 0.9372 - val_loss: 0.1980 - val_accuracy: 0.9292 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1637 - accuracy: 0.9414 - val_loss: 0.1805 - val_accuracy: 0.9362 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1703 - accuracy: 0.9389 - val_loss: 0.1831 - val_accuracy: 0.9349 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1657 - accuracy: 0.9396 - val_loss: 0.1978 - val_accuracy: 0.9289 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1643 - accuracy: 0.9409 - val_loss: 0.1881 - val_accuracy: 0.9331 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1655 - accuracy: 0.9407 - val_loss: 0.1962 - val_accuracy: 0.9295 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1694 - accuracy: 0.9387 - val_loss: 0.1851 - val_accuracy: 0.9340 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1653 - accuracy: 0.9372 - val_loss: 0.1899 - val_accuracy: 0.9323 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1615 - accuracy: 0.9412 - val_loss: 0.1875 - val_accuracy: 0.9325 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1686 - accuracy: 0.9384 - val_loss: 0.1924 - val_accuracy: 0.9311 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1700 - accuracy: 0.9384 - val_loss: 0.1913 - val_accuracy: 0.9312 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1595 - accuracy: 0.9420 - val_loss: 0.1844 - val_accuracy: 0.9344 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1655 - accuracy: 0.9389 - val_loss: 0.1946 - val_accuracy: 0.9308 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1660 - accuracy: 0.9385 - val_loss: 0.1829 - val_accuracy: 0.9358 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1669 - accuracy: 0.9413 - val_loss: 0.1833 - val_accuracy: 0.9352 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1655 - accuracy: 0.9414 - val_loss: 0.1831 - val_accuracy: 0.9356 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1611 - accuracy: 0.9400 - val_loss: 0.1855 - val_accuracy: 0.9340 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1660 - accuracy: 0.9370 - val_loss: 0.1917 - val_accuracy: 0.9314 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1556 - accuracy: 0.9401 - val_loss: 0.1874 - val_accuracy: 0.9335 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1536 - accuracy: 0.9401 - val_loss: 0.1903 - val_accuracy: 0.9325 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1643 - accuracy: 0.9402 - val_loss: 0.1822 - val_accuracy: 0.9357 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1625 - accuracy: 0.9400 - val_loss: 0.1913 - val_accuracy: 0.9322 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1697 - accuracy: 0.9415 - val_loss: 0.1835 - val_accuracy: 0.9354 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1572 - accuracy: 0.9414 - val_loss: 0.1925 - val_accuracy: 0.9314 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1599 - accuracy: 0.9411 - val_loss: 0.1850 - val_accuracy: 0.9346 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1643 - accuracy: 0.9410 - val_loss: 0.1846 - val_accuracy: 0.9346 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1685 - accuracy: 0.9383 - val_loss: 0.1893 - val_accuracy: 0.9331 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1619 - accuracy: 0.9430 - val_loss: 0.1833 - val_accuracy: 0.9357 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1634 - accuracy: 0.9403 - val_loss: 0.1878 - val_accuracy: 0.9331 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1594 - accuracy: 0.9439 - val_loss: 0.1809 - val_accuracy: 0.9362 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1615 - accuracy: 0.9427 - val_loss: 0.1851 - val_accuracy: 0.9348 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1650 - accuracy: 0.9399 - val_loss: 0.1875 - val_accuracy: 0.9337 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1667 - accuracy: 0.9403 - val_loss: 0.1829 - val_accuracy: 0.9356 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1618 - accuracy: 0.9417 - val_loss: 0.1897 - val_accuracy: 0.9328 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1674 - accuracy: 0.9387 - val_loss: 0.1881 - val_accuracy: 0.9335 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 2.9355 - accuracy: 0.7717 - val_loss: 2.8403 - val_accuracy: 0.5622 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.8959 - accuracy: 0.8073 - val_loss: 0.7039 - val_accuracy: 0.9079 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 1.2137 - accuracy: 0.8182 - val_loss: 0.7561 - val_accuracy: 0.8981 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.8466 - accuracy: 0.8292 - val_loss: 4.8930 - val_accuracy: 0.1127 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.8468 - accuracy: 0.7833 - val_loss: 2.5576 - val_accuracy: 0.9006 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 1.7308 - accuracy: 0.8170 - val_loss: 1.1135 - val_accuracy: 0.9101 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.9620 - accuracy: 0.8366 - val_loss: 4.3501 - val_accuracy: 0.3632 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.7188 - accuracy: 0.8388 - val_loss: 2.0489 - val_accuracy: 0.5312 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.7232 - accuracy: 0.8480 - val_loss: 2.0810 - val_accuracy: 0.4538 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.7490 - accuracy: 0.8375 - val_loss: 0.9409 - val_accuracy: 0.7609 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.6591 - accuracy: 0.8556 - val_loss: 0.4727 - val_accuracy: 0.9010 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.5354 - accuracy: 0.8644 - val_loss: 32.6952 - val_accuracy: 0.1026 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.5710 - accuracy: 0.8684 - val_loss: 1.4570 - val_accuracy: 0.8974 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.5637 - accuracy: 0.8700 - val_loss: 1.2178 - val_accuracy: 0.8974 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.4402 - accuracy: 0.8752 - val_loss: 0.2885 - val_accuracy: 0.9325 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.4085 - accuracy: 0.8826 - val_loss: 0.3898 - val_accuracy: 0.9348 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.4097 - accuracy: 0.8879 - val_loss: 0.2627 - val_accuracy: 0.9397 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.4607 - accuracy: 0.8730 - val_loss: 2.9911 - val_accuracy: 0.1710 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3846 - accuracy: 0.8941 - val_loss: 0.2387 - val_accuracy: 0.9408 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.3556 - accuracy: 0.8957 - val_loss: 0.6330 - val_accuracy: 0.8975 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.3309 - accuracy: 0.9023 - val_loss: 0.2340 - val_accuracy: 0.9356 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3471 - accuracy: 0.8947 - val_loss: 1.8293 - val_accuracy: 0.5590 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3039 - accuracy: 0.9058 - val_loss: 0.2874 - val_accuracy: 0.9132 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.3022 - accuracy: 0.9124 - val_loss: 3.0643 - val_accuracy: 0.2362 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2929 - accuracy: 0.9069 - val_loss: 0.4556 - val_accuracy: 0.9059 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2771 - accuracy: 0.9158 - val_loss: 0.3891 - val_accuracy: 0.8799 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.3085 - accuracy: 0.9065 - val_loss: 0.2573 - val_accuracy: 0.9221 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2797 - accuracy: 0.9126 - val_loss: 0.2635 - val_accuracy: 0.9234 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2562 - accuracy: 0.9200 - val_loss: 0.3191 - val_accuracy: 0.8957 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2464 - accuracy: 0.9270 - val_loss: 2.2115 - val_accuracy: 0.5638 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.2645 - accuracy: 0.9197 - val_loss: 0.2729 - val_accuracy: 0.9383 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2356 - accuracy: 0.9269 - val_loss: 0.1986 - val_accuracy: 0.9416 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2184 - accuracy: 0.9335 - val_loss: 0.5035 - val_accuracy: 0.8370 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2152 - accuracy: 0.9353 - val_loss: 0.3073 - val_accuracy: 0.9021 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2065 - accuracy: 0.9331 - val_loss: 0.1949 - val_accuracy: 0.9487 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2005 - accuracy: 0.9368 - val_loss: 0.1988 - val_accuracy: 0.9377 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2020 - accuracy: 0.9346 - val_loss: 0.2576 - val_accuracy: 0.9189 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1930 - accuracy: 0.9403 - val_loss: 0.2254 - val_accuracy: 0.9397 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.2036 - accuracy: 0.9376 - val_loss: 0.1852 - val_accuracy: 0.9506 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1863 - accuracy: 0.9419 - val_loss: 0.1788 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1840 - accuracy: 0.9415 - val_loss: 0.1792 - val_accuracy: 0.9465 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1697 - accuracy: 0.9464 - val_loss: 0.1746 - val_accuracy: 0.9519 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1698 - accuracy: 0.9470 - val_loss: 0.2070 - val_accuracy: 0.9367 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1678 - accuracy: 0.9428 - val_loss: 0.6399 - val_accuracy: 0.8620 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1635 - accuracy: 0.9498 - val_loss: 0.1830 - val_accuracy: 0.9455 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1550 - accuracy: 0.9489 - val_loss: 0.1662 - val_accuracy: 0.9530 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1568 - accuracy: 0.9492 - val_loss: 0.1807 - val_accuracy: 0.9453 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1585 - accuracy: 0.9528 - val_loss: 0.1747 - val_accuracy: 0.9526 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1497 - accuracy: 0.9520 - val_loss: 0.1611 - val_accuracy: 0.9536 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1454 - accuracy: 0.9531 - val_loss: 0.1984 - val_accuracy: 0.9416 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1485 - accuracy: 0.9524 - val_loss: 0.1931 - val_accuracy: 0.9436 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1450 - accuracy: 0.9543 - val_loss: 0.2468 - val_accuracy: 0.9234 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1380 - accuracy: 0.9544 - val_loss: 0.1812 - val_accuracy: 0.9530 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1436 - accuracy: 0.9570 - val_loss: 0.2563 - val_accuracy: 0.9228 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1415 - accuracy: 0.9561 - val_loss: 0.1751 - val_accuracy: 0.9498 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1443 - accuracy: 0.9533 - val_loss: 0.1774 - val_accuracy: 0.9496 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1399 - accuracy: 0.9580 - val_loss: 0.1709 - val_accuracy: 0.9524 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.1337 - accuracy: 0.9590 - val_loss: 0.1981 - val_accuracy: 0.9426 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1323 - accuracy: 0.9559 - val_loss: 0.1730 - val_accuracy: 0.9507 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1241 - accuracy: 0.9615 - val_loss: 0.1637 - val_accuracy: 0.9550 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1279 - accuracy: 0.9606 - val_loss: 0.1674 - val_accuracy: 0.9526 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.1262 - accuracy: 0.9621 - val_loss: 0.1733 - val_accuracy: 0.9511 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1306 - accuracy: 0.9605 - val_loss: 0.1627 - val_accuracy: 0.9554 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1240 - accuracy: 0.9606 - val_loss: 0.1715 - val_accuracy: 0.9506 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1295 - accuracy: 0.9596 - val_loss: 0.1711 - val_accuracy: 0.9515 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1218 - accuracy: 0.9634 - val_loss: 0.1633 - val_accuracy: 0.9533 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1299 - accuracy: 0.9596 - val_loss: 0.1633 - val_accuracy: 0.9546 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1207 - accuracy: 0.9641 - val_loss: 0.1692 - val_accuracy: 0.9521 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.1253 - accuracy: 0.9631 - val_loss: 0.1629 - val_accuracy: 0.9546 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1252 - accuracy: 0.9634 - val_loss: 0.1637 - val_accuracy: 0.9538 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1187 - accuracy: 0.9642 - val_loss: 0.1726 - val_accuracy: 0.9517 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1294 - accuracy: 0.9609 - val_loss: 0.1847 - val_accuracy: 0.9479 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.1186 - accuracy: 0.9642 - val_loss: 0.1630 - val_accuracy: 0.9568 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1197 - accuracy: 0.9641 - val_loss: 0.1720 - val_accuracy: 0.9523 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1165 - accuracy: 0.9635 - val_loss: 0.1642 - val_accuracy: 0.9546 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1122 - accuracy: 0.9650 - val_loss: 0.1673 - val_accuracy: 0.9540 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1143 - accuracy: 0.9658 - val_loss: 0.1706 - val_accuracy: 0.9532 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1146 - accuracy: 0.9657 - val_loss: 0.1646 - val_accuracy: 0.9559 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1136 - accuracy: 0.9653 - val_loss: 0.1645 - val_accuracy: 0.9556 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.1129 - accuracy: 0.9665 - val_loss: 0.1692 - val_accuracy: 0.9537 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1134 - accuracy: 0.9666 - val_loss: 0.1670 - val_accuracy: 0.9548 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1162 - accuracy: 0.9663 - val_loss: 0.1629 - val_accuracy: 0.9558 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 17s 31ms/step - loss: 0.1159 - accuracy: 0.9663 - val_loss: 0.1711 - val_accuracy: 0.9533 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1163 - accuracy: 0.9645 - val_loss: 0.1629 - val_accuracy: 0.9554 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1136 - accuracy: 0.9674 - val_loss: 0.1640 - val_accuracy: 0.9551 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1185 - accuracy: 0.9659 - val_loss: 0.1637 - val_accuracy: 0.9551 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.1164 - accuracy: 0.9657 - val_loss: 0.1665 - val_accuracy: 0.9546 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1191 - accuracy: 0.9626 - val_loss: 0.1638 - val_accuracy: 0.9554 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1085 - accuracy: 0.9663 - val_loss: 0.1621 - val_accuracy: 0.9557 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1136 - accuracy: 0.9676 - val_loss: 0.1631 - val_accuracy: 0.9551 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.1158 - accuracy: 0.9658 - val_loss: 0.1652 - val_accuracy: 0.9552 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1143 - accuracy: 0.9655 - val_loss: 0.1642 - val_accuracy: 0.9552 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1185 - accuracy: 0.9658 - val_loss: 0.1661 - val_accuracy: 0.9547 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 16s 31ms/step - loss: 0.1117 - accuracy: 0.9652 - val_loss: 0.1619 - val_accuracy: 0.9558 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 16s 30ms/step - loss: 0.1155 - accuracy: 0.9673 - val_loss: 0.1642 - val_accuracy: 0.9554 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1200 - accuracy: 0.9642 - val_loss: 0.1646 - val_accuracy: 0.9550 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1157 - accuracy: 0.9664 - val_loss: 0.1653 - val_accuracy: 0.9549 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 15s 29ms/step - loss: 0.1091 - accuracy: 0.9660 - val_loss: 0.1637 - val_accuracy: 0.9554 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1176 - accuracy: 0.9646 - val_loss: 0.1653 - val_accuracy: 0.9549 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 17s 32ms/step - loss: 0.1216 - accuracy: 0.9650 - val_loss: 0.1603 - val_accuracy: 0.9565 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 15s 26ms/step - loss: 8.0420 - accuracy: 0.7549 - val_loss: 10.5535 - val_accuracy: 0.1071 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 6.0535 - accuracy: 0.7465 - val_loss: 7.2731 - val_accuracy: 0.4584 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 6.6315 - accuracy: 0.7617 - val_loss: 7.0796 - val_accuracy: 0.1094 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 4.5814 - accuracy: 0.7797 - val_loss: 12.5255 - val_accuracy: 0.1026 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 2.9178 - accuracy: 0.7926 - val_loss: 1.7102 - val_accuracy: 0.8975 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 3.0421 - accuracy: 0.7858 - val_loss: 3.0017 - val_accuracy: 0.8972 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 4.6193 - accuracy: 0.7677 - val_loss: 1.4010 - val_accuracy: 0.8987 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.2254 - accuracy: 0.8128 - val_loss: 0.9946 - val_accuracy: 0.8974 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.0826 - accuracy: 0.8095 - val_loss: 1.3166 - val_accuracy: 0.8321 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.7206 - accuracy: 0.8174 - val_loss: 1.5422 - val_accuracy: 0.4865 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.7127 - accuracy: 0.8201 - val_loss: 0.5305 - val_accuracy: 0.8817 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.7509 - accuracy: 0.8228 - val_loss: 0.6596 - val_accuracy: 0.9094 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.8587 - accuracy: 0.8224 - val_loss: 3.0074 - val_accuracy: 0.4040 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.8947 - accuracy: 0.8076 - val_loss: 0.5180 - val_accuracy: 0.8974 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.7345 - accuracy: 0.8264 - val_loss: 1.4399 - val_accuracy: 0.8658 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.3073 - accuracy: 0.7897 - val_loss: 0.5419 - val_accuracy: 0.9118 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.1161 - accuracy: 0.7825 - val_loss: 0.7563 - val_accuracy: 0.8982 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.7937 - accuracy: 0.8077 - val_loss: 1.2614 - val_accuracy: 0.5062 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.5659 - accuracy: 0.8249 - val_loss: 1.0436 - val_accuracy: 0.6929 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.5932 - accuracy: 0.8303 - val_loss: 0.3972 - val_accuracy: 0.8990 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.5273 - accuracy: 0.8404 - val_loss: 0.7717 - val_accuracy: 0.6916 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.5231 - accuracy: 0.8493 - val_loss: 0.9313 - val_accuracy: 0.7327 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.5121 - accuracy: 0.8483 - val_loss: 1.3352 - val_accuracy: 0.5392 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.4888 - accuracy: 0.8591 - val_loss: 0.5667 - val_accuracy: 0.8988 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4623 - accuracy: 0.8609 - val_loss: 1.0112 - val_accuracy: 0.6780 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.4047 - accuracy: 0.8668 - val_loss: 0.3202 - val_accuracy: 0.9090 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3789 - accuracy: 0.8728 - val_loss: 0.2565 - val_accuracy: 0.9294 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3927 - accuracy: 0.8793 - val_loss: 0.6592 - val_accuracy: 0.8049 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.3659 - accuracy: 0.8826 - val_loss: 0.2693 - val_accuracy: 0.9347 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3520 - accuracy: 0.8855 - val_loss: 0.2462 - val_accuracy: 0.9301 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3232 - accuracy: 0.8904 - val_loss: 0.2673 - val_accuracy: 0.9135 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.3035 - accuracy: 0.8958 - val_loss: 5.7037 - val_accuracy: 0.1532 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3130 - accuracy: 0.8946 - val_loss: 0.4440 - val_accuracy: 0.8351 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2991 - accuracy: 0.9032 - val_loss: 0.4801 - val_accuracy: 0.8510 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2881 - accuracy: 0.9030 - val_loss: 1.0676 - val_accuracy: 0.6602 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.2742 - accuracy: 0.9080 - val_loss: 0.3313 - val_accuracy: 0.9151 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2660 - accuracy: 0.9117 - val_loss: 0.2420 - val_accuracy: 0.9201 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2563 - accuracy: 0.9144 - val_loss: 0.2541 - val_accuracy: 0.9164 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2475 - accuracy: 0.9165 - val_loss: 0.8133 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2299 - accuracy: 0.9213 - val_loss: 0.3954 - val_accuracy: 0.9109 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2314 - accuracy: 0.9277 - val_loss: 0.3650 - val_accuracy: 0.8757 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2137 - accuracy: 0.9308 - val_loss: 0.1986 - val_accuracy: 0.9343 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2140 - accuracy: 0.9284 - val_loss: 0.2710 - val_accuracy: 0.9081 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2061 - accuracy: 0.9299 - val_loss: 0.1879 - val_accuracy: 0.9424 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2154 - accuracy: 0.9327 - val_loss: 0.3431 - val_accuracy: 0.8873 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2021 - accuracy: 0.9317 - val_loss: 0.2404 - val_accuracy: 0.9201 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1930 - accuracy: 0.9351 - val_loss: 0.6849 - val_accuracy: 0.7766 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1963 - accuracy: 0.9363 - val_loss: 0.1974 - val_accuracy: 0.9397 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1907 - accuracy: 0.9384 - val_loss: 0.4946 - val_accuracy: 0.8472 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1849 - accuracy: 0.9411 - val_loss: 0.5274 - val_accuracy: 0.8259 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1822 - accuracy: 0.9406 - val_loss: 0.1934 - val_accuracy: 0.9395 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1811 - accuracy: 0.9395 - val_loss: 0.2178 - val_accuracy: 0.9321 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1688 - accuracy: 0.9434 - val_loss: 0.1985 - val_accuracy: 0.9397 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1785 - accuracy: 0.9398 - val_loss: 0.1748 - val_accuracy: 0.9471 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1675 - accuracy: 0.9443 - val_loss: 0.1999 - val_accuracy: 0.9376 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1696 - accuracy: 0.9439 - val_loss: 0.1999 - val_accuracy: 0.9365 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1624 - accuracy: 0.9460 - val_loss: 0.1705 - val_accuracy: 0.9474 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1603 - accuracy: 0.9463 - val_loss: 0.1715 - val_accuracy: 0.9502 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1613 - accuracy: 0.9476 - val_loss: 0.1980 - val_accuracy: 0.9387 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.1559 - accuracy: 0.9480 - val_loss: 0.1701 - val_accuracy: 0.9473 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1602 - accuracy: 0.9456 - val_loss: 0.2652 - val_accuracy: 0.9147 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1587 - accuracy: 0.9481 - val_loss: 0.1617 - val_accuracy: 0.9517 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1590 - accuracy: 0.9475 - val_loss: 0.2451 - val_accuracy: 0.9223 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1540 - accuracy: 0.9478 - val_loss: 0.1783 - val_accuracy: 0.9451 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1486 - accuracy: 0.9495 - val_loss: 0.1941 - val_accuracy: 0.9386 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1475 - accuracy: 0.9521 - val_loss: 0.1787 - val_accuracy: 0.9451 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1529 - accuracy: 0.9502 - val_loss: 0.2274 - val_accuracy: 0.9291 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1548 - accuracy: 0.9493 - val_loss: 0.1764 - val_accuracy: 0.9445 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.1490 - accuracy: 0.9506 - val_loss: 0.1877 - val_accuracy: 0.9423 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1575 - accuracy: 0.9484 - val_loss: 0.1688 - val_accuracy: 0.9487 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1461 - accuracy: 0.9514 - val_loss: 0.1993 - val_accuracy: 0.9373 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1479 - accuracy: 0.9506 - val_loss: 0.2206 - val_accuracy: 0.9321 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1458 - accuracy: 0.9493 - val_loss: 0.1700 - val_accuracy: 0.9489 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1440 - accuracy: 0.9513 - val_loss: 0.1826 - val_accuracy: 0.9420 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1515 - accuracy: 0.9486 - val_loss: 0.1868 - val_accuracy: 0.9411 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1462 - accuracy: 0.9495 - val_loss: 0.1716 - val_accuracy: 0.9472 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1447 - accuracy: 0.9517 - val_loss: 0.1706 - val_accuracy: 0.9477 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.1465 - accuracy: 0.9503 - val_loss: 0.1764 - val_accuracy: 0.9448 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1420 - accuracy: 0.9537 - val_loss: 0.1901 - val_accuracy: 0.9404 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1362 - accuracy: 0.9522 - val_loss: 0.1779 - val_accuracy: 0.9439 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1398 - accuracy: 0.9518 - val_loss: 0.1783 - val_accuracy: 0.9437 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1467 - accuracy: 0.9496 - val_loss: 0.1780 - val_accuracy: 0.9445 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1427 - accuracy: 0.9512 - val_loss: 0.1838 - val_accuracy: 0.9429 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1463 - accuracy: 0.9510 - val_loss: 0.1746 - val_accuracy: 0.9460 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1482 - accuracy: 0.9515 - val_loss: 0.1716 - val_accuracy: 0.9465 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1354 - accuracy: 0.9538 - val_loss: 0.1830 - val_accuracy: 0.9422 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.1426 - accuracy: 0.9528 - val_loss: 0.1778 - val_accuracy: 0.9445 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1360 - accuracy: 0.9525 - val_loss: 0.1738 - val_accuracy: 0.9460 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1329 - accuracy: 0.9550 - val_loss: 0.1686 - val_accuracy: 0.9476 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1387 - accuracy: 0.9551 - val_loss: 0.1724 - val_accuracy: 0.9463 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1368 - accuracy: 0.9536 - val_loss: 0.1734 - val_accuracy: 0.9451 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1365 - accuracy: 0.9536 - val_loss: 0.1741 - val_accuracy: 0.9451 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1424 - accuracy: 0.9524 - val_loss: 0.1756 - val_accuracy: 0.9447 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1378 - accuracy: 0.9553 - val_loss: 0.1759 - val_accuracy: 0.9447 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1410 - accuracy: 0.9541 - val_loss: 0.1737 - val_accuracy: 0.9458 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.1414 - accuracy: 0.9524 - val_loss: 0.1794 - val_accuracy: 0.9438 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1338 - accuracy: 0.9524 - val_loss: 0.1760 - val_accuracy: 0.9445 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1348 - accuracy: 0.9549 - val_loss: 0.1789 - val_accuracy: 0.9438 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1398 - accuracy: 0.9547 - val_loss: 0.1766 - val_accuracy: 0.9444 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1405 - accuracy: 0.9534 - val_loss: 0.1733 - val_accuracy: 0.9456 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 8ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 15s 26ms/step - loss: 11.9100 - accuracy: 0.7192 - val_loss: 6.2305 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 5.8682 - accuracy: 0.7492 - val_loss: 8.5720 - val_accuracy: 0.2102 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 6.1986 - accuracy: 0.7469 - val_loss: 3.8094 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 5.7566 - accuracy: 0.7766 - val_loss: 2.3952 - val_accuracy: 0.5977 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 1.6530 - accuracy: 0.8051 - val_loss: 1.2200 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 2.7369 - accuracy: 0.7846 - val_loss: 1.3422 - val_accuracy: 0.8999 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 3.3824 - accuracy: 0.7986 - val_loss: 1.1599 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.5472 - accuracy: 0.8169 - val_loss: 2.2457 - val_accuracy: 0.4454 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.9646 - accuracy: 0.7879 - val_loss: 9.6288 - val_accuracy: 0.1026 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.9565 - accuracy: 0.7831 - val_loss: 0.8637 - val_accuracy: 0.8976 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.1260 - accuracy: 0.8081 - val_loss: 1.0855 - val_accuracy: 0.8974 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.9696 - accuracy: 0.8043 - val_loss: 1.4076 - val_accuracy: 0.8974 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.8281 - accuracy: 0.8160 - val_loss: 0.4186 - val_accuracy: 0.9041 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.6715 - accuracy: 0.8203 - val_loss: 1.9071 - val_accuracy: 0.4306 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.6764 - accuracy: 0.8277 - val_loss: 0.4576 - val_accuracy: 0.8974 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.6598 - accuracy: 0.8343 - val_loss: 4.1314 - val_accuracy: 0.1026 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7701 - accuracy: 0.8318 - val_loss: 0.7393 - val_accuracy: 0.9170 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6143 - accuracy: 0.8360 - val_loss: 4.9798 - val_accuracy: 0.1323 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5662 - accuracy: 0.8470 - val_loss: 1.1038 - val_accuracy: 0.6600 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5718 - accuracy: 0.8445 - val_loss: 10.2897 - val_accuracy: 0.1026 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.6622 - accuracy: 0.8436 - val_loss: 0.4313 - val_accuracy: 0.8817 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4753 - accuracy: 0.8599 - val_loss: 0.6716 - val_accuracy: 0.8974 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5356 - accuracy: 0.8706 - val_loss: 4.5169 - val_accuracy: 0.2127 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4498 - accuracy: 0.8803 - val_loss: 0.2463 - val_accuracy: 0.9411 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3888 - accuracy: 0.8787 - val_loss: 0.2448 - val_accuracy: 0.9417 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3648 - accuracy: 0.8892 - val_loss: 0.2444 - val_accuracy: 0.9413 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3418 - accuracy: 0.8943 - val_loss: 0.3926 - val_accuracy: 0.8617 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3499 - accuracy: 0.8939 - val_loss: 1.2354 - val_accuracy: 0.6675 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3396 - accuracy: 0.8894 - val_loss: 0.8900 - val_accuracy: 0.7015 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3030 - accuracy: 0.9023 - val_loss: 12.7215 - val_accuracy: 0.1026 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3173 - accuracy: 0.9027 - val_loss: 0.3755 - val_accuracy: 0.8854 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3518 - accuracy: 0.9073 - val_loss: 6.0750 - val_accuracy: 0.1350 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3350 - accuracy: 0.9079 - val_loss: 0.4132 - val_accuracy: 0.8865 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3182 - accuracy: 0.9108 - val_loss: 0.8113 - val_accuracy: 0.7350 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3124 - accuracy: 0.8999 - val_loss: 0.2334 - val_accuracy: 0.9328 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2798 - accuracy: 0.9111 - val_loss: 0.1778 - val_accuracy: 0.9492 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2554 - accuracy: 0.9194 - val_loss: 0.1920 - val_accuracy: 0.9469 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2559 - accuracy: 0.9200 - val_loss: 0.2926 - val_accuracy: 0.9106 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2373 - accuracy: 0.9229 - val_loss: 1.4565 - val_accuracy: 0.6199 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2448 - accuracy: 0.9232 - val_loss: 0.3257 - val_accuracy: 0.9242 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2376 - accuracy: 0.9299 - val_loss: 2.8753 - val_accuracy: 0.3839 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2203 - accuracy: 0.9274 - val_loss: 0.6359 - val_accuracy: 0.8115 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2102 - accuracy: 0.9302 - val_loss: 0.1595 - val_accuracy: 0.9536 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2065 - accuracy: 0.9341 - val_loss: 0.1947 - val_accuracy: 0.9386 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2103 - accuracy: 0.9319 - val_loss: 0.6254 - val_accuracy: 0.8070 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2025 - accuracy: 0.9350 - val_loss: 0.1792 - val_accuracy: 0.9443 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1929 - accuracy: 0.9379 - val_loss: 0.1763 - val_accuracy: 0.9452 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1899 - accuracy: 0.9391 - val_loss: 0.1806 - val_accuracy: 0.9452 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1855 - accuracy: 0.9391 - val_loss: 0.2408 - val_accuracy: 0.9211 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1870 - accuracy: 0.9410 - val_loss: 0.3595 - val_accuracy: 0.8850 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1830 - accuracy: 0.9378 - val_loss: 0.3197 - val_accuracy: 0.8974 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1795 - accuracy: 0.9402 - val_loss: 0.1878 - val_accuracy: 0.9474 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1861 - accuracy: 0.9397 - val_loss: 0.1953 - val_accuracy: 0.9379 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1821 - accuracy: 0.9395 - val_loss: 0.1898 - val_accuracy: 0.9374 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1761 - accuracy: 0.9415 - val_loss: 0.2687 - val_accuracy: 0.9130 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1692 - accuracy: 0.9443 - val_loss: 0.1815 - val_accuracy: 0.9422 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1679 - accuracy: 0.9428 - val_loss: 0.1627 - val_accuracy: 0.9515 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1623 - accuracy: 0.9453 - val_loss: 0.3285 - val_accuracy: 0.8965 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1651 - accuracy: 0.9482 - val_loss: 0.1597 - val_accuracy: 0.9502 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1696 - accuracy: 0.9434 - val_loss: 0.3863 - val_accuracy: 0.8839 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1629 - accuracy: 0.9455 - val_loss: 0.3840 - val_accuracy: 0.8815 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1570 - accuracy: 0.9483 - val_loss: 0.1599 - val_accuracy: 0.9490 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1684 - accuracy: 0.9452 - val_loss: 0.2006 - val_accuracy: 0.9344 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1725 - accuracy: 0.9440 - val_loss: 0.1954 - val_accuracy: 0.9375 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1632 - accuracy: 0.9434 - val_loss: 0.2017 - val_accuracy: 0.9345 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1605 - accuracy: 0.9473 - val_loss: 0.2054 - val_accuracy: 0.9342 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1547 - accuracy: 0.9476 - val_loss: 0.2327 - val_accuracy: 0.9254 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1580 - accuracy: 0.9460 - val_loss: 0.1837 - val_accuracy: 0.9404 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1587 - accuracy: 0.9446 - val_loss: 0.1659 - val_accuracy: 0.9472 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1618 - accuracy: 0.9462 - val_loss: 0.2361 - val_accuracy: 0.9261 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1498 - accuracy: 0.9446 - val_loss: 0.2034 - val_accuracy: 0.9339 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1563 - accuracy: 0.9457 - val_loss: 0.1859 - val_accuracy: 0.9408 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1537 - accuracy: 0.9459 - val_loss: 0.1959 - val_accuracy: 0.9370 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1542 - accuracy: 0.9462 - val_loss: 0.2264 - val_accuracy: 0.9273 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1473 - accuracy: 0.9493 - val_loss: 0.2064 - val_accuracy: 0.9335 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1564 - accuracy: 0.9469 - val_loss: 0.1825 - val_accuracy: 0.9403 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.1552 - accuracy: 0.9444 - val_loss: 0.1899 - val_accuracy: 0.9388 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1497 - accuracy: 0.9461 - val_loss: 0.2193 - val_accuracy: 0.9302 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1442 - accuracy: 0.9487 - val_loss: 0.1846 - val_accuracy: 0.9410 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.1455 - accuracy: 0.9466 - val_loss: 0.1860 - val_accuracy: 0.9402 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1509 - accuracy: 0.9481 - val_loss: 0.1929 - val_accuracy: 0.9379 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1468 - accuracy: 0.9476 - val_loss: 0.1895 - val_accuracy: 0.9391 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1460 - accuracy: 0.9480 - val_loss: 0.1939 - val_accuracy: 0.9373 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1450 - accuracy: 0.9479 - val_loss: 0.1733 - val_accuracy: 0.9450 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1470 - accuracy: 0.9492 - val_loss: 0.1857 - val_accuracy: 0.9411 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1551 - accuracy: 0.9477 - val_loss: 0.1941 - val_accuracy: 0.9374 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1452 - accuracy: 0.9475 - val_loss: 0.1951 - val_accuracy: 0.9374 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1463 - accuracy: 0.9488 - val_loss: 0.1789 - val_accuracy: 0.9423 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1433 - accuracy: 0.9485 - val_loss: 0.1879 - val_accuracy: 0.9398 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.1443 - accuracy: 0.9485 - val_loss: 0.1884 - val_accuracy: 0.9397 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1488 - accuracy: 0.9486 - val_loss: 0.1894 - val_accuracy: 0.9394 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1515 - accuracy: 0.9483 - val_loss: 0.1929 - val_accuracy: 0.9377 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1474 - accuracy: 0.9480 - val_loss: 0.1961 - val_accuracy: 0.9369 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1453 - accuracy: 0.9496 - val_loss: 0.1884 - val_accuracy: 0.9393 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1428 - accuracy: 0.9499 - val_loss: 0.1913 - val_accuracy: 0.9388 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1495 - accuracy: 0.9486 - val_loss: 0.1983 - val_accuracy: 0.9367 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1466 - accuracy: 0.9486 - val_loss: 0.1885 - val_accuracy: 0.9397 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1499 - accuracy: 0.9486 - val_loss: 0.1929 - val_accuracy: 0.9381 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1471 - accuracy: 0.9488 - val_loss: 0.1896 - val_accuracy: 0.9389 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1477 - accuracy: 0.9503 - val_loss: 0.1904 - val_accuracy: 0.9387 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 9.7641 - accuracy: 0.7401 - val_loss: 5.0745 - val_accuracy: 0.5460 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 7.2464 - accuracy: 0.7195 - val_loss: 6.7378 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 6.7153 - accuracy: 0.7174 - val_loss: 7.9537 - val_accuracy: 0.1026 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 8.4165 - accuracy: 0.7492 - val_loss: 11.3318 - val_accuracy: 0.1026 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 4.7053 - accuracy: 0.7571 - val_loss: 17.1560 - val_accuracy: 0.1026 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 5.6988 - accuracy: 0.7470 - val_loss: 3.4367 - val_accuracy: 0.8993 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 3.3082 - accuracy: 0.7817 - val_loss: 5.8860 - val_accuracy: 0.1439 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 3.2621 - accuracy: 0.7859 - val_loss: 2.1350 - val_accuracy: 0.8561 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.9608 - accuracy: 0.8063 - val_loss: 14.5513 - val_accuracy: 0.1026 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 2.3312 - accuracy: 0.8101 - val_loss: 0.8018 - val_accuracy: 0.8974 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.5661 - accuracy: 0.8231 - val_loss: 2.6668 - val_accuracy: 0.8989 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.8035 - accuracy: 0.8176 - val_loss: 1.1445 - val_accuracy: 0.8876 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.3519 - accuracy: 0.8244 - val_loss: 0.8858 - val_accuracy: 0.8799 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.4135 - accuracy: 0.8258 - val_loss: 1.7817 - val_accuracy: 0.9026 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.3576 - accuracy: 0.8365 - val_loss: 1.1608 - val_accuracy: 0.8974 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.7881 - accuracy: 0.8191 - val_loss: 4.3225 - val_accuracy: 0.1026 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.8897 - accuracy: 0.8271 - val_loss: 5.2541 - val_accuracy: 0.2161 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.9315 - accuracy: 0.8379 - val_loss: 0.4554 - val_accuracy: 0.9206 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7089 - accuracy: 0.8443 - val_loss: 0.7314 - val_accuracy: 0.9231 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7135 - accuracy: 0.8567 - val_loss: 0.4679 - val_accuracy: 0.9180 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7338 - accuracy: 0.8622 - val_loss: 0.8228 - val_accuracy: 0.8991 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6647 - accuracy: 0.8629 - val_loss: 0.5464 - val_accuracy: 0.9202 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6453 - accuracy: 0.8679 - val_loss: 1.0241 - val_accuracy: 0.8974 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5949 - accuracy: 0.8796 - val_loss: 0.5574 - val_accuracy: 0.8605 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5465 - accuracy: 0.8792 - val_loss: 0.8626 - val_accuracy: 0.8049 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5116 - accuracy: 0.8864 - val_loss: 0.6637 - val_accuracy: 0.9015 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.4868 - accuracy: 0.8936 - val_loss: 1.0033 - val_accuracy: 0.8975 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4634 - accuracy: 0.8939 - val_loss: 0.9182 - val_accuracy: 0.8974 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4660 - accuracy: 0.9038 - val_loss: 0.3351 - val_accuracy: 0.9457 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4000 - accuracy: 0.9074 - val_loss: 1.6890 - val_accuracy: 0.8974 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3541 - accuracy: 0.9126 - val_loss: 0.5687 - val_accuracy: 0.9097 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3390 - accuracy: 0.9187 - val_loss: 0.3130 - val_accuracy: 0.9482 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3145 - accuracy: 0.9280 - val_loss: 0.9107 - val_accuracy: 0.6945 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3079 - accuracy: 0.9291 - val_loss: 0.7189 - val_accuracy: 0.8985 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3140 - accuracy: 0.9215 - val_loss: 0.4426 - val_accuracy: 0.8727 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2893 - accuracy: 0.9273 - val_loss: 0.4983 - val_accuracy: 0.9157 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2754 - accuracy: 0.9287 - val_loss: 0.4929 - val_accuracy: 0.9112 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2670 - accuracy: 0.9306 - val_loss: 0.3289 - val_accuracy: 0.9107 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2422 - accuracy: 0.9371 - val_loss: 0.3392 - val_accuracy: 0.9319 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2334 - accuracy: 0.9416 - val_loss: 0.9446 - val_accuracy: 0.6986 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2249 - accuracy: 0.9404 - val_loss: 1.1382 - val_accuracy: 0.6846 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2159 - accuracy: 0.9437 - val_loss: 0.3137 - val_accuracy: 0.9108 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2006 - accuracy: 0.9446 - val_loss: 0.2138 - val_accuracy: 0.9520 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1972 - accuracy: 0.9466 - val_loss: 1.9958 - val_accuracy: 0.5160 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1872 - accuracy: 0.9514 - val_loss: 0.2623 - val_accuracy: 0.9293 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2017 - accuracy: 0.9457 - val_loss: 0.2412 - val_accuracy: 0.9475 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1866 - accuracy: 0.9466 - val_loss: 0.1765 - val_accuracy: 0.9561 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1820 - accuracy: 0.9490 - val_loss: 0.2704 - val_accuracy: 0.9211 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1721 - accuracy: 0.9522 - val_loss: 0.1652 - val_accuracy: 0.9598 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1705 - accuracy: 0.9497 - val_loss: 0.1677 - val_accuracy: 0.9587 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1624 - accuracy: 0.9537 - val_loss: 0.1788 - val_accuracy: 0.9566 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1627 - accuracy: 0.9544 - val_loss: 0.1787 - val_accuracy: 0.9547 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1528 - accuracy: 0.9580 - val_loss: 0.7975 - val_accuracy: 0.7576 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1490 - accuracy: 0.9576 - val_loss: 0.2404 - val_accuracy: 0.9262 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1466 - accuracy: 0.9576 - val_loss: 0.2599 - val_accuracy: 0.9209 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1475 - accuracy: 0.9602 - val_loss: 0.1731 - val_accuracy: 0.9501 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1405 - accuracy: 0.9583 - val_loss: 0.1975 - val_accuracy: 0.9456 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1421 - accuracy: 0.9569 - val_loss: 0.1740 - val_accuracy: 0.9542 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1251 - accuracy: 0.9610 - val_loss: 0.1570 - val_accuracy: 0.9586 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1253 - accuracy: 0.9632 - val_loss: 0.1645 - val_accuracy: 0.9533 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1356 - accuracy: 0.9619 - val_loss: 0.1628 - val_accuracy: 0.9569 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1315 - accuracy: 0.9603 - val_loss: 0.1519 - val_accuracy: 0.9585 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1312 - accuracy: 0.9603 - val_loss: 0.1470 - val_accuracy: 0.9604 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1271 - accuracy: 0.9617 - val_loss: 0.1986 - val_accuracy: 0.9411 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1190 - accuracy: 0.9648 - val_loss: 0.2072 - val_accuracy: 0.9391 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1240 - accuracy: 0.9616 - val_loss: 0.1581 - val_accuracy: 0.9563 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1165 - accuracy: 0.9656 - val_loss: 0.1535 - val_accuracy: 0.9593 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1174 - accuracy: 0.9645 - val_loss: 0.1881 - val_accuracy: 0.9442 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1150 - accuracy: 0.9647 - val_loss: 0.2147 - val_accuracy: 0.9354 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1170 - accuracy: 0.9646 - val_loss: 0.1514 - val_accuracy: 0.9575 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1169 - accuracy: 0.9647 - val_loss: 0.2323 - val_accuracy: 0.9295 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1152 - accuracy: 0.9664 - val_loss: 0.1747 - val_accuracy: 0.9487 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1155 - accuracy: 0.9655 - val_loss: 0.1626 - val_accuracy: 0.9540 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1158 - accuracy: 0.9658 - val_loss: 0.1638 - val_accuracy: 0.9529 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1189 - accuracy: 0.9642 - val_loss: 0.1513 - val_accuracy: 0.9576 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1104 - accuracy: 0.9651 - val_loss: 0.1510 - val_accuracy: 0.9566 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1061 - accuracy: 0.9674 - val_loss: 0.1591 - val_accuracy: 0.9548 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1126 - accuracy: 0.9661 - val_loss: 0.1549 - val_accuracy: 0.9576 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1057 - accuracy: 0.9678 - val_loss: 0.1552 - val_accuracy: 0.9574 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1028 - accuracy: 0.9694 - val_loss: 0.1501 - val_accuracy: 0.9589 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1040 - accuracy: 0.9696 - val_loss: 0.1522 - val_accuracy: 0.9577 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1094 - accuracy: 0.9680 - val_loss: 0.1622 - val_accuracy: 0.9533 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1031 - accuracy: 0.9681 - val_loss: 0.1571 - val_accuracy: 0.9558 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1037 - accuracy: 0.9677 - val_loss: 0.1559 - val_accuracy: 0.9562 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1022 - accuracy: 0.9715 - val_loss: 0.1512 - val_accuracy: 0.9580 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1090 - accuracy: 0.9692 - val_loss: 0.1547 - val_accuracy: 0.9565 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0993 - accuracy: 0.9703 - val_loss: 0.1525 - val_accuracy: 0.9575 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.1038 - accuracy: 0.9706 - val_loss: 0.1460 - val_accuracy: 0.9597 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1028 - accuracy: 0.9719 - val_loss: 0.1515 - val_accuracy: 0.9575 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1009 - accuracy: 0.9700 - val_loss: 0.1537 - val_accuracy: 0.9568 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1013 - accuracy: 0.9700 - val_loss: 0.1572 - val_accuracy: 0.9562 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0995 - accuracy: 0.9715 - val_loss: 0.1505 - val_accuracy: 0.9584 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0956 - accuracy: 0.9710 - val_loss: 0.1511 - val_accuracy: 0.9586 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0993 - accuracy: 0.9711 - val_loss: 0.1524 - val_accuracy: 0.9576 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0995 - accuracy: 0.9710 - val_loss: 0.1504 - val_accuracy: 0.9582 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1016 - accuracy: 0.9710 - val_loss: 0.1520 - val_accuracy: 0.9582 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1027 - accuracy: 0.9707 - val_loss: 0.1532 - val_accuracy: 0.9574 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1041 - accuracy: 0.9698 - val_loss: 0.1539 - val_accuracy: 0.9576 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0981 - accuracy: 0.9718 - val_loss: 0.1512 - val_accuracy: 0.9580 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1027 - accuracy: 0.9705 - val_loss: 0.1508 - val_accuracy: 0.9581 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 15s 26ms/step - loss: 3.6374 - accuracy: 0.7917 - val_loss: 1.2550 - val_accuracy: 0.8805 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.2779 - accuracy: 0.8103 - val_loss: 0.9632 - val_accuracy: 0.8703 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.9637 - accuracy: 0.8174 - val_loss: 0.6001 - val_accuracy: 0.9009 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.1614 - accuracy: 0.8048 - val_loss: 3.0267 - val_accuracy: 0.3540 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7384 - accuracy: 0.8190 - val_loss: 0.5547 - val_accuracy: 0.9063 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6790 - accuracy: 0.8350 - val_loss: 1.9162 - val_accuracy: 0.6287 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7128 - accuracy: 0.8369 - val_loss: 0.8988 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7980 - accuracy: 0.8444 - val_loss: 0.5595 - val_accuracy: 0.9260 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7405 - accuracy: 0.8454 - val_loss: 0.7728 - val_accuracy: 0.9141 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.9303 - accuracy: 0.8543 - val_loss: 3.0356 - val_accuracy: 0.2970 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6123 - accuracy: 0.8566 - val_loss: 0.6805 - val_accuracy: 0.7927 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4820 - accuracy: 0.8684 - val_loss: 0.4958 - val_accuracy: 0.8973 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4464 - accuracy: 0.8738 - val_loss: 0.6452 - val_accuracy: 0.8138 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4123 - accuracy: 0.8764 - val_loss: 0.2691 - val_accuracy: 0.9368 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.4149 - accuracy: 0.8809 - val_loss: 0.3558 - val_accuracy: 0.8954 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3712 - accuracy: 0.8904 - val_loss: 0.3071 - val_accuracy: 0.9305 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3573 - accuracy: 0.8942 - val_loss: 1.5079 - val_accuracy: 0.5841 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3337 - accuracy: 0.8992 - val_loss: 1.1881 - val_accuracy: 0.6691 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4174 - accuracy: 0.8752 - val_loss: 0.5710 - val_accuracy: 0.8992 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3438 - accuracy: 0.8923 - val_loss: 0.2935 - val_accuracy: 0.9228 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3462 - accuracy: 0.9038 - val_loss: 0.2615 - val_accuracy: 0.9304 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3241 - accuracy: 0.9154 - val_loss: 0.3217 - val_accuracy: 0.9378 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3176 - accuracy: 0.9183 - val_loss: 0.2862 - val_accuracy: 0.9367 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2874 - accuracy: 0.9275 - val_loss: 1.4538 - val_accuracy: 0.7334 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2804 - accuracy: 0.9266 - val_loss: 0.2923 - val_accuracy: 0.9139 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2586 - accuracy: 0.9312 - val_loss: 0.5539 - val_accuracy: 0.8621 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2465 - accuracy: 0.9318 - val_loss: 0.3274 - val_accuracy: 0.8998 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2197 - accuracy: 0.9397 - val_loss: 0.5039 - val_accuracy: 0.9071 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2102 - accuracy: 0.9438 - val_loss: 0.2487 - val_accuracy: 0.9366 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2207 - accuracy: 0.9418 - val_loss: 0.6918 - val_accuracy: 0.7963 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2200 - accuracy: 0.9405 - val_loss: 0.4169 - val_accuracy: 0.8774 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1971 - accuracy: 0.9470 - val_loss: 0.2394 - val_accuracy: 0.9326 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1890 - accuracy: 0.9466 - val_loss: 0.2165 - val_accuracy: 0.9400 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1863 - accuracy: 0.9463 - val_loss: 0.1657 - val_accuracy: 0.9578 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1843 - accuracy: 0.9464 - val_loss: 0.2325 - val_accuracy: 0.9329 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1727 - accuracy: 0.9497 - val_loss: 0.1734 - val_accuracy: 0.9540 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1641 - accuracy: 0.9514 - val_loss: 0.3006 - val_accuracy: 0.9135 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1568 - accuracy: 0.9538 - val_loss: 0.1631 - val_accuracy: 0.9542 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1606 - accuracy: 0.9535 - val_loss: 0.1653 - val_accuracy: 0.9544 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1504 - accuracy: 0.9566 - val_loss: 0.1854 - val_accuracy: 0.9469 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1380 - accuracy: 0.9623 - val_loss: 0.1700 - val_accuracy: 0.9523 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1395 - accuracy: 0.9600 - val_loss: 0.2132 - val_accuracy: 0.9418 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1266 - accuracy: 0.9632 - val_loss: 0.1475 - val_accuracy: 0.9610 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.1310 - accuracy: 0.9621 - val_loss: 0.1687 - val_accuracy: 0.9536 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1220 - accuracy: 0.9653 - val_loss: 0.3069 - val_accuracy: 0.9135 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1207 - accuracy: 0.9637 - val_loss: 0.1516 - val_accuracy: 0.9594 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.1156 - accuracy: 0.9671 - val_loss: 0.1604 - val_accuracy: 0.9564 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1149 - accuracy: 0.9664 - val_loss: 0.2179 - val_accuracy: 0.9382 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1103 - accuracy: 0.9697 - val_loss: 0.1868 - val_accuracy: 0.9467 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1058 - accuracy: 0.9702 - val_loss: 0.1927 - val_accuracy: 0.9450 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1069 - accuracy: 0.9696 - val_loss: 0.1715 - val_accuracy: 0.9535 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1027 - accuracy: 0.9720 - val_loss: 0.2041 - val_accuracy: 0.9441 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1015 - accuracy: 0.9722 - val_loss: 0.1482 - val_accuracy: 0.9615 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1079 - accuracy: 0.9705 - val_loss: 0.1476 - val_accuracy: 0.9608 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0974 - accuracy: 0.9712 - val_loss: 0.1572 - val_accuracy: 0.9576 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0967 - accuracy: 0.9735 - val_loss: 0.1539 - val_accuracy: 0.9588 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0917 - accuracy: 0.9752 - val_loss: 0.1568 - val_accuracy: 0.9576 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0901 - accuracy: 0.9766 - val_loss: 0.1441 - val_accuracy: 0.9622 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0926 - accuracy: 0.9748 - val_loss: 0.1529 - val_accuracy: 0.9591 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0899 - accuracy: 0.9755 - val_loss: 0.1438 - val_accuracy: 0.9626 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0897 - accuracy: 0.9755 - val_loss: 0.1534 - val_accuracy: 0.9593 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0951 - accuracy: 0.9729 - val_loss: 0.1417 - val_accuracy: 0.9623 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0863 - accuracy: 0.9769 - val_loss: 0.1491 - val_accuracy: 0.9610 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0847 - accuracy: 0.9764 - val_loss: 0.1468 - val_accuracy: 0.9614 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0877 - accuracy: 0.9772 - val_loss: 0.1444 - val_accuracy: 0.9629 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0912 - accuracy: 0.9750 - val_loss: 0.1444 - val_accuracy: 0.9628 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0884 - accuracy: 0.9768 - val_loss: 0.1446 - val_accuracy: 0.9622 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0849 - accuracy: 0.9762 - val_loss: 0.1465 - val_accuracy: 0.9613 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0813 - accuracy: 0.9784 - val_loss: 0.1423 - val_accuracy: 0.9629 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0844 - accuracy: 0.9779 - val_loss: 0.1443 - val_accuracy: 0.9624 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0839 - accuracy: 0.9786 - val_loss: 0.1429 - val_accuracy: 0.9628 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0898 - accuracy: 0.9767 - val_loss: 0.1439 - val_accuracy: 0.9620 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0815 - accuracy: 0.9762 - val_loss: 0.1419 - val_accuracy: 0.9630 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0869 - accuracy: 0.9779 - val_loss: 0.1426 - val_accuracy: 0.9619 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0803 - accuracy: 0.9796 - val_loss: 0.1443 - val_accuracy: 0.9622 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0796 - accuracy: 0.9757 - val_loss: 0.1446 - val_accuracy: 0.9620 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0810 - accuracy: 0.9778 - val_loss: 0.1414 - val_accuracy: 0.9627 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0849 - accuracy: 0.9771 - val_loss: 0.1447 - val_accuracy: 0.9620 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0801 - accuracy: 0.9791 - val_loss: 0.1406 - val_accuracy: 0.9627 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0835 - accuracy: 0.9775 - val_loss: 0.1410 - val_accuracy: 0.9627 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0807 - accuracy: 0.9784 - val_loss: 0.1430 - val_accuracy: 0.9623 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0839 - accuracy: 0.9785 - val_loss: 0.1440 - val_accuracy: 0.9622 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0838 - accuracy: 0.9776 - val_loss: 0.1468 - val_accuracy: 0.9616 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.0829 - accuracy: 0.9774 - val_loss: 0.1415 - val_accuracy: 0.9626 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0850 - accuracy: 0.9772 - val_loss: 0.1411 - val_accuracy: 0.9629 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0788 - accuracy: 0.9787 - val_loss: 0.1435 - val_accuracy: 0.9618 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0805 - accuracy: 0.9783 - val_loss: 0.1411 - val_accuracy: 0.9628 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0794 - accuracy: 0.9781 - val_loss: 0.1408 - val_accuracy: 0.9628 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0775 - accuracy: 0.9794 - val_loss: 0.1416 - val_accuracy: 0.9628 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0817 - accuracy: 0.9790 - val_loss: 0.1420 - val_accuracy: 0.9624 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0793 - accuracy: 0.9781 - val_loss: 0.1416 - val_accuracy: 0.9627 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0798 - accuracy: 0.9790 - val_loss: 0.1414 - val_accuracy: 0.9625 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0839 - accuracy: 0.9771 - val_loss: 0.1423 - val_accuracy: 0.9625 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0853 - accuracy: 0.9780 - val_loss: 0.1426 - val_accuracy: 0.9626 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0813 - accuracy: 0.9769 - val_loss: 0.1412 - val_accuracy: 0.9629 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0796 - accuracy: 0.9789 - val_loss: 0.1413 - val_accuracy: 0.9626 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0762 - accuracy: 0.9784 - val_loss: 0.1432 - val_accuracy: 0.9622 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0799 - accuracy: 0.9781 - val_loss: 0.1422 - val_accuracy: 0.9624 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0801 - accuracy: 0.9781 - val_loss: 0.1427 - val_accuracy: 0.9624 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0799 - accuracy: 0.9796 - val_loss: 0.1392 - val_accuracy: 0.9633 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 4.7099 - accuracy: 0.7732 - val_loss: 4.8219 - val_accuracy: 0.8468 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 3.3196 - accuracy: 0.7816 - val_loss: 5.1872 - val_accuracy: 0.1347 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 2.1160 - accuracy: 0.7878 - val_loss: 1.2698 - val_accuracy: 0.8975 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.9182 - accuracy: 0.8121 - val_loss: 1.5589 - val_accuracy: 0.5357 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.4971 - accuracy: 0.8118 - val_loss: 0.9054 - val_accuracy: 0.9141 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7488 - accuracy: 0.8321 - val_loss: 0.6330 - val_accuracy: 0.8983 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.9161 - accuracy: 0.8135 - val_loss: 1.1190 - val_accuracy: 0.7145 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.6607 - accuracy: 0.8382 - val_loss: 0.4515 - val_accuracy: 0.8791 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5998 - accuracy: 0.8406 - val_loss: 1.6472 - val_accuracy: 0.6547 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.4990 - accuracy: 0.8509 - val_loss: 0.4330 - val_accuracy: 0.8995 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4517 - accuracy: 0.8673 - val_loss: 0.6962 - val_accuracy: 0.7607 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.4429 - accuracy: 0.8700 - val_loss: 0.8952 - val_accuracy: 0.7515 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4181 - accuracy: 0.8631 - val_loss: 0.4377 - val_accuracy: 0.8401 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3772 - accuracy: 0.8764 - val_loss: 1.2242 - val_accuracy: 0.6617 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3655 - accuracy: 0.8926 - val_loss: 0.3258 - val_accuracy: 0.9282 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3573 - accuracy: 0.8910 - val_loss: 0.5098 - val_accuracy: 0.8230 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3497 - accuracy: 0.8926 - val_loss: 0.4519 - val_accuracy: 0.8485 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3228 - accuracy: 0.9067 - val_loss: 0.5269 - val_accuracy: 0.8589 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3130 - accuracy: 0.9112 - val_loss: 0.2680 - val_accuracy: 0.9292 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2852 - accuracy: 0.9178 - val_loss: 0.2218 - val_accuracy: 0.9459 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2870 - accuracy: 0.9194 - val_loss: 0.4208 - val_accuracy: 0.8758 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2705 - accuracy: 0.9239 - val_loss: 0.3438 - val_accuracy: 0.9217 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2591 - accuracy: 0.9262 - val_loss: 0.2194 - val_accuracy: 0.9424 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2448 - accuracy: 0.9301 - val_loss: 0.2140 - val_accuracy: 0.9453 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2368 - accuracy: 0.9324 - val_loss: 0.5285 - val_accuracy: 0.8496 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2175 - accuracy: 0.9389 - val_loss: 0.2872 - val_accuracy: 0.9331 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.2166 - accuracy: 0.9371 - val_loss: 0.2216 - val_accuracy: 0.9420 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2141 - accuracy: 0.9384 - val_loss: 0.3056 - val_accuracy: 0.9109 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2027 - accuracy: 0.9416 - val_loss: 0.2145 - val_accuracy: 0.9405 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2009 - accuracy: 0.9420 - val_loss: 0.2440 - val_accuracy: 0.9277 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1847 - accuracy: 0.9478 - val_loss: 0.2969 - val_accuracy: 0.9161 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1833 - accuracy: 0.9478 - val_loss: 0.1818 - val_accuracy: 0.9577 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1698 - accuracy: 0.9497 - val_loss: 0.2766 - val_accuracy: 0.9399 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.1642 - accuracy: 0.9544 - val_loss: 0.1853 - val_accuracy: 0.9530 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1703 - accuracy: 0.9499 - val_loss: 0.1947 - val_accuracy: 0.9501 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1606 - accuracy: 0.9531 - val_loss: 0.1724 - val_accuracy: 0.9600 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1474 - accuracy: 0.9566 - val_loss: 0.1825 - val_accuracy: 0.9513 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.1475 - accuracy: 0.9581 - val_loss: 0.2979 - val_accuracy: 0.9218 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1468 - accuracy: 0.9573 - val_loss: 0.2070 - val_accuracy: 0.9564 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1371 - accuracy: 0.9611 - val_loss: 0.1799 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1413 - accuracy: 0.9594 - val_loss: 0.2023 - val_accuracy: 0.9438 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1347 - accuracy: 0.9597 - val_loss: 0.2160 - val_accuracy: 0.9432 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1344 - accuracy: 0.9593 - val_loss: 0.2109 - val_accuracy: 0.9442 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1289 - accuracy: 0.9615 - val_loss: 0.1674 - val_accuracy: 0.9571 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1297 - accuracy: 0.9606 - val_loss: 0.1696 - val_accuracy: 0.9599 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1201 - accuracy: 0.9648 - val_loss: 0.1729 - val_accuracy: 0.9569 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1181 - accuracy: 0.9651 - val_loss: 0.1967 - val_accuracy: 0.9489 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1195 - accuracy: 0.9662 - val_loss: 0.1716 - val_accuracy: 0.9566 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1150 - accuracy: 0.9652 - val_loss: 0.1710 - val_accuracy: 0.9585 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1192 - accuracy: 0.9658 - val_loss: 0.1947 - val_accuracy: 0.9481 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1131 - accuracy: 0.9672 - val_loss: 0.1928 - val_accuracy: 0.9497 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1101 - accuracy: 0.9655 - val_loss: 0.1822 - val_accuracy: 0.9529 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1133 - accuracy: 0.9671 - val_loss: 0.1801 - val_accuracy: 0.9583 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1095 - accuracy: 0.9670 - val_loss: 0.1743 - val_accuracy: 0.9569 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1055 - accuracy: 0.9669 - val_loss: 0.1773 - val_accuracy: 0.9560 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1097 - accuracy: 0.9671 - val_loss: 0.1834 - val_accuracy: 0.9562 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1068 - accuracy: 0.9655 - val_loss: 0.1756 - val_accuracy: 0.9571 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1065 - accuracy: 0.9672 - val_loss: 0.1776 - val_accuracy: 0.9565 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.1065 - accuracy: 0.9670 - val_loss: 0.1764 - val_accuracy: 0.9580 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1052 - accuracy: 0.9702 - val_loss: 0.1936 - val_accuracy: 0.9498 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1043 - accuracy: 0.9686 - val_loss: 0.1737 - val_accuracy: 0.9602 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1026 - accuracy: 0.9694 - val_loss: 0.1787 - val_accuracy: 0.9558 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1045 - accuracy: 0.9691 - val_loss: 0.1751 - val_accuracy: 0.9573 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0965 - accuracy: 0.9709 - val_loss: 0.1776 - val_accuracy: 0.9565 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1002 - accuracy: 0.9699 - val_loss: 0.1713 - val_accuracy: 0.9585 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1006 - accuracy: 0.9683 - val_loss: 0.1762 - val_accuracy: 0.9567 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1052 - accuracy: 0.9696 - val_loss: 0.1721 - val_accuracy: 0.9585 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0964 - accuracy: 0.9706 - val_loss: 0.1824 - val_accuracy: 0.9555 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.1031 - accuracy: 0.9681 - val_loss: 0.1790 - val_accuracy: 0.9568 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0993 - accuracy: 0.9702 - val_loss: 0.1743 - val_accuracy: 0.9576 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0964 - accuracy: 0.9719 - val_loss: 0.1816 - val_accuracy: 0.9558 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0959 - accuracy: 0.9706 - val_loss: 0.1758 - val_accuracy: 0.9572 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0985 - accuracy: 0.9710 - val_loss: 0.1811 - val_accuracy: 0.9563 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0956 - accuracy: 0.9717 - val_loss: 0.1760 - val_accuracy: 0.9580 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1043 - accuracy: 0.9697 - val_loss: 0.1804 - val_accuracy: 0.9566 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0978 - accuracy: 0.9727 - val_loss: 0.1769 - val_accuracy: 0.9575 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0963 - accuracy: 0.9696 - val_loss: 0.1787 - val_accuracy: 0.9566 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1020 - accuracy: 0.9678 - val_loss: 0.1756 - val_accuracy: 0.9577 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0954 - accuracy: 0.9721 - val_loss: 0.1760 - val_accuracy: 0.9579 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0967 - accuracy: 0.9714 - val_loss: 0.1757 - val_accuracy: 0.9575 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0966 - accuracy: 0.9702 - val_loss: 0.1771 - val_accuracy: 0.9575 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1025 - accuracy: 0.9712 - val_loss: 0.1758 - val_accuracy: 0.9573 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1061 - accuracy: 0.9687 - val_loss: 0.1760 - val_accuracy: 0.9580 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0994 - accuracy: 0.9709 - val_loss: 0.1789 - val_accuracy: 0.9562 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0961 - accuracy: 0.9703 - val_loss: 0.1767 - val_accuracy: 0.9573 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0968 - accuracy: 0.9700 - val_loss: 0.1754 - val_accuracy: 0.9572 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1061 - accuracy: 0.9685 - val_loss: 0.1751 - val_accuracy: 0.9581 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0990 - accuracy: 0.9713 - val_loss: 0.1744 - val_accuracy: 0.9579 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0959 - accuracy: 0.9712 - val_loss: 0.1758 - val_accuracy: 0.9577 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0936 - accuracy: 0.9702 - val_loss: 0.1764 - val_accuracy: 0.9571 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0973 - accuracy: 0.9721 - val_loss: 0.1755 - val_accuracy: 0.9579 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0975 - accuracy: 0.9728 - val_loss: 0.1784 - val_accuracy: 0.9566 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0980 - accuracy: 0.9707 - val_loss: 0.1782 - val_accuracy: 0.9573 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0966 - accuracy: 0.9730 - val_loss: 0.1744 - val_accuracy: 0.9581 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0969 - accuracy: 0.9723 - val_loss: 0.1744 - val_accuracy: 0.9581 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1001 - accuracy: 0.9718 - val_loss: 0.1750 - val_accuracy: 0.9580 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0977 - accuracy: 0.9707 - val_loss: 0.1733 - val_accuracy: 0.9581 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0990 - accuracy: 0.9719 - val_loss: 0.1759 - val_accuracy: 0.9575 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1006 - accuracy: 0.9700 - val_loss: 0.1777 - val_accuracy: 0.9570 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.0997 - accuracy: 0.9707 - val_loss: 0.1783 - val_accuracy: 0.9575 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 8ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 15s 26ms/step - loss: 3.4689 - accuracy: 0.7790 - val_loss: 1.1554 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.1207 - accuracy: 0.8087 - val_loss: 1.6769 - val_accuracy: 0.5593 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.6992 - accuracy: 0.8165 - val_loss: 1.1676 - val_accuracy: 0.7315 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.9948 - accuracy: 0.7993 - val_loss: 1.3220 - val_accuracy: 0.7304 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.5604 - accuracy: 0.7624 - val_loss: 1.4948 - val_accuracy: 0.8509 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 1.6169 - accuracy: 0.7865 - val_loss: 1.6679 - val_accuracy: 0.8896 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.0030 - accuracy: 0.8115 - val_loss: 1.5682 - val_accuracy: 0.1713 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.7600 - accuracy: 0.8245 - val_loss: 4.7271 - val_accuracy: 0.1300 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.9034 - accuracy: 0.8371 - val_loss: 0.8099 - val_accuracy: 0.9189 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 1.0772 - accuracy: 0.8139 - val_loss: 1.0722 - val_accuracy: 0.8018 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.7904 - accuracy: 0.8274 - val_loss: 0.3619 - val_accuracy: 0.9265 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.5308 - accuracy: 0.8628 - val_loss: 0.5983 - val_accuracy: 0.9030 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.5733 - accuracy: 0.8634 - val_loss: 0.3920 - val_accuracy: 0.9088 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.5625 - accuracy: 0.8653 - val_loss: 0.3245 - val_accuracy: 0.9364 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4663 - accuracy: 0.8781 - val_loss: 0.4138 - val_accuracy: 0.9248 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4265 - accuracy: 0.8861 - val_loss: 0.7023 - val_accuracy: 0.8998 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.4327 - accuracy: 0.8905 - val_loss: 0.2698 - val_accuracy: 0.9364 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.4362 - accuracy: 0.9002 - val_loss: 0.5213 - val_accuracy: 0.8604 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3723 - accuracy: 0.9021 - val_loss: 0.2422 - val_accuracy: 0.9429 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3947 - accuracy: 0.9033 - val_loss: 0.3539 - val_accuracy: 0.9235 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.4169 - accuracy: 0.8994 - val_loss: 0.2900 - val_accuracy: 0.9302 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.3275 - accuracy: 0.9130 - val_loss: 0.4806 - val_accuracy: 0.9053 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.3026 - accuracy: 0.9153 - val_loss: 0.7827 - val_accuracy: 0.7463 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2717 - accuracy: 0.9253 - val_loss: 0.2370 - val_accuracy: 0.9434 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2618 - accuracy: 0.9264 - val_loss: 0.2991 - val_accuracy: 0.9101 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2545 - accuracy: 0.9293 - val_loss: 0.2216 - val_accuracy: 0.9495 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2509 - accuracy: 0.9293 - val_loss: 0.1920 - val_accuracy: 0.9531 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2206 - accuracy: 0.9369 - val_loss: 0.2325 - val_accuracy: 0.9375 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2299 - accuracy: 0.9329 - val_loss: 0.2170 - val_accuracy: 0.9417 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2081 - accuracy: 0.9398 - val_loss: 0.1806 - val_accuracy: 0.9508 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.2091 - accuracy: 0.9409 - val_loss: 0.8387 - val_accuracy: 0.7720 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1984 - accuracy: 0.9419 - val_loss: 0.1820 - val_accuracy: 0.9474 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1874 - accuracy: 0.9450 - val_loss: 0.1999 - val_accuracy: 0.9480 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1826 - accuracy: 0.9461 - val_loss: 0.1697 - val_accuracy: 0.9575 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1693 - accuracy: 0.9520 - val_loss: 0.1869 - val_accuracy: 0.9471 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1679 - accuracy: 0.9522 - val_loss: 0.3353 - val_accuracy: 0.8974 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1604 - accuracy: 0.9549 - val_loss: 0.1814 - val_accuracy: 0.9572 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1602 - accuracy: 0.9542 - val_loss: 0.4191 - val_accuracy: 0.8767 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.1575 - accuracy: 0.9538 - val_loss: 0.1911 - val_accuracy: 0.9525 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1533 - accuracy: 0.9556 - val_loss: 0.1657 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1417 - accuracy: 0.9597 - val_loss: 0.1515 - val_accuracy: 0.9611 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1418 - accuracy: 0.9624 - val_loss: 0.1579 - val_accuracy: 0.9573 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1318 - accuracy: 0.9614 - val_loss: 0.1800 - val_accuracy: 0.9559 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1327 - accuracy: 0.9638 - val_loss: 0.1835 - val_accuracy: 0.9478 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1329 - accuracy: 0.9630 - val_loss: 0.2260 - val_accuracy: 0.9376 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1285 - accuracy: 0.9637 - val_loss: 0.1640 - val_accuracy: 0.9601 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1250 - accuracy: 0.9652 - val_loss: 0.2012 - val_accuracy: 0.9433 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1196 - accuracy: 0.9661 - val_loss: 0.1909 - val_accuracy: 0.9486 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1208 - accuracy: 0.9664 - val_loss: 0.1734 - val_accuracy: 0.9534 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1219 - accuracy: 0.9652 - val_loss: 0.1670 - val_accuracy: 0.9599 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1161 - accuracy: 0.9683 - val_loss: 0.1617 - val_accuracy: 0.9621 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1080 - accuracy: 0.9706 - val_loss: 0.1655 - val_accuracy: 0.9562 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1102 - accuracy: 0.9693 - val_loss: 0.1542 - val_accuracy: 0.9607 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1135 - accuracy: 0.9708 - val_loss: 0.1528 - val_accuracy: 0.9612 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1152 - accuracy: 0.9661 - val_loss: 0.1494 - val_accuracy: 0.9621 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.1157 - accuracy: 0.9675 - val_loss: 0.1523 - val_accuracy: 0.9613 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1038 - accuracy: 0.9703 - val_loss: 0.1534 - val_accuracy: 0.9602 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1067 - accuracy: 0.9733 - val_loss: 0.1547 - val_accuracy: 0.9607 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1043 - accuracy: 0.9724 - val_loss: 0.1545 - val_accuracy: 0.9617 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1106 - accuracy: 0.9691 - val_loss: 0.1556 - val_accuracy: 0.9602 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1019 - accuracy: 0.9715 - val_loss: 0.1502 - val_accuracy: 0.9616 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1013 - accuracy: 0.9736 - val_loss: 0.1530 - val_accuracy: 0.9618 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.1023 - accuracy: 0.9712 - val_loss: 0.1545 - val_accuracy: 0.9616 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0993 - accuracy: 0.9737 - val_loss: 0.1544 - val_accuracy: 0.9610 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.1024 - accuracy: 0.9732 - val_loss: 0.1517 - val_accuracy: 0.9633 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.1025 - accuracy: 0.9727 - val_loss: 0.1502 - val_accuracy: 0.9624 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0919 - accuracy: 0.9744 - val_loss: 0.1512 - val_accuracy: 0.9633 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0997 - accuracy: 0.9729 - val_loss: 0.1550 - val_accuracy: 0.9606 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0906 - accuracy: 0.9743 - val_loss: 0.1528 - val_accuracy: 0.9624 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0956 - accuracy: 0.9743 - val_loss: 0.1515 - val_accuracy: 0.9624 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0913 - accuracy: 0.9759 - val_loss: 0.1523 - val_accuracy: 0.9631 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0996 - accuracy: 0.9743 - val_loss: 0.1540 - val_accuracy: 0.9611 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0981 - accuracy: 0.9736 - val_loss: 0.1536 - val_accuracy: 0.9607 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.0946 - accuracy: 0.9757 - val_loss: 0.1552 - val_accuracy: 0.9604 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0977 - accuracy: 0.9740 - val_loss: 0.1561 - val_accuracy: 0.9613 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0950 - accuracy: 0.9751 - val_loss: 0.1533 - val_accuracy: 0.9620 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0963 - accuracy: 0.9746 - val_loss: 0.1536 - val_accuracy: 0.9618 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0924 - accuracy: 0.9755 - val_loss: 0.1543 - val_accuracy: 0.9619 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0980 - accuracy: 0.9736 - val_loss: 0.1546 - val_accuracy: 0.9613 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0973 - accuracy: 0.9745 - val_loss: 0.1546 - val_accuracy: 0.9613 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0940 - accuracy: 0.9751 - val_loss: 0.1566 - val_accuracy: 0.9609 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0992 - accuracy: 0.9723 - val_loss: 0.1564 - val_accuracy: 0.9611 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.0932 - accuracy: 0.9759 - val_loss: 0.1550 - val_accuracy: 0.9614 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0960 - accuracy: 0.9752 - val_loss: 0.1554 - val_accuracy: 0.9614 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 13s 26ms/step - loss: 0.0982 - accuracy: 0.9736 - val_loss: 0.1550 - val_accuracy: 0.9617 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0965 - accuracy: 0.9748 - val_loss: 0.1559 - val_accuracy: 0.9616 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0899 - accuracy: 0.9751 - val_loss: 0.1549 - val_accuracy: 0.9620 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0976 - accuracy: 0.9755 - val_loss: 0.1534 - val_accuracy: 0.9623 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0940 - accuracy: 0.9737 - val_loss: 0.1541 - val_accuracy: 0.9616 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0941 - accuracy: 0.9745 - val_loss: 0.1552 - val_accuracy: 0.9615 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0971 - accuracy: 0.9740 - val_loss: 0.1546 - val_accuracy: 0.9613 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 13s 24ms/step - loss: 0.0955 - accuracy: 0.9745 - val_loss: 0.1546 - val_accuracy: 0.9614 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0924 - accuracy: 0.9745 - val_loss: 0.1548 - val_accuracy: 0.9616 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0904 - accuracy: 0.9751 - val_loss: 0.1555 - val_accuracy: 0.9615 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0894 - accuracy: 0.9758 - val_loss: 0.1545 - val_accuracy: 0.9619 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0927 - accuracy: 0.9748 - val_loss: 0.1543 - val_accuracy: 0.9619 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 14s 26ms/step - loss: 0.0965 - accuracy: 0.9744 - val_loss: 0.1539 - val_accuracy: 0.9618 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0934 - accuracy: 0.9762 - val_loss: 0.1543 - val_accuracy: 0.9621 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0989 - accuracy: 0.9735 - val_loss: 0.1543 - val_accuracy: 0.9617 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 13s 25ms/step - loss: 0.0960 - accuracy: 0.9731 - val_loss: 0.1542 - val_accuracy: 0.9615 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 37ms/step - loss: 6.9053 - accuracy: 0.7441 - val_loss: 9.8564 - val_accuracy: 0.1038 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 2.4646 - accuracy: 0.7861 - val_loss: 3.6981 - val_accuracy: 0.4969 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 1.3128 - accuracy: 0.8036 - val_loss: 0.7609 - val_accuracy: 0.9012 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 1.2717 - accuracy: 0.8023 - val_loss: 0.9355 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 0.8717 - accuracy: 0.8130 - val_loss: 0.7687 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.7658 - accuracy: 0.8168 - val_loss: 0.5254 - val_accuracy: 0.8865 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.7142 - accuracy: 0.8197 - val_loss: 5.6417 - val_accuracy: 0.2665 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.7392 - accuracy: 0.8211 - val_loss: 8.8795 - val_accuracy: 0.1640 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.7981 - accuracy: 0.8166 - val_loss: 0.5440 - val_accuracy: 0.9042 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.6826 - accuracy: 0.8153 - val_loss: 0.7411 - val_accuracy: 0.8078 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 11s 42ms/step - loss: 0.5897 - accuracy: 0.8319 - val_loss: 0.7872 - val_accuracy: 0.7946 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.5754 - accuracy: 0.8344 - val_loss: 1.0042 - val_accuracy: 0.7025 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.5290 - accuracy: 0.8337 - val_loss: 0.3712 - val_accuracy: 0.9062 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.5959 - accuracy: 0.8306 - val_loss: 0.4024 - val_accuracy: 0.8951 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.5729 - accuracy: 0.8329 - val_loss: 1.5110 - val_accuracy: 0.6519 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.5358 - accuracy: 0.8391 - val_loss: 0.3392 - val_accuracy: 0.9127 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.5135 - accuracy: 0.8478 - val_loss: 0.6106 - val_accuracy: 0.9064 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.5657 - accuracy: 0.8298 - val_loss: 0.6007 - val_accuracy: 0.8084 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.4651 - accuracy: 0.8555 - val_loss: 0.3042 - val_accuracy: 0.9346 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.4513 - accuracy: 0.8581 - val_loss: 0.7253 - val_accuracy: 0.7604 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 0.4421 - accuracy: 0.8578 - val_loss: 0.3233 - val_accuracy: 0.9196 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.4463 - accuracy: 0.8661 - val_loss: 0.3015 - val_accuracy: 0.9352 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4156 - accuracy: 0.8729 - val_loss: 0.3473 - val_accuracy: 0.9204 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 0.3845 - accuracy: 0.8822 - val_loss: 0.3152 - val_accuracy: 0.9185 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.3657 - accuracy: 0.8846 - val_loss: 0.4369 - val_accuracy: 0.8501 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.3570 - accuracy: 0.8878 - val_loss: 0.2552 - val_accuracy: 0.9303 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.3297 - accuracy: 0.8997 - val_loss: 0.2715 - val_accuracy: 0.9209 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3161 - accuracy: 0.9043 - val_loss: 0.2864 - val_accuracy: 0.9114 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 11s 43ms/step - loss: 0.3042 - accuracy: 0.9040 - val_loss: 0.2642 - val_accuracy: 0.9196 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.2942 - accuracy: 0.9067 - val_loss: 0.2736 - val_accuracy: 0.9269 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 0.2868 - accuracy: 0.9126 - val_loss: 0.2130 - val_accuracy: 0.9461 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 0.2786 - accuracy: 0.9093 - val_loss: 0.2078 - val_accuracy: 0.9455 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2662 - accuracy: 0.9148 - val_loss: 0.3725 - val_accuracy: 0.8811 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2595 - accuracy: 0.9180 - val_loss: 0.2396 - val_accuracy: 0.9264 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 12s 43ms/step - loss: 0.2387 - accuracy: 0.9245 - val_loss: 0.2436 - val_accuracy: 0.9225 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.2424 - accuracy: 0.9233 - val_loss: 0.2009 - val_accuracy: 0.9458 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.2305 - accuracy: 0.9275 - val_loss: 0.2274 - val_accuracy: 0.9298 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.2364 - accuracy: 0.9252 - val_loss: 0.1811 - val_accuracy: 0.9511 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2143 - accuracy: 0.9303 - val_loss: 0.1681 - val_accuracy: 0.9541 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.2139 - accuracy: 0.9316 - val_loss: 0.2166 - val_accuracy: 0.9317 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1965 - accuracy: 0.9391 - val_loss: 0.2534 - val_accuracy: 0.9167 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1957 - accuracy: 0.9364 - val_loss: 0.1772 - val_accuracy: 0.9481 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1917 - accuracy: 0.9436 - val_loss: 0.1895 - val_accuracy: 0.9418 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1867 - accuracy: 0.9405 - val_loss: 0.1590 - val_accuracy: 0.9582 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 11s 42ms/step - loss: 0.1833 - accuracy: 0.9406 - val_loss: 0.1865 - val_accuracy: 0.9426 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1746 - accuracy: 0.9468 - val_loss: 0.1617 - val_accuracy: 0.9525 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1705 - accuracy: 0.9423 - val_loss: 0.2077 - val_accuracy: 0.9345 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1743 - accuracy: 0.9439 - val_loss: 0.1521 - val_accuracy: 0.9558 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1616 - accuracy: 0.9477 - val_loss: 0.1597 - val_accuracy: 0.9516 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1619 - accuracy: 0.9483 - val_loss: 0.1717 - val_accuracy: 0.9479 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1547 - accuracy: 0.9511 - val_loss: 0.2174 - val_accuracy: 0.9310 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1532 - accuracy: 0.9492 - val_loss: 0.2153 - val_accuracy: 0.9318 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1505 - accuracy: 0.9510 - val_loss: 0.1730 - val_accuracy: 0.9462 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 11s 42ms/step - loss: 0.1519 - accuracy: 0.9486 - val_loss: 0.1591 - val_accuracy: 0.9523 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1522 - accuracy: 0.9511 - val_loss: 0.1981 - val_accuracy: 0.9364 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 11s 42ms/step - loss: 0.1434 - accuracy: 0.9530 - val_loss: 0.1655 - val_accuracy: 0.9488 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1396 - accuracy: 0.9562 - val_loss: 0.1588 - val_accuracy: 0.9517 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1397 - accuracy: 0.9557 - val_loss: 0.1580 - val_accuracy: 0.9527 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1381 - accuracy: 0.9571 - val_loss: 0.1516 - val_accuracy: 0.9551 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1406 - accuracy: 0.9560 - val_loss: 0.1501 - val_accuracy: 0.9555 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1336 - accuracy: 0.9587 - val_loss: 0.1475 - val_accuracy: 0.9559 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1368 - accuracy: 0.9555 - val_loss: 0.1508 - val_accuracy: 0.9542 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1337 - accuracy: 0.9577 - val_loss: 0.1560 - val_accuracy: 0.9528 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1341 - accuracy: 0.9579 - val_loss: 0.1448 - val_accuracy: 0.9574 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1281 - accuracy: 0.9605 - val_loss: 0.1422 - val_accuracy: 0.9581 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1282 - accuracy: 0.9593 - val_loss: 0.1527 - val_accuracy: 0.9538 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 11s 43ms/step - loss: 0.1322 - accuracy: 0.9573 - val_loss: 0.1413 - val_accuracy: 0.9581 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1302 - accuracy: 0.9577 - val_loss: 0.1486 - val_accuracy: 0.9549 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1213 - accuracy: 0.9604 - val_loss: 0.1419 - val_accuracy: 0.9583 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1268 - accuracy: 0.9595 - val_loss: 0.1445 - val_accuracy: 0.9574 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1280 - accuracy: 0.9599 - val_loss: 0.1501 - val_accuracy: 0.9545 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1259 - accuracy: 0.9606 - val_loss: 0.1544 - val_accuracy: 0.9530 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1266 - accuracy: 0.9606 - val_loss: 0.1490 - val_accuracy: 0.9548 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1253 - accuracy: 0.9622 - val_loss: 0.1546 - val_accuracy: 0.9533 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1242 - accuracy: 0.9598 - val_loss: 0.1451 - val_accuracy: 0.9566 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1269 - accuracy: 0.9593 - val_loss: 0.1489 - val_accuracy: 0.9550 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1254 - accuracy: 0.9597 - val_loss: 0.1499 - val_accuracy: 0.9551 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 0.1217 - accuracy: 0.9605 - val_loss: 0.1511 - val_accuracy: 0.9540 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1236 - accuracy: 0.9607 - val_loss: 0.1494 - val_accuracy: 0.9546 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1236 - accuracy: 0.9612 - val_loss: 0.1492 - val_accuracy: 0.9546 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1260 - accuracy: 0.9605 - val_loss: 0.1481 - val_accuracy: 0.9558 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1257 - accuracy: 0.9600 - val_loss: 0.1483 - val_accuracy: 0.9549 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1257 - accuracy: 0.9608 - val_loss: 0.1506 - val_accuracy: 0.9545 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1218 - accuracy: 0.9602 - val_loss: 0.1492 - val_accuracy: 0.9550 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 0.1209 - accuracy: 0.9615 - val_loss: 0.1480 - val_accuracy: 0.9552 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1206 - accuracy: 0.9608 - val_loss: 0.1485 - val_accuracy: 0.9546 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1199 - accuracy: 0.9631 - val_loss: 0.1490 - val_accuracy: 0.9544 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1193 - accuracy: 0.9606 - val_loss: 0.1501 - val_accuracy: 0.9549 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1178 - accuracy: 0.9629 - val_loss: 0.1479 - val_accuracy: 0.9554 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1193 - accuracy: 0.9627 - val_loss: 0.1493 - val_accuracy: 0.9548 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1245 - accuracy: 0.9610 - val_loss: 0.1504 - val_accuracy: 0.9546 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 11s 42ms/step - loss: 0.1201 - accuracy: 0.9624 - val_loss: 0.1494 - val_accuracy: 0.9546 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1184 - accuracy: 0.9618 - val_loss: 0.1481 - val_accuracy: 0.9555 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 11s 42ms/step - loss: 0.1224 - accuracy: 0.9610 - val_loss: 0.1502 - val_accuracy: 0.9543 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1240 - accuracy: 0.9616 - val_loss: 0.1503 - val_accuracy: 0.9546 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1234 - accuracy: 0.9609 - val_loss: 0.1492 - val_accuracy: 0.9546 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1163 - accuracy: 0.9622 - val_loss: 0.1502 - val_accuracy: 0.9546 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1209 - accuracy: 0.9621 - val_loss: 0.1499 - val_accuracy: 0.9547 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1170 - accuracy: 0.9615 - val_loss: 0.1496 - val_accuracy: 0.9546 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 0.1206 - accuracy: 0.9631 - val_loss: 0.1493 - val_accuracy: 0.9550 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 5.7580 - accuracy: 0.7382 - val_loss: 9.3027 - val_accuracy: 0.2605 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 3.3834 - accuracy: 0.7874 - val_loss: 2.3820 - val_accuracy: 0.7524 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 2.1490 - accuracy: 0.8011 - val_loss: 1.3343 - val_accuracy: 0.8690 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 2.4970 - accuracy: 0.8018 - val_loss: 5.8910 - val_accuracy: 0.1463 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 1.2717 - accuracy: 0.8153 - val_loss: 1.0022 - val_accuracy: 0.8979 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 1.4407 - accuracy: 0.8180 - val_loss: 0.9057 - val_accuracy: 0.9081 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.9452 - accuracy: 0.8131 - val_loss: 0.7758 - val_accuracy: 0.8145 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 11s 43ms/step - loss: 0.7788 - accuracy: 0.8116 - val_loss: 1.2148 - val_accuracy: 0.5871 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.6507 - accuracy: 0.8249 - val_loss: 0.4924 - val_accuracy: 0.8640 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 11s 42ms/step - loss: 0.6621 - accuracy: 0.8295 - val_loss: 0.6951 - val_accuracy: 0.9145 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.6668 - accuracy: 0.8274 - val_loss: 0.4072 - val_accuracy: 0.9145 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.7426 - accuracy: 0.8238 - val_loss: 0.6109 - val_accuracy: 0.9117 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.7129 - accuracy: 0.8289 - val_loss: 0.4741 - val_accuracy: 0.9105 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.5968 - accuracy: 0.8292 - val_loss: 0.5177 - val_accuracy: 0.8397 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.5572 - accuracy: 0.8305 - val_loss: 0.4929 - val_accuracy: 0.8974 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.4962 - accuracy: 0.8389 - val_loss: 0.3205 - val_accuracy: 0.9140 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.4900 - accuracy: 0.8482 - val_loss: 0.5499 - val_accuracy: 0.8291 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.4511 - accuracy: 0.8514 - val_loss: 0.4621 - val_accuracy: 0.8502 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.4347 - accuracy: 0.8625 - val_loss: 0.3032 - val_accuracy: 0.9116 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.4130 - accuracy: 0.8644 - val_loss: 1.8285 - val_accuracy: 0.6062 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.3992 - accuracy: 0.8650 - val_loss: 0.2500 - val_accuracy: 0.9296 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.3950 - accuracy: 0.8687 - val_loss: 0.4190 - val_accuracy: 0.8615 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.3626 - accuracy: 0.8793 - val_loss: 0.3687 - val_accuracy: 0.8699 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.3554 - accuracy: 0.8794 - val_loss: 0.2740 - val_accuracy: 0.9313 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.3386 - accuracy: 0.8841 - val_loss: 0.4017 - val_accuracy: 0.8603 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.3309 - accuracy: 0.8866 - val_loss: 0.4318 - val_accuracy: 0.8482 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3120 - accuracy: 0.8905 - val_loss: 0.3863 - val_accuracy: 0.9038 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3061 - accuracy: 0.8940 - val_loss: 0.3972 - val_accuracy: 0.8602 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2952 - accuracy: 0.8969 - val_loss: 0.3273 - val_accuracy: 0.8764 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2842 - accuracy: 0.8999 - val_loss: 0.2181 - val_accuracy: 0.9324 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.2773 - accuracy: 0.9038 - val_loss: 0.1979 - val_accuracy: 0.9404 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2730 - accuracy: 0.9063 - val_loss: 0.1929 - val_accuracy: 0.9423 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.2637 - accuracy: 0.9087 - val_loss: 0.1795 - val_accuracy: 0.9465 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.2621 - accuracy: 0.9087 - val_loss: 0.1847 - val_accuracy: 0.9429 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2397 - accuracy: 0.9174 - val_loss: 0.1725 - val_accuracy: 0.9503 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2421 - accuracy: 0.9124 - val_loss: 0.1923 - val_accuracy: 0.9382 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2443 - accuracy: 0.9124 - val_loss: 0.1668 - val_accuracy: 0.9495 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.2318 - accuracy: 0.9170 - val_loss: 0.2207 - val_accuracy: 0.9213 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2326 - accuracy: 0.9191 - val_loss: 0.1718 - val_accuracy: 0.9444 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.2310 - accuracy: 0.9199 - val_loss: 0.2280 - val_accuracy: 0.9181 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2246 - accuracy: 0.9207 - val_loss: 0.1736 - val_accuracy: 0.9458 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.2194 - accuracy: 0.9217 - val_loss: 0.2073 - val_accuracy: 0.9386 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.2127 - accuracy: 0.9250 - val_loss: 0.1701 - val_accuracy: 0.9421 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.2150 - accuracy: 0.9191 - val_loss: 0.1828 - val_accuracy: 0.9352 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.2121 - accuracy: 0.9260 - val_loss: 0.1566 - val_accuracy: 0.9489 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.2110 - accuracy: 0.9222 - val_loss: 0.1632 - val_accuracy: 0.9445 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 11s 43ms/step - loss: 0.2058 - accuracy: 0.9287 - val_loss: 0.1739 - val_accuracy: 0.9390 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2013 - accuracy: 0.9262 - val_loss: 0.1787 - val_accuracy: 0.9368 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 11s 42ms/step - loss: 0.2011 - accuracy: 0.9293 - val_loss: 0.2440 - val_accuracy: 0.9112 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 12s 43ms/step - loss: 0.1967 - accuracy: 0.9281 - val_loss: 0.1955 - val_accuracy: 0.9305 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1912 - accuracy: 0.9303 - val_loss: 0.2161 - val_accuracy: 0.9226 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1954 - accuracy: 0.9287 - val_loss: 0.1533 - val_accuracy: 0.9489 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1935 - accuracy: 0.9280 - val_loss: 0.1761 - val_accuracy: 0.9385 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1907 - accuracy: 0.9318 - val_loss: 0.1671 - val_accuracy: 0.9423 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 11s 43ms/step - loss: 0.1866 - accuracy: 0.9324 - val_loss: 0.1742 - val_accuracy: 0.9388 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1841 - accuracy: 0.9329 - val_loss: 0.1774 - val_accuracy: 0.9371 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 0.1894 - accuracy: 0.9309 - val_loss: 0.1532 - val_accuracy: 0.9492 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1891 - accuracy: 0.9310 - val_loss: 0.1504 - val_accuracy: 0.9506 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1909 - accuracy: 0.9313 - val_loss: 0.1880 - val_accuracy: 0.9319 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 11s 43ms/step - loss: 0.1828 - accuracy: 0.9324 - val_loss: 0.1586 - val_accuracy: 0.9453 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1805 - accuracy: 0.9333 - val_loss: 0.1563 - val_accuracy: 0.9474 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1871 - accuracy: 0.9333 - val_loss: 0.1718 - val_accuracy: 0.9390 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1793 - accuracy: 0.9369 - val_loss: 0.1572 - val_accuracy: 0.9461 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1812 - accuracy: 0.9355 - val_loss: 0.1716 - val_accuracy: 0.9390 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1790 - accuracy: 0.9335 - val_loss: 0.1621 - val_accuracy: 0.9432 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1805 - accuracy: 0.9346 - val_loss: 0.1831 - val_accuracy: 0.9346 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1791 - accuracy: 0.9339 - val_loss: 0.1582 - val_accuracy: 0.9453 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1836 - accuracy: 0.9357 - val_loss: 0.1783 - val_accuracy: 0.9367 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1761 - accuracy: 0.9361 - val_loss: 0.1583 - val_accuracy: 0.9447 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1767 - accuracy: 0.9349 - val_loss: 0.1674 - val_accuracy: 0.9411 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1809 - accuracy: 0.9346 - val_loss: 0.1649 - val_accuracy: 0.9430 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1723 - accuracy: 0.9360 - val_loss: 0.1640 - val_accuracy: 0.9425 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1758 - accuracy: 0.9349 - val_loss: 0.1590 - val_accuracy: 0.9453 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1772 - accuracy: 0.9367 - val_loss: 0.1575 - val_accuracy: 0.9454 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1814 - accuracy: 0.9371 - val_loss: 0.1625 - val_accuracy: 0.9428 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1727 - accuracy: 0.9344 - val_loss: 0.1594 - val_accuracy: 0.9442 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1707 - accuracy: 0.9375 - val_loss: 0.1597 - val_accuracy: 0.9445 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1768 - accuracy: 0.9370 - val_loss: 0.1655 - val_accuracy: 0.9420 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1745 - accuracy: 0.9363 - val_loss: 0.1586 - val_accuracy: 0.9449 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1743 - accuracy: 0.9369 - val_loss: 0.1616 - val_accuracy: 0.9434 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1702 - accuracy: 0.9387 - val_loss: 0.1598 - val_accuracy: 0.9440 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1676 - accuracy: 0.9384 - val_loss: 0.1615 - val_accuracy: 0.9436 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1719 - accuracy: 0.9375 - val_loss: 0.1603 - val_accuracy: 0.9440 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1694 - accuracy: 0.9389 - val_loss: 0.1596 - val_accuracy: 0.9447 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1753 - accuracy: 0.9379 - val_loss: 0.1595 - val_accuracy: 0.9448 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1715 - accuracy: 0.9398 - val_loss: 0.1582 - val_accuracy: 0.9450 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1715 - accuracy: 0.9385 - val_loss: 0.1600 - val_accuracy: 0.9439 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1747 - accuracy: 0.9363 - val_loss: 0.1596 - val_accuracy: 0.9440 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1730 - accuracy: 0.9381 - val_loss: 0.1610 - val_accuracy: 0.9436 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1752 - accuracy: 0.9375 - val_loss: 0.1613 - val_accuracy: 0.9434 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1693 - accuracy: 0.9375 - val_loss: 0.1589 - val_accuracy: 0.9445 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1699 - accuracy: 0.9379 - val_loss: 0.1588 - val_accuracy: 0.9445 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1740 - accuracy: 0.9377 - val_loss: 0.1616 - val_accuracy: 0.9433 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1741 - accuracy: 0.9382 - val_loss: 0.1600 - val_accuracy: 0.9441 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1746 - accuracy: 0.9375 - val_loss: 0.1601 - val_accuracy: 0.9442 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1699 - accuracy: 0.9388 - val_loss: 0.1619 - val_accuracy: 0.9436 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1699 - accuracy: 0.9393 - val_loss: 0.1603 - val_accuracy: 0.9438 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 11s 42ms/step - loss: 0.1728 - accuracy: 0.9378 - val_loss: 0.1606 - val_accuracy: 0.9438 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.1721 - accuracy: 0.9392 - val_loss: 0.1588 - val_accuracy: 0.9445 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 11s 43ms/step - loss: 0.1769 - accuracy: 0.9366 - val_loss: 0.1604 - val_accuracy: 0.9437 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 1s 5ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 6.2683 - accuracy: 0.7684 - val_loss: 4.6306 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 4.0678 - accuracy: 0.7706 - val_loss: 3.6209 - val_accuracy: 0.7185 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 1.7579 - accuracy: 0.8007 - val_loss: 1.6861 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 1.9184 - accuracy: 0.8044 - val_loss: 6.2052 - val_accuracy: 0.1141 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.1034 - accuracy: 0.8165 - val_loss: 4.4587 - val_accuracy: 0.2305 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.9066 - accuracy: 0.8095 - val_loss: 2.9846 - val_accuracy: 0.5569 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.8173 - accuracy: 0.8174 - val_loss: 1.3075 - val_accuracy: 0.7696 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.7888 - accuracy: 0.8171 - val_loss: 0.4359 - val_accuracy: 0.9045 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.8072 - accuracy: 0.8210 - val_loss: 0.6302 - val_accuracy: 0.8974 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.6714 - accuracy: 0.8187 - val_loss: 0.8869 - val_accuracy: 0.8070 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.6485 - accuracy: 0.8180 - val_loss: 2.7857 - val_accuracy: 0.3513 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.5752 - accuracy: 0.8285 - val_loss: 0.8034 - val_accuracy: 0.8150 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.5766 - accuracy: 0.8278 - val_loss: 0.7459 - val_accuracy: 0.7688 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.5651 - accuracy: 0.8292 - val_loss: 0.5549 - val_accuracy: 0.8974 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.5901 - accuracy: 0.8403 - val_loss: 0.8644 - val_accuracy: 0.7833 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.5287 - accuracy: 0.8458 - val_loss: 0.3546 - val_accuracy: 0.9128 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4766 - accuracy: 0.8483 - val_loss: 1.1733 - val_accuracy: 0.6974 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.4822 - accuracy: 0.8413 - val_loss: 0.3999 - val_accuracy: 0.8996 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4405 - accuracy: 0.8578 - val_loss: 0.7679 - val_accuracy: 0.7729 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4496 - accuracy: 0.8607 - val_loss: 0.3788 - val_accuracy: 0.8828 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3976 - accuracy: 0.8668 - val_loss: 0.3176 - val_accuracy: 0.9180 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.4023 - accuracy: 0.8697 - val_loss: 0.5854 - val_accuracy: 0.8028 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3553 - accuracy: 0.8846 - val_loss: 0.2831 - val_accuracy: 0.9168 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.3479 - accuracy: 0.8840 - val_loss: 0.3579 - val_accuracy: 0.8768 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.3223 - accuracy: 0.8917 - val_loss: 0.2973 - val_accuracy: 0.9031 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.3049 - accuracy: 0.8993 - val_loss: 0.3344 - val_accuracy: 0.8821 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.3182 - accuracy: 0.8946 - val_loss: 0.3393 - val_accuracy: 0.8876 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2926 - accuracy: 0.9014 - val_loss: 0.2199 - val_accuracy: 0.9442 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2845 - accuracy: 0.9065 - val_loss: 0.3306 - val_accuracy: 0.8809 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2780 - accuracy: 0.9070 - val_loss: 0.5287 - val_accuracy: 0.8174 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2695 - accuracy: 0.9098 - val_loss: 0.1940 - val_accuracy: 0.9492 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2634 - accuracy: 0.9129 - val_loss: 0.2029 - val_accuracy: 0.9419 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2404 - accuracy: 0.9208 - val_loss: 0.3439 - val_accuracy: 0.8738 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.2478 - accuracy: 0.9203 - val_loss: 0.1775 - val_accuracy: 0.9505 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2424 - accuracy: 0.9187 - val_loss: 0.2480 - val_accuracy: 0.9171 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2399 - accuracy: 0.9200 - val_loss: 0.2587 - val_accuracy: 0.9124 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2319 - accuracy: 0.9182 - val_loss: 0.2237 - val_accuracy: 0.9258 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2165 - accuracy: 0.9255 - val_loss: 0.2729 - val_accuracy: 0.9051 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1993 - accuracy: 0.9309 - val_loss: 0.1757 - val_accuracy: 0.9459 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2050 - accuracy: 0.9324 - val_loss: 0.3239 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2044 - accuracy: 0.9313 - val_loss: 0.2817 - val_accuracy: 0.9005 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2007 - accuracy: 0.9290 - val_loss: 0.1665 - val_accuracy: 0.9518 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1920 - accuracy: 0.9345 - val_loss: 0.1746 - val_accuracy: 0.9443 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1928 - accuracy: 0.9337 - val_loss: 0.2516 - val_accuracy: 0.9113 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1865 - accuracy: 0.9342 - val_loss: 0.1821 - val_accuracy: 0.9404 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1845 - accuracy: 0.9357 - val_loss: 0.1650 - val_accuracy: 0.9490 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1813 - accuracy: 0.9386 - val_loss: 0.3019 - val_accuracy: 0.8926 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1854 - accuracy: 0.9345 - val_loss: 0.2350 - val_accuracy: 0.9189 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1771 - accuracy: 0.9374 - val_loss: 0.1820 - val_accuracy: 0.9385 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1752 - accuracy: 0.9385 - val_loss: 0.1782 - val_accuracy: 0.9392 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1698 - accuracy: 0.9391 - val_loss: 0.1497 - val_accuracy: 0.9545 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1743 - accuracy: 0.9400 - val_loss: 0.1606 - val_accuracy: 0.9467 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1724 - accuracy: 0.9411 - val_loss: 0.1628 - val_accuracy: 0.9460 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1677 - accuracy: 0.9410 - val_loss: 0.1942 - val_accuracy: 0.9325 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1633 - accuracy: 0.9415 - val_loss: 0.1454 - val_accuracy: 0.9540 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1687 - accuracy: 0.9395 - val_loss: 0.1728 - val_accuracy: 0.9410 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1625 - accuracy: 0.9413 - val_loss: 0.1855 - val_accuracy: 0.9363 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1659 - accuracy: 0.9408 - val_loss: 0.1461 - val_accuracy: 0.9529 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1601 - accuracy: 0.9420 - val_loss: 0.1542 - val_accuracy: 0.9488 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1604 - accuracy: 0.9403 - val_loss: 0.1651 - val_accuracy: 0.9438 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1533 - accuracy: 0.9454 - val_loss: 0.1570 - val_accuracy: 0.9473 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1576 - accuracy: 0.9436 - val_loss: 0.1576 - val_accuracy: 0.9469 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1585 - accuracy: 0.9457 - val_loss: 0.1535 - val_accuracy: 0.9489 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1590 - accuracy: 0.9441 - val_loss: 0.1582 - val_accuracy: 0.9467 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1521 - accuracy: 0.9452 - val_loss: 0.1618 - val_accuracy: 0.9446 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1543 - accuracy: 0.9457 - val_loss: 0.1612 - val_accuracy: 0.9453 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1532 - accuracy: 0.9441 - val_loss: 0.1626 - val_accuracy: 0.9452 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1557 - accuracy: 0.9439 - val_loss: 0.1411 - val_accuracy: 0.9556 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1524 - accuracy: 0.9467 - val_loss: 0.1537 - val_accuracy: 0.9482 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1517 - accuracy: 0.9469 - val_loss: 0.1481 - val_accuracy: 0.9513 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1531 - accuracy: 0.9469 - val_loss: 0.1531 - val_accuracy: 0.9480 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1486 - accuracy: 0.9474 - val_loss: 0.1503 - val_accuracy: 0.9503 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1521 - accuracy: 0.9466 - val_loss: 0.1534 - val_accuracy: 0.9488 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1477 - accuracy: 0.9463 - val_loss: 0.1575 - val_accuracy: 0.9467 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1514 - accuracy: 0.9466 - val_loss: 0.1582 - val_accuracy: 0.9461 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1514 - accuracy: 0.9475 - val_loss: 0.1556 - val_accuracy: 0.9474 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1473 - accuracy: 0.9465 - val_loss: 0.1518 - val_accuracy: 0.9490 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1509 - accuracy: 0.9458 - val_loss: 0.1491 - val_accuracy: 0.9506 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1463 - accuracy: 0.9472 - val_loss: 0.1546 - val_accuracy: 0.9476 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1475 - accuracy: 0.9460 - val_loss: 0.1544 - val_accuracy: 0.9478 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.1497 - accuracy: 0.9457 - val_loss: 0.1506 - val_accuracy: 0.9492 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1490 - accuracy: 0.9467 - val_loss: 0.1534 - val_accuracy: 0.9485 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1455 - accuracy: 0.9472 - val_loss: 0.1542 - val_accuracy: 0.9478 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1452 - accuracy: 0.9472 - val_loss: 0.1538 - val_accuracy: 0.9479 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1475 - accuracy: 0.9469 - val_loss: 0.1503 - val_accuracy: 0.9490 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1479 - accuracy: 0.9479 - val_loss: 0.1521 - val_accuracy: 0.9484 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1463 - accuracy: 0.9483 - val_loss: 0.1519 - val_accuracy: 0.9484 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1447 - accuracy: 0.9486 - val_loss: 0.1529 - val_accuracy: 0.9482 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1505 - accuracy: 0.9456 - val_loss: 0.1534 - val_accuracy: 0.9485 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1453 - accuracy: 0.9464 - val_loss: 0.1501 - val_accuracy: 0.9494 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1518 - accuracy: 0.9483 - val_loss: 0.1529 - val_accuracy: 0.9484 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1448 - accuracy: 0.9483 - val_loss: 0.1516 - val_accuracy: 0.9488 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1505 - accuracy: 0.9453 - val_loss: 0.1504 - val_accuracy: 0.9495 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1516 - accuracy: 0.9466 - val_loss: 0.1532 - val_accuracy: 0.9482 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1530 - accuracy: 0.9448 - val_loss: 0.1529 - val_accuracy: 0.9484 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1467 - accuracy: 0.9482 - val_loss: 0.1519 - val_accuracy: 0.9489 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1522 - accuracy: 0.9465 - val_loss: 0.1506 - val_accuracy: 0.9494 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1492 - accuracy: 0.9466 - val_loss: 0.1521 - val_accuracy: 0.9488 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1492 - accuracy: 0.9483 - val_loss: 0.1532 - val_accuracy: 0.9484 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 11s 42ms/step - loss: 0.1434 - accuracy: 0.9475 - val_loss: 0.1530 - val_accuracy: 0.9484 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 13s 45ms/step - loss: 3.1988 - accuracy: 0.7834 - val_loss: 1.6881 - val_accuracy: 0.9202 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 1.8771 - accuracy: 0.8056 - val_loss: 1.4332 - val_accuracy: 0.9003 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 11s 43ms/step - loss: 1.5077 - accuracy: 0.8155 - val_loss: 1.1976 - val_accuracy: 0.8977 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 1.2505 - accuracy: 0.8281 - val_loss: 0.6547 - val_accuracy: 0.9115 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.0731 - accuracy: 0.8249 - val_loss: 0.6910 - val_accuracy: 0.8803 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.8201 - accuracy: 0.8323 - val_loss: 2.1321 - val_accuracy: 0.3524 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.6475 - accuracy: 0.8442 - val_loss: 0.5181 - val_accuracy: 0.9175 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.5470 - accuracy: 0.8546 - val_loss: 0.4794 - val_accuracy: 0.8575 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 12s 44ms/step - loss: 0.5286 - accuracy: 0.8583 - val_loss: 0.4123 - val_accuracy: 0.9286 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 11s 43ms/step - loss: 0.4838 - accuracy: 0.8686 - val_loss: 0.6146 - val_accuracy: 0.8989 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.4430 - accuracy: 0.8736 - val_loss: 0.4286 - val_accuracy: 0.8722 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 11s 42ms/step - loss: 0.3966 - accuracy: 0.8835 - val_loss: 0.6175 - val_accuracy: 0.7820 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3637 - accuracy: 0.8929 - val_loss: 0.5906 - val_accuracy: 0.8179 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3661 - accuracy: 0.8924 - val_loss: 0.6580 - val_accuracy: 0.7555 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3379 - accuracy: 0.9005 - val_loss: 0.4561 - val_accuracy: 0.8463 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3053 - accuracy: 0.9079 - val_loss: 0.2933 - val_accuracy: 0.9207 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3114 - accuracy: 0.9039 - val_loss: 0.2317 - val_accuracy: 0.9435 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3051 - accuracy: 0.9144 - val_loss: 0.4817 - val_accuracy: 0.8374 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2808 - accuracy: 0.9170 - val_loss: 0.2510 - val_accuracy: 0.9324 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2569 - accuracy: 0.9254 - val_loss: 0.3589 - val_accuracy: 0.8863 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2425 - accuracy: 0.9294 - val_loss: 0.5079 - val_accuracy: 0.8382 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.2335 - accuracy: 0.9296 - val_loss: 0.7252 - val_accuracy: 0.7442 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2347 - accuracy: 0.9284 - val_loss: 0.2340 - val_accuracy: 0.9286 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2122 - accuracy: 0.9368 - val_loss: 0.1800 - val_accuracy: 0.9559 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2151 - accuracy: 0.9341 - val_loss: 0.3616 - val_accuracy: 0.8865 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2028 - accuracy: 0.9366 - val_loss: 0.1804 - val_accuracy: 0.9505 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1931 - accuracy: 0.9417 - val_loss: 0.1773 - val_accuracy: 0.9494 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1933 - accuracy: 0.9389 - val_loss: 0.2208 - val_accuracy: 0.9329 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1903 - accuracy: 0.9418 - val_loss: 0.1915 - val_accuracy: 0.9437 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1796 - accuracy: 0.9448 - val_loss: 0.1727 - val_accuracy: 0.9500 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1736 - accuracy: 0.9463 - val_loss: 0.2140 - val_accuracy: 0.9335 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1638 - accuracy: 0.9469 - val_loss: 0.2029 - val_accuracy: 0.9383 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1665 - accuracy: 0.9466 - val_loss: 0.1742 - val_accuracy: 0.9489 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1595 - accuracy: 0.9495 - val_loss: 0.1868 - val_accuracy: 0.9422 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1611 - accuracy: 0.9482 - val_loss: 0.1850 - val_accuracy: 0.9436 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1486 - accuracy: 0.9508 - val_loss: 0.1524 - val_accuracy: 0.9577 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1496 - accuracy: 0.9530 - val_loss: 0.1863 - val_accuracy: 0.9447 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1510 - accuracy: 0.9502 - val_loss: 0.2187 - val_accuracy: 0.9290 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1500 - accuracy: 0.9521 - val_loss: 0.1696 - val_accuracy: 0.9486 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1386 - accuracy: 0.9531 - val_loss: 0.1482 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1388 - accuracy: 0.9547 - val_loss: 0.1765 - val_accuracy: 0.9472 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1374 - accuracy: 0.9551 - val_loss: 0.1609 - val_accuracy: 0.9552 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1346 - accuracy: 0.9547 - val_loss: 0.1441 - val_accuracy: 0.9585 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1352 - accuracy: 0.9575 - val_loss: 0.1532 - val_accuracy: 0.9550 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1292 - accuracy: 0.9589 - val_loss: 0.1626 - val_accuracy: 0.9511 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1336 - accuracy: 0.9573 - val_loss: 0.1661 - val_accuracy: 0.9510 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1282 - accuracy: 0.9597 - val_loss: 0.1709 - val_accuracy: 0.9490 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1243 - accuracy: 0.9580 - val_loss: 0.1689 - val_accuracy: 0.9491 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1228 - accuracy: 0.9608 - val_loss: 0.1629 - val_accuracy: 0.9523 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1230 - accuracy: 0.9590 - val_loss: 0.1573 - val_accuracy: 0.9532 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1213 - accuracy: 0.9598 - val_loss: 0.1571 - val_accuracy: 0.9538 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1201 - accuracy: 0.9619 - val_loss: 0.1525 - val_accuracy: 0.9552 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1211 - accuracy: 0.9609 - val_loss: 0.1558 - val_accuracy: 0.9547 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1147 - accuracy: 0.9636 - val_loss: 0.1628 - val_accuracy: 0.9525 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1160 - accuracy: 0.9605 - val_loss: 0.1606 - val_accuracy: 0.9533 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1130 - accuracy: 0.9648 - val_loss: 0.1547 - val_accuracy: 0.9544 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1168 - accuracy: 0.9618 - val_loss: 0.1627 - val_accuracy: 0.9533 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1145 - accuracy: 0.9631 - val_loss: 0.1668 - val_accuracy: 0.9517 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1138 - accuracy: 0.9618 - val_loss: 0.1574 - val_accuracy: 0.9541 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1142 - accuracy: 0.9622 - val_loss: 0.1673 - val_accuracy: 0.9510 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1206 - accuracy: 0.9619 - val_loss: 0.1608 - val_accuracy: 0.9529 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1146 - accuracy: 0.9621 - val_loss: 0.1611 - val_accuracy: 0.9534 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1115 - accuracy: 0.9637 - val_loss: 0.1616 - val_accuracy: 0.9531 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1139 - accuracy: 0.9608 - val_loss: 0.1617 - val_accuracy: 0.9533 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1167 - accuracy: 0.9634 - val_loss: 0.1695 - val_accuracy: 0.9502 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1126 - accuracy: 0.9631 - val_loss: 0.1625 - val_accuracy: 0.9527 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1093 - accuracy: 0.9648 - val_loss: 0.1591 - val_accuracy: 0.9534 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1137 - accuracy: 0.9647 - val_loss: 0.1612 - val_accuracy: 0.9537 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1093 - accuracy: 0.9637 - val_loss: 0.1597 - val_accuracy: 0.9537 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1072 - accuracy: 0.9662 - val_loss: 0.1567 - val_accuracy: 0.9546 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1161 - accuracy: 0.9638 - val_loss: 0.1612 - val_accuracy: 0.9539 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1126 - accuracy: 0.9634 - val_loss: 0.1593 - val_accuracy: 0.9538 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1091 - accuracy: 0.9646 - val_loss: 0.1616 - val_accuracy: 0.9537 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1097 - accuracy: 0.9651 - val_loss: 0.1626 - val_accuracy: 0.9532 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1108 - accuracy: 0.9633 - val_loss: 0.1584 - val_accuracy: 0.9540 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1071 - accuracy: 0.9644 - val_loss: 0.1599 - val_accuracy: 0.9538 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1073 - accuracy: 0.9648 - val_loss: 0.1596 - val_accuracy: 0.9540 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1149 - accuracy: 0.9636 - val_loss: 0.1595 - val_accuracy: 0.9543 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1046 - accuracy: 0.9648 - val_loss: 0.1601 - val_accuracy: 0.9538 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1083 - accuracy: 0.9648 - val_loss: 0.1581 - val_accuracy: 0.9545 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1058 - accuracy: 0.9660 - val_loss: 0.1588 - val_accuracy: 0.9543 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1059 - accuracy: 0.9658 - val_loss: 0.1598 - val_accuracy: 0.9541 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1096 - accuracy: 0.9657 - val_loss: 0.1571 - val_accuracy: 0.9544 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1086 - accuracy: 0.9648 - val_loss: 0.1592 - val_accuracy: 0.9543 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1039 - accuracy: 0.9671 - val_loss: 0.1600 - val_accuracy: 0.9541 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1048 - accuracy: 0.9668 - val_loss: 0.1597 - val_accuracy: 0.9543 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1048 - accuracy: 0.9664 - val_loss: 0.1598 - val_accuracy: 0.9542 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1097 - accuracy: 0.9649 - val_loss: 0.1580 - val_accuracy: 0.9544 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1073 - accuracy: 0.9652 - val_loss: 0.1578 - val_accuracy: 0.9544 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1085 - accuracy: 0.9654 - val_loss: 0.1574 - val_accuracy: 0.9544 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1084 - accuracy: 0.9658 - val_loss: 0.1607 - val_accuracy: 0.9536 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1051 - accuracy: 0.9652 - val_loss: 0.1614 - val_accuracy: 0.9536 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1060 - accuracy: 0.9655 - val_loss: 0.1584 - val_accuracy: 0.9545 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1085 - accuracy: 0.9652 - val_loss: 0.1599 - val_accuracy: 0.9539 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1078 - accuracy: 0.9650 - val_loss: 0.1586 - val_accuracy: 0.9544 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1080 - accuracy: 0.9674 - val_loss: 0.1579 - val_accuracy: 0.9544 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1108 - accuracy: 0.9648 - val_loss: 0.1584 - val_accuracy: 0.9543 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1060 - accuracy: 0.9660 - val_loss: 0.1579 - val_accuracy: 0.9544 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1123 - accuracy: 0.9649 - val_loss: 0.1586 - val_accuracy: 0.9544 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1090 - accuracy: 0.9667 - val_loss: 0.1588 - val_accuracy: 0.9544 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 5ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 2.5780 - accuracy: 0.8004 - val_loss: 2.6483 - val_accuracy: 0.5518 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.9224 - accuracy: 0.8285 - val_loss: 0.8770 - val_accuracy: 0.7975 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.0142 - accuracy: 0.8205 - val_loss: 0.9619 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.3426 - accuracy: 0.8204 - val_loss: 1.1761 - val_accuracy: 0.9067 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.9699 - accuracy: 0.8311 - val_loss: 1.1942 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.8473 - accuracy: 0.8443 - val_loss: 0.7410 - val_accuracy: 0.8974 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.8571 - accuracy: 0.8530 - val_loss: 1.0569 - val_accuracy: 0.9022 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.8898 - accuracy: 0.8537 - val_loss: 0.8208 - val_accuracy: 0.9081 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.7636 - accuracy: 0.8540 - val_loss: 1.3266 - val_accuracy: 0.8974 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.9450 - accuracy: 0.8512 - val_loss: 2.4332 - val_accuracy: 0.7242 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.8594 - accuracy: 0.8538 - val_loss: 0.5431 - val_accuracy: 0.9002 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.5683 - accuracy: 0.8645 - val_loss: 0.8736 - val_accuracy: 0.8974 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.5260 - accuracy: 0.8729 - val_loss: 0.3890 - val_accuracy: 0.9032 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.5786 - accuracy: 0.8765 - val_loss: 1.0142 - val_accuracy: 0.8975 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.5282 - accuracy: 0.8796 - val_loss: 0.5942 - val_accuracy: 0.9035 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4726 - accuracy: 0.8884 - val_loss: 1.1679 - val_accuracy: 0.7134 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4495 - accuracy: 0.8914 - val_loss: 0.3564 - val_accuracy: 0.9052 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4311 - accuracy: 0.8966 - val_loss: 4.1500 - val_accuracy: 0.1280 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4019 - accuracy: 0.9016 - val_loss: 0.5806 - val_accuracy: 0.9012 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4006 - accuracy: 0.9076 - val_loss: 3.3155 - val_accuracy: 0.2810 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3421 - accuracy: 0.9177 - val_loss: 0.5945 - val_accuracy: 0.9040 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3280 - accuracy: 0.9148 - val_loss: 0.3796 - val_accuracy: 0.9204 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3071 - accuracy: 0.9208 - val_loss: 0.4254 - val_accuracy: 0.9101 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2872 - accuracy: 0.9264 - val_loss: 0.7343 - val_accuracy: 0.8980 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2850 - accuracy: 0.9330 - val_loss: 0.2883 - val_accuracy: 0.9375 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2951 - accuracy: 0.9303 - val_loss: 0.2688 - val_accuracy: 0.9490 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2711 - accuracy: 0.9390 - val_loss: 0.5615 - val_accuracy: 0.8556 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2737 - accuracy: 0.9379 - val_loss: 0.3606 - val_accuracy: 0.9279 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2529 - accuracy: 0.9386 - val_loss: 0.2747 - val_accuracy: 0.9374 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2333 - accuracy: 0.9469 - val_loss: 0.2640 - val_accuracy: 0.9385 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2194 - accuracy: 0.9427 - val_loss: 0.4346 - val_accuracy: 0.8868 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2186 - accuracy: 0.9414 - val_loss: 0.3196 - val_accuracy: 0.9109 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2018 - accuracy: 0.9507 - val_loss: 0.2255 - val_accuracy: 0.9484 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1987 - accuracy: 0.9482 - val_loss: 0.7258 - val_accuracy: 0.8008 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1965 - accuracy: 0.9503 - val_loss: 0.1908 - val_accuracy: 0.9533 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1810 - accuracy: 0.9508 - val_loss: 0.1957 - val_accuracy: 0.9550 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1753 - accuracy: 0.9529 - val_loss: 0.2894 - val_accuracy: 0.9215 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1667 - accuracy: 0.9548 - val_loss: 0.3011 - val_accuracy: 0.9362 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1756 - accuracy: 0.9508 - val_loss: 0.3230 - val_accuracy: 0.9087 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1671 - accuracy: 0.9527 - val_loss: 0.1894 - val_accuracy: 0.9541 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1587 - accuracy: 0.9565 - val_loss: 0.2477 - val_accuracy: 0.9312 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1652 - accuracy: 0.9519 - val_loss: 0.2350 - val_accuracy: 0.9398 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1518 - accuracy: 0.9553 - val_loss: 0.1872 - val_accuracy: 0.9549 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1419 - accuracy: 0.9595 - val_loss: 0.3335 - val_accuracy: 0.9084 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1451 - accuracy: 0.9595 - val_loss: 0.1703 - val_accuracy: 0.9553 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1490 - accuracy: 0.9586 - val_loss: 0.1887 - val_accuracy: 0.9491 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1434 - accuracy: 0.9566 - val_loss: 0.2208 - val_accuracy: 0.9392 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1373 - accuracy: 0.9611 - val_loss: 0.1893 - val_accuracy: 0.9493 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1342 - accuracy: 0.9622 - val_loss: 0.1831 - val_accuracy: 0.9504 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1304 - accuracy: 0.9618 - val_loss: 0.2213 - val_accuracy: 0.9396 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1399 - accuracy: 0.9613 - val_loss: 0.2038 - val_accuracy: 0.9421 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1297 - accuracy: 0.9637 - val_loss: 0.1759 - val_accuracy: 0.9505 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1305 - accuracy: 0.9606 - val_loss: 0.1757 - val_accuracy: 0.9524 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1238 - accuracy: 0.9627 - val_loss: 0.2073 - val_accuracy: 0.9431 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1195 - accuracy: 0.9638 - val_loss: 0.1735 - val_accuracy: 0.9540 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1183 - accuracy: 0.9655 - val_loss: 0.2005 - val_accuracy: 0.9473 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1168 - accuracy: 0.9657 - val_loss: 0.2190 - val_accuracy: 0.9417 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1165 - accuracy: 0.9655 - val_loss: 0.1720 - val_accuracy: 0.9542 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1182 - accuracy: 0.9647 - val_loss: 0.1882 - val_accuracy: 0.9480 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1157 - accuracy: 0.9653 - val_loss: 0.1810 - val_accuracy: 0.9504 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1186 - accuracy: 0.9659 - val_loss: 0.1744 - val_accuracy: 0.9520 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1205 - accuracy: 0.9637 - val_loss: 0.2333 - val_accuracy: 0.9366 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1188 - accuracy: 0.9637 - val_loss: 0.1825 - val_accuracy: 0.9501 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1145 - accuracy: 0.9641 - val_loss: 0.1706 - val_accuracy: 0.9561 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1131 - accuracy: 0.9689 - val_loss: 0.1663 - val_accuracy: 0.9566 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1174 - accuracy: 0.9665 - val_loss: 0.1863 - val_accuracy: 0.9500 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1072 - accuracy: 0.9690 - val_loss: 0.1864 - val_accuracy: 0.9508 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1116 - accuracy: 0.9661 - val_loss: 0.1851 - val_accuracy: 0.9502 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1048 - accuracy: 0.9701 - val_loss: 0.1832 - val_accuracy: 0.9504 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1055 - accuracy: 0.9704 - val_loss: 0.2006 - val_accuracy: 0.9452 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1057 - accuracy: 0.9690 - val_loss: 0.1871 - val_accuracy: 0.9497 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1087 - accuracy: 0.9685 - val_loss: 0.1783 - val_accuracy: 0.9529 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1118 - accuracy: 0.9678 - val_loss: 0.1981 - val_accuracy: 0.9471 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1067 - accuracy: 0.9683 - val_loss: 0.1845 - val_accuracy: 0.9507 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1019 - accuracy: 0.9715 - val_loss: 0.1829 - val_accuracy: 0.9511 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1005 - accuracy: 0.9691 - val_loss: 0.1851 - val_accuracy: 0.9515 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1047 - accuracy: 0.9717 - val_loss: 0.1945 - val_accuracy: 0.9488 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1044 - accuracy: 0.9705 - val_loss: 0.1913 - val_accuracy: 0.9493 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1068 - accuracy: 0.9696 - val_loss: 0.1823 - val_accuracy: 0.9518 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1062 - accuracy: 0.9690 - val_loss: 0.1875 - val_accuracy: 0.9498 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1050 - accuracy: 0.9705 - val_loss: 0.1932 - val_accuracy: 0.9485 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1048 - accuracy: 0.9699 - val_loss: 0.1831 - val_accuracy: 0.9510 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1025 - accuracy: 0.9702 - val_loss: 0.1962 - val_accuracy: 0.9480 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1017 - accuracy: 0.9710 - val_loss: 0.1851 - val_accuracy: 0.9511 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1045 - accuracy: 0.9699 - val_loss: 0.1938 - val_accuracy: 0.9491 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1018 - accuracy: 0.9697 - val_loss: 0.1910 - val_accuracy: 0.9491 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1009 - accuracy: 0.9701 - val_loss: 0.1877 - val_accuracy: 0.9502 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1069 - accuracy: 0.9685 - val_loss: 0.1926 - val_accuracy: 0.9490 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1077 - accuracy: 0.9683 - val_loss: 0.1900 - val_accuracy: 0.9495 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1006 - accuracy: 0.9720 - val_loss: 0.1888 - val_accuracy: 0.9498 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1004 - accuracy: 0.9706 - val_loss: 0.1878 - val_accuracy: 0.9502 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0961 - accuracy: 0.9713 - val_loss: 0.1874 - val_accuracy: 0.9505 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1024 - accuracy: 0.9707 - val_loss: 0.1877 - val_accuracy: 0.9504 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0965 - accuracy: 0.9715 - val_loss: 0.1854 - val_accuracy: 0.9511 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1024 - accuracy: 0.9716 - val_loss: 0.1877 - val_accuracy: 0.9501 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1084 - accuracy: 0.9686 - val_loss: 0.1880 - val_accuracy: 0.9500 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1033 - accuracy: 0.9697 - val_loss: 0.1897 - val_accuracy: 0.9499 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1034 - accuracy: 0.9703 - val_loss: 0.1895 - val_accuracy: 0.9499 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1031 - accuracy: 0.9689 - val_loss: 0.1869 - val_accuracy: 0.9504 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1016 - accuracy: 0.9712 - val_loss: 0.1879 - val_accuracy: 0.9502 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 5ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 2.7183 - accuracy: 0.7911 - val_loss: 1.1206 - val_accuracy: 0.9010 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.0520 - accuracy: 0.8274 - val_loss: 0.6897 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.7924 - accuracy: 0.8267 - val_loss: 0.6014 - val_accuracy: 0.9114 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.6879 - accuracy: 0.8320 - val_loss: 0.5257 - val_accuracy: 0.8460 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.6366 - accuracy: 0.8369 - val_loss: 0.7156 - val_accuracy: 0.8187 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.6486 - accuracy: 0.8445 - val_loss: 0.6535 - val_accuracy: 0.8978 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.5462 - accuracy: 0.8482 - val_loss: 0.4156 - val_accuracy: 0.8997 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.5098 - accuracy: 0.8503 - val_loss: 0.3888 - val_accuracy: 0.9308 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4745 - accuracy: 0.8626 - val_loss: 0.3825 - val_accuracy: 0.9264 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4645 - accuracy: 0.8653 - val_loss: 0.3113 - val_accuracy: 0.9305 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4371 - accuracy: 0.8774 - val_loss: 0.2912 - val_accuracy: 0.9401 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4184 - accuracy: 0.8787 - val_loss: 0.5488 - val_accuracy: 0.8235 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3931 - accuracy: 0.8887 - val_loss: 0.4197 - val_accuracy: 0.8697 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3836 - accuracy: 0.8920 - val_loss: 0.2985 - val_accuracy: 0.9290 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3615 - accuracy: 0.8991 - val_loss: 0.2755 - val_accuracy: 0.9383 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3464 - accuracy: 0.9007 - val_loss: 0.2675 - val_accuracy: 0.9350 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3312 - accuracy: 0.9077 - val_loss: 0.3332 - val_accuracy: 0.9011 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3158 - accuracy: 0.9121 - val_loss: 0.2697 - val_accuracy: 0.9325 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2992 - accuracy: 0.9134 - val_loss: 0.2381 - val_accuracy: 0.9405 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.2870 - accuracy: 0.9168 - val_loss: 0.2878 - val_accuracy: 0.9137 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2808 - accuracy: 0.9164 - val_loss: 0.4377 - val_accuracy: 0.8662 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2639 - accuracy: 0.9257 - val_loss: 0.2241 - val_accuracy: 0.9455 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2514 - accuracy: 0.9275 - val_loss: 0.4243 - val_accuracy: 0.8625 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2347 - accuracy: 0.9323 - val_loss: 0.2568 - val_accuracy: 0.9281 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2314 - accuracy: 0.9342 - val_loss: 0.2162 - val_accuracy: 0.9429 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2201 - accuracy: 0.9385 - val_loss: 0.2316 - val_accuracy: 0.9329 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2124 - accuracy: 0.9423 - val_loss: 0.3868 - val_accuracy: 0.8926 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2067 - accuracy: 0.9440 - val_loss: 0.2113 - val_accuracy: 0.9414 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2030 - accuracy: 0.9456 - val_loss: 0.1902 - val_accuracy: 0.9490 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.1878 - accuracy: 0.9480 - val_loss: 0.2312 - val_accuracy: 0.9356 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1902 - accuracy: 0.9507 - val_loss: 0.1886 - val_accuracy: 0.9492 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1837 - accuracy: 0.9508 - val_loss: 0.1805 - val_accuracy: 0.9515 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1726 - accuracy: 0.9533 - val_loss: 0.2138 - val_accuracy: 0.9403 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1668 - accuracy: 0.9559 - val_loss: 0.1850 - val_accuracy: 0.9519 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1632 - accuracy: 0.9568 - val_loss: 0.1733 - val_accuracy: 0.9550 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1577 - accuracy: 0.9562 - val_loss: 0.1661 - val_accuracy: 0.9589 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1502 - accuracy: 0.9593 - val_loss: 0.1703 - val_accuracy: 0.9543 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1483 - accuracy: 0.9603 - val_loss: 0.1616 - val_accuracy: 0.9585 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1379 - accuracy: 0.9611 - val_loss: 0.1659 - val_accuracy: 0.9552 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1372 - accuracy: 0.9629 - val_loss: 0.1590 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1340 - accuracy: 0.9635 - val_loss: 0.1620 - val_accuracy: 0.9557 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1327 - accuracy: 0.9638 - val_loss: 0.1654 - val_accuracy: 0.9550 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1197 - accuracy: 0.9673 - val_loss: 0.1549 - val_accuracy: 0.9590 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1238 - accuracy: 0.9660 - val_loss: 0.1715 - val_accuracy: 0.9532 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1170 - accuracy: 0.9698 - val_loss: 0.1666 - val_accuracy: 0.9561 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1193 - accuracy: 0.9674 - val_loss: 0.1598 - val_accuracy: 0.9575 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1139 - accuracy: 0.9697 - val_loss: 0.1734 - val_accuracy: 0.9527 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1124 - accuracy: 0.9689 - val_loss: 0.1564 - val_accuracy: 0.9587 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1080 - accuracy: 0.9724 - val_loss: 0.1714 - val_accuracy: 0.9539 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1031 - accuracy: 0.9739 - val_loss: 0.1623 - val_accuracy: 0.9573 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1060 - accuracy: 0.9729 - val_loss: 0.1681 - val_accuracy: 0.9547 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1025 - accuracy: 0.9732 - val_loss: 0.1508 - val_accuracy: 0.9604 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0987 - accuracy: 0.9733 - val_loss: 0.1782 - val_accuracy: 0.9523 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1030 - accuracy: 0.9720 - val_loss: 0.1665 - val_accuracy: 0.9555 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0967 - accuracy: 0.9749 - val_loss: 0.1542 - val_accuracy: 0.9595 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0977 - accuracy: 0.9741 - val_loss: 0.1636 - val_accuracy: 0.9569 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0971 - accuracy: 0.9743 - val_loss: 0.1611 - val_accuracy: 0.9580 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0953 - accuracy: 0.9744 - val_loss: 0.1549 - val_accuracy: 0.9595 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0943 - accuracy: 0.9752 - val_loss: 0.1595 - val_accuracy: 0.9585 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0922 - accuracy: 0.9785 - val_loss: 0.1601 - val_accuracy: 0.9588 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0962 - accuracy: 0.9745 - val_loss: 0.1587 - val_accuracy: 0.9584 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0900 - accuracy: 0.9765 - val_loss: 0.1597 - val_accuracy: 0.9594 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0920 - accuracy: 0.9772 - val_loss: 0.1547 - val_accuracy: 0.9604 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0910 - accuracy: 0.9761 - val_loss: 0.1627 - val_accuracy: 0.9582 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0875 - accuracy: 0.9764 - val_loss: 0.1577 - val_accuracy: 0.9600 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0831 - accuracy: 0.9780 - val_loss: 0.1593 - val_accuracy: 0.9593 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0860 - accuracy: 0.9786 - val_loss: 0.1637 - val_accuracy: 0.9575 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0912 - accuracy: 0.9770 - val_loss: 0.1592 - val_accuracy: 0.9589 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0848 - accuracy: 0.9785 - val_loss: 0.1594 - val_accuracy: 0.9588 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0900 - accuracy: 0.9761 - val_loss: 0.1607 - val_accuracy: 0.9581 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0841 - accuracy: 0.9782 - val_loss: 0.1575 - val_accuracy: 0.9595 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0864 - accuracy: 0.9772 - val_loss: 0.1643 - val_accuracy: 0.9578 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0866 - accuracy: 0.9770 - val_loss: 0.1600 - val_accuracy: 0.9591 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0830 - accuracy: 0.9796 - val_loss: 0.1581 - val_accuracy: 0.9597 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0842 - accuracy: 0.9783 - val_loss: 0.1584 - val_accuracy: 0.9593 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0845 - accuracy: 0.9786 - val_loss: 0.1587 - val_accuracy: 0.9595 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0837 - accuracy: 0.9777 - val_loss: 0.1593 - val_accuracy: 0.9593 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0866 - accuracy: 0.9784 - val_loss: 0.1615 - val_accuracy: 0.9589 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0880 - accuracy: 0.9764 - val_loss: 0.1619 - val_accuracy: 0.9586 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0840 - accuracy: 0.9786 - val_loss: 0.1608 - val_accuracy: 0.9592 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0820 - accuracy: 0.9791 - val_loss: 0.1610 - val_accuracy: 0.9593 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0840 - accuracy: 0.9788 - val_loss: 0.1599 - val_accuracy: 0.9593 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0871 - accuracy: 0.9775 - val_loss: 0.1618 - val_accuracy: 0.9586 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0844 - accuracy: 0.9790 - val_loss: 0.1617 - val_accuracy: 0.9586 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0860 - accuracy: 0.9781 - val_loss: 0.1598 - val_accuracy: 0.9592 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0863 - accuracy: 0.9774 - val_loss: 0.1594 - val_accuracy: 0.9593 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0857 - accuracy: 0.9782 - val_loss: 0.1615 - val_accuracy: 0.9587 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0815 - accuracy: 0.9782 - val_loss: 0.1603 - val_accuracy: 0.9592 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0861 - accuracy: 0.9781 - val_loss: 0.1595 - val_accuracy: 0.9593 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0869 - accuracy: 0.9785 - val_loss: 0.1592 - val_accuracy: 0.9593 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0840 - accuracy: 0.9786 - val_loss: 0.1598 - val_accuracy: 0.9592 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0855 - accuracy: 0.9796 - val_loss: 0.1603 - val_accuracy: 0.9593 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0845 - accuracy: 0.9784 - val_loss: 0.1604 - val_accuracy: 0.9592 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0807 - accuracy: 0.9775 - val_loss: 0.1594 - val_accuracy: 0.9591 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0825 - accuracy: 0.9786 - val_loss: 0.1593 - val_accuracy: 0.9592 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0838 - accuracy: 0.9801 - val_loss: 0.1598 - val_accuracy: 0.9590 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0856 - accuracy: 0.9794 - val_loss: 0.1607 - val_accuracy: 0.9592 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0858 - accuracy: 0.9776 - val_loss: 0.1606 - val_accuracy: 0.9592 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0841 - accuracy: 0.9777 - val_loss: 0.1611 - val_accuracy: 0.9591 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0851 - accuracy: 0.9792 - val_loss: 0.1595 - val_accuracy: 0.9592 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 1s 5ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 12s 40ms/step - loss: 10.8902 - accuracy: 0.7454 - val_loss: 3.9210 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 3.3520 - accuracy: 0.7889 - val_loss: 3.3777 - val_accuracy: 0.5919 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 3.0978 - accuracy: 0.8007 - val_loss: 6.5341 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 2.7408 - accuracy: 0.8097 - val_loss: 2.1442 - val_accuracy: 0.6010 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.4057 - accuracy: 0.8085 - val_loss: 1.5477 - val_accuracy: 0.5411 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.8469 - accuracy: 0.8086 - val_loss: 0.6239 - val_accuracy: 0.9003 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.8050 - accuracy: 0.8237 - val_loss: 0.6579 - val_accuracy: 0.8895 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.8271 - accuracy: 0.8212 - val_loss: 0.9353 - val_accuracy: 0.8316 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.1005 - accuracy: 0.8220 - val_loss: 0.7615 - val_accuracy: 0.9162 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 1.5792 - accuracy: 0.8204 - val_loss: 0.6384 - val_accuracy: 0.9070 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.8827 - accuracy: 0.8268 - val_loss: 0.6886 - val_accuracy: 0.9071 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.8801 - accuracy: 0.8289 - val_loss: 2.7782 - val_accuracy: 0.4479 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.8712 - accuracy: 0.8448 - val_loss: 0.7578 - val_accuracy: 0.8660 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.6689 - accuracy: 0.8426 - val_loss: 0.5134 - val_accuracy: 0.9154 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.6058 - accuracy: 0.8390 - val_loss: 0.6358 - val_accuracy: 0.8404 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.6161 - accuracy: 0.8380 - val_loss: 2.8826 - val_accuracy: 0.4720 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.6558 - accuracy: 0.8334 - val_loss: 0.5611 - val_accuracy: 0.8356 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5359 - accuracy: 0.8518 - val_loss: 0.3870 - val_accuracy: 0.9262 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.5529 - accuracy: 0.8511 - val_loss: 0.4154 - val_accuracy: 0.9185 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5061 - accuracy: 0.8587 - val_loss: 0.3891 - val_accuracy: 0.9180 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.4765 - accuracy: 0.8671 - val_loss: 0.7324 - val_accuracy: 0.7856 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.4408 - accuracy: 0.8742 - val_loss: 0.3146 - val_accuracy: 0.9218 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.4039 - accuracy: 0.8826 - val_loss: 0.4648 - val_accuracy: 0.8523 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.4290 - accuracy: 0.8793 - val_loss: 0.3718 - val_accuracy: 0.9029 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4003 - accuracy: 0.8820 - val_loss: 0.3307 - val_accuracy: 0.9125 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.3817 - accuracy: 0.8846 - val_loss: 0.2811 - val_accuracy: 0.9347 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.3571 - accuracy: 0.8921 - val_loss: 0.2760 - val_accuracy: 0.9313 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3529 - accuracy: 0.8924 - val_loss: 0.2416 - val_accuracy: 0.9480 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3306 - accuracy: 0.9003 - val_loss: 0.2403 - val_accuracy: 0.9457 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3258 - accuracy: 0.9041 - val_loss: 0.2596 - val_accuracy: 0.9433 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3069 - accuracy: 0.9021 - val_loss: 0.4830 - val_accuracy: 0.8315 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2927 - accuracy: 0.9105 - val_loss: 0.3970 - val_accuracy: 0.8692 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2810 - accuracy: 0.9130 - val_loss: 0.4073 - val_accuracy: 0.8669 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2709 - accuracy: 0.9153 - val_loss: 0.2689 - val_accuracy: 0.9146 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2628 - accuracy: 0.9206 - val_loss: 0.2243 - val_accuracy: 0.9414 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2504 - accuracy: 0.9256 - val_loss: 0.2859 - val_accuracy: 0.9131 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2484 - accuracy: 0.9222 - val_loss: 0.2939 - val_accuracy: 0.9103 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2323 - accuracy: 0.9293 - val_loss: 0.2323 - val_accuracy: 0.9329 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2314 - accuracy: 0.9291 - val_loss: 0.1937 - val_accuracy: 0.9476 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2215 - accuracy: 0.9318 - val_loss: 0.1790 - val_accuracy: 0.9532 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.2061 - accuracy: 0.9348 - val_loss: 0.2003 - val_accuracy: 0.9401 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2002 - accuracy: 0.9365 - val_loss: 0.2142 - val_accuracy: 0.9323 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2018 - accuracy: 0.9371 - val_loss: 0.1843 - val_accuracy: 0.9465 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1978 - accuracy: 0.9382 - val_loss: 0.1938 - val_accuracy: 0.9408 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1910 - accuracy: 0.9425 - val_loss: 0.1668 - val_accuracy: 0.9529 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1801 - accuracy: 0.9450 - val_loss: 0.1677 - val_accuracy: 0.9513 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1781 - accuracy: 0.9436 - val_loss: 0.1654 - val_accuracy: 0.9519 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1694 - accuracy: 0.9464 - val_loss: 0.1648 - val_accuracy: 0.9535 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1638 - accuracy: 0.9482 - val_loss: 0.1541 - val_accuracy: 0.9587 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1652 - accuracy: 0.9500 - val_loss: 0.1820 - val_accuracy: 0.9456 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1549 - accuracy: 0.9531 - val_loss: 0.1646 - val_accuracy: 0.9515 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1510 - accuracy: 0.9522 - val_loss: 0.1478 - val_accuracy: 0.9572 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1496 - accuracy: 0.9531 - val_loss: 0.1646 - val_accuracy: 0.9511 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1465 - accuracy: 0.9557 - val_loss: 0.1526 - val_accuracy: 0.9560 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1441 - accuracy: 0.9528 - val_loss: 0.1529 - val_accuracy: 0.9539 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1450 - accuracy: 0.9557 - val_loss: 0.1592 - val_accuracy: 0.9520 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1416 - accuracy: 0.9564 - val_loss: 0.1530 - val_accuracy: 0.9538 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1399 - accuracy: 0.9578 - val_loss: 0.1630 - val_accuracy: 0.9500 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1309 - accuracy: 0.9586 - val_loss: 0.1599 - val_accuracy: 0.9511 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1304 - accuracy: 0.9575 - val_loss: 0.1527 - val_accuracy: 0.9547 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1283 - accuracy: 0.9597 - val_loss: 0.1835 - val_accuracy: 0.9443 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1266 - accuracy: 0.9609 - val_loss: 0.1640 - val_accuracy: 0.9502 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1294 - accuracy: 0.9579 - val_loss: 0.1520 - val_accuracy: 0.9542 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1266 - accuracy: 0.9592 - val_loss: 0.1518 - val_accuracy: 0.9541 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1249 - accuracy: 0.9619 - val_loss: 0.1591 - val_accuracy: 0.9519 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1299 - accuracy: 0.9587 - val_loss: 0.1535 - val_accuracy: 0.9532 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1219 - accuracy: 0.9614 - val_loss: 0.1487 - val_accuracy: 0.9561 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1208 - accuracy: 0.9627 - val_loss: 0.1470 - val_accuracy: 0.9561 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1183 - accuracy: 0.9639 - val_loss: 0.1550 - val_accuracy: 0.9530 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1175 - accuracy: 0.9628 - val_loss: 0.1515 - val_accuracy: 0.9541 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1190 - accuracy: 0.9625 - val_loss: 0.1585 - val_accuracy: 0.9522 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1158 - accuracy: 0.9640 - val_loss: 0.1464 - val_accuracy: 0.9558 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1220 - accuracy: 0.9624 - val_loss: 0.1481 - val_accuracy: 0.9551 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1171 - accuracy: 0.9637 - val_loss: 0.1527 - val_accuracy: 0.9535 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1151 - accuracy: 0.9642 - val_loss: 0.1550 - val_accuracy: 0.9533 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1167 - accuracy: 0.9621 - val_loss: 0.1544 - val_accuracy: 0.9535 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1181 - accuracy: 0.9626 - val_loss: 0.1530 - val_accuracy: 0.9536 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1113 - accuracy: 0.9646 - val_loss: 0.1528 - val_accuracy: 0.9538 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1139 - accuracy: 0.9635 - val_loss: 0.1517 - val_accuracy: 0.9536 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1132 - accuracy: 0.9643 - val_loss: 0.1506 - val_accuracy: 0.9540 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1128 - accuracy: 0.9629 - val_loss: 0.1519 - val_accuracy: 0.9542 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1142 - accuracy: 0.9645 - val_loss: 0.1507 - val_accuracy: 0.9543 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1096 - accuracy: 0.9665 - val_loss: 0.1509 - val_accuracy: 0.9542 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1130 - accuracy: 0.9642 - val_loss: 0.1510 - val_accuracy: 0.9542 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1087 - accuracy: 0.9650 - val_loss: 0.1501 - val_accuracy: 0.9547 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1105 - accuracy: 0.9645 - val_loss: 0.1504 - val_accuracy: 0.9545 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1126 - accuracy: 0.9650 - val_loss: 0.1519 - val_accuracy: 0.9541 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1110 - accuracy: 0.9647 - val_loss: 0.1506 - val_accuracy: 0.9546 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1123 - accuracy: 0.9652 - val_loss: 0.1520 - val_accuracy: 0.9538 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1107 - accuracy: 0.9648 - val_loss: 0.1492 - val_accuracy: 0.9549 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1109 - accuracy: 0.9652 - val_loss: 0.1493 - val_accuracy: 0.9550 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1103 - accuracy: 0.9654 - val_loss: 0.1493 - val_accuracy: 0.9547 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1123 - accuracy: 0.9654 - val_loss: 0.1500 - val_accuracy: 0.9547 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1139 - accuracy: 0.9651 - val_loss: 0.1504 - val_accuracy: 0.9544 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1112 - accuracy: 0.9645 - val_loss: 0.1490 - val_accuracy: 0.9550 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1047 - accuracy: 0.9673 - val_loss: 0.1494 - val_accuracy: 0.9547 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1070 - accuracy: 0.9668 - val_loss: 0.1507 - val_accuracy: 0.9545 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1103 - accuracy: 0.9658 - val_loss: 0.1508 - val_accuracy: 0.9543 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1085 - accuracy: 0.9662 - val_loss: 0.1495 - val_accuracy: 0.9550 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1133 - accuracy: 0.9655 - val_loss: 0.1505 - val_accuracy: 0.9547 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 10.3377 - accuracy: 0.7340 - val_loss: 4.3905 - val_accuracy: 0.6938 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 5.2390 - accuracy: 0.7531 - val_loss: 4.4373 - val_accuracy: 0.8141 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 6.0151 - accuracy: 0.7554 - val_loss: 3.5166 - val_accuracy: 0.9027 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 10.2121 - accuracy: 0.7369 - val_loss: 11.0340 - val_accuracy: 0.3632 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 7.9195 - accuracy: 0.7771 - val_loss: 5.0513 - val_accuracy: 0.8590 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 3.5477 - accuracy: 0.7883 - val_loss: 4.3545 - val_accuracy: 0.3030 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 5.1813 - accuracy: 0.7839 - val_loss: 3.3034 - val_accuracy: 0.9013 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 3.7018 - accuracy: 0.7839 - val_loss: 2.7552 - val_accuracy: 0.8974 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 3.1523 - accuracy: 0.7917 - val_loss: 2.7293 - val_accuracy: 0.9064 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 2.0020 - accuracy: 0.8155 - val_loss: 2.8588 - val_accuracy: 0.9094 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 1.4297 - accuracy: 0.8191 - val_loss: 2.8711 - val_accuracy: 0.8974 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.1668 - accuracy: 0.8259 - val_loss: 1.7631 - val_accuracy: 0.8101 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.9983 - accuracy: 0.8411 - val_loss: 0.6856 - val_accuracy: 0.9183 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 1.0903 - accuracy: 0.8377 - val_loss: 0.6401 - val_accuracy: 0.9220 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.9286 - accuracy: 0.8519 - val_loss: 0.5649 - val_accuracy: 0.8977 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.7573 - accuracy: 0.8537 - val_loss: 0.6000 - val_accuracy: 0.9098 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.6697 - accuracy: 0.8569 - val_loss: 0.8503 - val_accuracy: 0.8980 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.7294 - accuracy: 0.8597 - val_loss: 0.5231 - val_accuracy: 0.9125 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5046 - accuracy: 0.8689 - val_loss: 1.0182 - val_accuracy: 0.6893 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4743 - accuracy: 0.8689 - val_loss: 0.9523 - val_accuracy: 0.6592 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.4891 - accuracy: 0.8717 - val_loss: 0.9495 - val_accuracy: 0.7097 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.5027 - accuracy: 0.8891 - val_loss: 0.6767 - val_accuracy: 0.9095 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.4690 - accuracy: 0.8861 - val_loss: 2.6306 - val_accuracy: 0.4133 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4132 - accuracy: 0.8911 - val_loss: 0.9483 - val_accuracy: 0.7418 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4049 - accuracy: 0.8970 - val_loss: 1.1154 - val_accuracy: 0.8974 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3600 - accuracy: 0.9048 - val_loss: 0.5336 - val_accuracy: 0.8507 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3931 - accuracy: 0.9050 - val_loss: 1.1826 - val_accuracy: 0.5783 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3491 - accuracy: 0.9112 - val_loss: 0.5281 - val_accuracy: 0.8353 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3464 - accuracy: 0.9039 - val_loss: 0.2773 - val_accuracy: 0.9337 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3182 - accuracy: 0.9145 - val_loss: 0.3876 - val_accuracy: 0.8914 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3101 - accuracy: 0.9128 - val_loss: 0.4458 - val_accuracy: 0.8694 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2839 - accuracy: 0.9204 - val_loss: 0.7505 - val_accuracy: 0.7159 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2701 - accuracy: 0.9253 - val_loss: 1.1758 - val_accuracy: 0.6604 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2635 - accuracy: 0.9230 - val_loss: 0.3430 - val_accuracy: 0.8986 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2362 - accuracy: 0.9276 - val_loss: 0.2149 - val_accuracy: 0.9474 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2428 - accuracy: 0.9293 - val_loss: 0.6572 - val_accuracy: 0.8067 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2276 - accuracy: 0.9320 - val_loss: 0.2415 - val_accuracy: 0.9275 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2208 - accuracy: 0.9342 - val_loss: 0.2257 - val_accuracy: 0.9327 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2054 - accuracy: 0.9386 - val_loss: 0.2246 - val_accuracy: 0.9323 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2046 - accuracy: 0.9399 - val_loss: 0.3524 - val_accuracy: 0.8870 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1920 - accuracy: 0.9417 - val_loss: 0.4102 - val_accuracy: 0.8720 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1949 - accuracy: 0.9412 - val_loss: 0.1870 - val_accuracy: 0.9469 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1821 - accuracy: 0.9436 - val_loss: 0.2975 - val_accuracy: 0.9060 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1887 - accuracy: 0.9431 - val_loss: 0.2138 - val_accuracy: 0.9389 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1846 - accuracy: 0.9422 - val_loss: 0.1792 - val_accuracy: 0.9474 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1746 - accuracy: 0.9457 - val_loss: 0.2849 - val_accuracy: 0.9095 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1678 - accuracy: 0.9483 - val_loss: 0.2985 - val_accuracy: 0.9080 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1688 - accuracy: 0.9469 - val_loss: 0.6409 - val_accuracy: 0.8004 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1617 - accuracy: 0.9491 - val_loss: 0.1964 - val_accuracy: 0.9403 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1603 - accuracy: 0.9497 - val_loss: 0.2348 - val_accuracy: 0.9308 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1481 - accuracy: 0.9515 - val_loss: 0.1677 - val_accuracy: 0.9501 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1543 - accuracy: 0.9506 - val_loss: 0.2721 - val_accuracy: 0.9166 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1527 - accuracy: 0.9496 - val_loss: 0.2137 - val_accuracy: 0.9298 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1482 - accuracy: 0.9535 - val_loss: 0.1682 - val_accuracy: 0.9476 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1480 - accuracy: 0.9530 - val_loss: 0.1955 - val_accuracy: 0.9388 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1421 - accuracy: 0.9541 - val_loss: 0.1713 - val_accuracy: 0.9476 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1410 - accuracy: 0.9546 - val_loss: 0.1964 - val_accuracy: 0.9400 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1365 - accuracy: 0.9560 - val_loss: 0.2775 - val_accuracy: 0.9158 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1420 - accuracy: 0.9551 - val_loss: 0.1856 - val_accuracy: 0.9416 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1411 - accuracy: 0.9535 - val_loss: 0.2118 - val_accuracy: 0.9339 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1374 - accuracy: 0.9546 - val_loss: 0.2081 - val_accuracy: 0.9352 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1311 - accuracy: 0.9556 - val_loss: 0.2116 - val_accuracy: 0.9332 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1332 - accuracy: 0.9563 - val_loss: 0.2463 - val_accuracy: 0.9239 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1406 - accuracy: 0.9527 - val_loss: 0.1896 - val_accuracy: 0.9403 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1279 - accuracy: 0.9598 - val_loss: 0.1748 - val_accuracy: 0.9458 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1313 - accuracy: 0.9583 - val_loss: 0.2017 - val_accuracy: 0.9356 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1305 - accuracy: 0.9579 - val_loss: 0.2031 - val_accuracy: 0.9368 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1280 - accuracy: 0.9574 - val_loss: 0.1776 - val_accuracy: 0.9452 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1302 - accuracy: 0.9563 - val_loss: 0.1896 - val_accuracy: 0.9417 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1251 - accuracy: 0.9595 - val_loss: 0.3218 - val_accuracy: 0.9007 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1230 - accuracy: 0.9599 - val_loss: 0.2145 - val_accuracy: 0.9335 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1227 - accuracy: 0.9599 - val_loss: 0.1929 - val_accuracy: 0.9393 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1238 - accuracy: 0.9589 - val_loss: 0.1921 - val_accuracy: 0.9390 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1219 - accuracy: 0.9611 - val_loss: 0.1916 - val_accuracy: 0.9399 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1212 - accuracy: 0.9598 - val_loss: 0.1960 - val_accuracy: 0.9388 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1210 - accuracy: 0.9599 - val_loss: 0.2053 - val_accuracy: 0.9361 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1290 - accuracy: 0.9558 - val_loss: 0.1880 - val_accuracy: 0.9403 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1197 - accuracy: 0.9609 - val_loss: 0.1794 - val_accuracy: 0.9442 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1229 - accuracy: 0.9593 - val_loss: 0.1945 - val_accuracy: 0.9389 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1198 - accuracy: 0.9602 - val_loss: 0.1976 - val_accuracy: 0.9381 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1178 - accuracy: 0.9599 - val_loss: 0.1938 - val_accuracy: 0.9393 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1237 - accuracy: 0.9596 - val_loss: 0.1903 - val_accuracy: 0.9403 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1191 - accuracy: 0.9599 - val_loss: 0.1986 - val_accuracy: 0.9383 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1190 - accuracy: 0.9615 - val_loss: 0.1983 - val_accuracy: 0.9381 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1216 - accuracy: 0.9602 - val_loss: 0.1909 - val_accuracy: 0.9402 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1230 - accuracy: 0.9591 - val_loss: 0.2005 - val_accuracy: 0.9376 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1177 - accuracy: 0.9609 - val_loss: 0.1954 - val_accuracy: 0.9386 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1176 - accuracy: 0.9611 - val_loss: 0.1940 - val_accuracy: 0.9385 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1159 - accuracy: 0.9611 - val_loss: 0.1913 - val_accuracy: 0.9400 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1189 - accuracy: 0.9617 - val_loss: 0.1923 - val_accuracy: 0.9399 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1232 - accuracy: 0.9592 - val_loss: 0.1986 - val_accuracy: 0.9381 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1234 - accuracy: 0.9611 - val_loss: 0.1966 - val_accuracy: 0.9385 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1196 - accuracy: 0.9589 - val_loss: 0.1899 - val_accuracy: 0.9403 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1207 - accuracy: 0.9611 - val_loss: 0.1923 - val_accuracy: 0.9397 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1170 - accuracy: 0.9608 - val_loss: 0.1952 - val_accuracy: 0.9390 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1191 - accuracy: 0.9603 - val_loss: 0.1924 - val_accuracy: 0.9396 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1193 - accuracy: 0.9605 - val_loss: 0.1899 - val_accuracy: 0.9402 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1201 - accuracy: 0.9599 - val_loss: 0.1920 - val_accuracy: 0.9397 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1189 - accuracy: 0.9592 - val_loss: 0.1881 - val_accuracy: 0.9409 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1186 - accuracy: 0.9609 - val_loss: 0.1949 - val_accuracy: 0.9387 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 38ms/step - loss: 12.3194 - accuracy: 0.7398 - val_loss: 19.0812 - val_accuracy: 0.8709 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 8.2842 - accuracy: 0.7629 - val_loss: 4.7891 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 6.0677 - accuracy: 0.7901 - val_loss: 7.8214 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 4.7382 - accuracy: 0.7936 - val_loss: 3.9445 - val_accuracy: 0.7124 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 2.2176 - accuracy: 0.8113 - val_loss: 2.0474 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 2.4281 - accuracy: 0.8085 - val_loss: 3.7550 - val_accuracy: 0.5099 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.5488 - accuracy: 0.8235 - val_loss: 2.0623 - val_accuracy: 0.6056 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 1.1054 - accuracy: 0.8222 - val_loss: 3.8968 - val_accuracy: 0.1695 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.1962 - accuracy: 0.8197 - val_loss: 1.7663 - val_accuracy: 0.7386 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.9642 - accuracy: 0.8130 - val_loss: 1.8091 - val_accuracy: 0.8974 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.2411 - accuracy: 0.8262 - val_loss: 0.6672 - val_accuracy: 0.9015 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.8898 - accuracy: 0.8283 - val_loss: 0.7499 - val_accuracy: 0.8361 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.9141 - accuracy: 0.8415 - val_loss: 0.4347 - val_accuracy: 0.9261 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.1734 - accuracy: 0.8404 - val_loss: 0.9777 - val_accuracy: 0.8974 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.7727 - accuracy: 0.8440 - val_loss: 0.8719 - val_accuracy: 0.8974 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.7239 - accuracy: 0.8424 - val_loss: 3.9723 - val_accuracy: 0.1044 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.6262 - accuracy: 0.8472 - val_loss: 0.4055 - val_accuracy: 0.9170 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.5281 - accuracy: 0.8541 - val_loss: 0.9287 - val_accuracy: 0.7683 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4563 - accuracy: 0.8641 - val_loss: 0.3896 - val_accuracy: 0.9119 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5232 - accuracy: 0.8678 - val_loss: 1.2713 - val_accuracy: 0.7252 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5372 - accuracy: 0.8664 - val_loss: 4.9539 - val_accuracy: 0.1026 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.5613 - accuracy: 0.8607 - val_loss: 1.1299 - val_accuracy: 0.5950 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4873 - accuracy: 0.8752 - val_loss: 0.9095 - val_accuracy: 0.8974 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.6104 - accuracy: 0.8622 - val_loss: 0.3972 - val_accuracy: 0.8827 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4559 - accuracy: 0.8740 - val_loss: 0.9537 - val_accuracy: 0.5995 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4898 - accuracy: 0.8758 - val_loss: 0.7754 - val_accuracy: 0.7405 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4582 - accuracy: 0.8810 - val_loss: 0.8089 - val_accuracy: 0.7982 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5238 - accuracy: 0.8842 - val_loss: 0.4649 - val_accuracy: 0.8598 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3802 - accuracy: 0.8960 - val_loss: 0.2642 - val_accuracy: 0.9443 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3608 - accuracy: 0.8993 - val_loss: 0.2731 - val_accuracy: 0.9199 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3279 - accuracy: 0.9027 - val_loss: 0.2410 - val_accuracy: 0.9410 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3033 - accuracy: 0.9085 - val_loss: 0.5062 - val_accuracy: 0.8371 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3049 - accuracy: 0.9126 - val_loss: 0.2284 - val_accuracy: 0.9273 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2881 - accuracy: 0.9168 - val_loss: 0.3083 - val_accuracy: 0.9015 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2869 - accuracy: 0.9172 - val_loss: 0.7523 - val_accuracy: 0.7929 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2920 - accuracy: 0.9157 - val_loss: 0.4774 - val_accuracy: 0.8447 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2780 - accuracy: 0.9189 - val_loss: 0.4368 - val_accuracy: 0.8613 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2689 - accuracy: 0.9167 - val_loss: 0.9892 - val_accuracy: 0.6980 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2422 - accuracy: 0.9236 - val_loss: 1.0936 - val_accuracy: 0.6923 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2393 - accuracy: 0.9263 - val_loss: 0.2537 - val_accuracy: 0.9362 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2481 - accuracy: 0.9291 - val_loss: 0.3660 - val_accuracy: 0.8834 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2349 - accuracy: 0.9267 - val_loss: 0.2361 - val_accuracy: 0.9258 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2132 - accuracy: 0.9307 - val_loss: 0.2255 - val_accuracy: 0.9298 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2177 - accuracy: 0.9318 - val_loss: 0.2249 - val_accuracy: 0.9408 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2027 - accuracy: 0.9332 - val_loss: 0.2444 - val_accuracy: 0.9205 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2046 - accuracy: 0.9356 - val_loss: 0.2986 - val_accuracy: 0.9000 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1914 - accuracy: 0.9394 - val_loss: 0.1777 - val_accuracy: 0.9513 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1924 - accuracy: 0.9393 - val_loss: 0.1880 - val_accuracy: 0.9408 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1754 - accuracy: 0.9431 - val_loss: 0.3505 - val_accuracy: 0.8833 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1698 - accuracy: 0.9466 - val_loss: 0.1708 - val_accuracy: 0.9504 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1701 - accuracy: 0.9471 - val_loss: 0.1753 - val_accuracy: 0.9486 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1724 - accuracy: 0.9485 - val_loss: 0.1895 - val_accuracy: 0.9423 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1846 - accuracy: 0.9550 - val_loss: 0.1751 - val_accuracy: 0.9526 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1729 - accuracy: 0.9512 - val_loss: 0.2049 - val_accuracy: 0.9367 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1814 - accuracy: 0.9502 - val_loss: 0.1804 - val_accuracy: 0.9468 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1739 - accuracy: 0.9443 - val_loss: 0.1735 - val_accuracy: 0.9500 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1687 - accuracy: 0.9478 - val_loss: 0.2229 - val_accuracy: 0.9288 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1641 - accuracy: 0.9480 - val_loss: 0.1682 - val_accuracy: 0.9507 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1611 - accuracy: 0.9475 - val_loss: 0.1787 - val_accuracy: 0.9447 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1548 - accuracy: 0.9515 - val_loss: 0.1831 - val_accuracy: 0.9438 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1564 - accuracy: 0.9485 - val_loss: 0.1849 - val_accuracy: 0.9423 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1581 - accuracy: 0.9511 - val_loss: 0.1774 - val_accuracy: 0.9453 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1481 - accuracy: 0.9509 - val_loss: 0.1955 - val_accuracy: 0.9393 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1523 - accuracy: 0.9504 - val_loss: 0.1705 - val_accuracy: 0.9486 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1473 - accuracy: 0.9522 - val_loss: 0.1826 - val_accuracy: 0.9448 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1470 - accuracy: 0.9542 - val_loss: 0.2045 - val_accuracy: 0.9352 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1430 - accuracy: 0.9557 - val_loss: 0.1683 - val_accuracy: 0.9507 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1474 - accuracy: 0.9563 - val_loss: 0.1772 - val_accuracy: 0.9461 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1440 - accuracy: 0.9552 - val_loss: 0.1773 - val_accuracy: 0.9450 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1424 - accuracy: 0.9552 - val_loss: 0.1739 - val_accuracy: 0.9466 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1482 - accuracy: 0.9532 - val_loss: 0.1819 - val_accuracy: 0.9437 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1381 - accuracy: 0.9555 - val_loss: 0.1624 - val_accuracy: 0.9520 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1409 - accuracy: 0.9582 - val_loss: 0.1852 - val_accuracy: 0.9430 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1384 - accuracy: 0.9591 - val_loss: 0.1777 - val_accuracy: 0.9465 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1399 - accuracy: 0.9567 - val_loss: 0.1796 - val_accuracy: 0.9456 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1457 - accuracy: 0.9577 - val_loss: 0.1707 - val_accuracy: 0.9491 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1354 - accuracy: 0.9590 - val_loss: 0.1727 - val_accuracy: 0.9487 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1348 - accuracy: 0.9612 - val_loss: 0.1746 - val_accuracy: 0.9484 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1338 - accuracy: 0.9602 - val_loss: 0.1772 - val_accuracy: 0.9469 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1372 - accuracy: 0.9622 - val_loss: 0.1794 - val_accuracy: 0.9472 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1375 - accuracy: 0.9616 - val_loss: 0.1819 - val_accuracy: 0.9455 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1347 - accuracy: 0.9583 - val_loss: 0.1917 - val_accuracy: 0.9440 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1318 - accuracy: 0.9598 - val_loss: 0.1909 - val_accuracy: 0.9442 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1328 - accuracy: 0.9578 - val_loss: 0.1876 - val_accuracy: 0.9451 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1342 - accuracy: 0.9587 - val_loss: 0.1768 - val_accuracy: 0.9480 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1325 - accuracy: 0.9619 - val_loss: 0.1898 - val_accuracy: 0.9438 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1343 - accuracy: 0.9598 - val_loss: 0.1808 - val_accuracy: 0.9472 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1356 - accuracy: 0.9609 - val_loss: 0.1782 - val_accuracy: 0.9482 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1327 - accuracy: 0.9617 - val_loss: 0.1869 - val_accuracy: 0.9449 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1336 - accuracy: 0.9593 - val_loss: 0.1861 - val_accuracy: 0.9448 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1312 - accuracy: 0.9598 - val_loss: 0.1812 - val_accuracy: 0.9467 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1326 - accuracy: 0.9610 - val_loss: 0.1844 - val_accuracy: 0.9454 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1379 - accuracy: 0.9611 - val_loss: 0.1849 - val_accuracy: 0.9457 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1309 - accuracy: 0.9614 - val_loss: 0.1853 - val_accuracy: 0.9455 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1329 - accuracy: 0.9615 - val_loss: 0.1808 - val_accuracy: 0.9466 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1291 - accuracy: 0.9618 - val_loss: 0.1831 - val_accuracy: 0.9460 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1409 - accuracy: 0.9596 - val_loss: 0.1835 - val_accuracy: 0.9458 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1270 - accuracy: 0.9598 - val_loss: 0.1844 - val_accuracy: 0.9457 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1329 - accuracy: 0.9601 - val_loss: 0.1811 - val_accuracy: 0.9466 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1356 - accuracy: 0.9600 - val_loss: 0.1835 - val_accuracy: 0.9458 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 38ms/step - loss: 5.1732 - accuracy: 0.7794 - val_loss: 2.9055 - val_accuracy: 0.9038 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 2.5719 - accuracy: 0.8031 - val_loss: 1.5700 - val_accuracy: 0.8980 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 1.5512 - accuracy: 0.8281 - val_loss: 3.4695 - val_accuracy: 0.9133 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 1.8407 - accuracy: 0.8253 - val_loss: 0.9953 - val_accuracy: 0.8638 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 1.1502 - accuracy: 0.8319 - val_loss: 1.2181 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.9454 - accuracy: 0.8414 - val_loss: 2.0126 - val_accuracy: 0.4704 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.8396 - accuracy: 0.8451 - val_loss: 1.2659 - val_accuracy: 0.6713 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.7149 - accuracy: 0.8473 - val_loss: 0.8031 - val_accuracy: 0.8856 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.8380 - accuracy: 0.8359 - val_loss: 0.5599 - val_accuracy: 0.9388 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.6989 - accuracy: 0.8547 - val_loss: 1.0893 - val_accuracy: 0.9088 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.7282 - accuracy: 0.8484 - val_loss: 0.6050 - val_accuracy: 0.8774 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5648 - accuracy: 0.8650 - val_loss: 0.5691 - val_accuracy: 0.9062 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5540 - accuracy: 0.8849 - val_loss: 0.7768 - val_accuracy: 0.8683 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4935 - accuracy: 0.8927 - val_loss: 0.8155 - val_accuracy: 0.7675 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3963 - accuracy: 0.9097 - val_loss: 1.1188 - val_accuracy: 0.6404 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3843 - accuracy: 0.8993 - val_loss: 0.9020 - val_accuracy: 0.7613 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3599 - accuracy: 0.9057 - val_loss: 0.3624 - val_accuracy: 0.9246 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3595 - accuracy: 0.9106 - val_loss: 0.6001 - val_accuracy: 0.8378 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3077 - accuracy: 0.9223 - val_loss: 0.3059 - val_accuracy: 0.9434 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3533 - accuracy: 0.9186 - val_loss: 0.2598 - val_accuracy: 0.9490 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2933 - accuracy: 0.9322 - val_loss: 0.2702 - val_accuracy: 0.9382 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2589 - accuracy: 0.9373 - val_loss: 0.2318 - val_accuracy: 0.9468 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2458 - accuracy: 0.9372 - val_loss: 0.2943 - val_accuracy: 0.9211 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2466 - accuracy: 0.9360 - val_loss: 0.3528 - val_accuracy: 0.8912 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2238 - accuracy: 0.9447 - val_loss: 0.2039 - val_accuracy: 0.9587 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2192 - accuracy: 0.9452 - val_loss: 0.2453 - val_accuracy: 0.9346 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2011 - accuracy: 0.9462 - val_loss: 0.5767 - val_accuracy: 0.8202 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2021 - accuracy: 0.9480 - val_loss: 0.1732 - val_accuracy: 0.9603 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1870 - accuracy: 0.9534 - val_loss: 0.1666 - val_accuracy: 0.9630 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1881 - accuracy: 0.9508 - val_loss: 0.2398 - val_accuracy: 0.9339 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1719 - accuracy: 0.9562 - val_loss: 0.3969 - val_accuracy: 0.8745 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1654 - accuracy: 0.9589 - val_loss: 0.1459 - val_accuracy: 0.9666 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1603 - accuracy: 0.9592 - val_loss: 0.1483 - val_accuracy: 0.9661 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1479 - accuracy: 0.9626 - val_loss: 0.1572 - val_accuracy: 0.9625 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1414 - accuracy: 0.9635 - val_loss: 0.1630 - val_accuracy: 0.9584 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1362 - accuracy: 0.9658 - val_loss: 0.1714 - val_accuracy: 0.9574 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1360 - accuracy: 0.9648 - val_loss: 0.1611 - val_accuracy: 0.9583 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1347 - accuracy: 0.9661 - val_loss: 0.1480 - val_accuracy: 0.9618 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1343 - accuracy: 0.9646 - val_loss: 0.2286 - val_accuracy: 0.9392 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1206 - accuracy: 0.9683 - val_loss: 0.1396 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1191 - accuracy: 0.9699 - val_loss: 0.1434 - val_accuracy: 0.9653 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1103 - accuracy: 0.9712 - val_loss: 0.1453 - val_accuracy: 0.9652 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1102 - accuracy: 0.9730 - val_loss: 0.1417 - val_accuracy: 0.9659 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1056 - accuracy: 0.9731 - val_loss: 0.1554 - val_accuracy: 0.9606 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1028 - accuracy: 0.9746 - val_loss: 0.1426 - val_accuracy: 0.9665 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1047 - accuracy: 0.9714 - val_loss: 0.1687 - val_accuracy: 0.9561 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1051 - accuracy: 0.9732 - val_loss: 0.1584 - val_accuracy: 0.9597 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0994 - accuracy: 0.9739 - val_loss: 0.1396 - val_accuracy: 0.9657 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0954 - accuracy: 0.9766 - val_loss: 0.1453 - val_accuracy: 0.9646 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0991 - accuracy: 0.9749 - val_loss: 0.1700 - val_accuracy: 0.9564 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0953 - accuracy: 0.9745 - val_loss: 0.1403 - val_accuracy: 0.9661 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0902 - accuracy: 0.9772 - val_loss: 0.1741 - val_accuracy: 0.9545 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0889 - accuracy: 0.9779 - val_loss: 0.1513 - val_accuracy: 0.9617 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0880 - accuracy: 0.9779 - val_loss: 0.1490 - val_accuracy: 0.9626 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0838 - accuracy: 0.9793 - val_loss: 0.1501 - val_accuracy: 0.9627 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0819 - accuracy: 0.9803 - val_loss: 0.1404 - val_accuracy: 0.9663 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0859 - accuracy: 0.9791 - val_loss: 0.1510 - val_accuracy: 0.9631 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0797 - accuracy: 0.9806 - val_loss: 0.1479 - val_accuracy: 0.9645 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0834 - accuracy: 0.9794 - val_loss: 0.1444 - val_accuracy: 0.9657 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0807 - accuracy: 0.9803 - val_loss: 0.1496 - val_accuracy: 0.9625 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0832 - accuracy: 0.9805 - val_loss: 0.1412 - val_accuracy: 0.9657 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0810 - accuracy: 0.9791 - val_loss: 0.1453 - val_accuracy: 0.9647 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0804 - accuracy: 0.9803 - val_loss: 0.1460 - val_accuracy: 0.9649 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0756 - accuracy: 0.9812 - val_loss: 0.1460 - val_accuracy: 0.9658 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0761 - accuracy: 0.9827 - val_loss: 0.1479 - val_accuracy: 0.9637 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0799 - accuracy: 0.9801 - val_loss: 0.1550 - val_accuracy: 0.9619 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0770 - accuracy: 0.9809 - val_loss: 0.1454 - val_accuracy: 0.9656 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0760 - accuracy: 0.9817 - val_loss: 0.1514 - val_accuracy: 0.9626 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0762 - accuracy: 0.9796 - val_loss: 0.1480 - val_accuracy: 0.9639 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0761 - accuracy: 0.9816 - val_loss: 0.1458 - val_accuracy: 0.9646 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0749 - accuracy: 0.9820 - val_loss: 0.1489 - val_accuracy: 0.9635 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0803 - accuracy: 0.9818 - val_loss: 0.1503 - val_accuracy: 0.9630 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0769 - accuracy: 0.9823 - val_loss: 0.1474 - val_accuracy: 0.9641 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.0760 - accuracy: 0.9814 - val_loss: 0.1492 - val_accuracy: 0.9633 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0753 - accuracy: 0.9820 - val_loss: 0.1481 - val_accuracy: 0.9641 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0752 - accuracy: 0.9822 - val_loss: 0.1472 - val_accuracy: 0.9642 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0726 - accuracy: 0.9830 - val_loss: 0.1475 - val_accuracy: 0.9643 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0761 - accuracy: 0.9828 - val_loss: 0.1466 - val_accuracy: 0.9645 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0766 - accuracy: 0.9810 - val_loss: 0.1467 - val_accuracy: 0.9649 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0739 - accuracy: 0.9814 - val_loss: 0.1459 - val_accuracy: 0.9652 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0722 - accuracy: 0.9830 - val_loss: 0.1459 - val_accuracy: 0.9655 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0709 - accuracy: 0.9822 - val_loss: 0.1473 - val_accuracy: 0.9647 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0753 - accuracy: 0.9819 - val_loss: 0.1455 - val_accuracy: 0.9653 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0762 - accuracy: 0.9826 - val_loss: 0.1459 - val_accuracy: 0.9651 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0738 - accuracy: 0.9821 - val_loss: 0.1464 - val_accuracy: 0.9651 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0712 - accuracy: 0.9842 - val_loss: 0.1463 - val_accuracy: 0.9653 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0730 - accuracy: 0.9830 - val_loss: 0.1459 - val_accuracy: 0.9651 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0751 - accuracy: 0.9827 - val_loss: 0.1470 - val_accuracy: 0.9647 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0696 - accuracy: 0.9843 - val_loss: 0.1463 - val_accuracy: 0.9652 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0780 - accuracy: 0.9822 - val_loss: 0.1464 - val_accuracy: 0.9648 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0752 - accuracy: 0.9809 - val_loss: 0.1476 - val_accuracy: 0.9640 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0754 - accuracy: 0.9821 - val_loss: 0.1479 - val_accuracy: 0.9642 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0735 - accuracy: 0.9833 - val_loss: 0.1478 - val_accuracy: 0.9640 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0714 - accuracy: 0.9830 - val_loss: 0.1478 - val_accuracy: 0.9643 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0741 - accuracy: 0.9827 - val_loss: 0.1472 - val_accuracy: 0.9649 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0674 - accuracy: 0.9839 - val_loss: 0.1478 - val_accuracy: 0.9643 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0745 - accuracy: 0.9822 - val_loss: 0.1485 - val_accuracy: 0.9639 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0739 - accuracy: 0.9830 - val_loss: 0.1475 - val_accuracy: 0.9643 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0739 - accuracy: 0.9836 - val_loss: 0.1466 - val_accuracy: 0.9651 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0721 - accuracy: 0.9837 - val_loss: 0.1466 - val_accuracy: 0.9649 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 38ms/step - loss: 5.1035 - accuracy: 0.7900 - val_loss: 2.7103 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 1.6333 - accuracy: 0.8177 - val_loss: 1.7913 - val_accuracy: 0.9000 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.2445 - accuracy: 0.8378 - val_loss: 1.6321 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.8167 - accuracy: 0.8491 - val_loss: 0.5049 - val_accuracy: 0.9118 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.8518 - accuracy: 0.8519 - val_loss: 0.7563 - val_accuracy: 0.9052 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.7164 - accuracy: 0.8543 - val_loss: 0.4663 - val_accuracy: 0.9050 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5247 - accuracy: 0.8756 - val_loss: 0.7103 - val_accuracy: 0.8975 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.5399 - accuracy: 0.8818 - val_loss: 1.3791 - val_accuracy: 0.5863 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.4331 - accuracy: 0.8837 - val_loss: 0.2919 - val_accuracy: 0.9415 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.3981 - accuracy: 0.8911 - val_loss: 0.5186 - val_accuracy: 0.8463 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.4008 - accuracy: 0.8898 - val_loss: 0.5180 - val_accuracy: 0.9158 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3667 - accuracy: 0.8988 - val_loss: 0.2927 - val_accuracy: 0.9182 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 12s 45ms/step - loss: 0.3434 - accuracy: 0.9050 - val_loss: 0.3657 - val_accuracy: 0.8896 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.3132 - accuracy: 0.9128 - val_loss: 0.3766 - val_accuracy: 0.8898 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.3231 - accuracy: 0.9134 - val_loss: 0.9413 - val_accuracy: 0.8975 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.3820 - accuracy: 0.9124 - val_loss: 0.4388 - val_accuracy: 0.9196 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.3693 - accuracy: 0.9083 - val_loss: 0.2914 - val_accuracy: 0.9419 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.3170 - accuracy: 0.9202 - val_loss: 0.2335 - val_accuracy: 0.9453 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2825 - accuracy: 0.9224 - val_loss: 0.2252 - val_accuracy: 0.9491 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2675 - accuracy: 0.9261 - val_loss: 0.3591 - val_accuracy: 0.8920 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.2472 - accuracy: 0.9306 - val_loss: 0.2223 - val_accuracy: 0.9406 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2468 - accuracy: 0.9265 - val_loss: 0.3055 - val_accuracy: 0.9068 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2354 - accuracy: 0.9327 - val_loss: 0.2366 - val_accuracy: 0.9329 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2302 - accuracy: 0.9319 - val_loss: 0.2463 - val_accuracy: 0.9296 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2209 - accuracy: 0.9382 - val_loss: 0.4331 - val_accuracy: 0.8594 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2077 - accuracy: 0.9397 - val_loss: 0.3327 - val_accuracy: 0.9257 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1977 - accuracy: 0.9437 - val_loss: 0.2458 - val_accuracy: 0.9251 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1964 - accuracy: 0.9422 - val_loss: 0.1952 - val_accuracy: 0.9461 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1869 - accuracy: 0.9418 - val_loss: 0.1631 - val_accuracy: 0.9569 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1856 - accuracy: 0.9426 - val_loss: 0.1718 - val_accuracy: 0.9507 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1841 - accuracy: 0.9447 - val_loss: 0.3353 - val_accuracy: 0.9005 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1742 - accuracy: 0.9458 - val_loss: 0.1662 - val_accuracy: 0.9551 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1736 - accuracy: 0.9453 - val_loss: 0.1831 - val_accuracy: 0.9503 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1560 - accuracy: 0.9524 - val_loss: 0.1674 - val_accuracy: 0.9554 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1558 - accuracy: 0.9511 - val_loss: 0.1606 - val_accuracy: 0.9571 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1529 - accuracy: 0.9528 - val_loss: 0.1581 - val_accuracy: 0.9564 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1551 - accuracy: 0.9511 - val_loss: 0.1947 - val_accuracy: 0.9421 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1491 - accuracy: 0.9531 - val_loss: 0.1685 - val_accuracy: 0.9540 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1413 - accuracy: 0.9558 - val_loss: 0.2200 - val_accuracy: 0.9332 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1423 - accuracy: 0.9540 - val_loss: 0.1542 - val_accuracy: 0.9566 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1439 - accuracy: 0.9553 - val_loss: 0.1576 - val_accuracy: 0.9577 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1342 - accuracy: 0.9574 - val_loss: 0.1987 - val_accuracy: 0.9407 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1342 - accuracy: 0.9570 - val_loss: 0.2011 - val_accuracy: 0.9408 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1284 - accuracy: 0.9594 - val_loss: 0.1727 - val_accuracy: 0.9521 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1311 - accuracy: 0.9580 - val_loss: 0.1531 - val_accuracy: 0.9575 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1280 - accuracy: 0.9585 - val_loss: 0.1689 - val_accuracy: 0.9517 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1309 - accuracy: 0.9595 - val_loss: 0.1653 - val_accuracy: 0.9524 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1268 - accuracy: 0.9615 - val_loss: 0.1753 - val_accuracy: 0.9513 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1301 - accuracy: 0.9588 - val_loss: 0.2039 - val_accuracy: 0.9415 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1302 - accuracy: 0.9586 - val_loss: 0.1573 - val_accuracy: 0.9558 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1266 - accuracy: 0.9611 - val_loss: 0.1617 - val_accuracy: 0.9550 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1250 - accuracy: 0.9600 - val_loss: 0.1515 - val_accuracy: 0.9581 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1159 - accuracy: 0.9642 - val_loss: 0.1520 - val_accuracy: 0.9585 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1227 - accuracy: 0.9608 - val_loss: 0.1534 - val_accuracy: 0.9577 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1207 - accuracy: 0.9628 - val_loss: 0.1836 - val_accuracy: 0.9466 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1205 - accuracy: 0.9621 - val_loss: 0.1628 - val_accuracy: 0.9538 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1242 - accuracy: 0.9593 - val_loss: 0.1835 - val_accuracy: 0.9473 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1201 - accuracy: 0.9617 - val_loss: 0.1562 - val_accuracy: 0.9569 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1200 - accuracy: 0.9613 - val_loss: 0.1585 - val_accuracy: 0.9557 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1154 - accuracy: 0.9630 - val_loss: 0.1671 - val_accuracy: 0.9532 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1210 - accuracy: 0.9611 - val_loss: 0.1624 - val_accuracy: 0.9549 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1170 - accuracy: 0.9631 - val_loss: 0.1668 - val_accuracy: 0.9532 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1158 - accuracy: 0.9626 - val_loss: 0.1701 - val_accuracy: 0.9512 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1162 - accuracy: 0.9616 - val_loss: 0.1596 - val_accuracy: 0.9559 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1135 - accuracy: 0.9625 - val_loss: 0.1618 - val_accuracy: 0.9544 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1119 - accuracy: 0.9638 - val_loss: 0.1589 - val_accuracy: 0.9562 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1117 - accuracy: 0.9654 - val_loss: 0.1661 - val_accuracy: 0.9535 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1167 - accuracy: 0.9633 - val_loss: 0.1647 - val_accuracy: 0.9538 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1102 - accuracy: 0.9642 - val_loss: 0.1699 - val_accuracy: 0.9521 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1144 - accuracy: 0.9652 - val_loss: 0.1628 - val_accuracy: 0.9547 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1132 - accuracy: 0.9654 - val_loss: 0.1587 - val_accuracy: 0.9562 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1122 - accuracy: 0.9631 - val_loss: 0.1569 - val_accuracy: 0.9570 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1086 - accuracy: 0.9651 - val_loss: 0.1647 - val_accuracy: 0.9542 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1112 - accuracy: 0.9652 - val_loss: 0.1628 - val_accuracy: 0.9542 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1132 - accuracy: 0.9648 - val_loss: 0.1593 - val_accuracy: 0.9556 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1147 - accuracy: 0.9648 - val_loss: 0.1650 - val_accuracy: 0.9540 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1134 - accuracy: 0.9643 - val_loss: 0.1606 - val_accuracy: 0.9556 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1086 - accuracy: 0.9649 - val_loss: 0.1589 - val_accuracy: 0.9562 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1193 - accuracy: 0.9643 - val_loss: 0.1587 - val_accuracy: 0.9563 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1109 - accuracy: 0.9654 - val_loss: 0.1631 - val_accuracy: 0.9546 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1088 - accuracy: 0.9657 - val_loss: 0.1592 - val_accuracy: 0.9559 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1135 - accuracy: 0.9641 - val_loss: 0.1610 - val_accuracy: 0.9554 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1144 - accuracy: 0.9648 - val_loss: 0.1615 - val_accuracy: 0.9550 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1101 - accuracy: 0.9650 - val_loss: 0.1626 - val_accuracy: 0.9549 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1135 - accuracy: 0.9638 - val_loss: 0.1600 - val_accuracy: 0.9556 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1123 - accuracy: 0.9648 - val_loss: 0.1602 - val_accuracy: 0.9556 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1116 - accuracy: 0.9661 - val_loss: 0.1660 - val_accuracy: 0.9544 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1132 - accuracy: 0.9647 - val_loss: 0.1633 - val_accuracy: 0.9547 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1107 - accuracy: 0.9661 - val_loss: 0.1613 - val_accuracy: 0.9552 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1110 - accuracy: 0.9652 - val_loss: 0.1615 - val_accuracy: 0.9554 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1108 - accuracy: 0.9660 - val_loss: 0.1605 - val_accuracy: 0.9555 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1092 - accuracy: 0.9677 - val_loss: 0.1620 - val_accuracy: 0.9553 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1098 - accuracy: 0.9649 - val_loss: 0.1610 - val_accuracy: 0.9554 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1117 - accuracy: 0.9652 - val_loss: 0.1615 - val_accuracy: 0.9554 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1061 - accuracy: 0.9657 - val_loss: 0.1618 - val_accuracy: 0.9554 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1155 - accuracy: 0.9639 - val_loss: 0.1624 - val_accuracy: 0.9553 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1078 - accuracy: 0.9670 - val_loss: 0.1609 - val_accuracy: 0.9556 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1089 - accuracy: 0.9650 - val_loss: 0.1617 - val_accuracy: 0.9553 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1137 - accuracy: 0.9650 - val_loss: 0.1621 - val_accuracy: 0.9552 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1109 - accuracy: 0.9642 - val_loss: 0.1634 - val_accuracy: 0.9551 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 37ms/step - loss: 4.8870 - accuracy: 0.7937 - val_loss: 2.4551 - val_accuracy: 0.8977 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 2.2639 - accuracy: 0.8093 - val_loss: 2.8840 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 1.2191 - accuracy: 0.8271 - val_loss: 0.5980 - val_accuracy: 0.9064 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 1.0973 - accuracy: 0.8304 - val_loss: 0.6756 - val_accuracy: 0.9188 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.9959 - accuracy: 0.8337 - val_loss: 1.0251 - val_accuracy: 0.8929 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.8099 - accuracy: 0.8395 - val_loss: 0.5893 - val_accuracy: 0.9091 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.6484 - accuracy: 0.8505 - val_loss: 0.4992 - val_accuracy: 0.8975 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.5677 - accuracy: 0.8382 - val_loss: 0.4386 - val_accuracy: 0.9037 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.6035 - accuracy: 0.8508 - val_loss: 0.5183 - val_accuracy: 0.8846 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.5233 - accuracy: 0.8651 - val_loss: 0.4047 - val_accuracy: 0.9041 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.5162 - accuracy: 0.8626 - val_loss: 0.5567 - val_accuracy: 0.8437 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.4500 - accuracy: 0.8778 - val_loss: 0.4773 - val_accuracy: 0.8644 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.4128 - accuracy: 0.8910 - val_loss: 0.3096 - val_accuracy: 0.9448 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.3837 - accuracy: 0.8937 - val_loss: 0.2993 - val_accuracy: 0.9226 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.3720 - accuracy: 0.8938 - val_loss: 0.3119 - val_accuracy: 0.9075 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.3352 - accuracy: 0.9124 - val_loss: 0.2552 - val_accuracy: 0.9376 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3198 - accuracy: 0.9167 - val_loss: 0.2949 - val_accuracy: 0.9273 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3028 - accuracy: 0.9219 - val_loss: 1.0502 - val_accuracy: 0.7482 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2812 - accuracy: 0.9274 - val_loss: 0.6300 - val_accuracy: 0.8056 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2629 - accuracy: 0.9317 - val_loss: 0.2385 - val_accuracy: 0.9414 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2618 - accuracy: 0.9320 - val_loss: 0.3399 - val_accuracy: 0.9081 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2403 - accuracy: 0.9402 - val_loss: 0.2749 - val_accuracy: 0.9233 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2272 - accuracy: 0.9425 - val_loss: 0.2377 - val_accuracy: 0.9383 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2132 - accuracy: 0.9449 - val_loss: 0.2810 - val_accuracy: 0.9200 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2132 - accuracy: 0.9452 - val_loss: 0.1960 - val_accuracy: 0.9496 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1972 - accuracy: 0.9480 - val_loss: 0.3153 - val_accuracy: 0.9123 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1974 - accuracy: 0.9497 - val_loss: 0.1744 - val_accuracy: 0.9593 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1763 - accuracy: 0.9540 - val_loss: 0.2521 - val_accuracy: 0.9284 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1789 - accuracy: 0.9532 - val_loss: 0.1564 - val_accuracy: 0.9642 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1738 - accuracy: 0.9551 - val_loss: 0.1712 - val_accuracy: 0.9578 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1736 - accuracy: 0.9565 - val_loss: 0.1855 - val_accuracy: 0.9493 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1586 - accuracy: 0.9571 - val_loss: 0.1583 - val_accuracy: 0.9604 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1554 - accuracy: 0.9595 - val_loss: 0.1518 - val_accuracy: 0.9622 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1478 - accuracy: 0.9609 - val_loss: 0.2762 - val_accuracy: 0.9373 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1402 - accuracy: 0.9634 - val_loss: 0.1686 - val_accuracy: 0.9536 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1399 - accuracy: 0.9649 - val_loss: 0.1544 - val_accuracy: 0.9601 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1309 - accuracy: 0.9634 - val_loss: 0.1495 - val_accuracy: 0.9607 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1280 - accuracy: 0.9660 - val_loss: 0.1675 - val_accuracy: 0.9574 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1263 - accuracy: 0.9666 - val_loss: 0.6407 - val_accuracy: 0.8104 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1202 - accuracy: 0.9668 - val_loss: 0.1712 - val_accuracy: 0.9548 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1222 - accuracy: 0.9668 - val_loss: 0.1813 - val_accuracy: 0.9488 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1136 - accuracy: 0.9685 - val_loss: 0.1492 - val_accuracy: 0.9626 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1140 - accuracy: 0.9696 - val_loss: 0.1884 - val_accuracy: 0.9490 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1113 - accuracy: 0.9691 - val_loss: 0.1508 - val_accuracy: 0.9616 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1044 - accuracy: 0.9728 - val_loss: 0.1684 - val_accuracy: 0.9539 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1042 - accuracy: 0.9720 - val_loss: 0.1516 - val_accuracy: 0.9611 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1032 - accuracy: 0.9722 - val_loss: 0.1548 - val_accuracy: 0.9599 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1012 - accuracy: 0.9722 - val_loss: 0.1594 - val_accuracy: 0.9567 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0997 - accuracy: 0.9736 - val_loss: 0.1551 - val_accuracy: 0.9590 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0944 - accuracy: 0.9739 - val_loss: 0.1594 - val_accuracy: 0.9584 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1003 - accuracy: 0.9721 - val_loss: 0.1595 - val_accuracy: 0.9563 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0978 - accuracy: 0.9740 - val_loss: 0.1470 - val_accuracy: 0.9609 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0934 - accuracy: 0.9731 - val_loss: 0.1481 - val_accuracy: 0.9606 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0906 - accuracy: 0.9746 - val_loss: 0.1620 - val_accuracy: 0.9570 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0883 - accuracy: 0.9752 - val_loss: 0.1604 - val_accuracy: 0.9583 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0893 - accuracy: 0.9744 - val_loss: 0.1638 - val_accuracy: 0.9550 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0901 - accuracy: 0.9758 - val_loss: 0.1532 - val_accuracy: 0.9591 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0820 - accuracy: 0.9781 - val_loss: 0.1501 - val_accuracy: 0.9607 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0879 - accuracy: 0.9761 - val_loss: 0.1543 - val_accuracy: 0.9594 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0842 - accuracy: 0.9777 - val_loss: 0.1567 - val_accuracy: 0.9593 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0833 - accuracy: 0.9776 - val_loss: 0.1578 - val_accuracy: 0.9581 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0884 - accuracy: 0.9769 - val_loss: 0.1546 - val_accuracy: 0.9599 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0836 - accuracy: 0.9772 - val_loss: 0.1555 - val_accuracy: 0.9593 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0841 - accuracy: 0.9775 - val_loss: 0.1544 - val_accuracy: 0.9602 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0833 - accuracy: 0.9776 - val_loss: 0.1525 - val_accuracy: 0.9599 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0829 - accuracy: 0.9784 - val_loss: 0.1534 - val_accuracy: 0.9602 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0797 - accuracy: 0.9788 - val_loss: 0.1547 - val_accuracy: 0.9595 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0830 - accuracy: 0.9785 - val_loss: 0.1531 - val_accuracy: 0.9597 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0794 - accuracy: 0.9772 - val_loss: 0.1568 - val_accuracy: 0.9593 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0727 - accuracy: 0.9800 - val_loss: 0.1537 - val_accuracy: 0.9599 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.0830 - accuracy: 0.9771 - val_loss: 0.1558 - val_accuracy: 0.9593 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0774 - accuracy: 0.9791 - val_loss: 0.1532 - val_accuracy: 0.9600 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0827 - accuracy: 0.9780 - val_loss: 0.1540 - val_accuracy: 0.9597 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0818 - accuracy: 0.9787 - val_loss: 0.1574 - val_accuracy: 0.9589 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0760 - accuracy: 0.9790 - val_loss: 0.1562 - val_accuracy: 0.9591 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0765 - accuracy: 0.9788 - val_loss: 0.1545 - val_accuracy: 0.9599 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0777 - accuracy: 0.9792 - val_loss: 0.1539 - val_accuracy: 0.9598 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0767 - accuracy: 0.9798 - val_loss: 0.1544 - val_accuracy: 0.9598 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.0766 - accuracy: 0.9794 - val_loss: 0.1548 - val_accuracy: 0.9596 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0779 - accuracy: 0.9797 - val_loss: 0.1541 - val_accuracy: 0.9600 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0796 - accuracy: 0.9786 - val_loss: 0.1543 - val_accuracy: 0.9597 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0770 - accuracy: 0.9799 - val_loss: 0.1555 - val_accuracy: 0.9596 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0803 - accuracy: 0.9782 - val_loss: 0.1552 - val_accuracy: 0.9594 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0764 - accuracy: 0.9795 - val_loss: 0.1555 - val_accuracy: 0.9595 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0784 - accuracy: 0.9788 - val_loss: 0.1550 - val_accuracy: 0.9597 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0806 - accuracy: 0.9789 - val_loss: 0.1549 - val_accuracy: 0.9599 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0806 - accuracy: 0.9788 - val_loss: 0.1543 - val_accuracy: 0.9600 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0797 - accuracy: 0.9785 - val_loss: 0.1574 - val_accuracy: 0.9594 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0760 - accuracy: 0.9796 - val_loss: 0.1559 - val_accuracy: 0.9597 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0794 - accuracy: 0.9791 - val_loss: 0.1553 - val_accuracy: 0.9598 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0750 - accuracy: 0.9792 - val_loss: 0.1554 - val_accuracy: 0.9599 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0791 - accuracy: 0.9777 - val_loss: 0.1551 - val_accuracy: 0.9600 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0783 - accuracy: 0.9791 - val_loss: 0.1574 - val_accuracy: 0.9591 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0784 - accuracy: 0.9803 - val_loss: 0.1563 - val_accuracy: 0.9594 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0766 - accuracy: 0.9788 - val_loss: 0.1565 - val_accuracy: 0.9595 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0754 - accuracy: 0.9804 - val_loss: 0.1557 - val_accuracy: 0.9596 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0749 - accuracy: 0.9798 - val_loss: 0.1563 - val_accuracy: 0.9595 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0786 - accuracy: 0.9781 - val_loss: 0.1549 - val_accuracy: 0.9599 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0792 - accuracy: 0.9787 - val_loss: 0.1551 - val_accuracy: 0.9597 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0779 - accuracy: 0.9786 - val_loss: 0.1567 - val_accuracy: 0.9594 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 35ms/step - loss: 5.8472 - accuracy: 0.7846 - val_loss: 3.3704 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 3.8911 - accuracy: 0.7947 - val_loss: 3.0361 - val_accuracy: 0.7624 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 4.0709 - accuracy: 0.7833 - val_loss: 14.9076 - val_accuracy: 0.1028 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 5.2405 - accuracy: 0.7904 - val_loss: 3.4600 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 3.3766 - accuracy: 0.8089 - val_loss: 3.0067 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 1.7858 - accuracy: 0.8178 - val_loss: 1.9039 - val_accuracy: 0.6658 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 2.1953 - accuracy: 0.8266 - val_loss: 1.9637 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 1.6097 - accuracy: 0.8313 - val_loss: 5.8796 - val_accuracy: 0.1541 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 1.7245 - accuracy: 0.8296 - val_loss: 0.9629 - val_accuracy: 0.9021 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 1.0028 - accuracy: 0.8270 - val_loss: 3.7648 - val_accuracy: 0.2843 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.7421 - accuracy: 0.8361 - val_loss: 0.6497 - val_accuracy: 0.8974 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.7057 - accuracy: 0.8387 - val_loss: 0.5287 - val_accuracy: 0.8974 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.6649 - accuracy: 0.8434 - val_loss: 0.5558 - val_accuracy: 0.9180 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.5815 - accuracy: 0.8564 - val_loss: 0.4104 - val_accuracy: 0.9079 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.5393 - accuracy: 0.8593 - val_loss: 3.4142 - val_accuracy: 0.4006 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.5689 - accuracy: 0.8629 - val_loss: 0.6180 - val_accuracy: 0.8320 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.4855 - accuracy: 0.8706 - val_loss: 1.3513 - val_accuracy: 0.6037 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.4636 - accuracy: 0.8719 - val_loss: 0.6079 - val_accuracy: 0.8974 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.4088 - accuracy: 0.8778 - val_loss: 0.2798 - val_accuracy: 0.9302 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.4033 - accuracy: 0.8800 - val_loss: 0.6087 - val_accuracy: 0.8322 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.3979 - accuracy: 0.8827 - val_loss: 0.3019 - val_accuracy: 0.9184 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3797 - accuracy: 0.8906 - val_loss: 1.0524 - val_accuracy: 0.6742 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.3781 - accuracy: 0.8926 - val_loss: 0.3183 - val_accuracy: 0.9371 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3800 - accuracy: 0.9002 - val_loss: 0.3015 - val_accuracy: 0.9183 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3263 - accuracy: 0.9049 - val_loss: 0.4705 - val_accuracy: 0.8526 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.3341 - accuracy: 0.9037 - val_loss: 0.2887 - val_accuracy: 0.9242 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3169 - accuracy: 0.9065 - val_loss: 0.2649 - val_accuracy: 0.9320 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3035 - accuracy: 0.9092 - val_loss: 2.6027 - val_accuracy: 0.4429 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.3182 - accuracy: 0.9133 - val_loss: 0.2343 - val_accuracy: 0.9422 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.2965 - accuracy: 0.9073 - val_loss: 0.2939 - val_accuracy: 0.9028 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.2640 - accuracy: 0.9199 - val_loss: 0.2427 - val_accuracy: 0.9383 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.2584 - accuracy: 0.9177 - val_loss: 0.2969 - val_accuracy: 0.9184 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.2599 - accuracy: 0.9190 - val_loss: 0.2317 - val_accuracy: 0.9356 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.2472 - accuracy: 0.9206 - val_loss: 0.2354 - val_accuracy: 0.9214 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.2353 - accuracy: 0.9239 - val_loss: 0.2071 - val_accuracy: 0.9392 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.2304 - accuracy: 0.9275 - val_loss: 0.3263 - val_accuracy: 0.8900 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.2347 - accuracy: 0.9260 - val_loss: 0.2156 - val_accuracy: 0.9393 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.2186 - accuracy: 0.9284 - val_loss: 0.2361 - val_accuracy: 0.9216 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2124 - accuracy: 0.9265 - val_loss: 0.2191 - val_accuracy: 0.9402 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.2114 - accuracy: 0.9298 - val_loss: 0.3309 - val_accuracy: 0.9218 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2047 - accuracy: 0.9333 - val_loss: 0.5370 - val_accuracy: 0.8210 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1997 - accuracy: 0.9300 - val_loss: 0.2780 - val_accuracy: 0.9270 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1964 - accuracy: 0.9366 - val_loss: 0.3271 - val_accuracy: 0.8889 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1900 - accuracy: 0.9357 - val_loss: 0.2774 - val_accuracy: 0.9110 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1847 - accuracy: 0.9361 - val_loss: 0.2797 - val_accuracy: 0.9052 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1779 - accuracy: 0.9390 - val_loss: 0.2346 - val_accuracy: 0.9209 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1798 - accuracy: 0.9392 - val_loss: 0.3335 - val_accuracy: 0.8886 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1734 - accuracy: 0.9404 - val_loss: 0.2274 - val_accuracy: 0.9268 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1697 - accuracy: 0.9397 - val_loss: 0.1979 - val_accuracy: 0.9343 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1676 - accuracy: 0.9426 - val_loss: 0.1918 - val_accuracy: 0.9428 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1695 - accuracy: 0.9409 - val_loss: 0.1947 - val_accuracy: 0.9408 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1611 - accuracy: 0.9454 - val_loss: 0.2418 - val_accuracy: 0.9195 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1591 - accuracy: 0.9439 - val_loss: 0.2068 - val_accuracy: 0.9323 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1617 - accuracy: 0.9444 - val_loss: 0.2615 - val_accuracy: 0.9118 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1655 - accuracy: 0.9437 - val_loss: 0.1893 - val_accuracy: 0.9386 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1663 - accuracy: 0.9462 - val_loss: 0.2039 - val_accuracy: 0.9320 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1640 - accuracy: 0.9449 - val_loss: 0.2269 - val_accuracy: 0.9253 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1587 - accuracy: 0.9456 - val_loss: 0.1969 - val_accuracy: 0.9349 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1586 - accuracy: 0.9443 - val_loss: 0.1952 - val_accuracy: 0.9370 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1537 - accuracy: 0.9473 - val_loss: 0.2058 - val_accuracy: 0.9354 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1550 - accuracy: 0.9465 - val_loss: 0.2234 - val_accuracy: 0.9254 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1548 - accuracy: 0.9453 - val_loss: 0.2021 - val_accuracy: 0.9355 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1521 - accuracy: 0.9456 - val_loss: 0.2415 - val_accuracy: 0.9209 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1535 - accuracy: 0.9446 - val_loss: 0.2017 - val_accuracy: 0.9352 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1521 - accuracy: 0.9487 - val_loss: 0.2111 - val_accuracy: 0.9310 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1514 - accuracy: 0.9476 - val_loss: 0.2321 - val_accuracy: 0.9238 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1487 - accuracy: 0.9472 - val_loss: 0.1926 - val_accuracy: 0.9393 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1451 - accuracy: 0.9470 - val_loss: 0.2192 - val_accuracy: 0.9273 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1491 - accuracy: 0.9483 - val_loss: 0.1986 - val_accuracy: 0.9365 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1531 - accuracy: 0.9450 - val_loss: 0.2027 - val_accuracy: 0.9346 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1506 - accuracy: 0.9469 - val_loss: 0.2072 - val_accuracy: 0.9328 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1476 - accuracy: 0.9484 - val_loss: 0.2220 - val_accuracy: 0.9276 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1465 - accuracy: 0.9495 - val_loss: 0.2164 - val_accuracy: 0.9292 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1466 - accuracy: 0.9489 - val_loss: 0.2002 - val_accuracy: 0.9365 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1447 - accuracy: 0.9460 - val_loss: 0.2037 - val_accuracy: 0.9349 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1457 - accuracy: 0.9478 - val_loss: 0.2057 - val_accuracy: 0.9333 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1470 - accuracy: 0.9462 - val_loss: 0.2083 - val_accuracy: 0.9324 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1454 - accuracy: 0.9498 - val_loss: 0.1995 - val_accuracy: 0.9361 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1397 - accuracy: 0.9499 - val_loss: 0.2039 - val_accuracy: 0.9341 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1445 - accuracy: 0.9501 - val_loss: 0.2019 - val_accuracy: 0.9352 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1474 - accuracy: 0.9480 - val_loss: 0.2028 - val_accuracy: 0.9348 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1402 - accuracy: 0.9486 - val_loss: 0.2068 - val_accuracy: 0.9332 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1384 - accuracy: 0.9498 - val_loss: 0.2048 - val_accuracy: 0.9339 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1401 - accuracy: 0.9498 - val_loss: 0.2056 - val_accuracy: 0.9338 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1455 - accuracy: 0.9480 - val_loss: 0.2065 - val_accuracy: 0.9333 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1402 - accuracy: 0.9512 - val_loss: 0.2040 - val_accuracy: 0.9348 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1447 - accuracy: 0.9501 - val_loss: 0.2023 - val_accuracy: 0.9350 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1454 - accuracy: 0.9504 - val_loss: 0.2039 - val_accuracy: 0.9344 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1408 - accuracy: 0.9511 - val_loss: 0.2116 - val_accuracy: 0.9310 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1372 - accuracy: 0.9498 - val_loss: 0.2072 - val_accuracy: 0.9332 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1398 - accuracy: 0.9509 - val_loss: 0.2064 - val_accuracy: 0.9335 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1380 - accuracy: 0.9511 - val_loss: 0.2069 - val_accuracy: 0.9333 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1434 - accuracy: 0.9493 - val_loss: 0.2066 - val_accuracy: 0.9337 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1432 - accuracy: 0.9492 - val_loss: 0.2086 - val_accuracy: 0.9323 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1412 - accuracy: 0.9507 - val_loss: 0.2059 - val_accuracy: 0.9336 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1365 - accuracy: 0.9517 - val_loss: 0.2066 - val_accuracy: 0.9337 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1370 - accuracy: 0.9515 - val_loss: 0.2053 - val_accuracy: 0.9341 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1449 - accuracy: 0.9494 - val_loss: 0.2032 - val_accuracy: 0.9347 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1354 - accuracy: 0.9505 - val_loss: 0.2056 - val_accuracy: 0.9337 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1413 - accuracy: 0.9508 - val_loss: 0.2048 - val_accuracy: 0.9342 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 1s 5ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 10s 34ms/step - loss: 5.9986 - accuracy: 0.7654 - val_loss: 5.0981 - val_accuracy: 0.8790 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 3.1093 - accuracy: 0.7952 - val_loss: 2.7689 - val_accuracy: 0.6230 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 2.8521 - accuracy: 0.8033 - val_loss: 1.4916 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 1.4624 - accuracy: 0.8173 - val_loss: 0.9916 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 1.7599 - accuracy: 0.8192 - val_loss: 1.7018 - val_accuracy: 0.7890 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.8329 - accuracy: 0.8220 - val_loss: 2.7253 - val_accuracy: 0.2495 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.8226 - accuracy: 0.8201 - val_loss: 0.6738 - val_accuracy: 0.8096 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.6457 - accuracy: 0.8335 - val_loss: 1.8810 - val_accuracy: 0.4154 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.5578 - accuracy: 0.8264 - val_loss: 0.3877 - val_accuracy: 0.8741 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.5154 - accuracy: 0.8307 - val_loss: 0.4422 - val_accuracy: 0.8679 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.4810 - accuracy: 0.8353 - val_loss: 1.3825 - val_accuracy: 0.6660 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.4540 - accuracy: 0.8468 - val_loss: 3.6596 - val_accuracy: 0.3014 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.4455 - accuracy: 0.8375 - val_loss: 0.4292 - val_accuracy: 0.8980 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.4256 - accuracy: 0.8404 - val_loss: 0.2602 - val_accuracy: 0.9205 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.4319 - accuracy: 0.8398 - val_loss: 0.2968 - val_accuracy: 0.9050 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3993 - accuracy: 0.8450 - val_loss: 1.5620 - val_accuracy: 0.5819 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.4138 - accuracy: 0.8438 - val_loss: 0.8496 - val_accuracy: 0.7420 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3951 - accuracy: 0.8492 - val_loss: 0.3977 - val_accuracy: 0.8480 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.3955 - accuracy: 0.8489 - val_loss: 0.3501 - val_accuracy: 0.8987 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.3842 - accuracy: 0.8469 - val_loss: 0.2905 - val_accuracy: 0.9024 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3687 - accuracy: 0.8534 - val_loss: 0.2504 - val_accuracy: 0.9103 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3662 - accuracy: 0.8515 - val_loss: 0.2351 - val_accuracy: 0.9211 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.3505 - accuracy: 0.8574 - val_loss: 0.2281 - val_accuracy: 0.9216 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3447 - accuracy: 0.8520 - val_loss: 0.2299 - val_accuracy: 0.9126 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3377 - accuracy: 0.8605 - val_loss: 0.2396 - val_accuracy: 0.9064 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3412 - accuracy: 0.8592 - val_loss: 0.2842 - val_accuracy: 0.8901 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3358 - accuracy: 0.8558 - val_loss: 0.4537 - val_accuracy: 0.8297 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3214 - accuracy: 0.8617 - val_loss: 0.3122 - val_accuracy: 0.8707 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3209 - accuracy: 0.8616 - val_loss: 0.3146 - val_accuracy: 0.8672 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3255 - accuracy: 0.8671 - val_loss: 0.2866 - val_accuracy: 0.8867 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.3121 - accuracy: 0.8717 - val_loss: 0.3668 - val_accuracy: 0.8488 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3011 - accuracy: 0.8772 - val_loss: 0.4749 - val_accuracy: 0.8346 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2938 - accuracy: 0.8800 - val_loss: 0.2326 - val_accuracy: 0.9098 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2853 - accuracy: 0.8840 - val_loss: 0.2479 - val_accuracy: 0.9028 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2668 - accuracy: 0.8967 - val_loss: 0.4768 - val_accuracy: 0.8376 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2496 - accuracy: 0.9036 - val_loss: 0.2019 - val_accuracy: 0.9319 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2363 - accuracy: 0.9102 - val_loss: 0.2053 - val_accuracy: 0.9273 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2386 - accuracy: 0.9075 - val_loss: 0.2149 - val_accuracy: 0.9242 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2358 - accuracy: 0.9084 - val_loss: 0.1655 - val_accuracy: 0.9456 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.2344 - accuracy: 0.9122 - val_loss: 0.1931 - val_accuracy: 0.9292 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2185 - accuracy: 0.9137 - val_loss: 0.1666 - val_accuracy: 0.9425 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2152 - accuracy: 0.9180 - val_loss: 0.1870 - val_accuracy: 0.9301 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.2047 - accuracy: 0.9230 - val_loss: 0.1805 - val_accuracy: 0.9368 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2018 - accuracy: 0.9248 - val_loss: 0.2302 - val_accuracy: 0.9135 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2016 - accuracy: 0.9208 - val_loss: 0.1594 - val_accuracy: 0.9454 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1916 - accuracy: 0.9283 - val_loss: 0.1960 - val_accuracy: 0.9284 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1878 - accuracy: 0.9279 - val_loss: 0.1733 - val_accuracy: 0.9366 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1866 - accuracy: 0.9243 - val_loss: 0.1653 - val_accuracy: 0.9413 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1845 - accuracy: 0.9286 - val_loss: 0.1925 - val_accuracy: 0.9291 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1875 - accuracy: 0.9304 - val_loss: 0.1950 - val_accuracy: 0.9260 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1772 - accuracy: 0.9290 - val_loss: 0.1544 - val_accuracy: 0.9455 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1718 - accuracy: 0.9347 - val_loss: 0.1853 - val_accuracy: 0.9319 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1735 - accuracy: 0.9343 - val_loss: 0.2078 - val_accuracy: 0.9211 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1723 - accuracy: 0.9352 - val_loss: 0.1479 - val_accuracy: 0.9482 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1643 - accuracy: 0.9385 - val_loss: 0.1773 - val_accuracy: 0.9360 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1661 - accuracy: 0.9353 - val_loss: 0.1588 - val_accuracy: 0.9432 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 8s 30ms/step - loss: 0.1642 - accuracy: 0.9371 - val_loss: 0.1573 - val_accuracy: 0.9443 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1635 - accuracy: 0.9369 - val_loss: 0.1846 - val_accuracy: 0.9325 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1634 - accuracy: 0.9409 - val_loss: 0.1665 - val_accuracy: 0.9396 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1566 - accuracy: 0.9418 - val_loss: 0.1599 - val_accuracy: 0.9427 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1563 - accuracy: 0.9417 - val_loss: 0.1794 - val_accuracy: 0.9332 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1590 - accuracy: 0.9393 - val_loss: 0.1666 - val_accuracy: 0.9399 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1482 - accuracy: 0.9438 - val_loss: 0.1596 - val_accuracy: 0.9444 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1509 - accuracy: 0.9447 - val_loss: 0.1553 - val_accuracy: 0.9455 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1532 - accuracy: 0.9450 - val_loss: 0.1627 - val_accuracy: 0.9422 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1478 - accuracy: 0.9452 - val_loss: 0.1679 - val_accuracy: 0.9399 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1485 - accuracy: 0.9469 - val_loss: 0.1529 - val_accuracy: 0.9460 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1482 - accuracy: 0.9459 - val_loss: 0.1734 - val_accuracy: 0.9380 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1457 - accuracy: 0.9470 - val_loss: 0.1814 - val_accuracy: 0.9350 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1404 - accuracy: 0.9493 - val_loss: 0.1650 - val_accuracy: 0.9417 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1459 - accuracy: 0.9458 - val_loss: 0.1545 - val_accuracy: 0.9456 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1439 - accuracy: 0.9472 - val_loss: 0.1610 - val_accuracy: 0.9432 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1448 - accuracy: 0.9475 - val_loss: 0.1622 - val_accuracy: 0.9429 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1446 - accuracy: 0.9472 - val_loss: 0.1560 - val_accuracy: 0.9455 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1374 - accuracy: 0.9502 - val_loss: 0.1594 - val_accuracy: 0.9442 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1410 - accuracy: 0.9485 - val_loss: 0.1578 - val_accuracy: 0.9445 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1387 - accuracy: 0.9483 - val_loss: 0.1598 - val_accuracy: 0.9444 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1382 - accuracy: 0.9501 - val_loss: 0.1659 - val_accuracy: 0.9418 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1422 - accuracy: 0.9485 - val_loss: 0.1608 - val_accuracy: 0.9435 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1377 - accuracy: 0.9491 - val_loss: 0.1544 - val_accuracy: 0.9463 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1433 - accuracy: 0.9486 - val_loss: 0.1643 - val_accuracy: 0.9428 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1356 - accuracy: 0.9502 - val_loss: 0.1553 - val_accuracy: 0.9461 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1328 - accuracy: 0.9511 - val_loss: 0.1577 - val_accuracy: 0.9449 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1367 - accuracy: 0.9491 - val_loss: 0.1626 - val_accuracy: 0.9433 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1347 - accuracy: 0.9502 - val_loss: 0.1567 - val_accuracy: 0.9453 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1367 - accuracy: 0.9509 - val_loss: 0.1633 - val_accuracy: 0.9434 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1363 - accuracy: 0.9507 - val_loss: 0.1569 - val_accuracy: 0.9452 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1374 - accuracy: 0.9495 - val_loss: 0.1624 - val_accuracy: 0.9435 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1351 - accuracy: 0.9501 - val_loss: 0.1616 - val_accuracy: 0.9439 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1331 - accuracy: 0.9530 - val_loss: 0.1629 - val_accuracy: 0.9429 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1365 - accuracy: 0.9506 - val_loss: 0.1619 - val_accuracy: 0.9437 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1373 - accuracy: 0.9498 - val_loss: 0.1608 - val_accuracy: 0.9439 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1339 - accuracy: 0.9518 - val_loss: 0.1586 - val_accuracy: 0.9448 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1376 - accuracy: 0.9524 - val_loss: 0.1619 - val_accuracy: 0.9438 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1405 - accuracy: 0.9495 - val_loss: 0.1595 - val_accuracy: 0.9445 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1392 - accuracy: 0.9509 - val_loss: 0.1600 - val_accuracy: 0.9444 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1347 - accuracy: 0.9502 - val_loss: 0.1587 - val_accuracy: 0.9448 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1415 - accuracy: 0.9514 - val_loss: 0.1588 - val_accuracy: 0.9446 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1414 - accuracy: 0.9495 - val_loss: 0.1619 - val_accuracy: 0.9436 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1384 - accuracy: 0.9498 - val_loss: 0.1603 - val_accuracy: 0.9441 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 1s 5ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 4.9616 - accuracy: 0.7783 - val_loss: 3.4866 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 3.0429 - accuracy: 0.7902 - val_loss: 2.0844 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 2.0271 - accuracy: 0.8038 - val_loss: 1.6510 - val_accuracy: 0.7848 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 2.5868 - accuracy: 0.8022 - val_loss: 1.3225 - val_accuracy: 0.8437 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 1.6523 - accuracy: 0.8198 - val_loss: 2.5732 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 1.2510 - accuracy: 0.8202 - val_loss: 0.6304 - val_accuracy: 0.8975 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.8156 - accuracy: 0.8172 - val_loss: 2.0697 - val_accuracy: 0.5750 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.6979 - accuracy: 0.8331 - val_loss: 0.5517 - val_accuracy: 0.9173 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.5978 - accuracy: 0.8264 - val_loss: 0.7155 - val_accuracy: 0.8974 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.5680 - accuracy: 0.8340 - val_loss: 0.3581 - val_accuracy: 0.9019 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.5716 - accuracy: 0.8417 - val_loss: 0.7206 - val_accuracy: 0.8974 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.5394 - accuracy: 0.8365 - val_loss: 6.6875 - val_accuracy: 0.1332 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.4752 - accuracy: 0.8415 - val_loss: 0.4939 - val_accuracy: 0.8974 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.5539 - accuracy: 0.8434 - val_loss: 2.6707 - val_accuracy: 0.3316 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.4793 - accuracy: 0.8395 - val_loss: 0.2844 - val_accuracy: 0.9130 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.4281 - accuracy: 0.8480 - val_loss: 1.5054 - val_accuracy: 0.5912 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.4943 - accuracy: 0.8478 - val_loss: 0.7330 - val_accuracy: 0.7867 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 8s 32ms/step - loss: 0.4441 - accuracy: 0.8433 - val_loss: 0.6337 - val_accuracy: 0.7766 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.4282 - accuracy: 0.8506 - val_loss: 0.3672 - val_accuracy: 0.8685 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.3979 - accuracy: 0.8558 - val_loss: 0.4584 - val_accuracy: 0.8982 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3859 - accuracy: 0.8597 - val_loss: 0.2369 - val_accuracy: 0.9273 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 8s 32ms/step - loss: 0.3687 - accuracy: 0.8648 - val_loss: 1.2591 - val_accuracy: 0.6223 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.3481 - accuracy: 0.8711 - val_loss: 0.3859 - val_accuracy: 0.8999 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3323 - accuracy: 0.8757 - val_loss: 0.3214 - val_accuracy: 0.8745 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.3336 - accuracy: 0.8787 - val_loss: 0.5446 - val_accuracy: 0.8039 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 8s 32ms/step - loss: 0.3113 - accuracy: 0.8852 - val_loss: 0.6030 - val_accuracy: 0.8198 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3084 - accuracy: 0.8893 - val_loss: 0.8829 - val_accuracy: 0.7595 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.2953 - accuracy: 0.8986 - val_loss: 0.3041 - val_accuracy: 0.9115 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2926 - accuracy: 0.8961 - val_loss: 0.2974 - val_accuracy: 0.9131 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2687 - accuracy: 0.9052 - val_loss: 0.1981 - val_accuracy: 0.9398 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2773 - accuracy: 0.9055 - val_loss: 0.6653 - val_accuracy: 0.7824 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2650 - accuracy: 0.9106 - val_loss: 0.2117 - val_accuracy: 0.9393 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2538 - accuracy: 0.9128 - val_loss: 0.2650 - val_accuracy: 0.9261 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2367 - accuracy: 0.9228 - val_loss: 0.2530 - val_accuracy: 0.9124 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2309 - accuracy: 0.9228 - val_loss: 0.8109 - val_accuracy: 0.7749 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2238 - accuracy: 0.9258 - val_loss: 0.2247 - val_accuracy: 0.9244 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 8s 32ms/step - loss: 0.2049 - accuracy: 0.9317 - val_loss: 0.1940 - val_accuracy: 0.9414 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2074 - accuracy: 0.9319 - val_loss: 0.1908 - val_accuracy: 0.9504 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1934 - accuracy: 0.9394 - val_loss: 0.2924 - val_accuracy: 0.8963 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1963 - accuracy: 0.9373 - val_loss: 0.2978 - val_accuracy: 0.9283 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1934 - accuracy: 0.9406 - val_loss: 0.2677 - val_accuracy: 0.9355 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1822 - accuracy: 0.9410 - val_loss: 0.1679 - val_accuracy: 0.9478 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1735 - accuracy: 0.9443 - val_loss: 0.2981 - val_accuracy: 0.8982 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1752 - accuracy: 0.9450 - val_loss: 0.1913 - val_accuracy: 0.9396 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1788 - accuracy: 0.9439 - val_loss: 0.2282 - val_accuracy: 0.9222 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1637 - accuracy: 0.9465 - val_loss: 0.1605 - val_accuracy: 0.9539 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1544 - accuracy: 0.9502 - val_loss: 0.2555 - val_accuracy: 0.9152 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1502 - accuracy: 0.9528 - val_loss: 0.1890 - val_accuracy: 0.9370 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1477 - accuracy: 0.9527 - val_loss: 0.1655 - val_accuracy: 0.9487 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1462 - accuracy: 0.9535 - val_loss: 0.2424 - val_accuracy: 0.9213 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1434 - accuracy: 0.9529 - val_loss: 0.2480 - val_accuracy: 0.9193 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1408 - accuracy: 0.9553 - val_loss: 0.1830 - val_accuracy: 0.9511 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1426 - accuracy: 0.9551 - val_loss: 0.1650 - val_accuracy: 0.9530 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1343 - accuracy: 0.9563 - val_loss: 0.2063 - val_accuracy: 0.9489 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1369 - accuracy: 0.9577 - val_loss: 0.1629 - val_accuracy: 0.9535 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1340 - accuracy: 0.9584 - val_loss: 0.1712 - val_accuracy: 0.9453 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1351 - accuracy: 0.9573 - val_loss: 0.1564 - val_accuracy: 0.9538 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1341 - accuracy: 0.9576 - val_loss: 0.1656 - val_accuracy: 0.9499 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1290 - accuracy: 0.9596 - val_loss: 0.1832 - val_accuracy: 0.9422 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1288 - accuracy: 0.9588 - val_loss: 0.1637 - val_accuracy: 0.9494 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1264 - accuracy: 0.9603 - val_loss: 0.2000 - val_accuracy: 0.9386 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1273 - accuracy: 0.9580 - val_loss: 0.1647 - val_accuracy: 0.9482 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1251 - accuracy: 0.9610 - val_loss: 0.1622 - val_accuracy: 0.9523 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1238 - accuracy: 0.9592 - val_loss: 0.1637 - val_accuracy: 0.9501 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1211 - accuracy: 0.9619 - val_loss: 0.1645 - val_accuracy: 0.9484 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1215 - accuracy: 0.9596 - val_loss: 0.1583 - val_accuracy: 0.9543 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1191 - accuracy: 0.9616 - val_loss: 0.1978 - val_accuracy: 0.9367 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1162 - accuracy: 0.9642 - val_loss: 0.1793 - val_accuracy: 0.9425 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1161 - accuracy: 0.9618 - val_loss: 0.1631 - val_accuracy: 0.9496 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1217 - accuracy: 0.9613 - val_loss: 0.1604 - val_accuracy: 0.9516 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1159 - accuracy: 0.9626 - val_loss: 0.1612 - val_accuracy: 0.9510 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1223 - accuracy: 0.9613 - val_loss: 0.1643 - val_accuracy: 0.9492 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1168 - accuracy: 0.9626 - val_loss: 0.1839 - val_accuracy: 0.9410 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1187 - accuracy: 0.9613 - val_loss: 0.1688 - val_accuracy: 0.9470 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1120 - accuracy: 0.9621 - val_loss: 0.1615 - val_accuracy: 0.9538 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1159 - accuracy: 0.9634 - val_loss: 0.1691 - val_accuracy: 0.9475 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1129 - accuracy: 0.9634 - val_loss: 0.1639 - val_accuracy: 0.9505 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1148 - accuracy: 0.9625 - val_loss: 0.1617 - val_accuracy: 0.9509 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1096 - accuracy: 0.9641 - val_loss: 0.1690 - val_accuracy: 0.9472 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1126 - accuracy: 0.9634 - val_loss: 0.1678 - val_accuracy: 0.9477 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1155 - accuracy: 0.9639 - val_loss: 0.1666 - val_accuracy: 0.9482 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1160 - accuracy: 0.9641 - val_loss: 0.1616 - val_accuracy: 0.9511 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1144 - accuracy: 0.9653 - val_loss: 0.1651 - val_accuracy: 0.9492 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1077 - accuracy: 0.9653 - val_loss: 0.1657 - val_accuracy: 0.9489 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1095 - accuracy: 0.9665 - val_loss: 0.1658 - val_accuracy: 0.9489 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1142 - accuracy: 0.9638 - val_loss: 0.1622 - val_accuracy: 0.9507 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1129 - accuracy: 0.9639 - val_loss: 0.1685 - val_accuracy: 0.9472 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1100 - accuracy: 0.9639 - val_loss: 0.1651 - val_accuracy: 0.9493 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1160 - accuracy: 0.9635 - val_loss: 0.1660 - val_accuracy: 0.9485 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1138 - accuracy: 0.9643 - val_loss: 0.1668 - val_accuracy: 0.9482 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1121 - accuracy: 0.9654 - val_loss: 0.1668 - val_accuracy: 0.9484 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1136 - accuracy: 0.9638 - val_loss: 0.1634 - val_accuracy: 0.9497 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1186 - accuracy: 0.9634 - val_loss: 0.1654 - val_accuracy: 0.9488 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1130 - accuracy: 0.9644 - val_loss: 0.1651 - val_accuracy: 0.9486 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1082 - accuracy: 0.9647 - val_loss: 0.1642 - val_accuracy: 0.9495 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1119 - accuracy: 0.9650 - val_loss: 0.1641 - val_accuracy: 0.9492 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1148 - accuracy: 0.9648 - val_loss: 0.1641 - val_accuracy: 0.9497 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1088 - accuracy: 0.9661 - val_loss: 0.1655 - val_accuracy: 0.9489 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1121 - accuracy: 0.9634 - val_loss: 0.1655 - val_accuracy: 0.9490 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.1050 - accuracy: 0.9647 - val_loss: 0.1650 - val_accuracy: 0.9494 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 1s 5ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 10s 34ms/step - loss: 2.6309 - accuracy: 0.8093 - val_loss: 1.0872 - val_accuracy: 0.9162 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 1.1998 - accuracy: 0.8278 - val_loss: 0.8658 - val_accuracy: 0.8989 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 1.0492 - accuracy: 0.8417 - val_loss: 0.8529 - val_accuracy: 0.8596 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.9540 - accuracy: 0.8363 - val_loss: 1.7694 - val_accuracy: 0.2527 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 1.2522 - accuracy: 0.8418 - val_loss: 1.3002 - val_accuracy: 0.9074 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.8434 - accuracy: 0.8463 - val_loss: 0.4833 - val_accuracy: 0.9174 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.5717 - accuracy: 0.8536 - val_loss: 0.4580 - val_accuracy: 0.8867 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.4878 - accuracy: 0.8706 - val_loss: 1.9268 - val_accuracy: 0.5714 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.4597 - accuracy: 0.8801 - val_loss: 0.3581 - val_accuracy: 0.9183 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.4048 - accuracy: 0.8946 - val_loss: 0.7341 - val_accuracy: 0.8197 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3764 - accuracy: 0.9021 - val_loss: 0.4618 - val_accuracy: 0.8997 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3811 - accuracy: 0.8996 - val_loss: 1.4562 - val_accuracy: 0.7376 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.3401 - accuracy: 0.9123 - val_loss: 1.0709 - val_accuracy: 0.7684 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3321 - accuracy: 0.9054 - val_loss: 0.6673 - val_accuracy: 0.8134 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.3123 - accuracy: 0.9209 - val_loss: 0.2209 - val_accuracy: 0.9498 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.3077 - accuracy: 0.9194 - val_loss: 0.2499 - val_accuracy: 0.9376 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2866 - accuracy: 0.9258 - val_loss: 0.7536 - val_accuracy: 0.7971 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2713 - accuracy: 0.9293 - val_loss: 0.2203 - val_accuracy: 0.9507 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.2637 - accuracy: 0.9300 - val_loss: 2.5485 - val_accuracy: 0.5405 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.2555 - accuracy: 0.9379 - val_loss: 0.2340 - val_accuracy: 0.9436 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.2282 - accuracy: 0.9430 - val_loss: 0.2035 - val_accuracy: 0.9502 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2114 - accuracy: 0.9485 - val_loss: 0.6130 - val_accuracy: 0.9013 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2113 - accuracy: 0.9460 - val_loss: 0.2073 - val_accuracy: 0.9488 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2001 - accuracy: 0.9514 - val_loss: 0.2160 - val_accuracy: 0.9518 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.1954 - accuracy: 0.9518 - val_loss: 0.3718 - val_accuracy: 0.8917 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1866 - accuracy: 0.9554 - val_loss: 0.5169 - val_accuracy: 0.9051 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1619 - accuracy: 0.9605 - val_loss: 0.1997 - val_accuracy: 0.9581 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1631 - accuracy: 0.9609 - val_loss: 0.2627 - val_accuracy: 0.9391 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1578 - accuracy: 0.9633 - val_loss: 0.3023 - val_accuracy: 0.9285 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1454 - accuracy: 0.9644 - val_loss: 0.1907 - val_accuracy: 0.9548 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1363 - accuracy: 0.9678 - val_loss: 0.4026 - val_accuracy: 0.8989 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1423 - accuracy: 0.9650 - val_loss: 0.1575 - val_accuracy: 0.9616 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1268 - accuracy: 0.9690 - val_loss: 0.2038 - val_accuracy: 0.9534 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1236 - accuracy: 0.9717 - val_loss: 0.2213 - val_accuracy: 0.9409 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1159 - accuracy: 0.9709 - val_loss: 0.1914 - val_accuracy: 0.9573 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1141 - accuracy: 0.9729 - val_loss: 0.1620 - val_accuracy: 0.9622 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1081 - accuracy: 0.9745 - val_loss: 0.1539 - val_accuracy: 0.9635 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1029 - accuracy: 0.9754 - val_loss: 0.1730 - val_accuracy: 0.9577 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1060 - accuracy: 0.9732 - val_loss: 0.2997 - val_accuracy: 0.9243 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0951 - accuracy: 0.9781 - val_loss: 0.1594 - val_accuracy: 0.9628 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0940 - accuracy: 0.9773 - val_loss: 0.1712 - val_accuracy: 0.9636 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0938 - accuracy: 0.9783 - val_loss: 0.1602 - val_accuracy: 0.9611 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0951 - accuracy: 0.9766 - val_loss: 0.1856 - val_accuracy: 0.9556 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0968 - accuracy: 0.9766 - val_loss: 0.1409 - val_accuracy: 0.9644 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0861 - accuracy: 0.9801 - val_loss: 0.1631 - val_accuracy: 0.9605 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0817 - accuracy: 0.9807 - val_loss: 0.1525 - val_accuracy: 0.9657 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0859 - accuracy: 0.9800 - val_loss: 0.1611 - val_accuracy: 0.9622 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0822 - accuracy: 0.9819 - val_loss: 0.1504 - val_accuracy: 0.9657 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0825 - accuracy: 0.9796 - val_loss: 0.1645 - val_accuracy: 0.9654 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0797 - accuracy: 0.9807 - val_loss: 0.1497 - val_accuracy: 0.9649 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0792 - accuracy: 0.9812 - val_loss: 0.1475 - val_accuracy: 0.9660 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0761 - accuracy: 0.9823 - val_loss: 0.1494 - val_accuracy: 0.9670 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0724 - accuracy: 0.9833 - val_loss: 0.1546 - val_accuracy: 0.9649 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0684 - accuracy: 0.9843 - val_loss: 0.1530 - val_accuracy: 0.9646 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0679 - accuracy: 0.9850 - val_loss: 0.1555 - val_accuracy: 0.9653 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0751 - accuracy: 0.9844 - val_loss: 0.1631 - val_accuracy: 0.9653 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0725 - accuracy: 0.9828 - val_loss: 0.1587 - val_accuracy: 0.9633 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0689 - accuracy: 0.9851 - val_loss: 0.1536 - val_accuracy: 0.9638 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0728 - accuracy: 0.9842 - val_loss: 0.1561 - val_accuracy: 0.9657 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0658 - accuracy: 0.9847 - val_loss: 0.1552 - val_accuracy: 0.9646 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0680 - accuracy: 0.9842 - val_loss: 0.1540 - val_accuracy: 0.9659 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0659 - accuracy: 0.9848 - val_loss: 0.1566 - val_accuracy: 0.9646 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0628 - accuracy: 0.9861 - val_loss: 0.1575 - val_accuracy: 0.9659 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0630 - accuracy: 0.9862 - val_loss: 0.1616 - val_accuracy: 0.9655 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.0663 - accuracy: 0.9852 - val_loss: 0.1557 - val_accuracy: 0.9657 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.0617 - accuracy: 0.9861 - val_loss: 0.1616 - val_accuracy: 0.9657 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.0630 - accuracy: 0.9859 - val_loss: 0.1596 - val_accuracy: 0.9654 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.0650 - accuracy: 0.9850 - val_loss: 0.1591 - val_accuracy: 0.9659 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.0648 - accuracy: 0.9861 - val_loss: 0.1560 - val_accuracy: 0.9660 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 9s 32ms/step - loss: 0.0632 - accuracy: 0.9855 - val_loss: 0.1575 - val_accuracy: 0.9657 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.0611 - accuracy: 0.9871 - val_loss: 0.1588 - val_accuracy: 0.9661 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.0626 - accuracy: 0.9871 - val_loss: 0.1578 - val_accuracy: 0.9655 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.0638 - accuracy: 0.9862 - val_loss: 0.1567 - val_accuracy: 0.9656 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.0584 - accuracy: 0.9868 - val_loss: 0.1595 - val_accuracy: 0.9659 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.0649 - accuracy: 0.9868 - val_loss: 0.1594 - val_accuracy: 0.9659 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.0608 - accuracy: 0.9863 - val_loss: 0.1606 - val_accuracy: 0.9659 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.0656 - accuracy: 0.9858 - val_loss: 0.1577 - val_accuracy: 0.9661 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0605 - accuracy: 0.9866 - val_loss: 0.1564 - val_accuracy: 0.9662 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 8s 31ms/step - loss: 0.0626 - accuracy: 0.9856 - val_loss: 0.1562 - val_accuracy: 0.9662 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0633 - accuracy: 0.9867 - val_loss: 0.1564 - val_accuracy: 0.9661 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0629 - accuracy: 0.9859 - val_loss: 0.1575 - val_accuracy: 0.9660 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0605 - accuracy: 0.9868 - val_loss: 0.1585 - val_accuracy: 0.9661 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0649 - accuracy: 0.9869 - val_loss: 0.1581 - val_accuracy: 0.9659 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0606 - accuracy: 0.9872 - val_loss: 0.1585 - val_accuracy: 0.9657 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0625 - accuracy: 0.9861 - val_loss: 0.1584 - val_accuracy: 0.9660 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0620 - accuracy: 0.9861 - val_loss: 0.1586 - val_accuracy: 0.9659 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.0632 - accuracy: 0.9872 - val_loss: 0.1582 - val_accuracy: 0.9659 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.0619 - accuracy: 0.9868 - val_loss: 0.1598 - val_accuracy: 0.9663 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0603 - accuracy: 0.9875 - val_loss: 0.1583 - val_accuracy: 0.9662 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0623 - accuracy: 0.9858 - val_loss: 0.1579 - val_accuracy: 0.9662 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0633 - accuracy: 0.9870 - val_loss: 0.1589 - val_accuracy: 0.9661 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0646 - accuracy: 0.9862 - val_loss: 0.1592 - val_accuracy: 0.9660 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0610 - accuracy: 0.9871 - val_loss: 0.1586 - val_accuracy: 0.9664 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0648 - accuracy: 0.9861 - val_loss: 0.1580 - val_accuracy: 0.9663 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0594 - accuracy: 0.9868 - val_loss: 0.1589 - val_accuracy: 0.9660 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0649 - accuracy: 0.9865 - val_loss: 0.1584 - val_accuracy: 0.9662 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.0631 - accuracy: 0.9858 - val_loss: 0.1587 - val_accuracy: 0.9661 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0651 - accuracy: 0.9858 - val_loss: 0.1593 - val_accuracy: 0.9660 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0616 - accuracy: 0.9856 - val_loss: 0.1586 - val_accuracy: 0.9660 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0605 - accuracy: 0.9863 - val_loss: 0.1588 - val_accuracy: 0.9661 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 5ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 38ms/step - loss: 2.9907 - accuracy: 0.8098 - val_loss: 1.3620 - val_accuracy: 0.9143 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 1.4222 - accuracy: 0.8164 - val_loss: 2.4625 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.9955 - accuracy: 0.8408 - val_loss: 1.0439 - val_accuracy: 0.9065 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.9290 - accuracy: 0.8463 - val_loss: 2.1201 - val_accuracy: 0.3757 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.7988 - accuracy: 0.8651 - val_loss: 1.4298 - val_accuracy: 0.6727 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.6187 - accuracy: 0.8767 - val_loss: 0.7866 - val_accuracy: 0.9090 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5562 - accuracy: 0.8883 - val_loss: 0.5066 - val_accuracy: 0.9111 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5194 - accuracy: 0.8837 - val_loss: 0.8254 - val_accuracy: 0.8979 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4658 - accuracy: 0.8942 - val_loss: 0.3540 - val_accuracy: 0.9399 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4175 - accuracy: 0.8988 - val_loss: 0.3955 - val_accuracy: 0.9146 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.3847 - accuracy: 0.9103 - val_loss: 0.6371 - val_accuracy: 0.9084 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 8s 32ms/step - loss: 0.3560 - accuracy: 0.9141 - val_loss: 0.4507 - val_accuracy: 0.8890 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 8s 32ms/step - loss: 0.3345 - accuracy: 0.9177 - val_loss: 0.4535 - val_accuracy: 0.9148 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 8s 31ms/step - loss: 0.3234 - accuracy: 0.9268 - val_loss: 2.2623 - val_accuracy: 0.3820 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2867 - accuracy: 0.9307 - val_loss: 0.3632 - val_accuracy: 0.9243 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2810 - accuracy: 0.9323 - val_loss: 0.5345 - val_accuracy: 0.8539 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2660 - accuracy: 0.9362 - val_loss: 0.4864 - val_accuracy: 0.9135 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 9s 33ms/step - loss: 0.2597 - accuracy: 0.9365 - val_loss: 0.2462 - val_accuracy: 0.9419 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2588 - accuracy: 0.9330 - val_loss: 0.5605 - val_accuracy: 0.9026 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2506 - accuracy: 0.9378 - val_loss: 0.2748 - val_accuracy: 0.9266 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2266 - accuracy: 0.9452 - val_loss: 0.5926 - val_accuracy: 0.8350 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2128 - accuracy: 0.9463 - val_loss: 0.5299 - val_accuracy: 0.9143 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2051 - accuracy: 0.9511 - val_loss: 0.2340 - val_accuracy: 0.9395 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1898 - accuracy: 0.9533 - val_loss: 0.4063 - val_accuracy: 0.9196 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1825 - accuracy: 0.9566 - val_loss: 1.8208 - val_accuracy: 0.6452 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1745 - accuracy: 0.9571 - val_loss: 0.2535 - val_accuracy: 0.9481 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1706 - accuracy: 0.9572 - val_loss: 0.4121 - val_accuracy: 0.8863 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1641 - accuracy: 0.9583 - val_loss: 0.1729 - val_accuracy: 0.9596 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1564 - accuracy: 0.9631 - val_loss: 0.2241 - val_accuracy: 0.9413 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1477 - accuracy: 0.9643 - val_loss: 0.4160 - val_accuracy: 0.8889 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1353 - accuracy: 0.9675 - val_loss: 0.2171 - val_accuracy: 0.9545 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1388 - accuracy: 0.9658 - val_loss: 0.4806 - val_accuracy: 0.9176 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1258 - accuracy: 0.9715 - val_loss: 0.3214 - val_accuracy: 0.9158 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1192 - accuracy: 0.9717 - val_loss: 0.1639 - val_accuracy: 0.9640 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1132 - accuracy: 0.9746 - val_loss: 0.2497 - val_accuracy: 0.9341 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1095 - accuracy: 0.9736 - val_loss: 0.1767 - val_accuracy: 0.9623 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 9s 34ms/step - loss: 0.1113 - accuracy: 0.9750 - val_loss: 0.2033 - val_accuracy: 0.9469 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1005 - accuracy: 0.9785 - val_loss: 0.2446 - val_accuracy: 0.9368 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0972 - accuracy: 0.9783 - val_loss: 0.1497 - val_accuracy: 0.9642 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0963 - accuracy: 0.9789 - val_loss: 0.1857 - val_accuracy: 0.9614 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0868 - accuracy: 0.9805 - val_loss: 0.1738 - val_accuracy: 0.9635 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0892 - accuracy: 0.9802 - val_loss: 0.2052 - val_accuracy: 0.9490 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0835 - accuracy: 0.9824 - val_loss: 0.1523 - val_accuracy: 0.9669 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0837 - accuracy: 0.9829 - val_loss: 0.1621 - val_accuracy: 0.9603 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0776 - accuracy: 0.9849 - val_loss: 0.1483 - val_accuracy: 0.9663 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0814 - accuracy: 0.9829 - val_loss: 0.1467 - val_accuracy: 0.9664 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0717 - accuracy: 0.9852 - val_loss: 0.1542 - val_accuracy: 0.9660 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0723 - accuracy: 0.9848 - val_loss: 0.1907 - val_accuracy: 0.9609 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0743 - accuracy: 0.9852 - val_loss: 0.1632 - val_accuracy: 0.9603 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0728 - accuracy: 0.9845 - val_loss: 0.1527 - val_accuracy: 0.9629 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0705 - accuracy: 0.9843 - val_loss: 0.1859 - val_accuracy: 0.9560 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0690 - accuracy: 0.9860 - val_loss: 0.1473 - val_accuracy: 0.9660 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0652 - accuracy: 0.9871 - val_loss: 0.1452 - val_accuracy: 0.9651 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0655 - accuracy: 0.9861 - val_loss: 0.1493 - val_accuracy: 0.9662 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0654 - accuracy: 0.9868 - val_loss: 0.1546 - val_accuracy: 0.9668 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.0640 - accuracy: 0.9867 - val_loss: 0.1627 - val_accuracy: 0.9657 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0628 - accuracy: 0.9871 - val_loss: 0.1477 - val_accuracy: 0.9658 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0644 - accuracy: 0.9875 - val_loss: 0.1487 - val_accuracy: 0.9654 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0649 - accuracy: 0.9868 - val_loss: 0.1517 - val_accuracy: 0.9663 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0587 - accuracy: 0.9887 - val_loss: 0.1503 - val_accuracy: 0.9664 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.0599 - accuracy: 0.9882 - val_loss: 0.1493 - val_accuracy: 0.9667 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0647 - accuracy: 0.9861 - val_loss: 0.1495 - val_accuracy: 0.9653 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0608 - accuracy: 0.9893 - val_loss: 0.1476 - val_accuracy: 0.9666 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0548 - accuracy: 0.9900 - val_loss: 0.1490 - val_accuracy: 0.9663 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0600 - accuracy: 0.9886 - val_loss: 0.1519 - val_accuracy: 0.9663 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0572 - accuracy: 0.9895 - val_loss: 0.1504 - val_accuracy: 0.9659 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0579 - accuracy: 0.9881 - val_loss: 0.1502 - val_accuracy: 0.9659 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0579 - accuracy: 0.9888 - val_loss: 0.1507 - val_accuracy: 0.9664 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0599 - accuracy: 0.9879 - val_loss: 0.1504 - val_accuracy: 0.9658 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0571 - accuracy: 0.9881 - val_loss: 0.1514 - val_accuracy: 0.9660 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0592 - accuracy: 0.9884 - val_loss: 0.1509 - val_accuracy: 0.9659 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0595 - accuracy: 0.9884 - val_loss: 0.1512 - val_accuracy: 0.9666 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.0558 - accuracy: 0.9890 - val_loss: 0.1495 - val_accuracy: 0.9660 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.0571 - accuracy: 0.9892 - val_loss: 0.1510 - val_accuracy: 0.9658 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0566 - accuracy: 0.9891 - val_loss: 0.1507 - val_accuracy: 0.9661 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.0549 - accuracy: 0.9891 - val_loss: 0.1509 - val_accuracy: 0.9660 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0561 - accuracy: 0.9894 - val_loss: 0.1513 - val_accuracy: 0.9661 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0557 - accuracy: 0.9891 - val_loss: 0.1506 - val_accuracy: 0.9659 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0557 - accuracy: 0.9885 - val_loss: 0.1516 - val_accuracy: 0.9659 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.0570 - accuracy: 0.9891 - val_loss: 0.1517 - val_accuracy: 0.9659 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.0585 - accuracy: 0.9892 - val_loss: 0.1510 - val_accuracy: 0.9660 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0579 - accuracy: 0.9881 - val_loss: 0.1512 - val_accuracy: 0.9662 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0520 - accuracy: 0.9899 - val_loss: 0.1523 - val_accuracy: 0.9664 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0544 - accuracy: 0.9889 - val_loss: 0.1515 - val_accuracy: 0.9661 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0549 - accuracy: 0.9901 - val_loss: 0.1536 - val_accuracy: 0.9662 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0556 - accuracy: 0.9895 - val_loss: 0.1521 - val_accuracy: 0.9660 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0555 - accuracy: 0.9893 - val_loss: 0.1528 - val_accuracy: 0.9658 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0553 - accuracy: 0.9889 - val_loss: 0.1513 - val_accuracy: 0.9659 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0555 - accuracy: 0.9904 - val_loss: 0.1518 - val_accuracy: 0.9663 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0568 - accuracy: 0.9890 - val_loss: 0.1521 - val_accuracy: 0.9659 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0544 - accuracy: 0.9889 - val_loss: 0.1520 - val_accuracy: 0.9658 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0563 - accuracy: 0.9902 - val_loss: 0.1525 - val_accuracy: 0.9660 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0560 - accuracy: 0.9888 - val_loss: 0.1529 - val_accuracy: 0.9661 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0559 - accuracy: 0.9889 - val_loss: 0.1529 - val_accuracy: 0.9661 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0552 - accuracy: 0.9900 - val_loss: 0.1520 - val_accuracy: 0.9660 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0565 - accuracy: 0.9891 - val_loss: 0.1534 - val_accuracy: 0.9661 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0540 - accuracy: 0.9898 - val_loss: 0.1527 - val_accuracy: 0.9660 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0513 - accuracy: 0.9908 - val_loss: 0.1523 - val_accuracy: 0.9657 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0543 - accuracy: 0.9894 - val_loss: 0.1521 - val_accuracy: 0.9657 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0565 - accuracy: 0.9906 - val_loss: 0.1527 - val_accuracy: 0.9659 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 6ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 37ms/step - loss: 2.4054 - accuracy: 0.8074 - val_loss: 1.1065 - val_accuracy: 0.8711 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 1.8307 - accuracy: 0.8102 - val_loss: 2.9412 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 1.4423 - accuracy: 0.8339 - val_loss: 1.1108 - val_accuracy: 0.9129 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.8463 - accuracy: 0.8478 - val_loss: 0.8447 - val_accuracy: 0.8750 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.6743 - accuracy: 0.8627 - val_loss: 0.5290 - val_accuracy: 0.8977 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.6679 - accuracy: 0.8462 - val_loss: 4.6844 - val_accuracy: 0.3027 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.6121 - accuracy: 0.8676 - val_loss: 0.5772 - val_accuracy: 0.9129 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5882 - accuracy: 0.8746 - val_loss: 0.4173 - val_accuracy: 0.9238 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.6220 - accuracy: 0.8744 - val_loss: 0.5255 - val_accuracy: 0.9333 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5463 - accuracy: 0.8910 - val_loss: 0.3444 - val_accuracy: 0.9320 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4671 - accuracy: 0.8907 - val_loss: 0.5295 - val_accuracy: 0.8677 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4019 - accuracy: 0.9042 - val_loss: 0.2878 - val_accuracy: 0.9334 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3780 - accuracy: 0.9070 - val_loss: 0.9877 - val_accuracy: 0.6841 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.3458 - accuracy: 0.9118 - val_loss: 0.5241 - val_accuracy: 0.8534 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.3074 - accuracy: 0.9226 - val_loss: 0.8859 - val_accuracy: 0.7899 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2942 - accuracy: 0.9237 - val_loss: 0.9639 - val_accuracy: 0.6821 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2844 - accuracy: 0.9270 - val_loss: 0.5346 - val_accuracy: 0.8430 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2700 - accuracy: 0.9280 - val_loss: 0.4565 - val_accuracy: 0.9089 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.2625 - accuracy: 0.9316 - val_loss: 0.2815 - val_accuracy: 0.9372 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2627 - accuracy: 0.9335 - val_loss: 0.6393 - val_accuracy: 0.8138 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2340 - accuracy: 0.9444 - val_loss: 0.2007 - val_accuracy: 0.9549 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2266 - accuracy: 0.9446 - val_loss: 0.2159 - val_accuracy: 0.9381 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.2206 - accuracy: 0.9415 - val_loss: 0.1931 - val_accuracy: 0.9515 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.2215 - accuracy: 0.9457 - val_loss: 0.3155 - val_accuracy: 0.9130 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1983 - accuracy: 0.9499 - val_loss: 0.1930 - val_accuracy: 0.9572 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1872 - accuracy: 0.9553 - val_loss: 0.6829 - val_accuracy: 0.8051 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1849 - accuracy: 0.9547 - val_loss: 0.3466 - val_accuracy: 0.8978 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1783 - accuracy: 0.9545 - val_loss: 0.1839 - val_accuracy: 0.9524 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 9s 35ms/step - loss: 0.1677 - accuracy: 0.9583 - val_loss: 0.2342 - val_accuracy: 0.9479 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1641 - accuracy: 0.9596 - val_loss: 0.2624 - val_accuracy: 0.9460 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1500 - accuracy: 0.9647 - val_loss: 0.3373 - val_accuracy: 0.9333 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1548 - accuracy: 0.9631 - val_loss: 0.1813 - val_accuracy: 0.9552 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1381 - accuracy: 0.9671 - val_loss: 0.2268 - val_accuracy: 0.9357 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1390 - accuracy: 0.9659 - val_loss: 0.2166 - val_accuracy: 0.9528 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1344 - accuracy: 0.9668 - val_loss: 0.1656 - val_accuracy: 0.9626 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1286 - accuracy: 0.9676 - val_loss: 0.1729 - val_accuracy: 0.9581 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1206 - accuracy: 0.9697 - val_loss: 0.1660 - val_accuracy: 0.9623 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1203 - accuracy: 0.9712 - val_loss: 0.1517 - val_accuracy: 0.9620 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1154 - accuracy: 0.9722 - val_loss: 0.1680 - val_accuracy: 0.9613 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1161 - accuracy: 0.9733 - val_loss: 0.1694 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1045 - accuracy: 0.9748 - val_loss: 0.1716 - val_accuracy: 0.9578 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1090 - accuracy: 0.9741 - val_loss: 0.1681 - val_accuracy: 0.9620 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1036 - accuracy: 0.9740 - val_loss: 0.1598 - val_accuracy: 0.9632 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 9s 36ms/step - loss: 0.1026 - accuracy: 0.9751 - val_loss: 0.1579 - val_accuracy: 0.9651 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0996 - accuracy: 0.9749 - val_loss: 0.1633 - val_accuracy: 0.9606 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1000 - accuracy: 0.9761 - val_loss: 0.1832 - val_accuracy: 0.9604 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0943 - accuracy: 0.9778 - val_loss: 0.1661 - val_accuracy: 0.9585 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0930 - accuracy: 0.9780 - val_loss: 0.1684 - val_accuracy: 0.9632 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0910 - accuracy: 0.9768 - val_loss: 0.1688 - val_accuracy: 0.9646 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0894 - accuracy: 0.9791 - val_loss: 0.1669 - val_accuracy: 0.9612 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0824 - accuracy: 0.9816 - val_loss: 0.1649 - val_accuracy: 0.9651 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0862 - accuracy: 0.9790 - val_loss: 0.1842 - val_accuracy: 0.9628 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0870 - accuracy: 0.9798 - val_loss: 0.1672 - val_accuracy: 0.9604 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0883 - accuracy: 0.9780 - val_loss: 0.1736 - val_accuracy: 0.9635 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0878 - accuracy: 0.9780 - val_loss: 0.1673 - val_accuracy: 0.9628 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0849 - accuracy: 0.9791 - val_loss: 0.1842 - val_accuracy: 0.9618 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0808 - accuracy: 0.9788 - val_loss: 0.1693 - val_accuracy: 0.9618 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0812 - accuracy: 0.9796 - val_loss: 0.1704 - val_accuracy: 0.9630 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0798 - accuracy: 0.9789 - val_loss: 0.1674 - val_accuracy: 0.9632 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0796 - accuracy: 0.9813 - val_loss: 0.1731 - val_accuracy: 0.9638 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0698 - accuracy: 0.9840 - val_loss: 0.1687 - val_accuracy: 0.9637 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0824 - accuracy: 0.9807 - val_loss: 0.1660 - val_accuracy: 0.9640 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0770 - accuracy: 0.9808 - val_loss: 0.1695 - val_accuracy: 0.9637 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0748 - accuracy: 0.9820 - val_loss: 0.1675 - val_accuracy: 0.9629 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0792 - accuracy: 0.9805 - val_loss: 0.1660 - val_accuracy: 0.9632 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0787 - accuracy: 0.9810 - val_loss: 0.1682 - val_accuracy: 0.9633 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0738 - accuracy: 0.9823 - val_loss: 0.1725 - val_accuracy: 0.9632 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0770 - accuracy: 0.9820 - val_loss: 0.1677 - val_accuracy: 0.9632 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0784 - accuracy: 0.9815 - val_loss: 0.1686 - val_accuracy: 0.9633 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0790 - accuracy: 0.9801 - val_loss: 0.1699 - val_accuracy: 0.9633 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0742 - accuracy: 0.9823 - val_loss: 0.1681 - val_accuracy: 0.9637 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0780 - accuracy: 0.9827 - val_loss: 0.1685 - val_accuracy: 0.9638 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0789 - accuracy: 0.9802 - val_loss: 0.1676 - val_accuracy: 0.9637 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0742 - accuracy: 0.9823 - val_loss: 0.1703 - val_accuracy: 0.9635 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0796 - accuracy: 0.9814 - val_loss: 0.1687 - val_accuracy: 0.9639 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0730 - accuracy: 0.9820 - val_loss: 0.1689 - val_accuracy: 0.9639 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0726 - accuracy: 0.9837 - val_loss: 0.1692 - val_accuracy: 0.9638 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0715 - accuracy: 0.9821 - val_loss: 0.1694 - val_accuracy: 0.9636 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0716 - accuracy: 0.9829 - val_loss: 0.1715 - val_accuracy: 0.9633 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0704 - accuracy: 0.9843 - val_loss: 0.1706 - val_accuracy: 0.9636 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0750 - accuracy: 0.9824 - val_loss: 0.1692 - val_accuracy: 0.9638 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0674 - accuracy: 0.9834 - val_loss: 0.1696 - val_accuracy: 0.9637 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0718 - accuracy: 0.9826 - val_loss: 0.1703 - val_accuracy: 0.9636 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0715 - accuracy: 0.9833 - val_loss: 0.1712 - val_accuracy: 0.9638 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0735 - accuracy: 0.9830 - val_loss: 0.1693 - val_accuracy: 0.9639 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0732 - accuracy: 0.9826 - val_loss: 0.1706 - val_accuracy: 0.9635 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0781 - accuracy: 0.9811 - val_loss: 0.1690 - val_accuracy: 0.9639 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0793 - accuracy: 0.9824 - val_loss: 0.1702 - val_accuracy: 0.9638 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0743 - accuracy: 0.9828 - val_loss: 0.1699 - val_accuracy: 0.9639 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0736 - accuracy: 0.9828 - val_loss: 0.1696 - val_accuracy: 0.9638 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0737 - accuracy: 0.9825 - val_loss: 0.1696 - val_accuracy: 0.9638 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0730 - accuracy: 0.9829 - val_loss: 0.1707 - val_accuracy: 0.9635 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0661 - accuracy: 0.9850 - val_loss: 0.1694 - val_accuracy: 0.9638 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0761 - accuracy: 0.9824 - val_loss: 0.1703 - val_accuracy: 0.9637 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0739 - accuracy: 0.9817 - val_loss: 0.1696 - val_accuracy: 0.9637 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0711 - accuracy: 0.9823 - val_loss: 0.1695 - val_accuracy: 0.9637 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0789 - accuracy: 0.9807 - val_loss: 0.1692 - val_accuracy: 0.9639 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0749 - accuracy: 0.9809 - val_loss: 0.1705 - val_accuracy: 0.9636 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0717 - accuracy: 0.9827 - val_loss: 0.1694 - val_accuracy: 0.9637 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.0730 - accuracy: 0.9820 - val_loss: 0.1698 - val_accuracy: 0.9637 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 5ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 12s 40ms/step - loss: 12.8441 - accuracy: 0.7589 - val_loss: 10.7495 - val_accuracy: 0.2197 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 6.7431 - accuracy: 0.7703 - val_loss: 17.6924 - val_accuracy: 0.1026 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 3.3931 - accuracy: 0.7949 - val_loss: 4.4963 - val_accuracy: 0.3333 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.8810 - accuracy: 0.8030 - val_loss: 2.9461 - val_accuracy: 0.4632 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.8756 - accuracy: 0.8140 - val_loss: 1.3591 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.6857 - accuracy: 0.8167 - val_loss: 1.4277 - val_accuracy: 0.8974 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.9702 - accuracy: 0.8207 - val_loss: 1.2189 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 3.1107 - accuracy: 0.8013 - val_loss: 20.5246 - val_accuracy: 0.1026 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 2.4660 - accuracy: 0.8088 - val_loss: 1.3682 - val_accuracy: 0.8974 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.3454 - accuracy: 0.8094 - val_loss: 1.1086 - val_accuracy: 0.8782 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.5884 - accuracy: 0.8239 - val_loss: 1.1172 - val_accuracy: 0.8178 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.1345 - accuracy: 0.8345 - val_loss: 1.6317 - val_accuracy: 0.7820 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.9876 - accuracy: 0.8325 - val_loss: 1.3747 - val_accuracy: 0.9023 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.7827 - accuracy: 0.8366 - val_loss: 6.5128 - val_accuracy: 0.1338 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.7187 - accuracy: 0.8349 - val_loss: 0.6339 - val_accuracy: 0.8974 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.7124 - accuracy: 0.8521 - val_loss: 0.8244 - val_accuracy: 0.7914 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.5291 - accuracy: 0.8495 - val_loss: 0.5791 - val_accuracy: 0.8974 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4567 - accuracy: 0.8611 - val_loss: 0.3642 - val_accuracy: 0.9303 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4425 - accuracy: 0.8745 - val_loss: 0.5107 - val_accuracy: 0.8980 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4766 - accuracy: 0.8817 - val_loss: 0.3568 - val_accuracy: 0.9100 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4002 - accuracy: 0.8745 - val_loss: 0.3109 - val_accuracy: 0.9141 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3705 - accuracy: 0.8915 - val_loss: 0.3354 - val_accuracy: 0.8989 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3845 - accuracy: 0.8899 - val_loss: 0.8438 - val_accuracy: 0.7867 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3550 - accuracy: 0.8970 - val_loss: 3.8665 - val_accuracy: 0.3632 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3491 - accuracy: 0.8947 - val_loss: 0.3600 - val_accuracy: 0.8945 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3287 - accuracy: 0.9030 - val_loss: 0.8534 - val_accuracy: 0.8975 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3039 - accuracy: 0.9090 - val_loss: 0.4174 - val_accuracy: 0.9108 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2890 - accuracy: 0.9187 - val_loss: 0.3750 - val_accuracy: 0.9077 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3105 - accuracy: 0.9129 - val_loss: 0.2836 - val_accuracy: 0.9414 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3002 - accuracy: 0.9176 - val_loss: 0.6457 - val_accuracy: 0.8022 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2732 - accuracy: 0.9256 - val_loss: 0.3831 - val_accuracy: 0.9130 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2625 - accuracy: 0.9258 - val_loss: 0.6301 - val_accuracy: 0.8207 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2324 - accuracy: 0.9335 - val_loss: 0.5293 - val_accuracy: 0.9081 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2391 - accuracy: 0.9335 - val_loss: 0.2398 - val_accuracy: 0.9266 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2057 - accuracy: 0.9450 - val_loss: 0.2103 - val_accuracy: 0.9475 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2079 - accuracy: 0.9405 - val_loss: 0.2667 - val_accuracy: 0.9332 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1964 - accuracy: 0.9463 - val_loss: 0.2338 - val_accuracy: 0.9443 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1928 - accuracy: 0.9505 - val_loss: 0.3214 - val_accuracy: 0.9069 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1792 - accuracy: 0.9503 - val_loss: 0.2249 - val_accuracy: 0.9383 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1634 - accuracy: 0.9600 - val_loss: 0.3401 - val_accuracy: 0.9316 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1677 - accuracy: 0.9544 - val_loss: 0.2406 - val_accuracy: 0.9346 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1557 - accuracy: 0.9601 - val_loss: 0.2715 - val_accuracy: 0.9308 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1407 - accuracy: 0.9624 - val_loss: 0.2900 - val_accuracy: 0.9369 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1416 - accuracy: 0.9624 - val_loss: 0.3065 - val_accuracy: 0.9317 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1320 - accuracy: 0.9654 - val_loss: 0.2349 - val_accuracy: 0.9452 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1299 - accuracy: 0.9683 - val_loss: 0.1685 - val_accuracy: 0.9569 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1302 - accuracy: 0.9670 - val_loss: 0.3917 - val_accuracy: 0.9003 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1246 - accuracy: 0.9673 - val_loss: 0.2192 - val_accuracy: 0.9531 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1231 - accuracy: 0.9683 - val_loss: 0.1658 - val_accuracy: 0.9620 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1174 - accuracy: 0.9700 - val_loss: 0.1694 - val_accuracy: 0.9592 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1123 - accuracy: 0.9735 - val_loss: 0.1591 - val_accuracy: 0.9630 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1096 - accuracy: 0.9732 - val_loss: 0.1692 - val_accuracy: 0.9624 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1041 - accuracy: 0.9733 - val_loss: 0.2342 - val_accuracy: 0.9519 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1028 - accuracy: 0.9743 - val_loss: 0.1809 - val_accuracy: 0.9597 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0972 - accuracy: 0.9767 - val_loss: 0.1551 - val_accuracy: 0.9658 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0965 - accuracy: 0.9767 - val_loss: 0.1850 - val_accuracy: 0.9565 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0989 - accuracy: 0.9777 - val_loss: 0.1659 - val_accuracy: 0.9604 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.0937 - accuracy: 0.9791 - val_loss: 0.1659 - val_accuracy: 0.9613 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0894 - accuracy: 0.9816 - val_loss: 0.1689 - val_accuracy: 0.9641 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0884 - accuracy: 0.9803 - val_loss: 0.1559 - val_accuracy: 0.9648 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0898 - accuracy: 0.9803 - val_loss: 0.2227 - val_accuracy: 0.9532 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0855 - accuracy: 0.9811 - val_loss: 0.2807 - val_accuracy: 0.9342 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0871 - accuracy: 0.9800 - val_loss: 0.1904 - val_accuracy: 0.9583 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0847 - accuracy: 0.9815 - val_loss: 0.1598 - val_accuracy: 0.9638 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0864 - accuracy: 0.9817 - val_loss: 0.2054 - val_accuracy: 0.9530 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0810 - accuracy: 0.9810 - val_loss: 0.1747 - val_accuracy: 0.9589 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0802 - accuracy: 0.9827 - val_loss: 0.1687 - val_accuracy: 0.9619 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 40ms/step - loss: 0.0760 - accuracy: 0.9834 - val_loss: 0.1610 - val_accuracy: 0.9644 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0834 - accuracy: 0.9830 - val_loss: 0.1779 - val_accuracy: 0.9598 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0768 - accuracy: 0.9819 - val_loss: 0.1673 - val_accuracy: 0.9638 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0770 - accuracy: 0.9824 - val_loss: 0.1675 - val_accuracy: 0.9634 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0836 - accuracy: 0.9842 - val_loss: 0.1681 - val_accuracy: 0.9632 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0787 - accuracy: 0.9837 - val_loss: 0.1684 - val_accuracy: 0.9622 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0724 - accuracy: 0.9861 - val_loss: 0.1634 - val_accuracy: 0.9632 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.0799 - accuracy: 0.9835 - val_loss: 0.1606 - val_accuracy: 0.9642 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0745 - accuracy: 0.9856 - val_loss: 0.1672 - val_accuracy: 0.9625 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0766 - accuracy: 0.9849 - val_loss: 0.1643 - val_accuracy: 0.9637 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0763 - accuracy: 0.9834 - val_loss: 0.1660 - val_accuracy: 0.9626 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0733 - accuracy: 0.9850 - val_loss: 0.1621 - val_accuracy: 0.9643 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0676 - accuracy: 0.9868 - val_loss: 0.1647 - val_accuracy: 0.9641 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0753 - accuracy: 0.9850 - val_loss: 0.1667 - val_accuracy: 0.9627 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0738 - accuracy: 0.9850 - val_loss: 0.1619 - val_accuracy: 0.9639 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0732 - accuracy: 0.9842 - val_loss: 0.1649 - val_accuracy: 0.9631 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0748 - accuracy: 0.9849 - val_loss: 0.1675 - val_accuracy: 0.9622 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0807 - accuracy: 0.9836 - val_loss: 0.1664 - val_accuracy: 0.9630 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.0701 - accuracy: 0.9870 - val_loss: 0.1638 - val_accuracy: 0.9643 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0707 - accuracy: 0.9858 - val_loss: 0.1628 - val_accuracy: 0.9641 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0711 - accuracy: 0.9855 - val_loss: 0.1627 - val_accuracy: 0.9645 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0656 - accuracy: 0.9877 - val_loss: 0.1632 - val_accuracy: 0.9635 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0744 - accuracy: 0.9853 - val_loss: 0.1626 - val_accuracy: 0.9642 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0701 - accuracy: 0.9859 - val_loss: 0.1625 - val_accuracy: 0.9636 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0733 - accuracy: 0.9850 - val_loss: 0.1639 - val_accuracy: 0.9636 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0720 - accuracy: 0.9853 - val_loss: 0.1621 - val_accuracy: 0.9639 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0756 - accuracy: 0.9843 - val_loss: 0.1638 - val_accuracy: 0.9634 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0751 - accuracy: 0.9842 - val_loss: 0.1641 - val_accuracy: 0.9634 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0709 - accuracy: 0.9853 - val_loss: 0.1630 - val_accuracy: 0.9640 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0732 - accuracy: 0.9846 - val_loss: 0.1644 - val_accuracy: 0.9634 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0709 - accuracy: 0.9861 - val_loss: 0.1640 - val_accuracy: 0.9633 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0723 - accuracy: 0.9848 - val_loss: 0.1637 - val_accuracy: 0.9636 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.0766 - accuracy: 0.9842 - val_loss: 0.1636 - val_accuracy: 0.9637 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 39ms/step - loss: 10.0326 - accuracy: 0.7685 - val_loss: 4.0168 - val_accuracy: 0.8834 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 4.1376 - accuracy: 0.7909 - val_loss: 3.4493 - val_accuracy: 0.8974 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 2.8010 - accuracy: 0.8037 - val_loss: 3.0563 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 2.1293 - accuracy: 0.8077 - val_loss: 1.0655 - val_accuracy: 0.9003 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.4097 - accuracy: 0.8174 - val_loss: 1.2357 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.7758 - accuracy: 0.8203 - val_loss: 1.3266 - val_accuracy: 0.8810 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.2468 - accuracy: 0.8290 - val_loss: 1.6748 - val_accuracy: 0.6187 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.4054 - accuracy: 0.8252 - val_loss: 1.3279 - val_accuracy: 0.8974 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.9013 - accuracy: 0.8263 - val_loss: 1.4572 - val_accuracy: 0.8974 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.3585 - accuracy: 0.8177 - val_loss: 1.0050 - val_accuracy: 0.8974 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.5450 - accuracy: 0.8296 - val_loss: 1.1869 - val_accuracy: 0.8974 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.7165 - accuracy: 0.8359 - val_loss: 1.0999 - val_accuracy: 0.8974 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.7167 - accuracy: 0.8376 - val_loss: 1.0015 - val_accuracy: 0.7272 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.5173 - accuracy: 0.8430 - val_loss: 0.3268 - val_accuracy: 0.9106 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4985 - accuracy: 0.8452 - val_loss: 4.5073 - val_accuracy: 0.1810 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4497 - accuracy: 0.8534 - val_loss: 0.4953 - val_accuracy: 0.8260 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4895 - accuracy: 0.8583 - val_loss: 0.2967 - val_accuracy: 0.9169 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4719 - accuracy: 0.8624 - val_loss: 0.4641 - val_accuracy: 0.8686 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4333 - accuracy: 0.8674 - val_loss: 0.7317 - val_accuracy: 0.8974 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3911 - accuracy: 0.8706 - val_loss: 0.2523 - val_accuracy: 0.9381 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3663 - accuracy: 0.8754 - val_loss: 2.0958 - val_accuracy: 0.4754 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4020 - accuracy: 0.8748 - val_loss: 0.3652 - val_accuracy: 0.8718 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3868 - accuracy: 0.8792 - val_loss: 0.3713 - val_accuracy: 0.8730 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3368 - accuracy: 0.8845 - val_loss: 0.2225 - val_accuracy: 0.9366 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3394 - accuracy: 0.8874 - val_loss: 1.3966 - val_accuracy: 0.6950 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3321 - accuracy: 0.8853 - val_loss: 0.4499 - val_accuracy: 0.8991 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.3120 - accuracy: 0.8952 - val_loss: 0.2058 - val_accuracy: 0.9414 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3169 - accuracy: 0.8926 - val_loss: 0.2428 - val_accuracy: 0.9250 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3072 - accuracy: 0.8934 - val_loss: 0.6098 - val_accuracy: 0.7931 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3051 - accuracy: 0.8983 - val_loss: 0.2389 - val_accuracy: 0.9323 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3001 - accuracy: 0.9022 - val_loss: 0.2118 - val_accuracy: 0.9357 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2653 - accuracy: 0.9171 - val_loss: 0.2224 - val_accuracy: 0.9401 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2637 - accuracy: 0.9121 - val_loss: 0.4413 - val_accuracy: 0.9031 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2759 - accuracy: 0.9095 - val_loss: 0.2577 - val_accuracy: 0.9323 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2446 - accuracy: 0.9202 - val_loss: 0.2267 - val_accuracy: 0.9381 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2327 - accuracy: 0.9217 - val_loss: 1.8127 - val_accuracy: 0.5960 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2339 - accuracy: 0.9255 - val_loss: 0.4629 - val_accuracy: 0.9073 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2198 - accuracy: 0.9254 - val_loss: 1.2997 - val_accuracy: 0.6733 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2315 - accuracy: 0.9294 - val_loss: 0.2208 - val_accuracy: 0.9302 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2140 - accuracy: 0.9306 - val_loss: 0.2677 - val_accuracy: 0.9121 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2091 - accuracy: 0.9323 - val_loss: 0.1876 - val_accuracy: 0.9450 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1986 - accuracy: 0.9340 - val_loss: 0.2603 - val_accuracy: 0.9216 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2046 - accuracy: 0.9330 - val_loss: 0.2057 - val_accuracy: 0.9358 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1894 - accuracy: 0.9369 - val_loss: 0.3300 - val_accuracy: 0.8948 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1848 - accuracy: 0.9367 - val_loss: 0.1921 - val_accuracy: 0.9422 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1804 - accuracy: 0.9371 - val_loss: 0.2806 - val_accuracy: 0.9095 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1714 - accuracy: 0.9434 - val_loss: 0.1937 - val_accuracy: 0.9382 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1724 - accuracy: 0.9414 - val_loss: 0.1987 - val_accuracy: 0.9354 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1684 - accuracy: 0.9434 - val_loss: 0.2663 - val_accuracy: 0.9167 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1649 - accuracy: 0.9452 - val_loss: 0.2043 - val_accuracy: 0.9430 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1689 - accuracy: 0.9432 - val_loss: 0.2055 - val_accuracy: 0.9358 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1574 - accuracy: 0.9465 - val_loss: 0.2432 - val_accuracy: 0.9221 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1547 - accuracy: 0.9486 - val_loss: 0.2589 - val_accuracy: 0.9366 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1588 - accuracy: 0.9490 - val_loss: 0.2389 - val_accuracy: 0.9229 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1521 - accuracy: 0.9485 - val_loss: 0.1915 - val_accuracy: 0.9469 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1502 - accuracy: 0.9488 - val_loss: 0.1959 - val_accuracy: 0.9371 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1459 - accuracy: 0.9520 - val_loss: 0.2080 - val_accuracy: 0.9350 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1441 - accuracy: 0.9527 - val_loss: 0.1847 - val_accuracy: 0.9430 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1376 - accuracy: 0.9548 - val_loss: 0.1987 - val_accuracy: 0.9379 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1431 - accuracy: 0.9536 - val_loss: 0.1917 - val_accuracy: 0.9430 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1383 - accuracy: 0.9543 - val_loss: 0.1826 - val_accuracy: 0.9459 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1345 - accuracy: 0.9535 - val_loss: 0.1928 - val_accuracy: 0.9426 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1328 - accuracy: 0.9569 - val_loss: 0.1995 - val_accuracy: 0.9391 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1355 - accuracy: 0.9579 - val_loss: 0.1943 - val_accuracy: 0.9408 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1310 - accuracy: 0.9576 - val_loss: 0.2059 - val_accuracy: 0.9383 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1365 - accuracy: 0.9585 - val_loss: 0.2051 - val_accuracy: 0.9386 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1313 - accuracy: 0.9570 - val_loss: 0.2056 - val_accuracy: 0.9384 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1295 - accuracy: 0.9574 - val_loss: 0.1964 - val_accuracy: 0.9420 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1327 - accuracy: 0.9579 - val_loss: 0.1949 - val_accuracy: 0.9419 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1272 - accuracy: 0.9599 - val_loss: 0.1909 - val_accuracy: 0.9437 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1244 - accuracy: 0.9602 - val_loss: 0.2018 - val_accuracy: 0.9405 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1259 - accuracy: 0.9583 - val_loss: 0.1918 - val_accuracy: 0.9433 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1187 - accuracy: 0.9615 - val_loss: 0.1833 - val_accuracy: 0.9465 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1229 - accuracy: 0.9602 - val_loss: 0.2034 - val_accuracy: 0.9402 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1271 - accuracy: 0.9607 - val_loss: 0.1940 - val_accuracy: 0.9428 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1200 - accuracy: 0.9599 - val_loss: 0.1915 - val_accuracy: 0.9439 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1184 - accuracy: 0.9634 - val_loss: 0.1876 - val_accuracy: 0.9451 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1204 - accuracy: 0.9616 - val_loss: 0.1935 - val_accuracy: 0.9426 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1184 - accuracy: 0.9629 - val_loss: 0.1942 - val_accuracy: 0.9426 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1162 - accuracy: 0.9640 - val_loss: 0.1970 - val_accuracy: 0.9422 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1209 - accuracy: 0.9622 - val_loss: 0.1902 - val_accuracy: 0.9434 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1236 - accuracy: 0.9606 - val_loss: 0.1910 - val_accuracy: 0.9434 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1226 - accuracy: 0.9628 - val_loss: 0.1927 - val_accuracy: 0.9430 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1178 - accuracy: 0.9626 - val_loss: 0.1972 - val_accuracy: 0.9423 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1153 - accuracy: 0.9638 - val_loss: 0.1886 - val_accuracy: 0.9449 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1145 - accuracy: 0.9628 - val_loss: 0.1916 - val_accuracy: 0.9438 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1202 - accuracy: 0.9640 - val_loss: 0.1997 - val_accuracy: 0.9420 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1136 - accuracy: 0.9651 - val_loss: 0.1928 - val_accuracy: 0.9432 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1187 - accuracy: 0.9618 - val_loss: 0.1953 - val_accuracy: 0.9425 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1197 - accuracy: 0.9640 - val_loss: 0.1950 - val_accuracy: 0.9428 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1146 - accuracy: 0.9630 - val_loss: 0.1909 - val_accuracy: 0.9436 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1154 - accuracy: 0.9628 - val_loss: 0.1934 - val_accuracy: 0.9433 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1175 - accuracy: 0.9643 - val_loss: 0.1920 - val_accuracy: 0.9436 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1158 - accuracy: 0.9639 - val_loss: 0.1916 - val_accuracy: 0.9438 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1211 - accuracy: 0.9619 - val_loss: 0.1936 - val_accuracy: 0.9431 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1249 - accuracy: 0.9616 - val_loss: 0.1942 - val_accuracy: 0.9431 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1173 - accuracy: 0.9645 - val_loss: 0.1920 - val_accuracy: 0.9437 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1142 - accuracy: 0.9637 - val_loss: 0.1906 - val_accuracy: 0.9441 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1137 - accuracy: 0.9644 - val_loss: 0.1907 - val_accuracy: 0.9441 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1202 - accuracy: 0.9611 - val_loss: 0.1920 - val_accuracy: 0.9436 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 39ms/step - loss: 10.2575 - accuracy: 0.7635 - val_loss: 3.8042 - val_accuracy: 0.8974 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 5.3685 - accuracy: 0.7819 - val_loss: 5.1792 - val_accuracy: 0.4280 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 4.0614 - accuracy: 0.7908 - val_loss: 2.3637 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 2.0073 - accuracy: 0.8031 - val_loss: 2.3205 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 2.5781 - accuracy: 0.7904 - val_loss: 3.4293 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 2.4415 - accuracy: 0.8051 - val_loss: 1.0068 - val_accuracy: 0.8974 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.6590 - accuracy: 0.8106 - val_loss: 1.0769 - val_accuracy: 0.8974 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 2.2917 - accuracy: 0.8177 - val_loss: 6.5135 - val_accuracy: 0.1785 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.3781 - accuracy: 0.8250 - val_loss: 1.1233 - val_accuracy: 0.8825 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.1396 - accuracy: 0.8271 - val_loss: 1.1493 - val_accuracy: 0.8294 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.4502 - accuracy: 0.8213 - val_loss: 1.0350 - val_accuracy: 0.8976 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.4540 - accuracy: 0.8412 - val_loss: 1.0041 - val_accuracy: 0.8974 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.9890 - accuracy: 0.8343 - val_loss: 0.5830 - val_accuracy: 0.9155 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.7833 - accuracy: 0.8408 - val_loss: 0.7700 - val_accuracy: 0.7984 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.8427 - accuracy: 0.8541 - val_loss: 0.5075 - val_accuracy: 0.9256 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.6410 - accuracy: 0.8572 - val_loss: 2.7572 - val_accuracy: 0.4615 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.6150 - accuracy: 0.8660 - val_loss: 0.5436 - val_accuracy: 0.9069 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.5950 - accuracy: 0.8791 - val_loss: 0.3844 - val_accuracy: 0.9273 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4904 - accuracy: 0.8798 - val_loss: 0.5208 - val_accuracy: 0.8732 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4647 - accuracy: 0.8848 - val_loss: 0.9926 - val_accuracy: 0.7624 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4625 - accuracy: 0.8878 - val_loss: 0.3116 - val_accuracy: 0.9165 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.4099 - accuracy: 0.8944 - val_loss: 0.6518 - val_accuracy: 0.8075 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3920 - accuracy: 0.8950 - val_loss: 0.3165 - val_accuracy: 0.9300 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3601 - accuracy: 0.9045 - val_loss: 0.3648 - val_accuracy: 0.9087 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.3414 - accuracy: 0.9043 - val_loss: 0.8408 - val_accuracy: 0.7504 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3181 - accuracy: 0.9082 - val_loss: 0.3989 - val_accuracy: 0.9072 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3063 - accuracy: 0.9162 - val_loss: 0.3199 - val_accuracy: 0.9343 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3051 - accuracy: 0.9157 - val_loss: 0.8553 - val_accuracy: 0.7856 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2878 - accuracy: 0.9202 - val_loss: 0.2370 - val_accuracy: 0.9466 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2866 - accuracy: 0.9238 - val_loss: 0.2633 - val_accuracy: 0.9341 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2683 - accuracy: 0.9284 - val_loss: 0.2333 - val_accuracy: 0.9389 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2652 - accuracy: 0.9291 - val_loss: 0.7162 - val_accuracy: 0.8029 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.2453 - accuracy: 0.9329 - val_loss: 2.1003 - val_accuracy: 0.6036 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2379 - accuracy: 0.9322 - val_loss: 0.7746 - val_accuracy: 0.8215 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2365 - accuracy: 0.9365 - val_loss: 0.5996 - val_accuracy: 0.8292 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2194 - accuracy: 0.9373 - val_loss: 0.3806 - val_accuracy: 0.8957 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2061 - accuracy: 0.9385 - val_loss: 0.2311 - val_accuracy: 0.9321 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1916 - accuracy: 0.9455 - val_loss: 0.1725 - val_accuracy: 0.9559 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1973 - accuracy: 0.9454 - val_loss: 0.3381 - val_accuracy: 0.9005 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1902 - accuracy: 0.9459 - val_loss: 0.1955 - val_accuracy: 0.9457 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1806 - accuracy: 0.9489 - val_loss: 0.2730 - val_accuracy: 0.9379 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1748 - accuracy: 0.9521 - val_loss: 0.3484 - val_accuracy: 0.9021 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1720 - accuracy: 0.9502 - val_loss: 0.1995 - val_accuracy: 0.9415 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1711 - accuracy: 0.9520 - val_loss: 0.2284 - val_accuracy: 0.9319 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1663 - accuracy: 0.9526 - val_loss: 0.1750 - val_accuracy: 0.9561 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1624 - accuracy: 0.9533 - val_loss: 0.1656 - val_accuracy: 0.9553 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1473 - accuracy: 0.9586 - val_loss: 0.3766 - val_accuracy: 0.8949 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1478 - accuracy: 0.9550 - val_loss: 0.1991 - val_accuracy: 0.9417 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1430 - accuracy: 0.9583 - val_loss: 0.4557 - val_accuracy: 0.8808 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1273 - accuracy: 0.9602 - val_loss: 0.1736 - val_accuracy: 0.9510 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1292 - accuracy: 0.9640 - val_loss: 0.1620 - val_accuracy: 0.9571 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1326 - accuracy: 0.9602 - val_loss: 0.1858 - val_accuracy: 0.9526 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1266 - accuracy: 0.9643 - val_loss: 0.2126 - val_accuracy: 0.9472 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1243 - accuracy: 0.9641 - val_loss: 0.2079 - val_accuracy: 0.9392 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1212 - accuracy: 0.9643 - val_loss: 0.2110 - val_accuracy: 0.9418 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1205 - accuracy: 0.9626 - val_loss: 0.1640 - val_accuracy: 0.9571 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1152 - accuracy: 0.9651 - val_loss: 0.1757 - val_accuracy: 0.9500 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1103 - accuracy: 0.9670 - val_loss: 0.1529 - val_accuracy: 0.9573 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1123 - accuracy: 0.9654 - val_loss: 0.1973 - val_accuracy: 0.9429 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1101 - accuracy: 0.9662 - val_loss: 0.1911 - val_accuracy: 0.9451 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1105 - accuracy: 0.9658 - val_loss: 0.2092 - val_accuracy: 0.9399 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1057 - accuracy: 0.9678 - val_loss: 0.1792 - val_accuracy: 0.9486 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1089 - accuracy: 0.9680 - val_loss: 0.1628 - val_accuracy: 0.9531 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1039 - accuracy: 0.9681 - val_loss: 0.1555 - val_accuracy: 0.9569 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1060 - accuracy: 0.9668 - val_loss: 0.1576 - val_accuracy: 0.9557 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1045 - accuracy: 0.9682 - val_loss: 0.1701 - val_accuracy: 0.9509 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1019 - accuracy: 0.9686 - val_loss: 0.1593 - val_accuracy: 0.9551 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1022 - accuracy: 0.9694 - val_loss: 0.1530 - val_accuracy: 0.9573 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0973 - accuracy: 0.9717 - val_loss: 0.1587 - val_accuracy: 0.9551 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1006 - accuracy: 0.9683 - val_loss: 0.1666 - val_accuracy: 0.9527 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0952 - accuracy: 0.9722 - val_loss: 0.1510 - val_accuracy: 0.9576 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0974 - accuracy: 0.9707 - val_loss: 0.1536 - val_accuracy: 0.9577 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1004 - accuracy: 0.9696 - val_loss: 0.1717 - val_accuracy: 0.9511 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0934 - accuracy: 0.9720 - val_loss: 0.1539 - val_accuracy: 0.9574 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0994 - accuracy: 0.9687 - val_loss: 0.1631 - val_accuracy: 0.9534 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0977 - accuracy: 0.9704 - val_loss: 0.1571 - val_accuracy: 0.9562 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0949 - accuracy: 0.9703 - val_loss: 0.1581 - val_accuracy: 0.9552 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0955 - accuracy: 0.9728 - val_loss: 0.1617 - val_accuracy: 0.9538 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0919 - accuracy: 0.9709 - val_loss: 0.1577 - val_accuracy: 0.9560 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0969 - accuracy: 0.9704 - val_loss: 0.1594 - val_accuracy: 0.9550 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0942 - accuracy: 0.9711 - val_loss: 0.1548 - val_accuracy: 0.9570 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0920 - accuracy: 0.9716 - val_loss: 0.1544 - val_accuracy: 0.9571 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0932 - accuracy: 0.9703 - val_loss: 0.1573 - val_accuracy: 0.9555 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0949 - accuracy: 0.9728 - val_loss: 0.1625 - val_accuracy: 0.9537 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0933 - accuracy: 0.9706 - val_loss: 0.1589 - val_accuracy: 0.9554 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0948 - accuracy: 0.9707 - val_loss: 0.1595 - val_accuracy: 0.9546 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0937 - accuracy: 0.9709 - val_loss: 0.1597 - val_accuracy: 0.9552 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0963 - accuracy: 0.9700 - val_loss: 0.1591 - val_accuracy: 0.9550 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0914 - accuracy: 0.9716 - val_loss: 0.1585 - val_accuracy: 0.9555 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0909 - accuracy: 0.9726 - val_loss: 0.1581 - val_accuracy: 0.9550 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0913 - accuracy: 0.9721 - val_loss: 0.1573 - val_accuracy: 0.9556 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0921 - accuracy: 0.9713 - val_loss: 0.1597 - val_accuracy: 0.9549 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0936 - accuracy: 0.9722 - val_loss: 0.1582 - val_accuracy: 0.9555 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0979 - accuracy: 0.9712 - val_loss: 0.1606 - val_accuracy: 0.9546 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0906 - accuracy: 0.9721 - val_loss: 0.1584 - val_accuracy: 0.9554 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0875 - accuracy: 0.9732 - val_loss: 0.1559 - val_accuracy: 0.9564 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0911 - accuracy: 0.9732 - val_loss: 0.1575 - val_accuracy: 0.9558 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0906 - accuracy: 0.9730 - val_loss: 0.1576 - val_accuracy: 0.9561 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0912 - accuracy: 0.9738 - val_loss: 0.1579 - val_accuracy: 0.9554 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0906 - accuracy: 0.9727 - val_loss: 0.1569 - val_accuracy: 0.9563 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 4.8619 - accuracy: 0.8041 - val_loss: 1.1177 - val_accuracy: 0.9042 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.0720 - accuracy: 0.8344 - val_loss: 2.3250 - val_accuracy: 0.3740 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.8599 - accuracy: 0.8366 - val_loss: 12.5081 - val_accuracy: 0.1427 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 1.4848 - accuracy: 0.8446 - val_loss: 1.5239 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.6831 - accuracy: 0.8168 - val_loss: 26.0204 - val_accuracy: 0.1026 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 2.8148 - accuracy: 0.8296 - val_loss: 1.6160 - val_accuracy: 0.8976 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.4337 - accuracy: 0.8379 - val_loss: 2.0124 - val_accuracy: 0.7499 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.4057 - accuracy: 0.8437 - val_loss: 2.3037 - val_accuracy: 0.2981 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.9518 - accuracy: 0.8425 - val_loss: 1.3889 - val_accuracy: 0.8974 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.9012 - accuracy: 0.8545 - val_loss: 1.6013 - val_accuracy: 0.5563 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.7217 - accuracy: 0.8666 - val_loss: 0.7190 - val_accuracy: 0.9095 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.6042 - accuracy: 0.8761 - val_loss: 0.5062 - val_accuracy: 0.9412 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.5110 - accuracy: 0.8882 - val_loss: 3.0141 - val_accuracy: 0.3238 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.6890 - accuracy: 0.8888 - val_loss: 0.5485 - val_accuracy: 0.9390 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.5061 - accuracy: 0.8979 - val_loss: 0.6332 - val_accuracy: 0.8998 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4220 - accuracy: 0.9053 - val_loss: 0.3446 - val_accuracy: 0.9389 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3774 - accuracy: 0.9054 - val_loss: 0.3361 - val_accuracy: 0.9213 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3388 - accuracy: 0.9191 - val_loss: 0.3506 - val_accuracy: 0.9306 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3096 - accuracy: 0.9235 - val_loss: 1.1784 - val_accuracy: 0.6354 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3016 - accuracy: 0.9284 - val_loss: 0.2494 - val_accuracy: 0.9479 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2743 - accuracy: 0.9310 - val_loss: 2.3707 - val_accuracy: 0.4211 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2497 - accuracy: 0.9352 - val_loss: 0.3407 - val_accuracy: 0.9123 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2555 - accuracy: 0.9380 - val_loss: 1.0095 - val_accuracy: 0.7458 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2221 - accuracy: 0.9452 - val_loss: 2.1729 - val_accuracy: 0.4811 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2156 - accuracy: 0.9453 - val_loss: 0.8608 - val_accuracy: 0.7858 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 0.1981 - accuracy: 0.9524 - val_loss: 0.4384 - val_accuracy: 0.8831 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1941 - accuracy: 0.9525 - val_loss: 0.2067 - val_accuracy: 0.9585 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1778 - accuracy: 0.9560 - val_loss: 0.1909 - val_accuracy: 0.9562 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1815 - accuracy: 0.9535 - val_loss: 0.3587 - val_accuracy: 0.9312 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1679 - accuracy: 0.9590 - val_loss: 0.3945 - val_accuracy: 0.8858 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1613 - accuracy: 0.9611 - val_loss: 0.1996 - val_accuracy: 0.9586 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1587 - accuracy: 0.9614 - val_loss: 0.1808 - val_accuracy: 0.9602 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1533 - accuracy: 0.9637 - val_loss: 0.5293 - val_accuracy: 0.9229 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1425 - accuracy: 0.9652 - val_loss: 0.2365 - val_accuracy: 0.9543 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1309 - accuracy: 0.9681 - val_loss: 0.1809 - val_accuracy: 0.9584 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1222 - accuracy: 0.9705 - val_loss: 0.5766 - val_accuracy: 0.8495 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1213 - accuracy: 0.9695 - val_loss: 0.3031 - val_accuracy: 0.9257 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1159 - accuracy: 0.9731 - val_loss: 0.2239 - val_accuracy: 0.9434 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1123 - accuracy: 0.9739 - val_loss: 0.2202 - val_accuracy: 0.9455 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1103 - accuracy: 0.9735 - val_loss: 0.1782 - val_accuracy: 0.9615 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1010 - accuracy: 0.9748 - val_loss: 0.1991 - val_accuracy: 0.9541 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1006 - accuracy: 0.9759 - val_loss: 0.6991 - val_accuracy: 0.8266 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0986 - accuracy: 0.9761 - val_loss: 0.2048 - val_accuracy: 0.9558 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1041 - accuracy: 0.9762 - val_loss: 0.2081 - val_accuracy: 0.9515 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0954 - accuracy: 0.9777 - val_loss: 0.1794 - val_accuracy: 0.9604 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0886 - accuracy: 0.9795 - val_loss: 0.2078 - val_accuracy: 0.9488 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0951 - accuracy: 0.9767 - val_loss: 0.2352 - val_accuracy: 0.9445 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0846 - accuracy: 0.9794 - val_loss: 0.1786 - val_accuracy: 0.9621 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0867 - accuracy: 0.9786 - val_loss: 0.1885 - val_accuracy: 0.9590 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0825 - accuracy: 0.9802 - val_loss: 0.2198 - val_accuracy: 0.9608 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0758 - accuracy: 0.9824 - val_loss: 0.1881 - val_accuracy: 0.9564 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0754 - accuracy: 0.9827 - val_loss: 0.1796 - val_accuracy: 0.9630 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0763 - accuracy: 0.9829 - val_loss: 0.1910 - val_accuracy: 0.9552 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0733 - accuracy: 0.9833 - val_loss: 0.1783 - val_accuracy: 0.9588 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0755 - accuracy: 0.9827 - val_loss: 0.1815 - val_accuracy: 0.9648 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0712 - accuracy: 0.9839 - val_loss: 0.1800 - val_accuracy: 0.9651 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0723 - accuracy: 0.9846 - val_loss: 0.1732 - val_accuracy: 0.9647 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0690 - accuracy: 0.9852 - val_loss: 0.1758 - val_accuracy: 0.9653 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0672 - accuracy: 0.9845 - val_loss: 0.1790 - val_accuracy: 0.9653 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0631 - accuracy: 0.9855 - val_loss: 0.1751 - val_accuracy: 0.9645 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0658 - accuracy: 0.9868 - val_loss: 0.1775 - val_accuracy: 0.9649 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0693 - accuracy: 0.9856 - val_loss: 0.1769 - val_accuracy: 0.9655 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0652 - accuracy: 0.9863 - val_loss: 0.1700 - val_accuracy: 0.9648 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0637 - accuracy: 0.9862 - val_loss: 0.1745 - val_accuracy: 0.9641 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0668 - accuracy: 0.9855 - val_loss: 0.1800 - val_accuracy: 0.9657 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0659 - accuracy: 0.9865 - val_loss: 0.1759 - val_accuracy: 0.9653 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0623 - accuracy: 0.9876 - val_loss: 0.1784 - val_accuracy: 0.9645 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0672 - accuracy: 0.9845 - val_loss: 0.1754 - val_accuracy: 0.9650 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0635 - accuracy: 0.9868 - val_loss: 0.1719 - val_accuracy: 0.9636 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0622 - accuracy: 0.9864 - val_loss: 0.1796 - val_accuracy: 0.9655 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0637 - accuracy: 0.9872 - val_loss: 0.1780 - val_accuracy: 0.9653 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0628 - accuracy: 0.9863 - val_loss: 0.1761 - val_accuracy: 0.9636 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0635 - accuracy: 0.9879 - val_loss: 0.1767 - val_accuracy: 0.9648 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0594 - accuracy: 0.9870 - val_loss: 0.1803 - val_accuracy: 0.9649 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0629 - accuracy: 0.9873 - val_loss: 0.1747 - val_accuracy: 0.9648 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0596 - accuracy: 0.9860 - val_loss: 0.1804 - val_accuracy: 0.9652 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0631 - accuracy: 0.9873 - val_loss: 0.1769 - val_accuracy: 0.9648 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0633 - accuracy: 0.9864 - val_loss: 0.1748 - val_accuracy: 0.9653 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0611 - accuracy: 0.9869 - val_loss: 0.1793 - val_accuracy: 0.9653 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0612 - accuracy: 0.9876 - val_loss: 0.1797 - val_accuracy: 0.9653 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0599 - accuracy: 0.9875 - val_loss: 0.1769 - val_accuracy: 0.9654 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0593 - accuracy: 0.9877 - val_loss: 0.1770 - val_accuracy: 0.9656 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0601 - accuracy: 0.9871 - val_loss: 0.1784 - val_accuracy: 0.9658 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0613 - accuracy: 0.9864 - val_loss: 0.1751 - val_accuracy: 0.9653 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0614 - accuracy: 0.9863 - val_loss: 0.1778 - val_accuracy: 0.9655 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0586 - accuracy: 0.9869 - val_loss: 0.1769 - val_accuracy: 0.9657 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0602 - accuracy: 0.9878 - val_loss: 0.1751 - val_accuracy: 0.9655 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0586 - accuracy: 0.9880 - val_loss: 0.1783 - val_accuracy: 0.9659 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0585 - accuracy: 0.9885 - val_loss: 0.1776 - val_accuracy: 0.9659 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0562 - accuracy: 0.9884 - val_loss: 0.1786 - val_accuracy: 0.9657 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0610 - accuracy: 0.9874 - val_loss: 0.1788 - val_accuracy: 0.9658 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0603 - accuracy: 0.9883 - val_loss: 0.1782 - val_accuracy: 0.9656 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0595 - accuracy: 0.9872 - val_loss: 0.1786 - val_accuracy: 0.9656 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0595 - accuracy: 0.9875 - val_loss: 0.1799 - val_accuracy: 0.9657 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0568 - accuracy: 0.9882 - val_loss: 0.1795 - val_accuracy: 0.9653 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0579 - accuracy: 0.9879 - val_loss: 0.1793 - val_accuracy: 0.9654 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0616 - accuracy: 0.9873 - val_loss: 0.1785 - val_accuracy: 0.9656 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0577 - accuracy: 0.9866 - val_loss: 0.1787 - val_accuracy: 0.9656 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0599 - accuracy: 0.9866 - val_loss: 0.1786 - val_accuracy: 0.9658 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0595 - accuracy: 0.9884 - val_loss: 0.1785 - val_accuracy: 0.9657 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 40ms/step - loss: 5.1792 - accuracy: 0.7984 - val_loss: 1.8032 - val_accuracy: 0.9201 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.4561 - accuracy: 0.8327 - val_loss: 1.7741 - val_accuracy: 0.6832 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 1.1189 - accuracy: 0.8321 - val_loss: 1.0494 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.8108 - accuracy: 0.8339 - val_loss: 0.8382 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.7192 - accuracy: 0.8493 - val_loss: 0.8088 - val_accuracy: 0.9172 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.6331 - accuracy: 0.8486 - val_loss: 4.7178 - val_accuracy: 0.2426 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.5108 - accuracy: 0.8657 - val_loss: 1.6266 - val_accuracy: 0.6591 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.4826 - accuracy: 0.8816 - val_loss: 0.5476 - val_accuracy: 0.9007 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4360 - accuracy: 0.8861 - val_loss: 0.4830 - val_accuracy: 0.9008 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3747 - accuracy: 0.8943 - val_loss: 0.3397 - val_accuracy: 0.9050 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3765 - accuracy: 0.9040 - val_loss: 0.2770 - val_accuracy: 0.9419 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3629 - accuracy: 0.9057 - val_loss: 1.0500 - val_accuracy: 0.7262 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3301 - accuracy: 0.9165 - val_loss: 0.5754 - val_accuracy: 0.9000 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3243 - accuracy: 0.9142 - val_loss: 21.4973 - val_accuracy: 0.1163 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3485 - accuracy: 0.9087 - val_loss: 0.3941 - val_accuracy: 0.9162 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2871 - accuracy: 0.9268 - val_loss: 0.5526 - val_accuracy: 0.9042 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2677 - accuracy: 0.9352 - val_loss: 0.4347 - val_accuracy: 0.9071 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2516 - accuracy: 0.9352 - val_loss: 0.2184 - val_accuracy: 0.9498 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2320 - accuracy: 0.9413 - val_loss: 0.2577 - val_accuracy: 0.9350 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2249 - accuracy: 0.9424 - val_loss: 0.3037 - val_accuracy: 0.9206 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2171 - accuracy: 0.9447 - val_loss: 0.2775 - val_accuracy: 0.9337 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2112 - accuracy: 0.9417 - val_loss: 0.1993 - val_accuracy: 0.9529 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1958 - accuracy: 0.9509 - val_loss: 0.2475 - val_accuracy: 0.9413 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1879 - accuracy: 0.9505 - val_loss: 0.1900 - val_accuracy: 0.9536 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1800 - accuracy: 0.9540 - val_loss: 0.2460 - val_accuracy: 0.9320 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1673 - accuracy: 0.9560 - val_loss: 0.4570 - val_accuracy: 0.8821 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1673 - accuracy: 0.9553 - val_loss: 0.1762 - val_accuracy: 0.9563 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1598 - accuracy: 0.9580 - val_loss: 0.1861 - val_accuracy: 0.9589 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1582 - accuracy: 0.9586 - val_loss: 0.1878 - val_accuracy: 0.9546 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1445 - accuracy: 0.9643 - val_loss: 0.2078 - val_accuracy: 0.9511 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1412 - accuracy: 0.9636 - val_loss: 0.1641 - val_accuracy: 0.9590 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1301 - accuracy: 0.9658 - val_loss: 0.1773 - val_accuracy: 0.9596 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1262 - accuracy: 0.9665 - val_loss: 0.1719 - val_accuracy: 0.9591 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1266 - accuracy: 0.9663 - val_loss: 0.2107 - val_accuracy: 0.9534 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1188 - accuracy: 0.9668 - val_loss: 0.1635 - val_accuracy: 0.9620 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1155 - accuracy: 0.9696 - val_loss: 0.2655 - val_accuracy: 0.9287 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1122 - accuracy: 0.9713 - val_loss: 0.1690 - val_accuracy: 0.9574 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1063 - accuracy: 0.9711 - val_loss: 0.2089 - val_accuracy: 0.9449 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1054 - accuracy: 0.9703 - val_loss: 0.1723 - val_accuracy: 0.9588 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1009 - accuracy: 0.9743 - val_loss: 0.1873 - val_accuracy: 0.9616 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0998 - accuracy: 0.9741 - val_loss: 0.1519 - val_accuracy: 0.9637 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0908 - accuracy: 0.9770 - val_loss: 0.1631 - val_accuracy: 0.9639 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0874 - accuracy: 0.9787 - val_loss: 0.1986 - val_accuracy: 0.9601 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0848 - accuracy: 0.9791 - val_loss: 0.1608 - val_accuracy: 0.9656 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0811 - accuracy: 0.9807 - val_loss: 0.1482 - val_accuracy: 0.9666 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0831 - accuracy: 0.9790 - val_loss: 0.1563 - val_accuracy: 0.9637 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0764 - accuracy: 0.9809 - val_loss: 0.1552 - val_accuracy: 0.9643 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0763 - accuracy: 0.9806 - val_loss: 0.2095 - val_accuracy: 0.9575 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0757 - accuracy: 0.9818 - val_loss: 0.1510 - val_accuracy: 0.9658 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0726 - accuracy: 0.9830 - val_loss: 0.1486 - val_accuracy: 0.9665 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0717 - accuracy: 0.9826 - val_loss: 0.1916 - val_accuracy: 0.9625 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0731 - accuracy: 0.9810 - val_loss: 0.1682 - val_accuracy: 0.9602 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.1491 - val_accuracy: 0.9655 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0725 - accuracy: 0.9827 - val_loss: 0.1571 - val_accuracy: 0.9669 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0707 - accuracy: 0.9823 - val_loss: 0.1500 - val_accuracy: 0.9672 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0704 - accuracy: 0.9829 - val_loss: 0.1508 - val_accuracy: 0.9666 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0705 - accuracy: 0.9821 - val_loss: 0.1549 - val_accuracy: 0.9666 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0696 - accuracy: 0.9819 - val_loss: 0.1509 - val_accuracy: 0.9672 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0664 - accuracy: 0.9845 - val_loss: 0.1479 - val_accuracy: 0.9670 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0628 - accuracy: 0.9846 - val_loss: 0.1502 - val_accuracy: 0.9672 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0621 - accuracy: 0.9850 - val_loss: 0.1553 - val_accuracy: 0.9668 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0639 - accuracy: 0.9845 - val_loss: 0.1528 - val_accuracy: 0.9672 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0599 - accuracy: 0.9844 - val_loss: 0.1553 - val_accuracy: 0.9674 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0587 - accuracy: 0.9860 - val_loss: 0.1530 - val_accuracy: 0.9674 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0591 - accuracy: 0.9862 - val_loss: 0.1568 - val_accuracy: 0.9673 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0623 - accuracy: 0.9853 - val_loss: 0.1563 - val_accuracy: 0.9673 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0574 - accuracy: 0.9863 - val_loss: 0.1571 - val_accuracy: 0.9674 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 11s 41ms/step - loss: 0.0612 - accuracy: 0.9859 - val_loss: 0.1547 - val_accuracy: 0.9674 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0606 - accuracy: 0.9857 - val_loss: 0.1572 - val_accuracy: 0.9677 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0565 - accuracy: 0.9865 - val_loss: 0.1578 - val_accuracy: 0.9673 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0605 - accuracy: 0.9856 - val_loss: 0.1523 - val_accuracy: 0.9678 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0596 - accuracy: 0.9863 - val_loss: 0.1524 - val_accuracy: 0.9679 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0630 - accuracy: 0.9856 - val_loss: 0.1573 - val_accuracy: 0.9677 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0619 - accuracy: 0.9852 - val_loss: 0.1567 - val_accuracy: 0.9678 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0616 - accuracy: 0.9851 - val_loss: 0.1555 - val_accuracy: 0.9675 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0645 - accuracy: 0.9845 - val_loss: 0.1551 - val_accuracy: 0.9675 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0595 - accuracy: 0.9863 - val_loss: 0.1557 - val_accuracy: 0.9675 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0573 - accuracy: 0.9862 - val_loss: 0.1548 - val_accuracy: 0.9675 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0592 - accuracy: 0.9856 - val_loss: 0.1560 - val_accuracy: 0.9678 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0606 - accuracy: 0.9864 - val_loss: 0.1553 - val_accuracy: 0.9678 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0593 - accuracy: 0.9862 - val_loss: 0.1549 - val_accuracy: 0.9675 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0577 - accuracy: 0.9874 - val_loss: 0.1562 - val_accuracy: 0.9678 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0594 - accuracy: 0.9861 - val_loss: 0.1554 - val_accuracy: 0.9679 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0600 - accuracy: 0.9862 - val_loss: 0.1554 - val_accuracy: 0.9677 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0581 - accuracy: 0.9856 - val_loss: 0.1556 - val_accuracy: 0.9678 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0592 - accuracy: 0.9859 - val_loss: 0.1557 - val_accuracy: 0.9678 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0571 - accuracy: 0.9865 - val_loss: 0.1566 - val_accuracy: 0.9679 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0584 - accuracy: 0.9870 - val_loss: 0.1552 - val_accuracy: 0.9678 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0566 - accuracy: 0.9878 - val_loss: 0.1563 - val_accuracy: 0.9679 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0568 - accuracy: 0.9876 - val_loss: 0.1557 - val_accuracy: 0.9680 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0584 - accuracy: 0.9882 - val_loss: 0.1561 - val_accuracy: 0.9677 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0574 - accuracy: 0.9874 - val_loss: 0.1559 - val_accuracy: 0.9678 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0575 - accuracy: 0.9876 - val_loss: 0.1549 - val_accuracy: 0.9678 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0544 - accuracy: 0.9882 - val_loss: 0.1561 - val_accuracy: 0.9679 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0564 - accuracy: 0.9865 - val_loss: 0.1564 - val_accuracy: 0.9678 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0564 - accuracy: 0.9865 - val_loss: 0.1565 - val_accuracy: 0.9677 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0570 - accuracy: 0.9876 - val_loss: 0.1566 - val_accuracy: 0.9679 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0576 - accuracy: 0.9858 - val_loss: 0.1567 - val_accuracy: 0.9678 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0582 - accuracy: 0.9866 - val_loss: 0.1560 - val_accuracy: 0.9678 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0595 - accuracy: 0.9868 - val_loss: 0.1570 - val_accuracy: 0.9680 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "265/265 [==============================] - 11s 39ms/step - loss: 3.7888 - accuracy: 0.7811 - val_loss: 1.6563 - val_accuracy: 0.9032 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.7543 - accuracy: 0.8010 - val_loss: 2.0346 - val_accuracy: 0.8548 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 1.5912 - accuracy: 0.8108 - val_loss: 0.8588 - val_accuracy: 0.8974 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.7871 - accuracy: 0.8318 - val_loss: 1.0580 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.7203 - accuracy: 0.8286 - val_loss: 0.5256 - val_accuracy: 0.8974 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.5661 - accuracy: 0.8556 - val_loss: 0.4284 - val_accuracy: 0.8695 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4917 - accuracy: 0.8538 - val_loss: 3.8297 - val_accuracy: 0.2919 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.5273 - accuracy: 0.8655 - val_loss: 0.8572 - val_accuracy: 0.8974 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4904 - accuracy: 0.8643 - val_loss: 1.0425 - val_accuracy: 0.7424 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4522 - accuracy: 0.8734 - val_loss: 0.3167 - val_accuracy: 0.9193 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.4143 - accuracy: 0.8806 - val_loss: 0.6265 - val_accuracy: 0.8196 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.3689 - accuracy: 0.8920 - val_loss: 0.4221 - val_accuracy: 0.9023 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3393 - accuracy: 0.9080 - val_loss: 0.3960 - val_accuracy: 0.9124 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3239 - accuracy: 0.9088 - val_loss: 0.2483 - val_accuracy: 0.9421 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.3247 - accuracy: 0.9122 - val_loss: 0.9112 - val_accuracy: 0.8979 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2946 - accuracy: 0.9225 - val_loss: 0.2694 - val_accuracy: 0.9319 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2651 - accuracy: 0.9318 - val_loss: 1.6400 - val_accuracy: 0.6225 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2506 - accuracy: 0.9337 - val_loss: 0.2785 - val_accuracy: 0.9259 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2338 - accuracy: 0.9427 - val_loss: 1.4657 - val_accuracy: 0.7038 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.2264 - accuracy: 0.9431 - val_loss: 0.3409 - val_accuracy: 0.9281 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.2235 - accuracy: 0.9444 - val_loss: 0.4694 - val_accuracy: 0.8699 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1962 - accuracy: 0.9505 - val_loss: 1.5554 - val_accuracy: 0.6164 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1902 - accuracy: 0.9502 - val_loss: 0.5371 - val_accuracy: 0.8608 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1850 - accuracy: 0.9550 - val_loss: 0.2163 - val_accuracy: 0.9558 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1836 - accuracy: 0.9515 - val_loss: 0.2463 - val_accuracy: 0.9396 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1716 - accuracy: 0.9574 - val_loss: 0.1739 - val_accuracy: 0.9593 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1546 - accuracy: 0.9631 - val_loss: 0.2856 - val_accuracy: 0.9253 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1581 - accuracy: 0.9626 - val_loss: 0.3578 - val_accuracy: 0.8937 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1479 - accuracy: 0.9622 - val_loss: 0.2494 - val_accuracy: 0.9447 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1425 - accuracy: 0.9655 - val_loss: 0.2233 - val_accuracy: 0.9533 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1301 - accuracy: 0.9686 - val_loss: 0.2907 - val_accuracy: 0.9263 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1265 - accuracy: 0.9711 - val_loss: 0.2282 - val_accuracy: 0.9584 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1273 - accuracy: 0.9679 - val_loss: 0.3313 - val_accuracy: 0.9228 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1245 - accuracy: 0.9688 - val_loss: 0.4010 - val_accuracy: 0.9071 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.1150 - accuracy: 0.9724 - val_loss: 0.1662 - val_accuracy: 0.9591 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1094 - accuracy: 0.9734 - val_loss: 0.1969 - val_accuracy: 0.9603 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1054 - accuracy: 0.9728 - val_loss: 0.3781 - val_accuracy: 0.9359 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.1046 - accuracy: 0.9743 - val_loss: 0.2302 - val_accuracy: 0.9444 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0952 - accuracy: 0.9763 - val_loss: 0.1687 - val_accuracy: 0.9614 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0975 - accuracy: 0.9754 - val_loss: 0.1951 - val_accuracy: 0.9597 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0924 - accuracy: 0.9781 - val_loss: 0.1802 - val_accuracy: 0.9638 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0944 - accuracy: 0.9771 - val_loss: 0.3270 - val_accuracy: 0.9214 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0898 - accuracy: 0.9784 - val_loss: 0.1852 - val_accuracy: 0.9647 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0884 - accuracy: 0.9784 - val_loss: 0.1775 - val_accuracy: 0.9614 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0851 - accuracy: 0.9780 - val_loss: 0.2040 - val_accuracy: 0.9535 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0874 - accuracy: 0.9791 - val_loss: 0.1712 - val_accuracy: 0.9630 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0814 - accuracy: 0.9807 - val_loss: 0.1806 - val_accuracy: 0.9622 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0755 - accuracy: 0.9810 - val_loss: 0.1749 - val_accuracy: 0.9638 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0804 - accuracy: 0.9809 - val_loss: 0.1786 - val_accuracy: 0.9610 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0778 - accuracy: 0.9803 - val_loss: 0.1767 - val_accuracy: 0.9643 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0752 - accuracy: 0.9822 - val_loss: 0.1825 - val_accuracy: 0.9639 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0766 - accuracy: 0.9821 - val_loss: 0.1926 - val_accuracy: 0.9631 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0757 - accuracy: 0.9817 - val_loss: 0.1881 - val_accuracy: 0.9639 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0770 - accuracy: 0.9821 - val_loss: 0.1829 - val_accuracy: 0.9637 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0736 - accuracy: 0.9815 - val_loss: 0.1879 - val_accuracy: 0.9622 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0689 - accuracy: 0.9826 - val_loss: 0.1859 - val_accuracy: 0.9636 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0718 - accuracy: 0.9828 - val_loss: 0.1842 - val_accuracy: 0.9643 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0665 - accuracy: 0.9828 - val_loss: 0.1881 - val_accuracy: 0.9633 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0767 - accuracy: 0.9816 - val_loss: 0.1894 - val_accuracy: 0.9631 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0629 - accuracy: 0.9845 - val_loss: 0.1899 - val_accuracy: 0.9616 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0686 - accuracy: 0.9849 - val_loss: 0.1917 - val_accuracy: 0.9633 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0662 - accuracy: 0.9841 - val_loss: 0.1886 - val_accuracy: 0.9639 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0690 - accuracy: 0.9833 - val_loss: 0.1900 - val_accuracy: 0.9635 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0676 - accuracy: 0.9842 - val_loss: 0.1903 - val_accuracy: 0.9632 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0658 - accuracy: 0.9840 - val_loss: 0.1872 - val_accuracy: 0.9631 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0650 - accuracy: 0.9844 - val_loss: 0.1938 - val_accuracy: 0.9636 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0717 - accuracy: 0.9842 - val_loss: 0.1881 - val_accuracy: 0.9633 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0652 - accuracy: 0.9852 - val_loss: 0.1933 - val_accuracy: 0.9635 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0622 - accuracy: 0.9850 - val_loss: 0.1922 - val_accuracy: 0.9636 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0670 - accuracy: 0.9832 - val_loss: 0.1948 - val_accuracy: 0.9634 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0631 - accuracy: 0.9846 - val_loss: 0.1931 - val_accuracy: 0.9638 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0618 - accuracy: 0.9858 - val_loss: 0.1917 - val_accuracy: 0.9638 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0653 - accuracy: 0.9839 - val_loss: 0.1908 - val_accuracy: 0.9629 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0638 - accuracy: 0.9847 - val_loss: 0.1926 - val_accuracy: 0.9637 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0665 - accuracy: 0.9861 - val_loss: 0.1909 - val_accuracy: 0.9639 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0649 - accuracy: 0.9845 - val_loss: 0.1912 - val_accuracy: 0.9636 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0647 - accuracy: 0.9848 - val_loss: 0.1909 - val_accuracy: 0.9639 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0627 - accuracy: 0.9845 - val_loss: 0.1891 - val_accuracy: 0.9638 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0625 - accuracy: 0.9854 - val_loss: 0.1895 - val_accuracy: 0.9638 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0648 - accuracy: 0.9847 - val_loss: 0.1925 - val_accuracy: 0.9638 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0612 - accuracy: 0.9861 - val_loss: 0.1912 - val_accuracy: 0.9640 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0689 - accuracy: 0.9839 - val_loss: 0.1926 - val_accuracy: 0.9635 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0603 - accuracy: 0.9853 - val_loss: 0.1901 - val_accuracy: 0.9639 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0627 - accuracy: 0.9852 - val_loss: 0.1915 - val_accuracy: 0.9639 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0630 - accuracy: 0.9847 - val_loss: 0.1918 - val_accuracy: 0.9640 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0645 - accuracy: 0.9850 - val_loss: 0.1915 - val_accuracy: 0.9639 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0636 - accuracy: 0.9855 - val_loss: 0.1910 - val_accuracy: 0.9641 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0662 - accuracy: 0.9847 - val_loss: 0.1918 - val_accuracy: 0.9639 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0633 - accuracy: 0.9848 - val_loss: 0.1910 - val_accuracy: 0.9639 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.0601 - accuracy: 0.9861 - val_loss: 0.1919 - val_accuracy: 0.9639 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0628 - accuracy: 0.9850 - val_loss: 0.1917 - val_accuracy: 0.9638 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0610 - accuracy: 0.9857 - val_loss: 0.1911 - val_accuracy: 0.9637 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0664 - accuracy: 0.9853 - val_loss: 0.1902 - val_accuracy: 0.9638 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0689 - accuracy: 0.9846 - val_loss: 0.1907 - val_accuracy: 0.9639 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0610 - accuracy: 0.9860 - val_loss: 0.1912 - val_accuracy: 0.9637 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "265/265 [==============================] - 10s 39ms/step - loss: 0.0596 - accuracy: 0.9864 - val_loss: 0.1915 - val_accuracy: 0.9637 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0645 - accuracy: 0.9842 - val_loss: 0.1915 - val_accuracy: 0.9638 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0637 - accuracy: 0.9854 - val_loss: 0.1915 - val_accuracy: 0.9638 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0623 - accuracy: 0.9868 - val_loss: 0.1919 - val_accuracy: 0.9637 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "265/265 [==============================] - 10s 38ms/step - loss: 0.0645 - accuracy: 0.9857 - val_loss: 0.1919 - val_accuracy: 0.9637 - lr: 2.5087e-06\n",
      "265/265 [==============================] - 2s 7ms/step\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 1/100\n",
      "397/397 [==============================] - 15s 36ms/step - loss: 5.0862 - accuracy: 0.7853 - val_loss: 4.1371 - val_accuracy: 0.9035 - lr: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.04524187090179798.\n",
      "Epoch 2/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 1.5642 - accuracy: 0.8303 - val_loss: 0.8477 - val_accuracy: 0.9051 - lr: 0.0452\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0409365376538991.\n",
      "Epoch 3/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.7478 - accuracy: 0.8376 - val_loss: 0.6103 - val_accuracy: 0.8979 - lr: 0.0409\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0370409110340859.\n",
      "Epoch 4/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 1.0207 - accuracy: 0.8401 - val_loss: 1.0563 - val_accuracy: 0.8974 - lr: 0.0370\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.03351600230178197.\n",
      "Epoch 5/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.6504 - accuracy: 0.8548 - val_loss: 3.6950 - val_accuracy: 0.4756 - lr: 0.0335\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.030326532985631673.\n",
      "Epoch 6/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.6317 - accuracy: 0.8574 - val_loss: 0.8325 - val_accuracy: 0.8974 - lr: 0.0303\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.02744058180470132.\n",
      "Epoch 7/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.5484 - accuracy: 0.8627 - val_loss: 8.5025 - val_accuracy: 0.1665 - lr: 0.0274\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.024829265189570474.\n",
      "Epoch 8/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.6396 - accuracy: 0.8521 - val_loss: 0.9153 - val_accuracy: 0.7967 - lr: 0.0248\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.022466448205861078.\n",
      "Epoch 9/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.5369 - accuracy: 0.8691 - val_loss: 0.3402 - val_accuracy: 0.9387 - lr: 0.0225\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020328482987029956.\n",
      "Epoch 10/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.4905 - accuracy: 0.8867 - val_loss: 0.2991 - val_accuracy: 0.9371 - lr: 0.0203\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.018393972058572117.\n",
      "Epoch 11/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.4248 - accuracy: 0.8969 - val_loss: 3.3582 - val_accuracy: 0.4320 - lr: 0.0184\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.01664355418490398.\n",
      "Epoch 12/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.4849 - accuracy: 0.8898 - val_loss: 0.4327 - val_accuracy: 0.9115 - lr: 0.0166\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015059710595610102.\n",
      "Epoch 13/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.4492 - accuracy: 0.8942 - val_loss: 0.5894 - val_accuracy: 0.8344 - lr: 0.0151\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.01362658965170063.\n",
      "Epoch 14/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.3643 - accuracy: 0.9065 - val_loss: 0.8968 - val_accuracy: 0.8974 - lr: 0.0136\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.012329848197080322.\n",
      "Epoch 15/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.3251 - accuracy: 0.9120 - val_loss: 0.2377 - val_accuracy: 0.9450 - lr: 0.0123\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.011156508007421491.\n",
      "Epoch 16/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.3181 - accuracy: 0.9110 - val_loss: 0.6430 - val_accuracy: 0.8987 - lr: 0.0112\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.01009482589973277.\n",
      "Epoch 17/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.2887 - accuracy: 0.9229 - val_loss: 0.7312 - val_accuracy: 0.7936 - lr: 0.0101\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.009134176202636731.\n",
      "Epoch 18/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.2799 - accuracy: 0.9259 - val_loss: 0.4199 - val_accuracy: 0.8798 - lr: 0.0091\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.008264944411079327.\n",
      "Epoch 19/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.2663 - accuracy: 0.9294 - val_loss: 0.3399 - val_accuracy: 0.9182 - lr: 0.0083\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.007478430961131752.\n",
      "Epoch 20/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.2563 - accuracy: 0.9316 - val_loss: 0.2109 - val_accuracy: 0.9458 - lr: 0.0075\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0067667641618306355.\n",
      "Epoch 21/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.2308 - accuracy: 0.9361 - val_loss: 0.1843 - val_accuracy: 0.9555 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006122821412649096.\n",
      "Epoch 22/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.2235 - accuracy: 0.9401 - val_loss: 0.2122 - val_accuracy: 0.9447 - lr: 0.0061\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.005540157918116694.\n",
      "Epoch 23/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.2061 - accuracy: 0.9476 - val_loss: 1.0270 - val_accuracy: 0.7909 - lr: 0.0055\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005012942186140186.\n",
      "Epoch 24/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1897 - accuracy: 0.9535 - val_loss: 0.1890 - val_accuracy: 0.9537 - lr: 0.0050\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.004535897664470624.\n",
      "Epoch 25/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.1915 - accuracy: 0.9516 - val_loss: 0.2666 - val_accuracy: 0.9247 - lr: 0.0045\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0041042499311949405.\n",
      "Epoch 26/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1666 - accuracy: 0.9596 - val_loss: 0.1826 - val_accuracy: 0.9528 - lr: 0.0041\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.003713678910716694.\n",
      "Epoch 27/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1692 - accuracy: 0.9591 - val_loss: 0.1811 - val_accuracy: 0.9579 - lr: 0.0037\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.003360275636987488.\n",
      "Epoch 28/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1528 - accuracy: 0.9635 - val_loss: 0.1798 - val_accuracy: 0.9553 - lr: 0.0034\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.003040503131260898.\n",
      "Epoch 29/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1451 - accuracy: 0.9639 - val_loss: 0.1900 - val_accuracy: 0.9592 - lr: 0.0030\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0027511610028203605.\n",
      "Epoch 30/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1432 - accuracy: 0.9653 - val_loss: 0.1508 - val_accuracy: 0.9660 - lr: 0.0028\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0024893534183931974.\n",
      "Epoch 31/100\n",
      "397/397 [==============================] - 13s 34ms/step - loss: 0.1328 - accuracy: 0.9692 - val_loss: 0.2473 - val_accuracy: 0.9340 - lr: 0.0025\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00225246011967789.\n",
      "Epoch 32/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1298 - accuracy: 0.9676 - val_loss: 0.1877 - val_accuracy: 0.9594 - lr: 0.0023\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0020381101989183107.\n",
      "Epoch 33/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1198 - accuracy: 0.9726 - val_loss: 0.1762 - val_accuracy: 0.9596 - lr: 0.0020\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018441583700619997.\n",
      "Epoch 34/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1215 - accuracy: 0.9724 - val_loss: 0.2367 - val_accuracy: 0.9350 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0016686634980163035.\n",
      "Epoch 35/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1133 - accuracy: 0.9746 - val_loss: 0.2129 - val_accuracy: 0.9424 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.001509869171115925.\n",
      "Epoch 36/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1014 - accuracy: 0.9771 - val_loss: 0.1641 - val_accuracy: 0.9573 - lr: 0.0015\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0013661861223646281.\n",
      "Epoch 37/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.1016 - accuracy: 0.9765 - val_loss: 0.2269 - val_accuracy: 0.9544 - lr: 0.0014\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0012361763235169696.\n",
      "Epoch 38/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0899 - accuracy: 0.9798 - val_loss: 0.1647 - val_accuracy: 0.9659 - lr: 0.0012\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0011185385928082795.\n",
      "Epoch 39/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0978 - accuracy: 0.9766 - val_loss: 0.1420 - val_accuracy: 0.9674 - lr: 0.0011\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.001012095572290219.\n",
      "Epoch 40/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0883 - accuracy: 0.9798 - val_loss: 0.1573 - val_accuracy: 0.9666 - lr: 0.0010\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.000915781944436709.\n",
      "Epoch 41/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0840 - accuracy: 0.9814 - val_loss: 0.1467 - val_accuracy: 0.9693 - lr: 9.1578e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.000828633770088062.\n",
      "Epoch 42/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0781 - accuracy: 0.9828 - val_loss: 0.1363 - val_accuracy: 0.9691 - lr: 8.2863e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0007497788410238852.\n",
      "Epoch 43/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0745 - accuracy: 0.9838 - val_loss: 0.2238 - val_accuracy: 0.9434 - lr: 7.4978e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006784279506100467.\n",
      "Epoch 44/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0722 - accuracy: 0.9843 - val_loss: 0.1489 - val_accuracy: 0.9643 - lr: 6.7843e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006138669951534218.\n",
      "Epoch 45/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0732 - accuracy: 0.9838 - val_loss: 0.1750 - val_accuracy: 0.9560 - lr: 6.1387e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0005554498269121153.\n",
      "Epoch 46/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0663 - accuracy: 0.9856 - val_loss: 0.1422 - val_accuracy: 0.9698 - lr: 5.5545e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0005025917872316788.\n",
      "Epoch 47/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0669 - accuracy: 0.9854 - val_loss: 0.1493 - val_accuracy: 0.9650 - lr: 5.0259e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0004547638550847908.\n",
      "Epoch 48/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0646 - accuracy: 0.9861 - val_loss: 0.1388 - val_accuracy: 0.9709 - lr: 4.5476e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0004114873524510012.\n",
      "Epoch 49/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0605 - accuracy: 0.9859 - val_loss: 0.1432 - val_accuracy: 0.9701 - lr: 4.1149e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00037232915354621694.\n",
      "Epoch 50/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0578 - accuracy: 0.9887 - val_loss: 0.1683 - val_accuracy: 0.9693 - lr: 3.7233e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.00033689734995427336.\n",
      "Epoch 51/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0619 - accuracy: 0.9864 - val_loss: 0.1505 - val_accuracy: 0.9700 - lr: 3.3690e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.00030483732827578163.\n",
      "Epoch 52/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0576 - accuracy: 0.9874 - val_loss: 0.1747 - val_accuracy: 0.9685 - lr: 3.0484e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0002758282210380386.\n",
      "Epoch 53/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0575 - accuracy: 0.9882 - val_loss: 0.1420 - val_accuracy: 0.9682 - lr: 2.7583e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00024957969534551065.\n",
      "Epoch 54/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0549 - accuracy: 0.9876 - val_loss: 0.1326 - val_accuracy: 0.9705 - lr: 2.4958e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0002258290471306333.\n",
      "Epoch 55/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0572 - accuracy: 0.9874 - val_loss: 0.1696 - val_accuracy: 0.9692 - lr: 2.2583e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.00020433857192320333.\n",
      "Epoch 56/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0543 - accuracy: 0.9892 - val_loss: 0.1543 - val_accuracy: 0.9698 - lr: 2.0434e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00018489318582414646.\n",
      "Epoch 57/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0538 - accuracy: 0.9892 - val_loss: 0.1382 - val_accuracy: 0.9715 - lr: 1.8489e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0001672982728735636.\n",
      "Epoch 58/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0567 - accuracy: 0.9888 - val_loss: 0.1586 - val_accuracy: 0.9699 - lr: 1.6730e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015137773726879065.\n",
      "Epoch 59/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0525 - accuracy: 0.9896 - val_loss: 0.1600 - val_accuracy: 0.9701 - lr: 1.5138e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.00013697224093841843.\n",
      "Epoch 60/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0518 - accuracy: 0.9902 - val_loss: 0.1485 - val_accuracy: 0.9707 - lr: 1.3697e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00012393760883331792.\n",
      "Epoch 61/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0519 - accuracy: 0.9888 - val_loss: 0.1666 - val_accuracy: 0.9692 - lr: 1.2394e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00011214338597429006.\n",
      "Epoch 62/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0530 - accuracy: 0.9890 - val_loss: 0.1565 - val_accuracy: 0.9698 - lr: 1.1214e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00010147153181478671.\n",
      "Epoch 63/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0477 - accuracy: 0.9908 - val_loss: 0.1445 - val_accuracy: 0.9710 - lr: 1.0147e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 9.181523885144528e-05.\n",
      "Epoch 64/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0492 - accuracy: 0.9900 - val_loss: 0.1647 - val_accuracy: 0.9697 - lr: 9.1815e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 8.30778636586967e-05.\n",
      "Epoch 65/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0515 - accuracy: 0.9894 - val_loss: 0.1522 - val_accuracy: 0.9704 - lr: 8.3078e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 7.517195964887862e-05.\n",
      "Epoch 66/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0478 - accuracy: 0.9904 - val_loss: 0.1437 - val_accuracy: 0.9708 - lr: 7.5172e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 6.801840187739464e-05.\n",
      "Epoch 67/100\n",
      "397/397 [==============================] - 16s 40ms/step - loss: 0.0494 - accuracy: 0.9896 - val_loss: 0.1581 - val_accuracy: 0.9700 - lr: 6.8018e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 6.154559513367405e-05.\n",
      "Epoch 68/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0477 - accuracy: 0.9906 - val_loss: 0.1583 - val_accuracy: 0.9699 - lr: 6.1546e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.5688757392240124e-05.\n",
      "Epoch 69/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0464 - accuracy: 0.9905 - val_loss: 0.1510 - val_accuracy: 0.9704 - lr: 5.5689e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.038927145242553e-05.\n",
      "Epoch 70/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0478 - accuracy: 0.9905 - val_loss: 0.1534 - val_accuracy: 0.9701 - lr: 5.0389e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 4.559409827772581e-05.\n",
      "Epoch 71/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0481 - accuracy: 0.9904 - val_loss: 0.1534 - val_accuracy: 0.9704 - lr: 4.5594e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 4.1255246163295196e-05.\n",
      "Epoch 72/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0472 - accuracy: 0.9903 - val_loss: 0.1544 - val_accuracy: 0.9699 - lr: 4.1255e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.732929041883396e-05.\n",
      "Epoch 73/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0483 - accuracy: 0.9904 - val_loss: 0.1606 - val_accuracy: 0.9699 - lr: 3.7329e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.377693875969219e-05.\n",
      "Epoch 74/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0455 - accuracy: 0.9911 - val_loss: 0.1605 - val_accuracy: 0.9695 - lr: 3.3777e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.0562638056478614e-05.\n",
      "Epoch 75/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0457 - accuracy: 0.9912 - val_loss: 0.1533 - val_accuracy: 0.9703 - lr: 3.0563e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.765421850739168e-05.\n",
      "Epoch 76/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0459 - accuracy: 0.9900 - val_loss: 0.1520 - val_accuracy: 0.9707 - lr: 2.7654e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.502257167203052e-05.\n",
      "Epoch 77/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0444 - accuracy: 0.9913 - val_loss: 0.1536 - val_accuracy: 0.9705 - lr: 2.5023e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.264135914433985e-05.\n",
      "Epoch 78/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0446 - accuracy: 0.9913 - val_loss: 0.1556 - val_accuracy: 0.9703 - lr: 2.2641e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.0486748948989323e-05.\n",
      "Epoch 79/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0439 - accuracy: 0.9916 - val_loss: 0.1572 - val_accuracy: 0.9704 - lr: 2.0487e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.8537177022954413e-05.\n",
      "Epoch 80/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0478 - accuracy: 0.9913 - val_loss: 0.1553 - val_accuracy: 0.9705 - lr: 1.8537e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.6773131395125595e-05.\n",
      "Epoch 81/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0466 - accuracy: 0.9902 - val_loss: 0.1579 - val_accuracy: 0.9704 - lr: 1.6773e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.517695690394334e-05.\n",
      "Epoch 82/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0456 - accuracy: 0.9915 - val_loss: 0.1616 - val_accuracy: 0.9697 - lr: 1.5177e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3732678498607103e-05.\n",
      "Epoch 83/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0483 - accuracy: 0.9905 - val_loss: 0.1577 - val_accuracy: 0.9704 - lr: 1.3733e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.2425841355397594e-05.\n",
      "Epoch 84/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0458 - accuracy: 0.9904 - val_loss: 0.1555 - val_accuracy: 0.9703 - lr: 1.2426e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.124336620894241e-05.\n",
      "Epoch 85/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0431 - accuracy: 0.9914 - val_loss: 0.1601 - val_accuracy: 0.9702 - lr: 1.1243e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.0173418450532209e-05.\n",
      "Epoch 86/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0457 - accuracy: 0.9914 - val_loss: 0.1568 - val_accuracy: 0.9702 - lr: 1.0173e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 9.20528968337896e-06.\n",
      "Epoch 87/100\n",
      "397/397 [==============================] - 13s 34ms/step - loss: 0.0438 - accuracy: 0.9914 - val_loss: 0.1584 - val_accuracy: 0.9703 - lr: 9.2053e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 8.329290549381662e-06.\n",
      "Epoch 88/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0463 - accuracy: 0.9905 - val_loss: 0.1561 - val_accuracy: 0.9704 - lr: 8.3293e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 7.5366537547738255e-06.\n",
      "Epoch 89/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0468 - accuracy: 0.9909 - val_loss: 0.1583 - val_accuracy: 0.9701 - lr: 7.5367e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 6.81944632410057e-06.\n",
      "Epoch 90/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0477 - accuracy: 0.9911 - val_loss: 0.1560 - val_accuracy: 0.9704 - lr: 6.8194e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 6.170490204333978e-06.\n",
      "Epoch 91/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0474 - accuracy: 0.9909 - val_loss: 0.1568 - val_accuracy: 0.9701 - lr: 6.1705e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 5.583290424505739e-06.\n",
      "Epoch 92/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0435 - accuracy: 0.9915 - val_loss: 0.1592 - val_accuracy: 0.9700 - lr: 5.5833e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 5.051970091854662e-06.\n",
      "Epoch 93/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0437 - accuracy: 0.9921 - val_loss: 0.1574 - val_accuracy: 0.9702 - lr: 5.0520e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.571211573908664e-06.\n",
      "Epoch 94/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0482 - accuracy: 0.9905 - val_loss: 0.1585 - val_accuracy: 0.9702 - lr: 4.5712e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.136203277831611e-06.\n",
      "Epoch 95/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0445 - accuracy: 0.9910 - val_loss: 0.1573 - val_accuracy: 0.9702 - lr: 4.1362e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.74259149438503e-06.\n",
      "Epoch 96/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0457 - accuracy: 0.9914 - val_loss: 0.1585 - val_accuracy: 0.9701 - lr: 3.7426e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.386436824542689e-06.\n",
      "Epoch 97/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0445 - accuracy: 0.9913 - val_loss: 0.1573 - val_accuracy: 0.9701 - lr: 3.3864e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.0641747526611013e-06.\n",
      "Epoch 98/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0471 - accuracy: 0.9907 - val_loss: 0.1565 - val_accuracy: 0.9701 - lr: 3.0642e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.7725799716088475e-06.\n",
      "Epoch 99/100\n",
      "397/397 [==============================] - 14s 34ms/step - loss: 0.0446 - accuracy: 0.9912 - val_loss: 0.1570 - val_accuracy: 0.9701 - lr: 2.7726e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.5087341028087645e-06.\n",
      "Epoch 100/100\n",
      "397/397 [==============================] - 14s 35ms/step - loss: 0.0445 - accuracy: 0.9914 - val_loss: 0.1583 - val_accuracy: 0.9702 - lr: 2.5087e-06\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Intial learning rate\n",
    "initial_learning_rate = 0.05\n",
    "max_time_steps = 109\n",
    "\n",
    "def create_model(num_filters=32, kernel_size=(3, 3), reg_strength=0.01, batch_size=32):\n",
    "    model = tf.keras.Sequential([\n",
    "        Conv2D(num_filters, kernel_size=kernel_size, activation='relu', input_shape=(N_MFCC, max_time_steps, 1),\n",
    "               kernel_regularizer=l2(reg_strength)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(num_filters * 2, kernel_size=kernel_size, activation='relu', kernel_regularizer=l2(reg_strength)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(reg_strength)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.7),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "param_grid = {\n",
    "    'num_filters': [32, 64],\n",
    "    'kernel_size': [(3, 3), (4, 4)],\n",
    "    'reg_strength': [0.01, 0.001],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, verbose=1)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "grid_search_result = grid_search.fit(np.expand_dims(X_train_normalized, -1), y_train, \n",
    "                                     validation_data=(np.expand_dims(X_dev_normalized, -1), y_dev),class_weight=class_weight_dict, callbacks = [lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_params \u001b[39m=\u001b[39m grid_search_result\u001b[39m.\u001b[39mbest_params_\n\u001b[1;32m      2\u001b[0m best_model \u001b[39m=\u001b[39m grid_search_result\u001b[39m.\u001b[39mbest_estimator_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search_result' is not defined"
     ]
    }
   ],
   "source": [
    "best_params = grid_search_result.best_params_\n",
    "best_model = grid_search_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'kernel_size': (4, 4), 'num_filters': 64, 'reg_strength': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)\n",
    "\n",
    "#{'batch_size': 64, 'kernel_size': (4, 4), 'num_filters': 64, 'reg_strength': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([1662.33402205, 1654.84170667, 1402.85460997, 1403.65441298,\n",
      "       1624.74258184, 1629.65203126, 1348.17692097, 1351.70187958,\n",
      "       1082.1031696 , 1034.7342871 ,  984.82633328,  976.41651829,\n",
      "        880.97306832,  961.86274385, 1021.9291664 , 1017.83712419]), 'std_fit_time': array([ 4.51824293,  3.29657431,  3.57456357, 10.21849168, 15.31750725,\n",
      "        6.72662691, 12.59992584,  4.73628866, 23.75635503,  3.17788303,\n",
      "        2.15438085, 13.7859982 ,  8.84969834, 15.69572828, 10.29709316,\n",
      "        3.94546895]), 'mean_score_time': array([1.86704612, 1.83888117, 2.27609364, 2.30669308, 1.88249787,\n",
      "       1.87398601, 2.18774827, 2.19455886, 1.73755201, 1.66202696,\n",
      "       2.06634951, 2.08076374, 1.60978826, 1.70388436, 2.00321142,\n",
      "       2.01202027]), 'std_score_time': array([0.01435269, 0.03318501, 0.05257543, 0.02826533, 0.02497987,\n",
      "       0.02917202, 0.04712168, 0.06872545, 0.11372505, 0.0254075 ,\n",
      "       0.01245738, 0.06714681, 0.00614593, 0.04806509, 0.01910582,\n",
      "       0.01294078]), 'param_batch_size': masked_array(data=[32, 32, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64,\n",
      "                   64, 64],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_kernel_size': masked_array(data=[(3, 3), (3, 3), (3, 3), (3, 3), (4, 4), (4, 4), (4, 4),\n",
      "                   (4, 4), (3, 3), (3, 3), (3, 3), (3, 3), (4, 4), (4, 4),\n",
      "                   (4, 4), (4, 4)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_num_filters': masked_array(data=[32, 32, 64, 64, 32, 32, 64, 64, 32, 32, 64, 64, 32, 32,\n",
      "                   64, 64],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_reg_strength': masked_array(data=[0.01, 0.001, 0.01, 0.001, 0.01, 0.001, 0.01, 0.001,\n",
      "                   0.01, 0.001, 0.01, 0.001, 0.01, 0.001, 0.01, 0.001],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'batch_size': 32, 'kernel_size': (3, 3), 'num_filters': 32, 'reg_strength': 0.01}, {'batch_size': 32, 'kernel_size': (3, 3), 'num_filters': 32, 'reg_strength': 0.001}, {'batch_size': 32, 'kernel_size': (3, 3), 'num_filters': 64, 'reg_strength': 0.01}, {'batch_size': 32, 'kernel_size': (3, 3), 'num_filters': 64, 'reg_strength': 0.001}, {'batch_size': 32, 'kernel_size': (4, 4), 'num_filters': 32, 'reg_strength': 0.01}, {'batch_size': 32, 'kernel_size': (4, 4), 'num_filters': 32, 'reg_strength': 0.001}, {'batch_size': 32, 'kernel_size': (4, 4), 'num_filters': 64, 'reg_strength': 0.01}, {'batch_size': 32, 'kernel_size': (4, 4), 'num_filters': 64, 'reg_strength': 0.001}, {'batch_size': 64, 'kernel_size': (3, 3), 'num_filters': 32, 'reg_strength': 0.01}, {'batch_size': 64, 'kernel_size': (3, 3), 'num_filters': 32, 'reg_strength': 0.001}, {'batch_size': 64, 'kernel_size': (3, 3), 'num_filters': 64, 'reg_strength': 0.01}, {'batch_size': 64, 'kernel_size': (3, 3), 'num_filters': 64, 'reg_strength': 0.001}, {'batch_size': 64, 'kernel_size': (4, 4), 'num_filters': 32, 'reg_strength': 0.01}, {'batch_size': 64, 'kernel_size': (4, 4), 'num_filters': 32, 'reg_strength': 0.001}, {'batch_size': 64, 'kernel_size': (4, 4), 'num_filters': 64, 'reg_strength': 0.01}, {'batch_size': 64, 'kernel_size': (4, 4), 'num_filters': 64, 'reg_strength': 0.001}], 'split0_test_score': array([0.93817967, 0.95059102, 0.95094563, 0.95118203, 0.95307329,\n",
      "       0.97423168, 0.9644208 , 0.98392435, 0.96406619, 0.96489362,\n",
      "       0.96347518, 0.97695035, 0.94893617, 0.98498818, 0.98463357,\n",
      "       0.98605201]), 'split1_test_score': array([0.94160757, 0.9534279 , 0.9463357 , 0.95862884, 0.93794326,\n",
      "       0.94444444, 0.95638298, 0.97352246, 0.94219858, 0.96572104,\n",
      "       0.96052009, 0.96146572, 0.95248227, 0.9858156 , 0.96205674,\n",
      "       0.98286052]), 'split2_test_score': array([0.91855792, 0.94893617, 0.93156028, 0.96501182, 0.92210402,\n",
      "       0.97352246, 0.97033097, 0.97541371, 0.94243499, 0.9748227 ,\n",
      "       0.95543735, 0.97399527, 0.95957447, 0.97600473, 0.97009456,\n",
      "       0.98049645]), 'mean_test_score': array([0.93278172, 0.95098503, 0.9429472 , 0.95827423, 0.93770686,\n",
      "       0.96406619, 0.96371158, 0.97762017, 0.94956659, 0.96847912,\n",
      "       0.95981087, 0.97080378, 0.9536643 , 0.9822695 , 0.97226162,\n",
      "       0.98313633]), 'std_test_score': array([0.01015464, 0.00185478, 0.00826879, 0.00565155, 0.01264426,\n",
      "       0.01387769, 0.00571628, 0.0045241 , 0.01025322, 0.00449829,\n",
      "       0.00331953, 0.00671231, 0.00442276, 0.00444273, 0.00934346,\n",
      "       0.00227642]), 'rank_test_score': array([16, 12, 14, 10, 15,  7,  8,  3, 13,  6,  9,  5, 11,  2,  4,  1],\n",
      "      dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "results = grid_search_result.cv_results_\n",
    "print(results)\n",
    "\n",
    "import json\n",
    "\n",
    "# Convert NumPy arrays to lists\n",
    "for key, value in results.items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        results[key] = value.tolist()\n",
    "\n",
    "with open('grid_search_results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"mean_fit_time\": [1662.3340220451355, 1654.8417066733043, 1402.854609966278, 1403.654412984848, 1624.7425818443298, 1629.6520312627156, 1348.176920970281,\n",
    "                             1351.7018795808156, 1082.103169600169, 1034.734287103017, 984.826333284378, 976.4165182908376, 880.9730683167776, 961.8627438545227, \n",
    "                             1021.929166396459, 1017.8371241887411], \n",
    "           \"std_fit_time\": [4.5182429333903205, 3.2965743087957766, 3.5745635667112143, 10.218491680826542, 15.317507253004887, 6.726626912579431, 12.599925835039512, \n",
    "                            4.736288656271523, 23.756355031037664, 3.1778830303514978, 2.1543808522268764, 13.785998200726961, 8.849698338380348, 15.695728278467966, \n",
    "                            10.29709316284437, 3.9454689527064954], \n",
    "           \"mean_score_time\": [1.8670461177825928, 1.8388811747233074, 2.2760936419169107, 2.3066930770874023, 1.8824978669484456, 1.873986005783081, 2.1877482732137046, \n",
    "                               2.19455885887146, 1.737552007039388, 1.6620269616444905, 2.066349506378174, 2.0807637373606362, 1.6097882588704426, 1.7038843631744385, \n",
    "                               2.003211418787638, 2.0120202700297036], \n",
    "           \"std_score_time\": [0.014352686802111846, 0.03318501356609282, 0.05257542715488204, 0.02826533248094351, 0.024979874593309456, 0.029172024987784047,\n",
    "                              0.0471216777907646, 0.06872544606114345, 0.113725053176864, 0.02540750362440959, 0.012457380113795902, 0.06714681285671516, 0.006145925063693268, \n",
    "                              0.04806509017501242, 0.019105824654631183, 0.012940778003135632], \n",
    "           \"param_batch_size\": [32, 32, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64, 64, 64], \n",
    "           \"param_kernel_size\": [[3, 3], [3, 3], [3, 3], [3, 3], [4, 4], [4, 4], [4, 4], [4, 4], [3, 3], [3, 3], [3, 3], [3, 3], [4, 4], [4, 4], [4, 4], [4, 4]], \n",
    "           \"param_num_filters\": [32, 32, 64, 64, 32, 32, 64, 64, 32, 32, 64, 64, 32, 32, 64, 64], \n",
    "           \"param_reg_strength\": [0.01, 0.001, 0.01, 0.001, 0.01, 0.001, 0.01, 0.001, 0.01, 0.001, 0.01, 0.001, 0.01, 0.001, 0.01, 0.001], \n",
    "           \n",
    "           \"params\": [{\"batch_size\": 32, \"kernel_size\": [3, 3], \"num_filters\": 32, \"reg_strength\": 0.01}, {\"batch_size\": 32, \"kernel_size\": [3, 3], \"num_filters\": 32, \"reg_strength\": 0.001},\n",
    "                      {\"batch_size\": 32, \"kernel_size\": [3, 3], \"num_filters\": 64, \"reg_strength\": 0.01}, {\"batch_size\": 32, \"kernel_size\": [3, 3], \"num_filters\": 64, \"reg_strength\": 0.001},\n",
    "                      {\"batch_size\": 32, \"kernel_size\": [4, 4], \"num_filters\": 32, \"reg_strength\": 0.01}, {\"batch_size\": 32, \"kernel_size\": [4, 4], \"num_filters\": 32, \"reg_strength\": 0.001}, \n",
    "                      {\"batch_size\": 32, \"kernel_size\": [4, 4], \"num_filters\": 64, \"reg_strength\": 0.01}, {\"batch_size\": 32, \"kernel_size\": [4, 4], \"num_filters\": 64, \"reg_strength\": 0.001},\n",
    "                      {\"batch_size\": 64, \"kernel_size\": [3, 3], \"num_filters\": 32, \"reg_strength\": 0.01}, {\"batch_size\": 64, \"kernel_size\": [3, 3], \"num_filters\": 32, \"reg_strength\": 0.001}, \n",
    "                      {\"batch_size\": 64, \"kernel_size\": [3, 3], \"num_filters\": 64, \"reg_strength\": 0.01}, {\"batch_size\": 64, \"kernel_size\": [3, 3], \"num_filters\": 64, \"reg_strength\": 0.001}, \n",
    "                      {\"batch_size\": 64, \"kernel_size\": [4, 4], \"num_filters\": 32, \"reg_strength\": 0.01}, {\"batch_size\": 64, \"kernel_size\": [4, 4], \"num_filters\": 32, \"reg_strength\": 0.001}, \n",
    "                      {\"batch_size\": 64, \"kernel_size\": [4, 4], \"num_filters\": 64, \"reg_strength\": 0.01}, {\"batch_size\": 64, \"kernel_size\": [4, 4], \"num_filters\": 64, \"reg_strength\": 0.001}], \n",
    "           \n",
    "           \"split0_test_score\": [0.9381796690307329, 0.9505910165484633, 0.9509456264775413, 0.9511820330969267, 0.9530732860520095, 0.9742316784869977, 0.9644208037825059, 0.9839243498817967, \n",
    "                                 0.9640661938534278, 0.9648936170212766, 0.9634751773049646, 0.9769503546099291, 0.948936170212766, 0.9849881796690307, 0.9846335697399528, 0.9860520094562648], \n",
    "           \"split1_test_score\": [0.9416075650118203, 0.9534278959810875, 0.9463356973995272, 0.958628841607565, 0.9379432624113475, 0.9444444444444444, 0.9563829787234043, 0.9735224586288416, \n",
    "                                 0.9421985815602837, 0.9657210401891253, 0.9605200945626478, 0.9614657210401891, 0.9524822695035461, 0.9858156028368794, 0.9620567375886525, 0.9828605200945626], \n",
    "           \"split2_test_score\": [0.9185579196217494, 0.948936170212766, 0.9315602836879433, 0.9650118203309692, 0.9221040189125296, 0.9735224586288416, 0.9703309692671395, 0.9754137115839243, \n",
    "                                 0.942434988179669, 0.974822695035461, 0.9554373522458629, 0.9739952718676123, 0.9595744680851064, 0.9760047281323877, 0.9700945626477542, 0.9804964539007093], \n",
    "           \"mean_test_score\": [0.9327817178881008, 0.9509850275807722, 0.9429472025216706, 0.958274231678487, 0.9377068557919621, 0.9640661938534278, 0.9637115839243499, 0.9776201733648543, \n",
    "                               0.9495665878644601, 0.9684791174152876, 0.9598108747044917, 0.9708037825059103, 0.9536643026004729, 0.9822695035460992, 0.9722616233254531, 0.9831363278171789], \n",
    "           \"std_test_score\": [0.010154635905361533, 0.0018547836557824598, 0.008268788783552288, 0.0056515522874145945, 0.01264425542440477, 0.013877692786230902, 0.005716284029415947, \n",
    "                              0.0045240977444940406, 0.010253223961236218, 0.004498287825535892, 0.0033195283325178192, 0.0067123107028142755, 0.004422762868527104, 0.004442725553295487,\n",
    "                              0.009343463008350381, 0.002276415575359222], \n",
    "           \"rank_test_score\": [16, 12, 14, 10, 15, 7, 8, 3, 13, 6, 9, 5, 11, 2, 4, 1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'results' is a list of dictionaries, one for each combination\n",
    "# Each dictionary contains the results for that combination\n",
    "\n",
    "# Create a grid of subplots (4x4 grid for 16 combinations)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Iterate through the combinations and create a plot for each one\n",
    "for i, combination_results in enumerate(results):\n",
    "    row, col = divmod(i, 4)  # Calculate the row and column for the subplot\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Extract the data you want to visualize from the combination_results dictionary\n",
    "    # You can customize this part based on your specific data structure\n",
    "    x_data = combination_results['x_data']\n",
    "    y_data = combination_results['y_data']\n",
    "    \n",
    "    # Create a plot for this combination\n",
    "    ax.plot(x_data, y_data)\n",
    "    ax.set_title(f'Combination {i + 1}')\n",
    "    ax.set_xlabel('X-Axis Label')\n",
    "    ax.set_ylabel('Y-Axis Label')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'results' is a 2D grid of results\n",
    "# It should be in the format of a list of lists or a NumPy array\n",
    "# For example:\n",
    "# results = [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]]\n",
    "\n",
    "# Create a heatmap\n",
    "sns.heatmap(results, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "\n",
    "# Add labels to the axes if needed\n",
    "plt.xlabel('Parameter 1')\n",
    "plt.ylabel('Parameter 2')\n",
    "\n",
    "# Show the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6044542193412781\n",
      "Test Accuracy: 0.8258208632469177\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "y_test_pred_thresholded = (y_test_pred > 0.9).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 2.3396 - accuracy: 0.8350 - val_loss: 1.2712 - val_accuracy: 0.8924\n",
      "Epoch 2/5\n",
      "635/635 [==============================] - 9s 15ms/step - loss: 1.0501 - accuracy: 0.8788 - val_loss: 0.8246 - val_accuracy: 0.8920\n",
      "Epoch 3/5\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.6944 - accuracy: 0.9064 - val_loss: 0.5629 - val_accuracy: 0.9370\n",
      "Epoch 4/5\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.4819 - accuracy: 0.9306 - val_loss: 0.3914 - val_accuracy: 0.9444\n",
      "Epoch 5/5\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.3815 - accuracy: 0.9375 - val_loss: 0.5153 - val_accuracy: 0.8652\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.5448 - accuracy: 0.8664\n",
      "Test Loss: 0.5448422431945801\n",
      "Test Accuracy: 0.8664302825927734\n",
      "Epoch 1/7\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 1.9835 - accuracy: 0.8247 - val_loss: 1.0394 - val_accuracy: 0.9043\n",
      "Epoch 2/7\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.8825 - accuracy: 0.8755 - val_loss: 0.6136 - val_accuracy: 0.9346\n",
      "Epoch 3/7\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.5692 - accuracy: 0.9019 - val_loss: 0.5312 - val_accuracy: 0.8700\n",
      "Epoch 4/7\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.4007 - accuracy: 0.9257 - val_loss: 0.4518 - val_accuracy: 0.8940\n",
      "Epoch 5/7\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.3314 - accuracy: 0.9290 - val_loss: 0.2175 - val_accuracy: 0.9760\n",
      "Epoch 6/7\n",
      "635/635 [==============================] - 9s 15ms/step - loss: 0.2759 - accuracy: 0.9435 - val_loss: 0.2302 - val_accuracy: 0.9630\n",
      "Epoch 7/7\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2582 - accuracy: 0.9453 - val_loss: 0.1915 - val_accuracy: 0.9728\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1981 - accuracy: 0.9669\n",
      "Test Loss: 0.19813142716884613\n",
      "Test Accuracy: 0.9669030904769897\n",
      "Epoch 1/9\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 2.0534 - accuracy: 0.8191 - val_loss: 1.1348 - val_accuracy: 0.8830\n",
      "Epoch 2/9\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.9210 - accuracy: 0.8851 - val_loss: 0.6732 - val_accuracy: 0.9310\n",
      "Epoch 3/9\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.5842 - accuracy: 0.9243 - val_loss: 0.5790 - val_accuracy: 0.8964\n",
      "Epoch 4/9\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.4250 - accuracy: 0.9359 - val_loss: 0.4164 - val_accuracy: 0.9121\n",
      "Epoch 5/9\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.3396 - accuracy: 0.9386 - val_loss: 0.2328 - val_accuracy: 0.9764\n",
      "Epoch 6/9\n",
      "635/635 [==============================] - 9s 15ms/step - loss: 0.2777 - accuracy: 0.9454 - val_loss: 0.2332 - val_accuracy: 0.9578\n",
      "Epoch 7/9\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2575 - accuracy: 0.9487 - val_loss: 0.2356 - val_accuracy: 0.9586\n",
      "Epoch 8/9\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2498 - accuracy: 0.9451 - val_loss: 0.2188 - val_accuracy: 0.9574\n",
      "Epoch 9/9\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2435 - accuracy: 0.9436 - val_loss: 0.1855 - val_accuracy: 0.9756\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1933 - accuracy: 0.9712\n",
      "Test Loss: 0.19333580136299133\n",
      "Test Accuracy: 0.9712371826171875\n",
      "Epoch 1/10\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 1.9605 - accuracy: 0.8287 - val_loss: 0.9813 - val_accuracy: 0.9322\n",
      "Epoch 2/10\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.8126 - accuracy: 0.8914 - val_loss: 0.5301 - val_accuracy: 0.9630\n",
      "Epoch 3/10\n",
      "635/635 [==============================] - 9s 14ms/step - loss: 0.5179 - accuracy: 0.9087 - val_loss: 0.4311 - val_accuracy: 0.9409\n",
      "Epoch 4/10\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.3764 - accuracy: 0.9217 - val_loss: 0.2295 - val_accuracy: 0.9838\n",
      "Epoch 5/10\n",
      "635/635 [==============================] - 9s 15ms/step - loss: 0.2888 - accuracy: 0.9371 - val_loss: 0.2052 - val_accuracy: 0.9716\n",
      "Epoch 6/10\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2894 - accuracy: 0.9206 - val_loss: 0.2712 - val_accuracy: 0.9287\n",
      "Epoch 7/10\n",
      "635/635 [==============================] - 9s 14ms/step - loss: 0.2684 - accuracy: 0.9309 - val_loss: 0.2067 - val_accuracy: 0.9815\n",
      "Epoch 8/10\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2580 - accuracy: 0.9403 - val_loss: 0.1623 - val_accuracy: 0.9827\n",
      "Epoch 9/10\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2311 - accuracy: 0.9483 - val_loss: 0.2513 - val_accuracy: 0.9476\n",
      "Epoch 10/10\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2278 - accuracy: 0.9507 - val_loss: 0.1495 - val_accuracy: 0.9799\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1724 - accuracy: 0.9724\n",
      "Test Loss: 0.17238442599773407\n",
      "Test Accuracy: 0.9724192023277283\n",
      "Epoch 1/11\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 2.0147 - accuracy: 0.8347 - val_loss: 1.0669 - val_accuracy: 0.9208\n",
      "Epoch 2/11\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.8814 - accuracy: 0.8889 - val_loss: 0.6756 - val_accuracy: 0.8842\n",
      "Epoch 3/11\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.5535 - accuracy: 0.9112 - val_loss: 0.5991 - val_accuracy: 0.8503\n",
      "Epoch 4/11\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.4077 - accuracy: 0.9229 - val_loss: 0.3243 - val_accuracy: 0.9401\n",
      "Epoch 5/11\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.3223 - accuracy: 0.9337 - val_loss: 0.2416 - val_accuracy: 0.9697\n",
      "Epoch 6/11\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2744 - accuracy: 0.9425 - val_loss: 0.1891 - val_accuracy: 0.9850\n",
      "Epoch 7/11\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2721 - accuracy: 0.9443 - val_loss: 0.1881 - val_accuracy: 0.9866\n",
      "Epoch 8/11\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2411 - accuracy: 0.9480 - val_loss: 0.1905 - val_accuracy: 0.9771\n",
      "Epoch 9/11\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2345 - accuracy: 0.9508 - val_loss: 0.2260 - val_accuracy: 0.9618\n",
      "Epoch 10/11\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2327 - accuracy: 0.9505 - val_loss: 0.1502 - val_accuracy: 0.9827\n",
      "Epoch 11/11\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2330 - accuracy: 0.9489 - val_loss: 0.1612 - val_accuracy: 0.9846\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1862 - accuracy: 0.9673\n",
      "Test Loss: 0.18624095618724823\n",
      "Test Accuracy: 0.9672970771789551\n",
      "Epoch 1/13\n",
      "635/635 [==============================] - 10s 16ms/step - loss: 1.9643 - accuracy: 0.8333 - val_loss: 1.0963 - val_accuracy: 0.8656\n",
      "Epoch 2/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.8366 - accuracy: 0.8925 - val_loss: 0.7492 - val_accuracy: 0.8719\n",
      "Epoch 3/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.5606 - accuracy: 0.8999 - val_loss: 0.4348 - val_accuracy: 0.9267\n",
      "Epoch 4/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.4118 - accuracy: 0.9152 - val_loss: 0.3599 - val_accuracy: 0.9039\n",
      "Epoch 5/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.3218 - accuracy: 0.9250 - val_loss: 0.3523 - val_accuracy: 0.8913\n",
      "Epoch 6/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.3054 - accuracy: 0.9264 - val_loss: 0.3599 - val_accuracy: 0.9117\n",
      "Epoch 7/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2630 - accuracy: 0.9427 - val_loss: 0.4477 - val_accuracy: 0.8617\n",
      "Epoch 8/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2593 - accuracy: 0.9331 - val_loss: 0.3214 - val_accuracy: 0.9153\n",
      "Epoch 9/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2283 - accuracy: 0.9476 - val_loss: 0.1757 - val_accuracy: 0.9748\n",
      "Epoch 10/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2257 - accuracy: 0.9425 - val_loss: 0.1950 - val_accuracy: 0.9543\n",
      "Epoch 11/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2446 - accuracy: 0.9300 - val_loss: 0.2720 - val_accuracy: 0.9086\n",
      "Epoch 12/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2522 - accuracy: 0.9315 - val_loss: 0.2105 - val_accuracy: 0.9657\n",
      "Epoch 13/13\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2209 - accuracy: 0.9478 - val_loss: 0.2304 - val_accuracy: 0.9397\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2408 - accuracy: 0.9338\n",
      "Test Loss: 0.2408178448677063\n",
      "Test Accuracy: 0.9338061213493347\n",
      "Epoch 1/15\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 1.8645 - accuracy: 0.8377 - val_loss: 0.9681 - val_accuracy: 0.9307\n",
      "Epoch 2/15\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.8176 - accuracy: 0.8880 - val_loss: 0.6330 - val_accuracy: 0.8783\n",
      "Epoch 3/15\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.5170 - accuracy: 0.9081 - val_loss: 0.3461 - val_accuracy: 0.9673\n",
      "Epoch 4/15\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.3854 - accuracy: 0.9202 - val_loss: 0.3055 - val_accuracy: 0.9460\n",
      "Epoch 5/15\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.3150 - accuracy: 0.9214 - val_loss: 0.2646 - val_accuracy: 0.9693\n",
      "Epoch 6/15\n",
      "635/635 [==============================] - 9s 15ms/step - loss: 0.2725 - accuracy: 0.9283 - val_loss: 0.2443 - val_accuracy: 0.9346\n",
      "Epoch 7/15\n",
      "635/635 [==============================] - 9s 15ms/step - loss: 0.2577 - accuracy: 0.9269 - val_loss: 0.2437 - val_accuracy: 0.9362\n",
      "Epoch 8/15\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2541 - accuracy: 0.9305 - val_loss: 0.2676 - val_accuracy: 0.9247\n",
      "Epoch 9/15\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2368 - accuracy: 0.9341 - val_loss: 0.1910 - val_accuracy: 0.9756\n",
      "Epoch 10/15\n",
      "635/635 [==============================] - 9s 15ms/step - loss: 0.2278 - accuracy: 0.9353 - val_loss: 0.1570 - val_accuracy: 0.9716\n",
      "Epoch 11/15\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2360 - accuracy: 0.9361 - val_loss: 0.2105 - val_accuracy: 0.9567\n",
      "Epoch 12/15\n",
      "635/635 [==============================] - 9s 15ms/step - loss: 0.2217 - accuracy: 0.9406 - val_loss: 0.1792 - val_accuracy: 0.9641\n",
      "Epoch 13/15\n",
      "635/635 [==============================] - 10s 15ms/step - loss: 0.2179 - accuracy: 0.9413 - val_loss: 0.1795 - val_accuracy: 0.9712\n",
      "Epoch 14/15\n",
      "635/635 [==============================] - 9s 15ms/step - loss: 0.2196 - accuracy: 0.9397 - val_loss: 0.2558 - val_accuracy: 0.9165\n",
      "Epoch 15/15\n",
      "635/635 [==============================] - 9s 15ms/step - loss: 0.2128 - accuracy: 0.9408 - val_loss: 0.1942 - val_accuracy: 0.9444\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.9456\n",
      "Test Loss: 0.19771648943424225\n",
      "Test Accuracy: 0.9456264972686768\n"
     ]
    }
   ],
   "source": [
    "#epoch experiment\n",
    "from sklearn.utils import shuffle\n",
    "# Shuffle the training data\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "# Shuffle the validation data (if needed)\n",
    "X_validation, y_validation = shuffle(X_val, y_val, random_state=42)\n",
    "\n",
    "# Shuffle the test data\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = [5, 7, 9, 10,11,13,15]\n",
    "num_batch_size = 32 #number of features to train at once\n",
    "\n",
    "#Find the best epoch\n",
    "for epoch in num_epochs:\n",
    "\n",
    "    # Define and compile a CNN model with L2 regularization and other improvements\n",
    "    model = tf.keras.Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(N_MFCC, max_time_steps, 1),\n",
    "            kernel_regularizer=l2(0.01)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # Train the model using class weights\n",
    "    history = model.fit(np.expand_dims(X_train, -1), y_train, batch_size=num_batch_size, epochs=epoch,\n",
    "                    validation_data=(np.expand_dims(X_val, -1), y_val), class_weight=class_weight_dict)\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(np.expand_dims(X_test, -1), y_test)\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch vs acurracy (without feature and batch normalization)\n",
    "\n",
    "Epoch 5\n",
    "Test Loss: 0.5448422431945801\n",
    "Test Accuracy: 0.8664302825927734\n",
    "\n",
    "Epoch 7\n",
    "Test Loss: 0.19813142716884613\n",
    "Test Accuracy: 0.9669030904769897\n",
    "\n",
    "Epcoh 9\n",
    "Test Loss: 0.19333580136299133\n",
    "Test Accuracy: 0.9712371826171875\n",
    "\n",
    "Epoch 10\n",
    "Test Loss: 0.17238442599773407\n",
    "Test Accuracy: 0.9724192023277283\n",
    "\n",
    "Epoch 11\n",
    "Test Loss: 0.18624095618724823\n",
    "Test Accuracy: 0.9672970771789551\n",
    "\n",
    "Epoch 13\n",
    "Test Loss: 0.2408178448677063\n",
    "Test Accuracy: 0.9338061213493347\n",
    "\n",
    "Epoch 15\n",
    "Test Loss: 0.19771648943424225\n",
    "Test Accuracy: 0.9456264972686768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_thresholded = (y_test_pred > 0.9).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22842\n",
      "22842\n",
      "X_train_fold shape: (20557, 13, 109)\n",
      "y_train_fold shape: (20557,)\n",
      "Epoch 1/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 1.8626 - accuracy: 0.8300 - val_loss: 1.1709 - val_accuracy: 0.8083\n",
      "Epoch 2/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.7492 - accuracy: 0.8818 - val_loss: 0.5604 - val_accuracy: 0.9208\n",
      "Epoch 3/10\n",
      "643/643 [==============================] - 7s 11ms/step - loss: 0.5288 - accuracy: 0.8948 - val_loss: 0.3788 - val_accuracy: 0.9427\n",
      "Epoch 4/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.3788 - accuracy: 0.9239 - val_loss: 0.3242 - val_accuracy: 0.9606\n",
      "Epoch 5/10\n",
      "643/643 [==============================] - 5s 9ms/step - loss: 0.3099 - accuracy: 0.9430 - val_loss: 0.2281 - val_accuracy: 0.9698\n",
      "Epoch 6/10\n",
      "643/643 [==============================] - 7s 11ms/step - loss: 0.2805 - accuracy: 0.9433 - val_loss: 0.2415 - val_accuracy: 0.9545\n",
      "Epoch 7/10\n",
      "643/643 [==============================] - 7s 10ms/step - loss: 0.2755 - accuracy: 0.9447 - val_loss: 0.6546 - val_accuracy: 0.8534\n",
      "Epoch 8/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2576 - accuracy: 0.9453 - val_loss: 0.2112 - val_accuracy: 0.9742\n",
      "Epoch 9/10\n",
      "643/643 [==============================] - 5s 9ms/step - loss: 0.2289 - accuracy: 0.9548 - val_loss: 0.2309 - val_accuracy: 0.9532\n",
      "Epoch 10/10\n",
      "643/643 [==============================] - 8s 13ms/step - loss: 0.2434 - accuracy: 0.9499 - val_loss: 0.1666 - val_accuracy: 0.9794\n",
      "80/80 [==============================] - 0s 5ms/step\n",
      "X_train_fold shape: (20557, 13, 109)\n",
      "y_train_fold shape: (20557,)\n",
      "Epoch 1/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 1.8763 - accuracy: 0.8369 - val_loss: 0.8994 - val_accuracy: 0.9414\n",
      "Epoch 2/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.7326 - accuracy: 0.9077 - val_loss: 0.4935 - val_accuracy: 0.9584\n",
      "Epoch 3/10\n",
      "643/643 [==============================] - 9s 15ms/step - loss: 0.4808 - accuracy: 0.9166 - val_loss: 0.3507 - val_accuracy: 0.9554\n",
      "Epoch 4/10\n",
      "643/643 [==============================] - 9s 15ms/step - loss: 0.3527 - accuracy: 0.9308 - val_loss: 0.5641 - val_accuracy: 0.8512\n",
      "Epoch 5/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.3007 - accuracy: 0.9330 - val_loss: 0.4986 - val_accuracy: 0.8560\n",
      "Epoch 6/10\n",
      "643/643 [==============================] - 9s 15ms/step - loss: 0.2949 - accuracy: 0.9298 - val_loss: 0.1988 - val_accuracy: 0.9755\n",
      "Epoch 7/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.2472 - accuracy: 0.9440 - val_loss: 0.1946 - val_accuracy: 0.9641\n",
      "Epoch 8/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.2300 - accuracy: 0.9506 - val_loss: 0.1868 - val_accuracy: 0.9716\n",
      "Epoch 9/10\n",
      "643/643 [==============================] - 9s 15ms/step - loss: 0.2161 - accuracy: 0.9542 - val_loss: 0.1750 - val_accuracy: 0.9768\n",
      "Epoch 10/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.2142 - accuracy: 0.9541 - val_loss: 0.1477 - val_accuracy: 0.9864\n",
      "80/80 [==============================] - 0s 5ms/step\n",
      "X_train_fold shape: (20558, 13, 109)\n",
      "y_train_fold shape: (20558,)\n",
      "Epoch 1/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 1.8884 - accuracy: 0.8265 - val_loss: 1.1730 - val_accuracy: 0.8533\n",
      "Epoch 2/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.8434 - accuracy: 0.8864 - val_loss: 0.7679 - val_accuracy: 0.8525\n",
      "Epoch 3/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.5529 - accuracy: 0.8947 - val_loss: 0.4631 - val_accuracy: 0.8892\n",
      "Epoch 4/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.4014 - accuracy: 0.9107 - val_loss: 0.3574 - val_accuracy: 0.9247\n",
      "Epoch 5/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.3330 - accuracy: 0.9170 - val_loss: 0.2884 - val_accuracy: 0.9282\n",
      "Epoch 6/10\n",
      "643/643 [==============================] - 9s 14ms/step - loss: 0.2896 - accuracy: 0.9233 - val_loss: 0.1843 - val_accuracy: 0.9799\n",
      "Epoch 7/10\n",
      "643/643 [==============================] - 9s 14ms/step - loss: 0.2685 - accuracy: 0.9327 - val_loss: 0.2560 - val_accuracy: 0.9505\n",
      "Epoch 8/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.2566 - accuracy: 0.9382 - val_loss: 0.2911 - val_accuracy: 0.9116\n",
      "Epoch 9/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.2328 - accuracy: 0.9491 - val_loss: 0.2836 - val_accuracy: 0.9247\n",
      "Epoch 10/10\n",
      "643/643 [==============================] - 9s 14ms/step - loss: 0.2295 - accuracy: 0.9472 - val_loss: 0.1944 - val_accuracy: 0.9593\n",
      "80/80 [==============================] - 0s 5ms/step\n",
      "X_train_fold shape: (20558, 13, 109)\n",
      "y_train_fold shape: (20558,)\n",
      "Epoch 1/10\n",
      "643/643 [==============================] - 9s 14ms/step - loss: 2.0171 - accuracy: 0.8341 - val_loss: 1.2087 - val_accuracy: 0.8568\n",
      "Epoch 2/10\n",
      "643/643 [==============================] - 9s 15ms/step - loss: 0.9374 - accuracy: 0.8792 - val_loss: 0.7203 - val_accuracy: 0.9024\n",
      "Epoch 3/10\n",
      "643/643 [==============================] - 9s 14ms/step - loss: 0.5921 - accuracy: 0.9058 - val_loss: 0.4399 - val_accuracy: 0.9343\n",
      "Epoch 4/10\n",
      "643/643 [==============================] - 9s 14ms/step - loss: 0.4102 - accuracy: 0.9312 - val_loss: 0.4019 - val_accuracy: 0.9137\n",
      "Epoch 5/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.3271 - accuracy: 0.9396 - val_loss: 0.3543 - val_accuracy: 0.9273\n",
      "Epoch 6/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2864 - accuracy: 0.9449 - val_loss: 0.1982 - val_accuracy: 0.9807\n",
      "Epoch 7/10\n",
      "643/643 [==============================] - 5s 8ms/step - loss: 0.2543 - accuracy: 0.9520 - val_loss: 0.2320 - val_accuracy: 0.9742\n",
      "Epoch 8/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2516 - accuracy: 0.9491 - val_loss: 0.2317 - val_accuracy: 0.9461\n",
      "Epoch 9/10\n",
      "643/643 [==============================] - 5s 8ms/step - loss: 0.2349 - accuracy: 0.9514 - val_loss: 0.1685 - val_accuracy: 0.9785\n",
      "Epoch 10/10\n",
      "643/643 [==============================] - 7s 11ms/step - loss: 0.2278 - accuracy: 0.9508 - val_loss: 0.1600 - val_accuracy: 0.9785\n",
      "80/80 [==============================] - 1s 6ms/step\n",
      "X_train_fold shape: (20558, 13, 109)\n",
      "y_train_fold shape: (20558,)\n",
      "Epoch 1/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 2.1728 - accuracy: 0.8477 - val_loss: 1.2382 - val_accuracy: 0.8577\n",
      "Epoch 2/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.9043 - accuracy: 0.9083 - val_loss: 0.7047 - val_accuracy: 0.9256\n",
      "Epoch 3/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.6029 - accuracy: 0.9257 - val_loss: 0.4574 - val_accuracy: 0.9588\n",
      "Epoch 4/10\n",
      "643/643 [==============================] - 5s 9ms/step - loss: 0.4370 - accuracy: 0.9356 - val_loss: 0.3300 - val_accuracy: 0.9694\n",
      "Epoch 5/10\n",
      "643/643 [==============================] - 7s 11ms/step - loss: 0.3735 - accuracy: 0.9370 - val_loss: 0.3804 - val_accuracy: 0.9221\n",
      "Epoch 6/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.3091 - accuracy: 0.9430 - val_loss: 0.3061 - val_accuracy: 0.9299\n",
      "Epoch 7/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2673 - accuracy: 0.9489 - val_loss: 0.2156 - val_accuracy: 0.9729\n",
      "Epoch 8/10\n",
      "643/643 [==============================] - 5s 9ms/step - loss: 0.2735 - accuracy: 0.9439 - val_loss: 0.1853 - val_accuracy: 0.9768\n",
      "Epoch 9/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2421 - accuracy: 0.9518 - val_loss: 0.2136 - val_accuracy: 0.9588\n",
      "Epoch 10/10\n",
      "643/643 [==============================] - 7s 10ms/step - loss: 0.2276 - accuracy: 0.9535 - val_loss: 0.2240 - val_accuracy: 0.9523\n",
      "80/80 [==============================] - 1s 6ms/step\n",
      "X_train_fold shape: (20558, 13, 109)\n",
      "y_train_fold shape: (20558,)\n",
      "Epoch 1/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 2.2140 - accuracy: 0.8364 - val_loss: 1.3275 - val_accuracy: 0.8323\n",
      "Epoch 2/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.9141 - accuracy: 0.8948 - val_loss: 0.6985 - val_accuracy: 0.8993\n",
      "Epoch 3/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.5762 - accuracy: 0.9250 - val_loss: 0.4121 - val_accuracy: 0.9729\n",
      "Epoch 4/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.4062 - accuracy: 0.9423 - val_loss: 0.3156 - val_accuracy: 0.9685\n",
      "Epoch 5/10\n",
      "643/643 [==============================] - 7s 11ms/step - loss: 0.3314 - accuracy: 0.9399 - val_loss: 0.5902 - val_accuracy: 0.8682\n",
      "Epoch 6/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.3068 - accuracy: 0.9398 - val_loss: 0.2813 - val_accuracy: 0.9422\n",
      "Epoch 7/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2524 - accuracy: 0.9493 - val_loss: 0.2344 - val_accuracy: 0.9588\n",
      "Epoch 8/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2330 - accuracy: 0.9512 - val_loss: 0.2121 - val_accuracy: 0.9619\n",
      "Epoch 9/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2361 - accuracy: 0.9507 - val_loss: 0.2183 - val_accuracy: 0.9571\n",
      "Epoch 10/10\n",
      "643/643 [==============================] - 7s 11ms/step - loss: 0.2205 - accuracy: 0.9532 - val_loss: 0.1654 - val_accuracy: 0.9720\n",
      "80/80 [==============================] - 0s 5ms/step\n",
      "X_train_fold shape: (20558, 13, 109)\n",
      "y_train_fold shape: (20558,)\n",
      "Epoch 1/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 2.0217 - accuracy: 0.8285 - val_loss: 1.2818 - val_accuracy: 0.8135\n",
      "Epoch 2/10\n",
      "643/643 [==============================] - 7s 11ms/step - loss: 0.8869 - accuracy: 0.8864 - val_loss: 0.5951 - val_accuracy: 0.9641\n",
      "Epoch 3/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.5739 - accuracy: 0.9131 - val_loss: 0.4560 - val_accuracy: 0.9273\n",
      "Epoch 4/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.4013 - accuracy: 0.9330 - val_loss: 0.3042 - val_accuracy: 0.9676\n",
      "Epoch 5/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.3228 - accuracy: 0.9389 - val_loss: 0.2590 - val_accuracy: 0.9575\n",
      "Epoch 6/10\n",
      "643/643 [==============================] - 5s 8ms/step - loss: 0.2753 - accuracy: 0.9441 - val_loss: 0.2235 - val_accuracy: 0.9702\n",
      "Epoch 7/10\n",
      "643/643 [==============================] - 7s 11ms/step - loss: 0.2674 - accuracy: 0.9425 - val_loss: 0.2910 - val_accuracy: 0.9304\n",
      "Epoch 8/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2396 - accuracy: 0.9495 - val_loss: 0.3262 - val_accuracy: 0.9159\n",
      "Epoch 9/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2350 - accuracy: 0.9506 - val_loss: 0.3170 - val_accuracy: 0.9137\n",
      "Epoch 10/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2235 - accuracy: 0.9531 - val_loss: 0.2004 - val_accuracy: 0.9628\n",
      "80/80 [==============================] - 1s 6ms/step\n",
      "X_train_fold shape: (20558, 13, 109)\n",
      "y_train_fold shape: (20558,)\n",
      "Epoch 1/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 2.1517 - accuracy: 0.8407 - val_loss: 1.1994 - val_accuracy: 0.9221\n",
      "Epoch 2/10\n",
      "643/643 [==============================] - 7s 11ms/step - loss: 0.9771 - accuracy: 0.8860 - val_loss: 0.8509 - val_accuracy: 0.8752\n",
      "Epoch 3/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.6097 - accuracy: 0.9074 - val_loss: 0.4542 - val_accuracy: 0.9418\n",
      "Epoch 4/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.4248 - accuracy: 0.9179 - val_loss: 0.4554 - val_accuracy: 0.8857\n",
      "Epoch 5/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.3456 - accuracy: 0.9234 - val_loss: 0.2522 - val_accuracy: 0.9658\n",
      "Epoch 6/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2973 - accuracy: 0.9325 - val_loss: 0.2826 - val_accuracy: 0.9317\n",
      "Epoch 7/10\n",
      "643/643 [==============================] - 7s 11ms/step - loss: 0.2727 - accuracy: 0.9354 - val_loss: 0.2453 - val_accuracy: 0.9514\n",
      "Epoch 8/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.2559 - accuracy: 0.9392 - val_loss: 0.3075 - val_accuracy: 0.9173\n",
      "Epoch 9/10\n",
      "643/643 [==============================] - 7s 11ms/step - loss: 0.2437 - accuracy: 0.9406 - val_loss: 0.2897 - val_accuracy: 0.9164\n",
      "Epoch 10/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2490 - accuracy: 0.9365 - val_loss: 0.2641 - val_accuracy: 0.9282\n",
      "80/80 [==============================] - 1s 6ms/step\n",
      "X_train_fold shape: (20558, 13, 109)\n",
      "y_train_fold shape: (20558,)\n",
      "Epoch 1/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 1.8844 - accuracy: 0.8319 - val_loss: 0.9962 - val_accuracy: 0.8722\n",
      "Epoch 2/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.7724 - accuracy: 0.8980 - val_loss: 0.5623 - val_accuracy: 0.9391\n",
      "Epoch 3/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.5079 - accuracy: 0.9040 - val_loss: 0.4198 - val_accuracy: 0.9024\n",
      "Epoch 4/10\n",
      "643/643 [==============================] - 7s 10ms/step - loss: 0.3778 - accuracy: 0.9135 - val_loss: 0.2838 - val_accuracy: 0.9562\n",
      "Epoch 5/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.3201 - accuracy: 0.9235 - val_loss: 0.2973 - val_accuracy: 0.9278\n",
      "Epoch 6/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2766 - accuracy: 0.9311 - val_loss: 0.2218 - val_accuracy: 0.9676\n",
      "Epoch 7/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2560 - accuracy: 0.9345 - val_loss: 0.2149 - val_accuracy: 0.9623\n",
      "Epoch 8/10\n",
      "643/643 [==============================] - 6s 9ms/step - loss: 0.2548 - accuracy: 0.9346 - val_loss: 0.2619 - val_accuracy: 0.9374\n",
      "Epoch 9/10\n",
      "643/643 [==============================] - 8s 13ms/step - loss: 0.2451 - accuracy: 0.9394 - val_loss: 0.2603 - val_accuracy: 0.9194\n",
      "Epoch 10/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.2424 - accuracy: 0.9396 - val_loss: 0.3139 - val_accuracy: 0.9015\n",
      "80/80 [==============================] - 0s 5ms/step\n",
      "X_train_fold shape: (20558, 13, 109)\n",
      "y_train_fold shape: (20558,)\n",
      "Epoch 1/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 2.0192 - accuracy: 0.8390 - val_loss: 1.1463 - val_accuracy: 0.8792\n",
      "Epoch 2/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.8790 - accuracy: 0.8886 - val_loss: 0.6523 - val_accuracy: 0.9203\n",
      "Epoch 3/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.5636 - accuracy: 0.8973 - val_loss: 0.4132 - val_accuracy: 0.9413\n",
      "Epoch 4/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.4153 - accuracy: 0.9158 - val_loss: 0.3758 - val_accuracy: 0.9256\n",
      "Epoch 5/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.3389 - accuracy: 0.9200 - val_loss: 0.2706 - val_accuracy: 0.9523\n",
      "Epoch 6/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.3046 - accuracy: 0.9260 - val_loss: 0.2139 - val_accuracy: 0.9698\n",
      "Epoch 7/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.2743 - accuracy: 0.9338 - val_loss: 0.1987 - val_accuracy: 0.9715\n",
      "Epoch 8/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.2641 - accuracy: 0.9354 - val_loss: 0.2168 - val_accuracy: 0.9514\n",
      "Epoch 9/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.2523 - accuracy: 0.9377 - val_loss: 0.1762 - val_accuracy: 0.9724\n",
      "Epoch 10/10\n",
      "643/643 [==============================] - 10s 15ms/step - loss: 0.2445 - accuracy: 0.9423 - val_loss: 0.1982 - val_accuracy: 0.9619\n",
      "80/80 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "k = 10 # 10 fold validation\n",
    "cv = StratifiedKFold(n_splits = k, shuffle = True, random_state = 42)\n",
    "\n",
    "#Combine training, validation, and testing data\n",
    "X_combined = np.concatenate((X_train, X_val))\n",
    "y_combined = np.concatenate((y_train, y_val))\n",
    "X_combined, y_combined = shuffle(X_combined, y_combined, random_state = 42)\n",
    "print(len(X_combined))\n",
    "print(len(y_combined))\n",
    "\n",
    "#Store accuracy\n",
    "results = []\n",
    "\n",
    "#Store training and validation indices for each fold\n",
    "train_indices = []\n",
    "validation_indices = []\n",
    "\n",
    "#split the data into k folds\n",
    "for train_idx, val_idx in cv.split(X_combined, y_combined):\n",
    "    train_indices.append(train_idx)\n",
    "    validation_indices.append(val_idx)\n",
    "    \n",
    "#Perform k-fold cross-validation\n",
    "for fold in range(k):\n",
    "    train_idx = train_indices[fold]\n",
    "    val_idx = validation_indices[fold]\n",
    "    \n",
    "    X_train_fold, y_train_fold = X_combined[train_idx], y_combined[train_idx]\n",
    "    X_val_fold, y_val_fold = X_combined[val_idx], y_combined[val_idx]\n",
    "    print(\"X_train_fold shape:\", X_train_fold.shape)\n",
    "    print(\"y_train_fold shape:\", y_train_fold.shape)\n",
    "\n",
    "    \n",
    "    # y_train_encoded = to_categorical(le.fit_transform(y_train_fold))\n",
    "    # y_validation_encoded = to_categorical(le.transform(y_val_fold))\n",
    "    # print(\"X_train_fold shape:\", X_train_fold.shape)\n",
    "    # print(\"y_train_encoded shape:\", y_train_encoded.shape)\n",
    "\n",
    "   # Define and compile a CNN model with L2 regularization and other improvements\n",
    "    model = tf.keras.Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(N_MFCC, max_time_steps, 1),\n",
    "            kernel_regularizer=l2(0.01)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # Train the model using class weights\n",
    "    history = model.fit(np.expand_dims(X_train_fold, -1), y_train_fold, batch_size=32, epochs=10,\n",
    "                    validation_data=(np.expand_dims(X_val_fold, -1), y_val_fold), class_weight=class_weight_dict)\n",
    "    \n",
    "\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_thresholded = (y_test_pred > 0.9).astype(int)\n",
    "\n",
    "    # Calculate accuracy for this fold\n",
    "    fold_accuracy = accuracy_score(y_test, y_test_pred_thresholded)\n",
    "    results.append(fold_accuracy)\n",
    "\n",
    "# Calculate mean and standard deviation of accuracy scores\n",
    "mean_accuracy = np.mean(results)\n",
    "std_accuracy = np.std(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1  Accuracy:  0.9743892828999212\n",
      "Fold:  2  Accuracy:  0.9657210401891253\n",
      "Fold:  3  Accuracy:  0.9747832939322301\n",
      "Fold:  4  Accuracy:  0.9684791174152876\n",
      "Fold:  5  Accuracy:  0.9755713159968479\n",
      "Fold:  6  Accuracy:  0.9377462568951931\n",
      "Fold:  7  Accuracy:  0.9724192277383766\n",
      "Fold:  8  Accuracy:  0.9700551615445232\n",
      "Fold:  9  Accuracy:  0.9613869188337274\n",
      "Fold:  10  Accuracy:  0.9716312056737588\n",
      "Mean acuracy:  0.9672182821118991\n"
     ]
    }
   ],
   "source": [
    "#Print results from k fold cross validation\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Fold: \", i + 1, \" Accuracy: \", results[i])\n",
    "\n",
    "print(\"Mean acuracy: \", mean_accuracy)\n",
    "\n",
    "#Use this to compare performance across different models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold:  1  Accuracy:  0.9743892828999212\n",
    "Fold:  2  Accuracy:  0.9657210401891253\n",
    "Fold:  3  Accuracy:  0.9747832939322301\n",
    "Fold:  4  Accuracy:  0.9684791174152876\n",
    "Fold:  5  Accuracy:  0.9755713159968479\n",
    "Fold:  6  Accuracy:  0.9377462568951931\n",
    "Fold:  7  Accuracy:  0.9724192277383766\n",
    "Fold:  8  Accuracy:  0.9700551615445232\n",
    "Fold:  9  Accuracy:  0.9613869188337274\n",
    "Fold:  10  Accuracy:  0.9716312056737588\n",
    "Mean acuracy:  0.9672182821118991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP:  398  FN:  1\n",
      "[[1894  398]\n",
      " [   1  245]]\n",
      "FP:  297  FN:  2\n",
      "[[1995  297]\n",
      " [   2  244]]\n",
      "FP:  229  FN:  2\n",
      "[[2063  229]\n",
      " [   2  244]]\n",
      "FP:  191  FN:  6\n",
      "[[2101  191]\n",
      " [   6  240]]\n",
      "FP:  153  FN:  7\n",
      "[[2139  153]\n",
      " [   7  239]]\n",
      "FP:  121  FN:  13\n",
      "[[2171  121]\n",
      " [  13  233]]\n",
      "FP:  87  FN:  18\n",
      "[[2205   87]\n",
      " [  18  228]]\n",
      "FP:  59  FN:  23\n",
      "[[2233   59]\n",
      " [  23  223]]\n",
      "FP:  30  FN:  38\n",
      "[[2262   30]\n",
      " [  38  208]]\n"
     ]
    }
   ],
   "source": [
    "#precision/recall calculation - use 0.7 threshold for now, do not run this code unless we want to test out recall/precision\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#Store accuracy and precision/recall\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "\n",
    "#F1 scores\n",
    "fold_f1_scores = []\n",
    "fold_half_scores = []\n",
    "fold_double_scores = []\n",
    "\n",
    "import numpy as np\n",
    "# Initialize an array of threshold values (e.g., from 0.1 to 0.9)\n",
    "thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "#save confusion matrix\n",
    "fold_cm = []\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# num_epochs = 3\n",
    "# num_batch_size = 32\n",
    "\n",
    "# Train the model\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# y_train_encoded = to_categorical(le.fit_transform(y_train))\n",
    "# y_validation_encoded = to_categorical(le.transform(y_validation))\n",
    "# y_test_encoded = to_categorical(le.transform(y_test))\n",
    "\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_test_pred_thresholded = (y_test_pred > threshold).astype(int)  # Adjust the column index if needed\n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_test_pred_thresholded)\n",
    "    FP = cm[0, 1]  # False Positives\n",
    "    FN = cm[1, 0]  # False Negatives\n",
    "    \n",
    "    print(\"FP: \", FP, \" FN: \", FN)\n",
    "    print(cm)\n",
    "\n",
    "    # Calculate TP, FP, FN for the current threshold\n",
    "    precision = precision_score(y_test, y_test_pred_thresholded)\n",
    "    recall = recall_score(y_test, y_test_pred_thresholded) \n",
    "\n",
    "    # Calculate F1 score using precision and recall\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    fhalf = (1 + 0.5**2) * (precision * recall) / (0.5**2 * precision + recall) if (precision + recall) > 0 else 0\n",
    "    fdouble = (1 + 2**2) * (precision * recall) / (2**2 * precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_cm.append(cm)\n",
    "    fold_f1_scores.append(f1)\n",
    "    fold_half_scores.append(fhalf)\n",
    "    fold_double_scores.append(fdouble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0.1   Precision:  0.3810264385692068   Recall:  0.9959349593495935\n",
      "F1 Score:  0.5511811023622047 F-0.5 Score:  0.4347054648687012 F-2 Score:  [0.7529194837123541, 0.7999999999999999, 0.8373369938229238, 0.8480565371024735, 0.8684593023255814, 0.8707025411061284, 0.8775981524249424, 0.8807266982622433, 0.851063829787234]\n",
      "\n",
      "Fold 0.2   Precision:  0.4510166358595194   Recall:  0.991869918699187\n",
      "F1 Score:  0.6200762388818297 F-0.5 Score:  0.5062240663900415 F-2 Score:  [0.7529194837123541, 0.7999999999999999, 0.8373369938229238, 0.8480565371024735, 0.8684593023255814, 0.8707025411061284, 0.8775981524249424, 0.8807266982622433, 0.851063829787234]\n",
      "\n",
      "Fold 0.30000000000000004   Precision:  0.5158562367864693   Recall:  0.991869918699187\n",
      "F1 Score:  0.6787204450625869 F-0.5 Score:  0.5706267539756782 F-2 Score:  [0.7529194837123541, 0.7999999999999999, 0.8373369938229238, 0.8480565371024735, 0.8684593023255814, 0.8707025411061284, 0.8775981524249424, 0.8807266982622433, 0.851063829787234]\n",
      "\n",
      "Fold 0.4   Precision:  0.5568445475638051   Recall:  0.975609756097561\n",
      "F1 Score:  0.7090103397341211 F-0.5 Score:  0.6091370558375635 F-2 Score:  [0.7529194837123541, 0.7999999999999999, 0.8373369938229238, 0.8480565371024735, 0.8684593023255814, 0.8707025411061284, 0.8775981524249424, 0.8807266982622433, 0.851063829787234]\n",
      "\n",
      "Fold 0.5   Precision:  0.6096938775510204   Recall:  0.9715447154471545\n",
      "F1 Score:  0.749216300940439 F-0.5 Score:  0.6587651598676957 F-2 Score:  [0.7529194837123541, 0.7999999999999999, 0.8373369938229238, 0.8480565371024735, 0.8684593023255814, 0.8707025411061284, 0.8775981524249424, 0.8807266982622433, 0.851063829787234]\n",
      "\n",
      "Fold 0.6   Precision:  0.6581920903954802   Recall:  0.9471544715447154\n",
      "F1 Score:  0.7766666666666666 F-0.5 Score:  0.700962695547533 F-2 Score:  [0.7529194837123541, 0.7999999999999999, 0.8373369938229238, 0.8480565371024735, 0.8684593023255814, 0.8707025411061284, 0.8775981524249424, 0.8807266982622433, 0.851063829787234]\n",
      "\n",
      "Fold 0.7000000000000001   Precision:  0.7238095238095238   Recall:  0.926829268292683\n",
      "F1 Score:  0.8128342245989305 F-0.5 Score:  0.756972111553785 F-2 Score:  [0.7529194837123541, 0.7999999999999999, 0.8373369938229238, 0.8480565371024735, 0.8684593023255814, 0.8707025411061284, 0.8775981524249424, 0.8807266982622433, 0.851063829787234]\n",
      "\n",
      "Fold 0.8   Precision:  0.7907801418439716   Recall:  0.9065040650406504\n",
      "F1 Score:  0.8446969696969696 F-0.5 Score:  0.8114992721979621 F-2 Score:  [0.7529194837123541, 0.7999999999999999, 0.8373369938229238, 0.8480565371024735, 0.8684593023255814, 0.8707025411061284, 0.8775981524249424, 0.8807266982622433, 0.851063829787234]\n",
      "\n",
      "Fold 0.9   Precision:  0.8739495798319328   Recall:  0.8455284552845529\n",
      "F1 Score:  0.859504132231405 F-0.5 Score:  0.8681135225375626 F-2 Score:  [0.7529194837123541, 0.7999999999999999, 0.8373369938229238, 0.8480565371024735, 0.8684593023255814, 0.8707025411061284, 0.8775981524249424, 0.8807266982622433, 0.851063829787234]\n",
      "\n",
      "  Mean precision:  0.6179076746901033   Mean recall:  0.950316169828365\n",
      " Mean F1 Score:  0.7335451577972392\n",
      " Mean F-0.5 Score:  0.6574451225307247\n",
      " Mean F-0.5 Score:  0.8429848376159867\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAHFCAYAAAC90vA7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABTM0lEQVR4nO3deVxU5f4H8M+wDYgwCggDiYooikKKS4CVYhqKW6WlhpkkYrlermtqCmaC2nVJzCVTIKXUbmplRmqaZW6A4oJc00LFBEFjEWSf8/vDHydHYGSYwyDT5/16ndeL85znPPM9k8bXZzsyQRAEEBEREemBUUMHQERERP8cTDyIiIhIb5h4EBERkd4w8SAiIiK9YeJBREREesPEg4iIiPSGiQcRERHpDRMPIiIi0hsmHkRERKQ3TDyo0Tl//jzeeustuLi4wNzcHE2bNkW3bt2wYsUK/PXXX/X62WfPnkWfPn2gUCggk8mwZs0ayT9DJpMhPDxc8nYfJyYmBjKZDDKZDD/99FOV64IgoF27dpDJZPDz86vTZ6xfvx4xMTFa3fPTTz/VGJPUoqKi0LFjR8jlcri4uGDx4sUoKyvTup1Dhw6J3+WdO3fqIVKixsukoQMg0sbmzZsxefJkdOjQAbNnz0anTp1QVlaGxMREbNy4ESdOnMCePXvq7fPHjx+PwsJC7NixA82bN0ebNm0k/4wTJ06gZcuWkrdbW1ZWVtiyZUuV5OLo0aP4/fffYWVlVee2169fDzs7OwQFBdX6nm7duuHEiRPo1KlTnT+3NpYuXYqFCxfi3Xffhb+/PxISEvDee+/hzz//xCeffFLrdgoKChASEgInJyfcunWrHiMmaqQEokbi+PHjgrGxsTBw4EChuLi4yvWSkhLh66+/rtcYTExMhEmTJtXrZzSU6OhoAYAwYcIEwcLCQsjLy1O7/sYbbwi+vr5C586dhT59+tTpM7S5t7S0VCgrK6vT52jrzp07grm5uTBx4kS18qVLlwoymUxISUmpdVtTpkwRvLy8hPfee08AIGRnZ0sdLlGjxqEWajQiIiIgk8nwySefQC6XV7luZmaGYcOGiecqlQorVqwQu87t7e3x5ptv4ubNm2r3+fn5wcPDAwkJCXj++efRpEkTtG3bFsuWLYNKpQLw9zBEeXk5NmzYIHajA0B4eLj488Mq77l27ZpYdvjwYfj5+cHW1hYWFhZo1aoVRowYgfv374t1qhtquXjxIl566SU0b94c5ubm6Nq1K2JjY9XqVA5JfPHFF1iwYAGcnJxgbW2N/v374/Lly7X7kgG8/vrrAIAvvvhCLMvLy8NXX32F8ePHV3vP4sWL4e3tDRsbG1hbW6Nbt27YsmULhIfeQdmmTRukpKTg6NGj4vdX2WNUGfu2bdswc+ZMPPXUU5DL5bh69WqVoZY7d+7A2dkZvXr1UhsGuXTpEiwtLTF27NhaP2ul+Ph4FBcX46233lIrf+uttyAIAvbu3Vurdn755Rd88skn+PTTT2FsbKx1HET/BEw8qFGoqKjA4cOH0b17dzg7O9fqnkmTJmHu3Ll48cUX8c0332DJkiWIj49Hr169qoy7Z2ZmYsyYMXjjjTfwzTffICAgAPPmzcP27dsBAIMHD8aJEycAAK+++ipOnDghntfWtWvXMHjwYJiZmWHr1q2Ij4/HsmXLYGlpidLS0hrvu3z5Mnr16oWUlBSsXbsWu3fvRqdOnRAUFIQVK1ZUqT9//nxcv34dn376KT755BNcuXIFQ4cORUVFRa3itLa2xquvvoqtW7eKZV988QWMjIwwatSoGp/t7bffxq5du7B7924MHz4c06ZNw5IlS8Q6e/bsQdu2beHl5SV+f48Oi82bNw83btzAxo0b8e2338Le3r7KZ9nZ2WHHjh1ISEjA3LlzAQD379/Ha6+9hlatWmHjxo21es6HXbx4EQDg6empVu7o6Ag7OzvxuiZFRUUIDg5GaGgounXrpnUMRP8YDd3lQlQbmZmZAgBh9OjRtaqfmpoqABAmT56sVn7q1CkBgDB//nyxrE+fPgIA4dSpU2p1O3XqJAwYMECtDIAwZcoUtbKwsDChur9KlUMXaWlpgiAIwn//+18BgJCcnKwxdgBCWFiYeD569GhBLpcLN27cUKsXEBAgNGnSRMjNzRUEQRCOHDkiABAGDRqkVm/Xrl0CAOHEiRMaP7cy3oSEBLGtixcvCoIgCD179hSCgoIEQXj8cElFRYVQVlYmvP/++4Ktra2gUqnEazXdW/l5vXv3rvHakSNH1MqXL18uABD27NkjjBs3TrCwsBDOnz+v8RlrEhISIsjl8mqvubm5Cf7+/o9tY+bMmULbtm2F+/fvC4Lw958LDrUQqWOPBxmkI0eOAECVSYzPPPMM3N3d8eOPP6qVK5VKPPPMM2plTz/9NK5fvy5ZTF27doWZmRkmTpyI2NhY/PHHH7W67/Dhw+jXr1+Vnp6goCDcv3+/Ss/Lw8NNwIPnAKDVs/Tp0weurq7YunUrLly4gISEhBqHWSpj7N+/PxQKBYyNjWFqaopFixbh7t27yMrKqvXnjhgxotZ1Z8+ejcGDB+P1119HbGwsoqKiqvRYaKO64bLaXAOA06dPY82aNdi0aRMsLCzqHAPRPwETD2oU7Ozs0KRJE6SlpdWq/t27dwE86Cp/lJOTk3i9kq2tbZV6crkcRUVFdYi2eq6urjh06BDs7e0xZcoUuLq6wtXVFR999JHG++7evVvjc1Ref9ijz1I5H0abZ5HJZHjrrbewfft2bNy4EW5ubnj++eerrXv69Gn4+/sDeLDq6Ndff0VCQgIWLFig9edW95yaYgwKCkJxcTGUSmWd5nZUsrW1RXFxsdpcm0p//fUXbGxsNN4/fvx4DB8+HD169EBubi5yc3NRXFwMAMjPz8e9e/fqHBuRoWHiQY2CsbEx+vXrh6SkpCqTQ6tT+cs3IyOjyrVbt27Bzs5OstjMzc0BACUlJWrl1e3f8Pzzz+Pbb79FXl4eTp48CV9fX4SGhmLHjh01tm9ra1vjcwCQ9FkeFhQUhDt37mDjxo1VJl0+bMeOHTA1NcW+ffswcuRI9OrVCz169KjTZz6uZ+FhGRkZmDJlCrp27Yq7d+9i1qxZdfpM4O+5HRcuXFArz8zMxJ07d+Dh4aHx/pSUFHz55Zdo3ry5eCxfvhzAg4SzpqSN6J+IiQc1GvPmzYMgCAgJCal2MmZZWRm+/fZbAMALL7wAAOLk0EoJCQlITU1Fv379JIurcmXG+fPn1corY6mOsbExvL298fHHHwMAzpw5U2Pdfv364fDhw1X2hPjss8/QpEkT+Pj41DFyzZ566inMnj0bQ4cOxbhx42qsJ5PJYGJioraKo6ioCNu2batSV6pepIqKCrz++uuQyWT4/vvvERkZiaioKOzevbtO7Q0cOBDm5uZVNjerXJn08ssva7z/yJEjVY7K72zv3r349NNP6xQXkSHiBmLUaPj6+mLDhg2YPHkyunfvjkmTJqFz584oKyvD2bNn8cknn8DDwwNDhw5Fhw4dMHHiRERFRcHIyAgBAQG4du0aFi5cCGdnZ/z73/+WLK5BgwbBxsYGwcHBeP/992FiYoKYmBikp6er1du4cSMOHz6MwYMHo1WrViguLhZXjvTv37/G9sPCwrBv3z707dsXixYtgo2NDeLi4vDdd99hxYoVUCgUkj3Lo5YtW/bYOoMHD8aqVasQGBiIiRMn4u7du/jPf/5T7ZJnT09P7NixAzt37kTbtm1hbm5ep3kZYWFh+OWXX3DgwAEolUrMnDkTR48eRXBwMLy8vODi4qJVezY2NnjvvfewcOFC2NjYiBuIhYeHY8KECWqbl3322WcYP348tm7dijfffBMAqt3JtXL577PPPltvvVJEjRETD2pUQkJC8Mwzz2D16tVYvnw5MjMzYWpqCjc3NwQGBmLq1Kli3Q0bNsDV1RVbtmzBxx9/DIVCgYEDByIyMrLaOR11ZW1tjfj4eISGhuKNN95As2bNMGHCBAQEBGDChAliva5du+LAgQMICwtDZmYmmjZtCg8PD3zzzTfiHInqdOjQAcePH8f8+fMxZcoUFBUVwd3dHdHR0VrtAFpfXnjhBWzduhXLly/H0KFD8dRTTyEkJAT29vYIDg5Wq7t48WJkZGQgJCQE9+7dQ+vWrdX2OamNgwcPIjIyEgsXLlTruYqJiYGXlxdGjRqFY8eOwczMTKt2FyxYACsrK3z88cf4z3/+A6VSiXfffVecq1JJpVKhoqJC3OOFiLQjE4SHdvghIiIiqkec40FERER6w8SDiIiI9IaJBxEREekNEw8iIiLSGyYeREREpDdMPIiIiEhvuI9HLahUKty6dQtWVlZabelMRERPBkEQcO/ePTg5OcHIqP7+zV1cXFztzsraMjMzE1/HYGiYeNTCrVu3qrwZlIiIGp/09HS0bNmyXtouLi6GS+umyMyq0LktpVKJtLQ0g0w+mHjUgpWVFQDg+pk2sG7K0SkyTK/1H9jQIRDVm3JVKX66+an4//P6UFpaisysClxPagNrq7r/rsi/p0Lr7tdQWlrKxOOfqnJ4xbqpkU5/mIieZCZGVd+tQmRo9DFc3tRKhqZWdf8cFQx7SJ+JBxERkYQqBBUqdHgZSYVg2O8BYuJBREQkIRUEqFD3zEOXexsDjhsQERGR3rDHg4iISEIqqKDLYIludz/5mHgQERFJqEIQUCHUfbhEl3sbAw61EBERkd6wx4OIiEhCnFyqGRMPIiIiCakgoIKJR4041EJERER6wx4PIiIiCXGoRTMmHkRERBLiqhbNONRCRETUiEVGRqJnz56wsrKCvb09Xn75ZVy+fFmtjiAICA8Ph5OTEywsLODn54eUlBS1OiUlJZg2bRrs7OxgaWmJYcOG4ebNm2p1cnJyMHbsWCgUCigUCowdOxa5ublaxcvEg4iISEIqCQ5tHD16FFOmTMHJkydx8OBBlJeXw9/fH4WFhWKdFStWYNWqVVi3bh0SEhKgVCrx4osv4t69e2Kd0NBQ7NmzBzt27MCxY8dQUFCAIUOGoKKiQqwTGBiI5ORkxMfHIz4+HsnJyRg7dqxW8coEwcD7dCSQn58PhUKBnN/a8u20ZLAG+w5t6BCI6k25qgSHbqxHXl4erK2t6+UzKn9XpKTaw0qH3xX37qnQ2T2rzrFmZ2fD3t4eR48eRe/evSEIApycnBAaGoq5c+cCeNC74eDggOXLl+Ptt99GXl4eWrRogW3btmHUqFEAgFu3bsHZ2Rn79+/HgAEDkJqaik6dOuHkyZPw9vYGAJw8eRK+vr743//+hw4dOtQqPv4WJSIiklCFoPsBPEhkHj5KSkpq9fl5eXkAABsbGwBAWloaMjMz4e/vL9aRy+Xo06cPjh8/DgBISkpCWVmZWh0nJyd4eHiIdU6cOAGFQiEmHQDg4+MDhUIh1qkNJh5ERERPIGdnZ3EuhUKhQGRk5GPvEQQBM2bMwHPPPQcPDw8AQGZmJgDAwcFBra6Dg4N4LTMzE2ZmZmjevLnGOvb29lU+097eXqxTG1zVQkREJKG6zNN49H4ASE9PVxtqkcvlj7136tSpOH/+PI4dO1blmkwmUzsXBKFK2aMerVNd/dq08zD2eBAREUlIBRkqdDhUePBL3NraWu14XOIxbdo0fPPNNzhy5AhatmwpliuVSgCo0iuRlZUl9oIolUqUlpYiJydHY53bt29X+dzs7OwqvSmaMPEgIiJqxARBwNSpU7F7924cPnwYLi4uatddXFygVCpx8OBBsay0tBRHjx5Fr169AADdu3eHqampWp2MjAxcvHhRrOPr64u8vDycPn1arHPq1Cnk5eWJdWqDQy1EREQSUgkPDl3u18aUKVPw+eef4+uvv4aVlZXYs6FQKGBhYQGZTIbQ0FBERESgffv2aN++PSIiItCkSRMEBgaKdYODgzFz5kzY2trCxsYGs2bNgqenJ/r37w8AcHd3x8CBAxESEoJNmzYBACZOnIghQ4bUekULwMSDiIhIUpVDJrrcr40NGzYAAPz8/NTKo6OjERQUBACYM2cOioqKMHnyZOTk5MDb2xsHDhyAlZWVWH/16tUwMTHByJEjUVRUhH79+iEmJgbGxsZinbi4OEyfPl1c/TJs2DCsW7dOq3i5j0ctcB8P+ifgPh5kyPS5j8epFCWa6vC7ouCeCt6dM+s11obEHg8iIiIJ6bvHo7Fh4kFERCQhlSCDSqh78qDLvY0Bxw2IiIhIb9jjQUREJCEOtWjGxIOIiEhCFTBChQ4DChWPr9KoMfEgIiKSkKDjHA+BczyIiIiIpMEeDyIiIglxjodmTDyIiIgkVCEYoULQYY6HgW/ryaEWIiIi0hv2eBAREUlIBRlUOvy7XgXD7vJg4kFERCQhzvHQjEMtREREpDfs8SAiIpKQ7pNLOdRCREREtfRgjocOL4njUAsRERGRNNjjQUREJCGVju9q4aoWIiIiqjXO8dCMiQcREZGEVDDiPh4acI4HERER6Q17PIiIiCRUIchQocOr7XW5tzFg4kFERCShCh0nl1ZwqIWIiIhIGuzxICIikpBKMIJKh1UtKq5qISIiotriUItmHGohIiIivWGPBxERkYRU0G1likq6UJ5ITDyIiIgkpPsGYoY9GGHYT0dERERPFPZ4EBERSUj3d7UYdp8AEw8iIiIJqSCDCrrM8eDOpURERFRL7PHQzLCfjoiIiJ4oTDyIiIgkVLmBmC6HNn7++WcMHToUTk5OkMlk2Lt3r9p1mUxW7fHhhx+Kdfz8/KpcHz16tFo7OTk5GDt2LBQKBRQKBcaOHYvc3Fytvx8mHkRERBJSCTKdD20UFhaiS5cuWLduXbXXMzIy1I6tW7dCJpNhxIgRavVCQkLU6m3atEntemBgIJKTkxEfH4/4+HgkJydj7Nix2n054BwPIiKiRi0gIAABAQE1XlcqlWrnX3/9Nfr27Yu2bduqlTdp0qRK3UqpqamIj4/HyZMn4e3tDQDYvHkzfH19cfnyZXTo0KHW8bLHg4iISEIqHYdZKjcQy8/PVztKSkp0ju327dv47rvvEBwcXOVaXFwc7Ozs0LlzZ8yaNQv37t0Tr504cQIKhUJMOgDAx8cHCoUCx48f1yoG9ngQERFJSPe30z6419nZWa08LCwM4eHhuoSG2NhYWFlZYfjw4WrlY8aMgYuLC5RKJS5evIh58+bh3LlzOHjwIAAgMzMT9vb2Vdqzt7dHZmamVjEw8SAiInoCpaenw9raWjyXy+U6t7l161aMGTMG5ubmauUhISHizx4eHmjfvj169OiBM2fOoFu3bgAeTFJ9lCAI1ZZrwsSDiIhIQhWQoUKHTcAq77W2tlZLPHT1yy+/4PLly9i5c+dj63br1g2mpqa4cuUKunXrBqVSidu3b1epl52dDQcHB63i4BwPIiIiCVUOtehy1IctW7age/fu6NKly2PrpqSkoKysDI6OjgAAX19f5OXl4fTp02KdU6dOIS8vD7169dIqDvZ4EBERNWIFBQW4evWqeJ6Wlobk5GTY2NigVatWAB5MVP3yyy+xcuXKKvf//vvviIuLw6BBg2BnZ4dLly5h5syZ8PLywrPPPgsAcHd3x8CBAxESEiIus504cSKGDBmi1YoWgD0eREREkqrA38MtdTu0k5iYCC8vL3h5eQEAZsyYAS8vLyxatEiss2PHDgiCgNdff73K/WZmZvjxxx8xYMAAdOjQAdOnT4e/vz8OHToEY2NjsV5cXBw8PT3h7+8Pf39/PP3009i2bZvW3w97PIiIiCQk1aqW2vLz84MgCBrrTJw4ERMnTqz2mrOzM44ePfrYz7GxscH27du1iq06TDyIiIgkxJfEaWbYT0dERERPFPZ4EBERSUiADCodltMKOtzbGDDxICIikhCHWjQz7KcjIiKiJwp7PIiIiCRUl1fbP3q/IWPiQUREJKHKt8zqcr8hM+ynIyIioicKezyIiIgkxKEWzZh4EBERSUgFI6h0GFDQ5d7GwLCfjoiIiJ4o7PEgIiKSUIUgQ4UOwyW63NsYMPEgIiKSEOd4aMbEg4iISEKCjm+nFbhzKREREZE02ONBREQkoQrIUKHDi950ubcxYOJBREQkIZWg2zwNlSBhME8gDrUQERGR3jTKHo+YmBiEhoYiNze3oUOhGuyIssev+5sh/aocZuYqdOpxH8ELbsG5XYlY59h+BfZvs8WV802Qn2OC9Qcuw9WjSK2d0hIZNr/vhJ/2NkdJsQxezxVgauRNtHAqE+t8/pEDTh+yxh8pFjAxE7D7fxf09pxED+vc9S5GjPkd7TrkwbZFCZbM7YGTPyvF682al+CtKanweiYbllZlSEm2xcaVnXHrZlOxzsCXrqOP/59o1yEfTSzLMfLFASgsMG2Ix6E6Uuk4uVSXexuDBn26oKAgyGSyKsfVq1cbMiySwPkTTTE06A7W7LuCyB2/o6ICmP+6K4rv//1Hrvi+ETr1LMT4+bdqbGdj2FM4Hq/AvA3XsGrvVRTdN8KiN9uiouLvOuWlMvQemovB4+7U5yMRPZa5eQXSrlhj40qPaq4KeG95ApRO97Fkbk9MH9cbWZkWWLr2FOTm5WItuXkFzpy0x67YdvoLnCSlgkznw5A1eI/HwIEDER0drVbWokWLBoqGpBLx+R9q5zNX38AoT09cOW8BT59CAED/V3MAAJnpZtW2UZhvhB++sMHstTfQrXcBAGBu1HW80aMzzv5ihR5+9wAAb87OBAAc2GlTL89CVFtJJ+2RdNK+2mtOzoVw98zFpMA+uJFmBQBY/6En4vYfQJ8Xb+HAt60AAF/vbAsA8PRiIk2GqcH7c+RyOZRKpdrx0UcfwdPTE5aWlnB2dsbkyZNRUFBQYxvnzp1D3759YWVlBWtra3Tv3h2JiYni9ePHj6N3796wsLCAs7Mzpk+fjsLCQn08Hv2/wnxjAIBVs4rH1PzblfNNUF5mhO597olltspytO5YjEsJlpLHSFSfTM1UAIDS0r//t6tSyVBeZoTOXf5qqLCoHlTuXKrLYcgaPPGojpGREdauXYuLFy8iNjYWhw8fxpw5c2qsP2bMGLRs2RIJCQlISkrCu+++C1PTB2OiFy5cwIABAzB8+HCcP38eO3fuxLFjxzB16lR9Pc4/niAAn4Q/hc7PFKBNx+Ja3/dXlglMzVRVkpXmdmXIyW7wzjoirdy81hS3MywQNOl/aGpVChMTFV4bexU2diVoblvy+Aao0aic46HLYcga/P/e+/btQ9Omf0+sCggIwJdffimeu7i4YMmSJZg0aRLWr19fbRs3btzA7Nmz0bFjRwBA+/btxWsffvghAgMDERoaKl5bu3Yt+vTpgw0bNsDc3LxKeyUlJSgp+ft/BPn5+To94z/dx/OfQlqqBVbuvSJJe4Igg4EPgZIBqqgwQsS87vjX/PPYeeAAKsplSE60Q8JxDi3TP0uDJx59+/bFhg0bxHNLS0scOXIEERERuHTpEvLz81FeXo7i4mIUFhbC0rJqF/uMGTMwYcIEbNu2Df3798drr70GV1dXAEBSUhKuXr2KuLg4sb4gCFCpVEhLS4O7u3uV9iIjI7F48eJ6eNp/no8XPIUTBxRYueeq2kqU2rCxL0dZqRHu5Rqr9Xrk3jVBpx4cKqPG5+rlZpg2rjeaWJbBxFSF/Fw5Vn16DFf+p2jo0EhCKuj4rhYD/5dVg/fnWFpaol27duJRWlqKQYMGwcPDA1999RWSkpLw8ccfAwDKyqr/xRUeHo6UlBQMHjwYhw8fRqdOnbBnzx4AgEqlwttvv43k5GTxOHfuHK5cuSImJ4+aN28e8vLyxCM9Pb1+Ht6ACQKwbv5T+PV7BVZ8eRXKVqVat9H+6fswMVXhzM9WYtnd2ya4/j9zdOrJxIMar/uFpsjPlcOpZQHadcxVW3JLjZ+g44oWwcATjwbv8XhUYmIiysvLsXLlShgZPciLdu3a9dj73Nzc4Obmhn//+994/fXXER0djVdeeQXdunVDSkoK2rWr/dI0uVwOuVxe52cgYN38ljiypznCo/+ARVMV/sp68EfN0qoCcosH2/Ll5xgj+08z3L394Fr67w++8+b2ZbCxL4eltQoDXv8Lnyx2gnXzclg1q8DmJU5o07EYXs//PeE066Yp7uWaIOtPU6gqgN8vWgAAnFxKYGGp0udj0z+cuUU5nFr+nRQrne6jbfs83Ms3Q/ZtCzz3wi3k5Tz4uY3rPUz8dwpO/qzE2dN/D7c0tylGc9sSOLa8DwBo45qPovsmyLptgYL86leA0ZOFb6fV7IlLPFxdXVFeXo6oqCgMHToUv/76KzZu3Fhj/aKiIsyePRuvvvoqXFxccPPmTSQkJGDEiBEAgLlz58LHxwdTpkxBSEgILC0tkZqaioMHDyIqKkpfj/WPsy/WDgAwe0R7tfKZq2/Af9SDGfwnDyiw8t+txGuRk9oAAN6YkYmxsx4skX0n/E8YGwtY+k4blBYZoetz97A49g8YG//d5mf/ccTBXX8vpZ3s3wEAsOK/V9GlV82roYik1r5jLpatPymeh/zrEgDg0HctsfqDrmhuW4IJ0y+hmU0Jcu6Y48f4ltixVf3vSMAr1zFmwt/zoVZsPAEAWL2kCw7td9bDUxDVL5kgCA22K3xQUBByc3Oxd+9etfLVq1fjww8/RG5uLnr37o0xY8bgzTffRE5ODpo1a6a2c2lpaSnGjRuHX3/9Fbdv34adnR2GDx+ODz/8UJw4mpCQgAULFuDEiRMQBAGurq4YNWoU5s+fX6s48/PzoVAokPNbW1hbNfjoFFG9GOw7tKFDIKo35aoSHLqxHnl5ebC2tq6Xz6j8XfHKwbdgaln33qmywlLseTG6XmNtSA2aeDQWTDzon4CJBxkyfSYeLx0Yr3Pi8bX/VoNNPPhblIiIiPTmiZvjQURE1Jjp+r4VQ19Oy8SDiIhIQlzVohmHWoiIiBqxn3/+GUOHDoWTkxNkMlmVBRvVvQnex8dHrU5JSQmmTZsGOzs7WFpaYtiwYbh586ZanZycHIwdOxYKhQIKhQJjx45Fbm6u1vEy8SAiIpJQZY+HLoc2CgsL0aVLF6xbt67GOgMHDkRGRoZ47N+/X+16aGgo9uzZgx07duDYsWMoKCjAkCFDUFHx967RgYGBSE5ORnx8POLj45GcnIyxY8dq9+WAQy1ERESS0vdQS0BAAAICAjTWqXwTfHXy8vKwZcsW8bUjALB9+3Y4Ozvj0KFDGDBgAFJTUxEfH4+TJ0/C29sbALB582b4+vri8uXL6NChQ63jZY8HERHREyg/P1/tePjlpdr66aefYG9vDzc3N4SEhCArK0u8lpSUhLKyMvj7+4tlTk5O8PDwwPHjxwEAJ06cgEKhEJMOAPDx8YFCoRDr1BYTDyIiIglJNdTi7OwszqdQKBSIjIysUzwBAQGIi4vD4cOHsXLlSiQkJOCFF14QE5nMzEyYmZmhefPmavc5ODggMzNTrGNvb1+lbXt7e7FObXGohYiISEICdFsSW7mrZ3p6utoGYnV9h9ioUaPEnz08PNCjRw+0bt0a3333HYYPH15zHIIAmezv53j455rq1AYTDyIiIglJNcfD2tq6XnYudXR0ROvWrXHlyoN3AimVSpSWliInJ0et1yMrKwu9evUS69y+fbtKW9nZ2XBwcNDq8znUQkRE9A9y9+5dpKenw9HREQDQvXt3mJqa4uDBg2KdjIwMXLx4UUw8fH19kZeXh9OnT4t1Tp06hby8PLFObbHHg4iISEL6XtVSUFCAq1eviudpaWlITk6GjY0NbGxsEB4ejhEjRsDR0RHXrl3D/PnzYWdnh1deeQUAoFAoEBwcjJkzZ8LW1hY2NjaYNWsWPD09xVUu7u7uGDhwIEJCQrBp0yYAwMSJEzFkyBCtVrQATDyIiIgkpe/EIzExEX379hXPZ8yYAQAYN24cNmzYgAsXLuCzzz5Dbm4uHB0d0bdvX+zcuRNWVlbiPatXr4aJiQlGjhyJoqIi9OvXDzExMTA2NhbrxMXFYfr06eLql2HDhmncO6QmTDyIiIgaMT8/P2h60fwPP/zw2DbMzc0RFRWFqKioGuvY2Nhg+/btdYrxYUw8iIiIJMR3tWjGxIOIiEhCgiCDoEPyoMu9jQFXtRAREZHesMeDiIhIQirIdNpATJd7GwMmHkRERBLiHA/NONRCREREesMeDyIiIglxcqlmTDyIiIgkxKEWzZh4EBERSYg9HppxjgcRERHpDXs8iIiIJCToONRi6D0eTDyIiIgkJADQ8OqUWt1vyDjUQkRERHrDHg8iIiIJqSCDjDuX1oiJBxERkYS4qkUzDrUQERGR3rDHg4iISEIqQQYZNxCrERMPIiIiCQmCjqtaDHxZC4daiIiISG/Y40FERCQhTi7VjIkHERGRhJh4aMbEg4iISEKcXKoZ53gQERGR3rDHg4iISEJc1aIZEw8iIiIJPUg8dJnjIWEwTyAOtRAREZHesMeDiIhIQlzVohkTDyIiIgkJ/3/ocr8h41ALERER6Q17PIiIiCTEoRbNmHgQERFJiWMtGjHxICIikpKOPR4w8B4PzvEgIiIivWHiQUREJKHKnUt1ObTx888/Y+jQoXBycoJMJsPevXvFa2VlZZg7dy48PT1haWkJJycnvPnmm7h165ZaG35+fpDJZGrH6NGj1erk5ORg7NixUCgUUCgUGDt2LHJzc7X+fph4EBERSahycqkuhzYKCwvRpUsXrFu3rsq1+/fv48yZM1i4cCHOnDmD3bt347fffsOwYcOq1A0JCUFGRoZ4bNq0Se16YGAgkpOTER8fj/j4eCQnJ2Ps2LHafTngHA8iIqJGLSAgAAEBAdVeUygUOHjwoFpZVFQUnnnmGdy4cQOtWrUSy5s0aQKlUlltO6mpqYiPj8fJkyfh7e0NANi8eTN8fX1x+fJldOjQodbxsseDiIhISoJM9wNAfn6+2lFSUiJJeHl5eZDJZGjWrJlaeVxcHOzs7NC5c2fMmjUL9+7dE6+dOHECCoVCTDoAwMfHBwqFAsePH9fq89njQUREJCGp3k7r7OysVh4WFobw8PC6NwyguLgY7777LgIDA2FtbS2WjxkzBi4uLlAqlbh48SLmzZuHc+fOib0lmZmZsLe3r9Kevb09MjMztYqBiQcREdETKD09XS05kMvlOrVXVlaG0aNHQ6VSYf369WrXQkJCxJ89PDzQvn179OjRA2fOnEG3bt0AADJZ1bkngiBUW64Jh1qIiIikJEhwALC2tlY7dEk8ysrKMHLkSKSlpeHgwYNqCU11unXrBlNTU1y5cgUAoFQqcfv27Sr1srOz4eDgoFUsterxWLt2ba0bnD59ulYBEBERGZInbcv0yqTjypUrOHLkCGxtbR97T0pKCsrKyuDo6AgA8PX1RV5eHk6fPo1nnnkGAHDq1Cnk5eWhV69eWsVTq8Rj9erVtWpMJpMx8SAiItKjgoICXL16VTxPS0tDcnIybGxs4OTkhFdffRVnzpzBvn37UFFRIc7JsLGxgZmZGX7//XfExcVh0KBBsLOzw6VLlzBz5kx4eXnh2WefBQC4u7tj4MCBCAkJEZfZTpw4EUOGDNFqRQtQy8QjLS1Nq0aJiIj+0fT4vpXExET07dtXPJ8xYwYAYNy4cQgPD8c333wDAOjatavafUeOHIGfnx/MzMzw448/4qOPPkJBQQGcnZ0xePBghIWFwdjYWKwfFxeH6dOnw9/fHwAwbNiwavcOeZw6Ty4tLS1FWloaXF1dYWLCOapERESA/oda/Pz8IGhYRqPpGvBg9czRo0cf+zk2NjbYvn27VrFVR+vJpffv30dwcDCaNGmCzp0748aNGwAezO1YtmyZzgERERE1ahJNLjVUWicelWt7f/rpJ5ibm4vl/fv3x86dOyUNjoiIiAyL1mMke/fuxc6dO+Hj46O2drdTp074/fffJQ2OiIio8ZH9/6HL/YZL68QjOzu72t3LCgsLtd5EhIiIyODoOlzCoRZ1PXv2xHfffSeeVyYblS+LISIiIqqJ1j0ekZGRGDhwIC5duoTy8nJ89NFHSElJwYkTJ2o1K5aIiMigscdDI617PHr16oVff/0V9+/fh6urKw4cOAAHBwecOHEC3bt3r48YiYiIGg+J3k5rqOq0AYenpydiY2OljoWIiIgMXJ0Sj4qKCuzZswepqamQyWRwd3fHSy+9xI3EiIjoH08Q/n61fV3vN2RaZwoXL17ESy+9hMzMTHF/9t9++w0tWrTAN998A09PT8mDJCIiajQ4x0Mjred4TJgwAZ07d8bNmzdx5swZnDlzBunp6Xj66acxceLE+oiRiIiIDITWPR7nzp1DYmIimjdvLpY1b94cS5cuRc+ePSUNjoiIqNHRdYKogU8u1brHo0OHDrh9+3aV8qysLLRr106SoIiIiBormaD7Ychq1eORn58v/hwREYHp06cjPDwcPj4+AICTJ0/i/fffx/Lly+snSiIiosaCczw0qlXi0axZM7Xt0AVBwMiRI8WyylfuDh06FBUVFfUQJhERERmCWiUeR44cqe84iIiIDAPneGhUq8SjT58+9R0HERGRYeBQi0Z13vHr/v37uHHjBkpLS9XKn376aZ2DIiIiIsOkdeKRnZ2Nt956C99//3211znHg4iI/tHY46GR1stpQ0NDkZOTg5MnT8LCwgLx8fGIjY1F+/bt8c0339RHjERERI2HIMFhwLTu8Th8+DC+/vpr9OzZE0ZGRmjdujVefPFFWFtbIzIyEoMHD66POImIiMgAaN3jUVhYCHt7ewCAjY0NsrOzATx4Y+2ZM2ekjY6IiKixqc1r7x93GLA67Vx6+fJlAEDXrl2xadMm/Pnnn9i4cSMcHR0lD5CIiKgx4c6lmmk91BIaGoqMjAwAQFhYGAYMGIC4uDiYmZkhJiZG6viIiIjIgGideIwZM0b82cvLC9euXcP//vc/tGrVCnZ2dpIGR0RE1OhwVYtGdd7Ho1KTJk3QrVs3KWIhIiIiA1erxGPGjBm1bnDVqlV1DoaIiKixk0G3eRqGPbW0lonH2bNna9XYwy+SIyIiInoUXxKnhVfcPGEiM23oMIjqhbGbWUOHQFRvhAo9TpzgS+I00nmOBxERET2Ek0s10nofDyIiIqK6Yo8HERGRlNjjoRETDyIiIgnpuvuooe9cyqEWIiKiRuznn3/G0KFD4eTkBJlMhr1796pdFwQB4eHhcHJygoWFBfz8/JCSkqJWp6SkBNOmTYOdnR0sLS0xbNgw3Lx5U61OTk4Oxo4dC4VCAYVCgbFjxyI3N1freOuUeGzbtg3PPvssnJyccP36dQDAmjVr8PXXX9elOSIiIsNRm9feP+7QQmFhIbp06YJ169ZVe33FihVYtWoV1q1bh4SEBCiVSrz44ou4d++eWCc0NBR79uzBjh07cOzYMRQUFGDIkCGoqKgQ6wQGBiI5ORnx8fGIj49HcnIyxo4dq12wqEPisWHDBsyYMQODBg1Cbm6uGFSzZs2wZs0arQMgIiIyKHpOPAICAvDBBx9g+PDhVUMRBKxZswYLFizA8OHD4eHhgdjYWNy/fx+ff/45ACAvLw9btmzBypUr0b9/f3h5eWH79u24cOECDh06BABITU1FfHw8Pv30U/j6+sLX1xebN2/Gvn37xBfH1pbWiUdUVBQ2b96MBQsWwNjYWCzv0aMHLly4oG1zREREVI38/Hy1o6SkROs20tLSkJmZCX9/f7FMLpejT58+OH78OAAgKSkJZWVlanWcnJzg4eEh1jlx4gQUCgW8vb3FOj4+PlAoFGKd2tI68UhLS4OXl1eVcrlcjsLCQm2bIyIiMii1ee394w4AcHZ2FudTKBQKREZGah1LZmYmAMDBwUGt3MHBQbyWmZkJMzMzNG/eXGMde3v7Ku3b29uLdWpL61UtLi4uSE5ORuvWrdXKv//+e3Tq1Enb5oiIiAyLRDuXpqenw9raWiyWy+V1bvLRV5oIgvDY15w8Wqe6+rVp51FaJx6zZ8/GlClTUFxcDEEQcPr0aXzxxReIjIzEp59+qm1zREREhkWifTysra3VEo+6UCqVAB70WDg6OorlWVlZYi+IUqlEaWkpcnJy1Ho9srKy0KtXL7HO7du3q7SfnZ1dpTflcbQeannrrbcQFhaGOXPm4P79+wgMDMTGjRvx0UcfYfTo0do2R0RERPXExcUFSqUSBw8eFMtKS0tx9OhRMano3r07TE1N1epkZGTg4sWLYh1fX1/k5eXh9OnTYp1Tp04hLy9PrFNbddpALCQkBCEhIbhz5w5UKlW14z5ERET/RPreQKygoABXr14Vz9PS0pCcnAwbGxu0atUKoaGhiIiIQPv27dG+fXtERESgSZMmCAwMBAAoFAoEBwdj5syZsLW1hY2NDWbNmgVPT0/0798fAODu7o6BAwciJCQEmzZtAgBMnDgRQ4YMQYcOHbSKV6edS+3s7HS5nYiIyPDoecv0xMRE9O3bVzyfMWMGAGDcuHGIiYnBnDlzUFRUhMmTJyMnJwfe3t44cOAArKysxHtWr14NExMTjBw5EkVFRejXrx9iYmLUVq/GxcVh+vTp4uqXYcOG1bh3iCYyQRC0ekQXFxeNE0n++OMPrYN40uXn50OhUMAPL8FEZtrQ4RDVC2M314YOgajelFeU4Mera5CXl6fzvImaVP6uaLsoAkbm5nVuR1VcjD/en1+vsTYkrXs8QkND1c7Lyspw9uxZxMfHY/bs2VLFRURE1DjpONTCl8Q94l//+le15R9//DESExN1DoiIiKhR49tpNZLsJXEBAQH46quvpGqOiIiIDJBOk0sf9t///hc2NjZSNUdERNQ4scdDI60TDy8vL7XJpYIgIDMzE9nZ2Vi/fr2kwRERETU2+l5O29honXi8/PLLaudGRkZo0aIF/Pz80LFjR6niIiIiIgOkVeJRXl6ONm3aYMCAAeI2rERERES1pdXkUhMTE0yaNKlOr+YlIiL6RxAkOAyY1qtavL29cfbs2fqIhYiIqNGrzWvvH3cYMq3neEyePBkzZ87EzZs30b17d1haWqpdf/rppyULjoiIiAxLrROP8ePHY82aNRg1ahQAYPr06eI1mUwGQRAgk8lQUVEhfZRERESNiYH3Wuii1olHbGwsli1bhrS0tPqMh4iIqHHjPh4a1TrxqHyXXOvWrestGCIiIjJsWs3x0PRWWiIiIuIGYo+jVeLh5ub22OTjr7/+0ikgIiKiRo1DLRpplXgsXrwYCoWivmIhIiIiA6dV4jF69GjY29vXVyxERESNHodaNKt14sH5HURERLXAoRaNar1zaeWqFiIiIqK6qnWPh0qlqs84iIiIDAN7PDTSest0IiIiqhnneGjGxIOIiEhK7PHQSOu30xIRERHVFXs8iIiIpMQeD42YeBAREUmIczw041ALERER6Q17PIiIiKTEoRaNmHgQERFJiEMtmnGohYiIiPSGPR5ERERS4lCLRkw8iIiIpMTEQyMOtRAREZHesMeDiIhIQrL/P3S535Cxx4OIiEhKggSHFtq0aQOZTFblmDJlCgAgKCioyjUfHx+1NkpKSjBt2jTY2dnB0tISw4YNw82bN+v6DWjExIOIiEhClctpdTm0kZCQgIyMDPE4ePAgAOC1114T6wwcOFCtzv79+9XaCA0NxZ49e7Bjxw4cO3YMBQUFGDJkCCoqKnT+Ph7FoRYiIqJGrEWLFmrny5Ytg6urK/r06SOWyeVyKJXKau/Py8vDli1bsG3bNvTv3x8AsH37djg7O+PQoUMYMGCApPGyx4OIiEhKEg215Ofnqx0lJSWP/ejS0lJs374d48ePh0z292yRn376Cfb29nBzc0NISAiysrLEa0lJSSgrK4O/v79Y5uTkBA8PDxw/frzu30MNmHgQERFJTYL5Hc7OzlAoFOIRGRn52I/du3cvcnNzERQUJJYFBAQgLi4Ohw8fxsqVK5GQkIAXXnhBTGQyMzNhZmaG5s2bq7Xl4OCAzMzMOn4BNeNQCxER0RMoPT0d1tbW4rlcLn/sPVu2bEFAQACcnJzEslGjRok/e3h4oEePHmjdujW+++47DB8+vMa2BEFQ6zWRChMPIiIiCUn1rhZra2u1xONxrl+/jkOHDmH37t0a6zk6OqJ169a4cuUKAECpVKK0tBQ5OTlqvR5ZWVno1auX9g/wGBxqISIikpKel9NWio6Ohr29PQYPHqyx3t27d5Geng5HR0cAQPfu3WFqaiquhgGAjIwMXLx4sV4SD/Z4EBERNXIqlQrR0dEYN24cTEz+/tVeUFCA8PBwjBgxAo6Ojrh27Rrmz58POzs7vPLKKwAAhUKB4OBgzJw5E7a2trCxscGsWbPg6ekprnKREhMPIiIiCUk11KKNQ4cO4caNGxg/frxaubGxMS5cuIDPPvsMubm5cHR0RN++fbFz505YWVmJ9VavXg0TExOMHDkSRUVF6NevH2JiYmBsbFz3B6kBEw8iIiIpNcBL4vz9/SEIVW+0sLDADz/88Nj7zc3NERUVhaioKO0/XEuc40FERER6wx4PIiIiCTXEUEtjwsSDiIhISg0w1NKYMPEgIiKSEhMPjTjHg4iIiPSGPR5EREQS4hwPzZh4EBERSYlDLRpxqIWIiIj0hj0eREREEpIJAmTVbOalzf2GjIkHERGRlDjUohGHWoiIiEhv2ONBREQkIa5q0YyJBxERkZQ41KIRh1qIiIhIb9jjQUREJCEOtWjGxIOIiEhKHGrRiIkHERGRhNjjoRnneBAREZHesMeDiIhIShxq0YiJBxERkcQMfbhEFxxqISIiIr1hjwcREZGUBOHBocv9BoyJBxERkYS4qkUzDrUQERGR3rDHg4iISEpc1aIREw8iIiIJyVQPDl3uN2QcaiEiIiK9YY8HPVFslWUIXnALPfveg5mFCn/+IceqGc64eqFJQ4dGpNHIwMvo1ftPtGxVgNISY6Sm2GDrJg/8mW5Vbf2pM85g0LBr2LTuaXz933ZiuYlpBSZMuoA+/W5CblaB5DMt8PGarribzb8DjQaHWjR6ono8ZDKZxiMoKKihQ6R61FRRjlVfX0FFuQzvvdEWE/t0xCeLnVCYb9zQoRE9lkfXbOzb64oZk/2wYNazMDYWsPTDY5Cbl1ep6/vcLXTolIM72eZVrr099Tx6PX8Ly99/BrOm9YGFRQXCI0/AyMjAfxsZkMpVLbochuyJ6vHIyMgQf965cycWLVqEy5cvi2UWFhZq9cvKymBqaqq3+Kh+jZyShTu3zLDy363Ests3zRowIqLaWzTnObXzVcu6Y8fX36G9Wy4unrcTy23tijDpX8l4b/ZzWLzsuNo9TSzL4D/oGlZG9ERykj0A4MOlPRC763t07Z6FMwkO9f8gpDvu46HRE9XjoVQqxUOhUEAmk4nnxcXFaNasGXbt2gU/Pz+Ym5tj+/btCA8PR9euXdXaWbNmDdq0aaNWFh0dDXd3d5ibm6Njx45Yv369/h6MasXHPx+/nbPAgk3XsPN8Cj4+cBkBgXcbOiyiOrFsWgYAuHfv738cyWQCZs1PxFc73HDjmnWVe9q75cDUVMCZBHux7K+7FriepoB7Z/5dIMPwRPV41MbcuXOxcuVKREdHQy6X45NPPnnsPZs3b0ZYWBjWrVsHLy8vnD17FiEhIbC0tMS4ceOq1C8pKUFJSYl4np+fL+kzUPUcW5ViyJt3sfuTFtgRZY8OXYswacmfKCuV4dB/bRo6PCItCAiZfB4Xz9vieppCLH3t9d9QUSHD11+5VntXc5sSlJUaoaBAvacvN0eO5jbF9RoxSYcbiGnW6BKP0NBQDB8+XKt7lixZgpUrV4r3ubi44NKlS9i0aVO1iUdkZCQWL14sSbxUezIj4Mp5C0QvcwQA/H6xCVp3KMbgN+8y8aBGZfK/zsHFNR+zpvUWy9q55WDYq1cxPeQFADKt2pPJoPU91IA4uVSjJ2qopTZ69OihVf3s7Gykp6cjODgYTZs2FY8PPvgAv//+e7X3zJs3D3l5eeKRnp4uRej0GH9lmeD6b+qT7dKvyGH/VGkDRUSkvXemJ8P72Qy8G/q82kqUzk/fRbNmJYjdFY9vf9yDb3/cAwflfUyYdB7RO+IBADl/yWFqpkLTpup/5hXNSpDzl1yvz0GNR3h4eJXFGEqlUrwuCALCw8Ph5OQECwsL+Pn5ISUlRa2NkpISTJs2DXZ2drC0tMSwYcNw8+bNeom30fV4WFpaqp0bGRlBeGQiTllZmfizSvVgJ5bNmzfD29tbrZ6xcfWrJeRyOeRy/iXXt0sJlnB2LVEre6ptCbL+5ARTagwETPrXOfg+dwvvhvbG7Uz1/1cdPuCM5KQWamVLVvyKwwdb4eD3rQEAV35rjrIyGbx6ZOGXn1oCAJrbFKG1Sx62bvLQz2OQzhpiqKVz5844dOiQeP7w77cVK1Zg1apViImJgZubGz744AO8+OKLuHz5MqysHiz3Dg0NxbfffosdO3bA1tYWM2fOxJAhQ5CUlFTj78q6anSJx6NatGiBzMxMCIIA2YP+SCQnJ4vXHRwc8NRTT+GPP/7AmDFjGihKqo3dn7TA6m+uYPS02/j522bo4HUfg974C2tmt2zo0Igea3JoMvz638T7C3xQVGQizskoLDBFaakx7uXLcS9f/R80FRVGyPnLXNzr436hKQ7sb4MJky8gP98M9/LNMGHSBVxLU4irXKgRaIBVLSYmJmq9HH83JWDNmjVYsGCBON0gNjYWDg4O+Pzzz/H2228jLy8PW7ZswbZt29C/f38AwPbt2+Hs7IxDhw5hwIABdX+W6mKVtLUG4Ofnh+zsbKxYsQKvvvoq4uPj8f3338Pa+u8Z4+Hh4Zg+fTqsra0REBCAkpISJCYmIicnBzNmzGjA6Olhv51rgveDXfDWvAyM+fdtZKabYeMiJxzZ07yhQyN6rCEvpwEAVnz0i1r5qmXdcSi+da3b+eTjp1FRIcO8sNMwk1fg3JkWWDXPFyoV53hQza5cuQInJyfI5XJ4e3sjIiICbdu2RVpaGjIzM+Hv7y/Wlcvl6NOnD44fP463334bSUlJKCsrU6vj5OQEDw8PHD9+nInHo9zd3bF+/XpERERgyZIlGDFiBGbNmqW22mXChAlo0qQJPvzwQ8yZMweWlpbw9PREaGhowwVO1Tp1yBqnDlVdZkj0pBvkp92kdwB4a/TAKmVlpcbYuLYrNq7tKkFU1BCkGmp5dEVlTdMAvL298dlnn8HNzQ23b9/GBx98gF69eiElJQWZmZkAHvT+P8zBwQHXr18HAGRmZsLMzAzNmzevUqfyfik9sYlHUFCQ2k6lbdq0qTKXo9I777yDd955R61s/vz5aueBgYEIDAyUPE4iIiI1Eq1qcXZ2VisOCwtDeHh4leoBAQHiz56envD19YWrqytiY2Ph4+MDAOJUBPEjHpqeUGMYtahTF09s4kFERPRPlp6erjZtoLaLHip79a9cuYKXX34ZwINeDUdHR7FOVlaW2AuiVCpRWlqKnJwctV6PrKws9OrVS4InUdfoltMSERE9yaR6V4u1tbXaUdvEo6SkBKmpqXB0dISLiwuUSiUOHjwoXi8tLcXRo0fFpKJ79+4wNTVVq5ORkYGLFy/WS+LBHg8iIiIpqYQHhy73a2HWrFkYOnQoWrVqhaysLHzwwQfIz8/HuHHjIJPJEBoaioiICLRv3x7t27dHREQEmjRpIk4/UCgUCA4OxsyZM2FrawsbGxvMmjULnp6e4ioXKTHxICIikpKedy69efMmXn/9ddy5cwctWrSAj48PTp48idatH6ymmjNnDoqKijB58mTk5OTA29sbBw4cEPfwAIDVq1fDxMQEI0eORFFREfr164eYmBjJ9/AAAJlQ04xNEuXn50OhUMAPL8FExrfhkmEydqv+/SFEhqC8ogQ/Xl2DvLw8tXkTUqr8XdGr/2KYmJo//oYalJcV4/ihsHqNtSGxx4OIiEhCMui4nFaySJ5MTDyIiIik1AA7lzYmXNVCREREesMeDyIiIgk1xEviGhMmHkRERFLS86qWxoZDLURERKQ37PEgIiKSkEwQINNhgqgu9zYGTDyIiIikpPr/Q5f7DRiHWoiIiEhv2ONBREQkIQ61aMbEg4iISEpc1aIREw8iIiIpcedSjTjHg4iIiPSGPR5EREQS4s6lmjHxICIikhKHWjTiUAsRERHpDXs8iIiIJCRTPTh0ud+QMfEgIiKSEodaNOJQCxEREekNezyIiIikxA3ENGLiQUREJCFuma4Zh1qIiIhIb9jjQUREJCVOLtWIiQcREZGUBAC6LIk17LyDiQcREZGUOMdDM87xICIiIr1hjwcREZGUBOg4x0OySJ5ITDyIiIikxMmlGnGohYiIiPSGPR5ERERSUgGQ6Xi/AWPiQUREJCGuatGMQy1ERESkN+zxICIikhInl2rEHg8iIiIpVSYeuhxaiIyMRM+ePWFlZQV7e3u8/PLLuHz5slqdoKAgyGQytcPHx0etTklJCaZNmwY7OztYWlpi2LBhuHnzps5fx6OYeBARETViR48exZQpU3Dy5EkcPHgQ5eXl8Pf3R2FhoVq9gQMHIiMjQzz279+vdj00NBR79uzBjh07cOzYMRQUFGDIkCGoqKiQNF4OtRAREUlJz0Mt8fHxaufR0dGwt7dHUlISevfuLZbL5XIolcpq28jLy8OWLVuwbds29O/fHwCwfft2ODs749ChQxgwYICWD1Ez9ngQERFJSSXBoYO8vDwAgI2NjVr5Tz/9BHt7e7i5uSEkJARZWVnitaSkJJSVlcHf318sc3JygoeHB44fP65bQI9gjwcREZGEpFpOm5+fr1Yul8shl8s13isIAmbMmIHnnnsOHh4eYnlAQABee+01tG7dGmlpaVi4cCFeeOEFJCUlQS6XIzMzE2ZmZmjevLlaew4ODsjMzKzzs1SHiQcREdETyNnZWe08LCwM4eHhGu+ZOnUqzp8/j2PHjqmVjxo1SvzZw8MDPXr0QOvWrfHdd99h+PDhNbYnCAJkMl12Q6uKiQcREZGUJJrjkZ6eDmtra7H4cb0d06ZNwzfffIOff/4ZLVu21FjX0dERrVu3xpUrVwAASqUSpaWlyMnJUev1yMrKQq9ever6JNXiHA8iIiIpqQTdDwDW1tZqR02JhyAImDp1Knbv3o3Dhw/DxcXlsSHevXsX6enpcHR0BAB0794dpqamOHjwoFgnIyMDFy9elDzxYI8HERFRIzZlyhR8/vnn+Prrr2FlZSXOyVAoFLCwsEBBQQHCw8MxYsQIODo64tq1a5g/fz7s7OzwyiuviHWDg4Mxc+ZM2NrawsbGBrNmzYKnp6e4ykUqTDyIiIikpOfltBs2bAAA+Pn5qZVHR0cjKCgIxsbGuHDhAj777DPk5ubC0dERffv2xc6dO2FlZSXWX716NUxMTDBy5EgUFRWhX79+iImJgbGxcd2fpRpMPIiIiCSlY+IB7e4VHvNZFhYW+OGHHx7bjrm5OaKiohAVFaXV52uLczyIiIhIb9jjQUREJCW+JE4jJh5ERERSUgnQdrik6v2Gi0MtREREpDfs8SAiIpKSoHpw6HK/AWPiQUREJCXO8dCIiQcREZGUOMdDI87xICIiIr1hjwcREZGUONSiERMPIiIiKQnQMfGQLJInEodaiIiISG/Y40FERCQlDrVoxMSDiIhISioVAB324lAZ9j4eHGohIiIivWGPBxERkZQ41KIREw8iIiIpMfHQiEMtREREpDfs8SAiIpISt0zXiIkHERGRhARBBUGHN8zqcm9jwMSDiIhISoKgW68F53gQERERSYM9HkRERFISdJzjYeA9Hkw8iIiIpKRSATId5mkY+BwPDrUQERGR3rDHg4iISEocatGIiQcREZGEBJUKgg5DLYa+nJZDLURERKQ37PEgIiKSEodaNGLiQUREJCWVAMiYeNSEQy1ERESkN+zxICIikpIgANBlHw/D7vFg4kFERCQhQSVA0GGoRWDiQURERLUmqKBbjweX0xIRERFJgj0eREREEuJQi2ZMPIiIiKTEoRaNmHjUQmX2WY4ynfaEIXqSCRUlDR0CUb0pVz34862P3gRdf1eUo0y6YJ5ATDxq4d69ewCAY9jfwJEQ1aOrDR0AUf27d+8eFApFvbRtZmYGpVKJY5m6/65QKpUwMzOTIKonj0ww9MEkCahUKty6dQtWVlaQyWQNHc4/Qn5+PpydnZGeng5ra+uGDodIUvzzrX+CIODevXtwcnKCkVH9rasoLi5GaWmpzu2YmZnB3NxcgoiePOzxqAUjIyO0bNmyocP4R7K2tub/mMlg8c+3ftVXT8fDzM3NDTZhkAqX0xIREZHeMPEgIiIivWHiQU8kuVyOsLAwyOXyhg6FSHL8803/ZJxcSkRERHrDHg8iIiLSGyYeREREpDdMPIiIiEhvmHjQEyUmJgbNmjVr6DCIiKieMPGgehEUFASZTFbluHqV+3KTYanuz/nDR1BQUEOHSPRE4c6lVG8GDhyI6OhotbIWLVo0UDRE9SMjI0P8eefOnVi0aBEuX74slllYWKjVLysrg6mpqd7iI3rSsMeD6o1cLodSqVQ7PvroI3h6esLS0hLOzs6YPHkyCgoKamzj3Llz6Nu3L6ysrGBtbY3u3bsjMTFRvH78+HH07t0bFhYWcHZ2xvTp01FYWKiPxyMCALU/3wqFAjKZTDwvLi5Gs2bNsGvXLvj5+cHc3Bzbt29HeHg4unbtqtbOmjVr0KZNG7Wy6OhouLu7w9zcHB07dsT69ev192BE9YSJB+mVkZER1q5di4sXLyI2NhaHDx/GnDlzaqw/ZswYtGzZEgkJCUhKSsK7774r/mvxwoULGDBgAIYPH47z589j586dOHbsGKZOnaqvxyGqlblz52L69OlITU3FgAEDanXP5s2bsWDBAixduhSpqamIiIjAwoULERsbW8/REtUvDrVQvdm3bx+aNm0qngcEBODLL78Uz11cXLBkyRJMmjSpxn/J3bhxA7Nnz0bHjh0BAO3btxevffjhhwgMDERoaKh4be3atejTpw82bNjAFzXREyM0NBTDhw/X6p4lS5Zg5cqV4n0uLi64dOkSNm3ahHHjxtVHmER6wcSD6k3fvn2xYcMG8dzS0hJHjhxBREQELl26hPz8fJSXl6O4uBiFhYWwtLSs0saMGTMwYcIEbNu2Df3798drr70GV1dXAEBSUhKuXr2KuLg4sb4gCFCpVEhLS4O7u3v9PyRRLfTo0UOr+tnZ2UhPT0dwcDBCQkLE8vLycr28YZWoPjHxoHpjaWmJdu3aiefXr1/HoEGD8M4772DJkiWwsbHBsWPHEBwcjLKysmrbCA8PR2BgIL777jt8//33CAsLw44dO/DKK69ApVLh7bffxvTp06vc16pVq3p7LiJtPZpUGxkZ4dG3VTz8d0ClUgF4MNzi7e2tVs/Y2LieoiTSDyYepDeJiYkoLy/HypUrYWT0YHrRrl27Hnufm5sb3Nzc8O9//xuvv/46oqOj8corr6Bbt25ISUlRS26IGoMWLVogMzMTgiBAJpMBAJKTk8XrDg4OeOqpp/DHH39gzJgxDRQlUf1g4kF64+rqivLyckRFRWHo0KH49ddfsXHjxhrrFxUVYfbs2Xj11Vfh4uKCmzdvIiEhASNGjADwYMKej48PpkyZgpCQEFhaWiI1NRUHDx5EVFSUvh6LSGt+fn7Izs7GihUr8OqrryI+Ph7ff/89rK2txTrh4eGYPn06rK2tERAQgJKSEiQmJiInJwczZsxowOiJdMNVLaQ3Xbt2xapVq7B8+XJ4eHggLi4OkZGRNdY3NjbG3bt38eabb8LNzQ0jR45EQEAAFi9eDAB4+umncfToUVy5cgXPP/88vLy8sHDhQjg6OurrkYjqxN3dHevXr8fHH3+MLl264PTp05g1a5ZanQkTJuDTTz9FTEwMPD090adPH8TExMDFxaWBoiaShkx4dKCRiIiIqJ6wx4OIiIj0hokHERER6Q0TDyIiItIbJh5ERESkN0w8iIiISG+YeBAREZHeMPEgIiIivWHiQdRIhIeHo2vXruJ5UFAQXn75Zb3Hce3aNchkMrUtvh/Vpk0brFmzptZtxsTEoFmzZjrHJpPJsHfvXp3bIaL6w8SDSAdBQUGQyWSQyWQwNTVF27ZtMWvWLBQWFtb7Z3/00UeIiYmpVd3aJAtERPrAd7UQ6WjgwIGIjo5GWVkZfvnlF0yYMAGFhYXYsGFDlbplZWUwNTWV5HP5enQiaozY40GkI7lcDqVSCWdnZwQGBmLMmDFid3/l8MjWrVvRtm1byOVyCIKAvLw8TJw4Efb29rC2tsYLL7yAc+fOqbW7bNkyODg4wMrKCsHBwSguLla7/uhQi0qlwvLly9GuXTvI5XK0atUKS5cuBQDx/R5eXl6QyWTw8/MT74uOjoa7uzvMzc3RsWNHrF+/Xu1zTp8+DS8vL5ibm6NHjx44e/as1t/RqlWr4OnpCUtLSzg7O2Py5MkoKCioUm/v3r1wc3ODubk5XnzxRaSnp6td//bbb9G9e3eYm5ujbdu2WLx4McrLy7WOh4gaDhMPIolZWFigrKxMPL969Sp27dqFr776ShzqGDx4MDIzM7F//34kJSWhW7du6NevH/766y8AwK5duxAWFoalS5ciMTERjo6OVRKCR82bNw/Lly/HwoULcenSJXz++edwcHAA8CB5AIBDhw4hIyMDu3fvBgBs3rwZCxYswNKlS5GamoqIiAgsXLgQsbGxAIDCwkIMGTIEHTp0QFJSEsLDw6u8zKw2jIyMsHbtWly8eBGxsbE4fPgw5syZo1bn/v37WLp0KWJjY/Hrr78iPz8fo0ePFq//8MMPeOONNzB9+nRcunQJmzZtQkxMjJhcEVEjIRBRnY0bN0546aWXxPNTp04Jtra2wsiRIwVBEISwsDDB1NRUyMrKEuv8+OOPgrW1tVBcXKzWlqurq7Bp0yZBEATB19dXeOedd9Sue3t7C126dKn2s/Pz8wW5XC5s3ry52jjT0tIEAMLZs2fVyp2dnYXPP/9crWzJkiWCr6+vIAiCsGnTJsHGxkYoLCwUr2/YsKHath7WunVrYfXq1TVe37Vrl2BrayueR0dHCwCEkydPimWpqakCAOHUqVOCIAjC888/L0RERKi1s23bNsHR0VE8ByDs2bOnxs8loobHOR5EOtq3bx+aNm2K8vJylJWV4aWXXkJUVJR4vXXr1mjRooV4npSUhIKCAtja2qq1U1RUhN9//x0AkJqainfeeUftuq+vL44cOVJtDKmpqSgpKUG/fv1qHXd2djbS09MRHByMkJAQsby8vFycP5KamoouXbqgSZMmanFo68iRI4iIiMClS5eQn5+P8vJyFBcXo7CwEJaWlgAAExMT9OjRQ7ynY8eOaNasGVJTU/HMM88gKSkJCQkJaj0cFRUVKC4uxv3799ViJKInFxMPIh317dsXGzZsgKmpKZycnKpMHq38xVpJpVLB0dERP/30U5W26rqk1MLCQut7VCoVgAfDLd7e3mrXjI2NAQCCINQpnoddv34dgwYNwjvvvIMlS5bAxsYGx44dQ3BwsNqQFPBgOeyjKstUKhUWL16M4cOHV6ljbm6uc5xEpB9MPIh0ZGlpiXbt2tW6frdu3ZCZmQkTExO0adOm2jru7u44efIk3nzzTbHs5MmTNbbZvn17WFhY4Mcff8SECROqXDczMwPwoIegkoODA5566in88ccfGDNmTLXtdurUCdu2bUNRUZGY3GiKozqJiYkoLy/HypUrYWT0YFrZrl27qtQrLy9HYmIinnnmGQDA5cuXkZubi44dOwJ48L1dvnxZq++aiJ48TDyI9Kx///7w9fXFyy+/jOXLl6NDhw64desW9u/fj5dffhk9evTAv/71L4wbNw49evTAc889h7i4OKSkpKBt27bVtmlubo65c+dizpw5MDMzw7PPPovs7GykpKQgODgY9vb2sLCwQHx8PFq2bAlzc3MoFAqEh4dj+vTpsLa2RkBAAEpKSpCYmIicnBzMmDEDgYGBWLBgAYKDg/Hee+/h2rVr+M9//qPV87q6uqK8vBxRUVEYOnQofv31V2zcuLFKPVNTU0ybNg1r166Fqakppk6dCh8fHzERWbRoEYYMGQJnZ2e89tprMDIywvnz53HhwgV88MEH2v+HIKIGwVUtRHomk8mwf/9+9O7dG+PHj4ebmxtGjx6Na9euiatQRo0ahUWLFmHu3Lno3r07rl+/jkmTJmlsd+HChZg5cyYWLVoEd3d3jBo1CllZWQAezJ9Yu3YtNm3aBCcnJ7z00ksAgAkTJuDTTz9FTEwMPD090adPH8TExIjLb5s2bYpvv/0Wly5dgpeXFxYsWIDly5dr9bxdu3bFqlWrsHz5cnh4eCAuLg6RkZFV6jVp0gRz585FYGAgfH19YWFhgR07dojXBwwYgH379uHgwYPo2bMnfHx8sGrVKrRu3VqreIioYckEKQZxiYiIiGqBPR5ERESkN0w8iIiISG+YeBAREZHeMPEgIiIivWHiQURERHrDxIOIiIj0hokHERER6Q0TDyIiItIbJh5ERESkN0w8iIiISG+YeBAREZHeMPEgIiIivfk/dwlXKxg39aoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculate mean F1 scores over all folds\n",
    "mean_f1_scores = np.mean(fold_f1_scores, axis=0)\n",
    "mean_fhalf_scores = np.mean(fold_half_scores, axis=0)\n",
    "mean_fdouble_scores = np.mean(fold_double_scores, axis=0)\n",
    "mean_recall = np.mean(fold_recalls, axis=0)\n",
    "mean_precision = np.mean(fold_precisions, axis=0)\n",
    "\n",
    "for i in range(len(thresholds)):\n",
    "     print(\"Fold\", i*0.1+0.1, \"  Precision: \", fold_precisions[i], \"  Recall: \", fold_recalls[i])\n",
    "     print(\"F1 Score: \", fold_f1_scores[i], \"F-0.5 Score: \", fold_half_scores[i], \"F-2 Score: \", fold_double_scores)\n",
    "     print()\n",
    "\n",
    "print(\"  Mean precision: \", mean_precision, \"  Mean recall: \", mean_recall)\n",
    "print(\" Mean F1 Score: \", mean_f1_scores)\n",
    "print(\" Mean F-0.5 Score: \", mean_fhalf_scores)\n",
    "print(\" Mean F-0.5 Score: \", mean_fdouble_scores)\n",
    "\n",
    "\n",
    "#Print confusion matrix\n",
    "import matplotlib.pyplot as metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "for i in range(len(fold_cm)):\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix = fold_cm[i], display_labels = [False, True])\n",
    "    cm_display.plot()\n",
    "    title = i * 0.1+0.1\n",
    "     \n",
    "    plt.title(f'Confusion Matrix {title: .1f}')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "#pick 0.9 as threshold for now, but we might have to priotize recalls moving on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fold_recalls, fold_precisions, marker='o', linestyle='-')\n",
    "plt.xlabel('Recalls')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Recalls vs Precision')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIhCAYAAABdSTJTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACSjklEQVR4nOzdeVzVVf7H8de9lx0BRQQBEXFfcN81LUvNFm3RNisrW35qNeM4Ndo0LbZv49im7anZ7lJq5VZZ7ntm7isoIKgooMh27/f3x1dJAhQU+HLh/Xw8eAzn8L3czz0x+Obc8z3HZhiGgYiIiIiIG7JbXYCIiIiIyIVSmBURERERt6UwKyIiIiJuS2FWRERERNyWwqyIiIiIuC2FWRERERFxWwqzIiIiIuK2FGZFRERExG0pzIqIiIiI21KYFRG5AFOmTMFmsxX58cgjj+RfN2/ePIYNG0br1q3x9PTEZrOV+rnS09N5/vnn6dSpE4GBgXh7e9OgQQOGDx/Ohg0byvJliYi4HQ+rCxARcWcff/wxzZs3L9AXERGR//ns2bNZtWoV7du3x9vbm/Xr15fq++/Zs4f+/fuTkpLCiBEjGD9+PDVq1GD//v189dVXdOzYkePHjxMUFFQmr0dExN0ozIqIXITY2Fg6depU7Nfff/997HbzTbCHHnqoVGHW6XRyww03cOTIEVauXElsbGz+1y699FLuuusufvjhBzw9PS/8BZxmGAZZWVn4+vpe9PcSEalIWmYgIlKOzgTZC/HNN9+wefNmHnvssQJB9mxXXXUVfn5+ANx99900aNCg0DVPP/10oeUNNpuNhx56iHfeeYcWLVrg7e3NBx98QGhoKHfeeWeh73H8+HF8fX0ZM2ZMfl96ejqPPPIIMTExeHl5ERkZyejRozl58uQFv2YRkdLSzKyIyEVwOp3k5eUV6PPwKJtfrQsXLgTg+uuvL5Pv91fffPMNS5cu5cknn6Ru3bqEhoayb98+3nnnHd5++20CAwPzr/3888/JysrinnvuASAzM5NLL72UgwcP8u9//5s2bdqwZcsWnnzySTZv3szixYsvaH2wiEhpKcyKiFyEbt26FerLzc0tk0AbHx8PQExMzEV/r6KcOHGCzZs3U6tWrfy+e+65h//97398+eWX3H///fn9U6ZMoWPHjrRu3RqAN954g99//53Vq1fnL7O44ooriIyMZMiQIcyfP5+rrrqqXOoWETmblhmIiFyEadOmsXbt2gIfZTUzW94uv/zyAkEWoHXr1nTs2JGPP/44v2/btm2sWbOG4cOH5/fNmzeP2NhY2rVrR15eXv7HlVdeic1mY8mSJRX1MkSkmnOP37giIpVUixYtznkD2MWoX78+APv27Su0Y0JZCA8PL7J/+PDhPPjgg2zfvp3mzZvz8ccf4+3tzW233ZZ/TXJyMrt37y725rMjR46Ueb0iIkXRzKyISCV15ZVXAuba1pLw8fEhOzu7UH9xwbK4Na233XYb3t7eTJkyBafTySeffML1119fYBY3JCSE1q1bF5qVPvPxxBNPlKhmEZGLpZlZEZFK6rrrrqN169a8+OKLXHvttUXuaLBgwQJ69eqFn58fDRo0ICUlheTkZMLCwgDIyclhwYIFpXreWrVqcf311zNt2jS6d+/OoUOHCiwxALj22mt54YUXqF27drmt6RURKQmFWRGRchQXF8fatWsB8wAEgBkzZgDQoEGDcy5RcDgczJ49m/79+9O9e3dGjhxJnz598Pf3Jy4ujhkzZjB37lyOHTsGwC233MKTTz7JrbfeyqOPPkpWVhZvvPEGTqez1HUPHz6cL7/8koceeoh69erRt2/fAl8fPXo0M2fOpHfv3vzjH/+gTZs2uFwu4uPjWbhwIf/85z/p2rVrqZ9XRKS0FGZFRMrRzz//nL+d1Rk33XQTAHfddRdTpkw55+MbNWrEhg0bePPNN5k9ezaTJ08mOzub8PBwevfuzbJly/JP/4qJieHbb7/l3//+N0OGDCE8PJwxY8Zw+PBhxo8fX6q6+/btS1RUFAcOHODxxx8vtF+uv78/S5cu5aWXXuK9995j3759+Pr6Ur9+ffr27VvkfrciIuXBZhiGYXURIiIiIiIXQjeAiYiIiIjbUpgVEREREbelMCsiIiIibkthVkRERETclsKsiIiIiLgthVkRERERcVuW7zM7adIkXn31VZKSkmjVqhUTJ06kV69exV7/9ttv89Zbb7F//37q16/P448/zrBhw0r8fC6Xi8TERAICAoo9ylFERERErGMYBhkZGURERBTa57qoiy3zxRdfGJ6ensb7779vbN261fj73/9u+Pv7G3FxcUVeP2nSJCMgIMD44osvjD179hiff/65UaNGDWPOnDklfs4DBw4YgD70oQ996EMf+tCHPir5x4EDB86b7Sw9NKFr16506NCByZMn5/e1aNGC66+/nhdffLHQ9T169KBnz568+uqr+X2jR49m3bp1LFu2rETPmZaWRs2aNTlw4ACBgYEX/yJKIDc3l4ULF9K/f388PT0r5DndgcalaBqX4mlsiqZxKZ7Gpmgal+JpbIpW0eOSnp5OVFQUx48fzz/lsDiWLTPIyclh/fr1jBs3rkB///79WbFiRZGPyc7OxsfHp0Cfr68va9asITc3t8jBzc7OJjs7O7+dkZGR/zhfX9+LfRkl4uHhgZ+fH76+vvo/xlk0LkXTuBRPY1M0jUvxNDZF07gUT2NTtIoel9zcXIASLQm1bGY2MTGRyMhIli9fTo8ePfL7X3jhBaZOncqOHTsKPebf//43H3/8MfPmzaNDhw6sX7+ea665hpSUFBITEwkPDy/0mKeffrrIM8k/++wz/Pz8yvZFiYiIiMhFy8zMZOjQoaSlpZ33nXTLbwD7a+I2DKPYFP7EE09w6NAhunXrhmEYhIWFcffdd/PKK6/gcDiKfMxjjz3GmDFj8ttnpq379+9focsMFi1aRL9+/fRX3lk0LkXTuBRPY1M0jUvxNDZF07gUT2NTtIoel/T09BJfa1mYDQkJweFwcOjQoQL9KSkphIWFFfkYX19fPvroI959912Sk5MJDw/nvffeIyAggJCQkCIf4+3tjbe3d6F+T0/PCv8hteI53YHGpWgal+JpbIqmcSmexqZoGpfiaWyKVlHjUprnsGyfWS8vLzp27MiiRYsK9C9atKjAsoOieHp6Uq9ePRwOB1988QXXXnvt+bdtEBEREZEqx9JlBmPGjOHOO++kU6dOdO/enffee4/4+HhGjBgBmEsEEhISmDZtGgA7d+5kzZo1dO3alWPHjjFhwgT++OMPpk6dauXLEBERERGLWBpmb7nlFo4ePcozzzxDUlISsbGxfP/990RHRwOQlJREfHx8/vVOp5P//ve/7NixA09PT/r06cOKFSto0KCBRa9ARERERKxk+Q1go0aNYtSoUUV+bcqUKQXaLVq0YOPGjRVQlYiIiIi4Ay00FRERERG3pTArIiIiIm5LYVZERERE3JbCrIiIiIi4LYVZEREREXFbCrMiIiIi4rYUZkVEREQAp8vJuuR1bMrZxLrkdThdTqtLkhKwfJ9ZEREREastjlvMS2teIjkzGYCvf/yaML8wxnUZR9/ovhZXJ+eimVkRERGp1hbHLWbMkjH5QfaMlMwUxiwZw+K4xRZVJiWhMCsiIlKN6K10yHXlkp6TTvLJZPYc38Nzq57DwCh03Zm+l9e8XC3HyV1omYGIiEg14S5vpee58jiVdyr/Iysvi1N5p8jMy8z//K9fK+rj7K+d/XmekVfiWgwMDmUeYkPKBjrX7VyOr1oulMKsiIhINXDmrfS/zkCeeSt9wmUTShxonS5ngZCYmZdZdIB0ng6huZkF2qdyz/q8iI88V8nD5sWw2+x42j3Jdmaf99rtqdsVZisphVkREZEqzuly8uKaF8/5Vvrjyx5necLy/JB5rhnPXFduhdRtt9nx9fDFx+GDr4cvvp6++Dp8zc9Pf/h4+BT5+V8/ivqap92TdcnrGL5g+HlreWXtK/x68FcGNx3MFVFX4OnwrIARkJJQmBUREXFTuc5cjmYdNT9OmR9HTh3haJb5v0dOHeHoqaMkn0zmlPPUOb9XZl4mM3bNKNXz27AVCot+Hn6FgmNxIbOo6/w8/PI/97J7YbPZLmaIzqtDaAfC/MJIyUwpMuwDeNm9yHHlsCppFauSVhHsE8x1ja7jxiY30iCoQbnWJ+enMCsiIlKJOF1OjmUfyw+ifw2nqadS8/uOZx8v0+fuF92PtnXamjOhnr7nnhX19K2QsFneHHYH47qMY8ySMdiwFQi0NszX9nLvl2lRuwWzds1i9q7ZHD51mI+3fMzHWz6mc93ODG4ymL7RffF2eFv1Mqo1hVkREamSzr5rPzQ5lC4RXXDYHZbU4jJcHM8+XiCcnj2TenZgPZ59HJfhKvH39rB5EOwTTG3f2oT4hvz5vz5/thNPJPKf5f857/e6rflt1XJdaN/ovky4bEKBm+MAwvzCGNtlbP5a4ofbP8zItiNZenApM3bNYFnCMtYeWsvaQ2sJWhPEwIYDGdJ0CI1qNrLqpVRLCrMiIlLlVMRd+4ZhkJ6TbobS00H0r+H0TGA9mnUUp1HyrZ1s2AoG1LOC6V/7gryDsNvOvdOm0+XkzY1vFvtWug0bYX5hdAjtUOpxqCr6RvelT1Qf1iSuYdHKRfTr3q/IP4A87B70qd+HPvX7cOjkIWbvms2s3bM4dPIQ07dNZ/q26bQPbc/gJoPp36A/vh6+Fr2i6kNhVkTEjVWm2cfK4mLu2jcMg5O5JwuF0zPBNL8vy/zf0t4IVdO7Zn4QPTuY/jWw1vSuiYe97P6JLslb6WO7jK32PzsOu4NOYZ1I8UqhU1in845HXf+6jGw3kgfaPMDyxOXM3DmTXw7+wsaUjWxM2cjLa17mmobXMKTpEJoFN6ugV1H9KMyKiLgpd9kztCI5XU5eWvPSOe/aH79yvLn2NCu1UDg9euooWc6sUj1ngGfAOd/ir+1bmxCfEIJ9g/G0W3cHfEnfSpfSc9gd9K7Xm971epOSmcK3u79l5q6ZJJxI4IsdX/DFji9oHdKaIU2HMKDBAPw8/awuuXRcTmxxy4hMXYktLhAa9oZK9IePwqyIiBsqyz1DK4phGOS4csh2ZpPjzCHHWcznxVyT7cwmx1XM4073Hzl1pNCRpH91PPs4z69+/pzX+Hn4FZg1DfYJ/jOs+oQUCKrudNNPSd9KlwsX6hfK/W3u597W97IqaRUzds7g5/if2XxkM5uPbOaVta9wdczVDG46mFa1W1ld7vltnQPzx+KRnkgngLjJEBgBA16GloOsrg5QmBURcTvnm320YePlNS/TJ6pPfkhxupxkO7PJdeWS7cwuVYg8V39RwfLs5zm7v6L2Ji2JlsEtaRXSKj+cnj2zWtuntvvNnJVCad9Klwtjt9npEdGDHhE9OHLqCHP2zGHmzpnEZ8Tz9c6v+Xrn17QIbsGQpkO4OuZqanjVsLrkwrbOga+GwV9/16Qnmf03T6sUgVZhVkTEzWxI2XDO2cczx2/2/KInLsNFrjO3VMd3VhRvhzdeDi/zf+1ef37u8Dpvv6fdE2+Ht/m548/P4zPieWfTO+d97kc6P1It79oXa4T4hjA8djj3tLqHtYfWMmPXDBbHLWZb6jaeXfUsr617jQENBjCk6RBah7SuHNuduZwwfyyFgiyc7rPB/HHQ/BrLlxwozIqIuAmX4WJb6ja+2vFVia4/mXuyyH6HzXH+sOjwxNteOCwW+LyYQHl2f4Fg6vDCy25+7mH3KJd/sJ0uJ7N3zdZd+1Ip2Ww2uoR3oUt4F45lHWPunrnM2DWDfWn7mL17NrN3z6ZJrSYMaTKEaxtdS6BXoHXFxq2A9MRzXGBAeoJ5XUyvCiurKAqzIiKV2KGTh1iZuJKViStZlbSKY9nHSvzYZ3s+S8ewjgVCq5fDq0zvkq9sdNe+uItaPrUY1moYd7a8k40pG5mxcwYL4xay69guXlzzIhPWT+DKBlcyuMlg2oe2r/jZ2hPnXnte6uvKUdX9jSYi4oYyczNZl7yOlYkrWZG4gr1pewt83d/Tn05hndiQsoGMnIwiv8eZ2ceBDQdWy9Cmu/bFndhsNjqEdaBDWAfGdhnLvL3zmLlrJruO7WLOnjnM2TOHhkENGdxkMIMaDaKmT82KKSz33Mcf56sRVr51lIDCrIiIhc4sHTgTXjembCTP9ef6VrvNTmztWLpHdKdHRA9a12mNp90zfzcDQLOPRdBd++KOgryDuL3F7QxtPpTfj/zOzJ0zmb9/PnvT9vLquleZuGEifaP7clPTm+gU1ql8ZmsNAzZOh+/+eZ4LbeauBtE9yr6GUlKYFRGpYOdbOhDhH0GPSPMu6C51uxDkHVToe2j28fx01764K5vNRts6bWlbpy3/6vwvvt/3PTN2zmBb6jZ+2PcDP+z7gejA6PzZ2tq+tcvmiXNOwnePwKbPzHbdNnBo8+nbvf78o9k482fzgJcsv/kLFGZFRMpdSZYOdK7bOX8bn/oB9Us046LZR5Gqr4ZXDW5udjM3N7uZLUe3MGPnDL7f+z1x6XFMWD+BNza+weVRlzO46WC6hXc779HGxTq8A766Cw5vA5sdLv8P9PwHGxd9QsTK8YRxNP/SZIJJ6v4U7SvBtlygMCsiUuYudOnAhdDso0j10ap2K1p1b8WjnR7lh30/MHPXTDYf2czCuIUsjFtIZI1IBjcZzPWNr6eOX52Sf+NNX8K8f0DuSXMN7JCPoMElzP8jiZE/h2DjdbrYtxPKcVKoyVpXc1w/25kcmcSA2PDye8ElpDArIlIGzl46sDJpJcezjxf4ekmWDoiIlISfpx+Dmw5mcNPB7EjdwYydM5i3dx4JJxJ4Y+MbvP3b21xa71KGNB1Cj4gexf+Rm3sKfhgLG6aa7ZhLYfAHUCMUp8tg/NytGICBnVWulgUeagPGz91Kv5Z1cdit3RdXYVZE5AKUZOlAl7pd6BHRg+4R3Uu8dEBEpDSaBTfj8W6PM6bTGBbuX8iMnTP47fBv/HTgJ3468BPh/uHc0OQGbmh8A3X96/75wKN7zGUFyZsBG1w6Fi79F6fyYGtcKnM3JZGUllXs8xpAUloWa/al0r1RGa3ZvUAKsyIiJVCRSwdERErL18OX6xpfx3WNr2P3sd3M3DWTOXvmkHQyiUm/TeKdTe/QK7IXg5sMplf6UTzmjIacDHJ9avNji+dYmNKSP15fxu6UE7iKOvSrGCkZxQfeiqIwKyJSDC0dEBF31LhWY8Z2GcvojqNZFLeImTtnsi55Hb8c/IVfDv5CaF4e1/vZaZTXlKeP/52UlUFAQv7j6wR4U6+mLxsPHD/vc4UG+JTfCykhhVkRkdO0dEBEqoK0U7lsSUjjj8Q0NidEsj/hLmpkxNI7eCorA/JI8fDgvVpBGDWz8cj+lg4+V3BJRG/a1qtN68ggQgN9cLoMLnn5Jw6lZRVxMLS5ZrZukA9dYoIr+uUVojArItVWiZYOhMTSPVxLB0SkcjqemcMfCelsTkjjj9MBNu5oZoFr+trX81/PyQQdyyQ1LYDJTe5gg08SO9M34PTZzi62k5r6Bbbg62jCYKA+DruNpwa2ZOT0DdhwYffbh80jAyMvAFdmDGDnqYEtLb/5CxRmRaSaOd/SgcgakfnrXrV0QEQqk9STOX+G1oQ0NiekcfBY0cfO1qvlS9sIf+7Lnkb7g9NPd3YmeMjHPF4zCoAD6QeYuWsm3+z+hqNZR/noj4/46I+P6Fq3K0OaDuHyFpcz6ppMPtn1BobjeP73tjlrcmeTv1WKbblAYVZE3ITT5WRd8jo25WwiNDm0xIcDlGbpQI+IHkQFRGnpgIhY7nBGdoHQ+kdCGonF7C4QXduP2MggYiOCaB0ZRGxkIDVzU+Dre+DgGvOibg9C36fBwyv/cVGBUYzuOJoH2z/Irwd+5etdX7MiYQWrD61m9aHV+Hv4czLvJPz1V60jjU/2Pkv7+rUqxWmDCrMiUuktjltc4NjWr3/8mjC/MMZ1GVfoF6mWDoiIu0lOz2LzQXOJwJnwmpyeXeS1DUP8aRUZROvIQGIjg2gVEUSQ719+h+1aDLPuh1Op4B0E178NLQYW+/yedk+uiL6CK6KvIOFEArN3zWbWzlkczjpc5PXG6QNtX17zMn2i+lh+WIvCrIhUaovjFjNmyRiMv9yCkJKZwpglY5hw2QRiQ2Lzw+uqpFVaOiAilZJhGCSlZRWccU1M53BG4eBqs0GjOjWIjTBDqxlcAwnwOccf3848WPICLP2v2Q5vCzdNheCYEtcYWSOSh9o/RKewTty/6P7iXwsGhzIPsSFlA53rdi7x9y8PCrMiUmk5XU5eWvNSoSAL5Pc98ssjOA1nga9p6YCIWM0wDBKOnzprmUA6fySkcfRkTqFr7TZoHFrjz6UC9YJoGR6Iv3cpYlrGIZhxL8QtM9ud74P+z4PnhW2dlZqVWqLrDmcWPXtbkRRmRaTS2pCyIX9pQXGchhMbNlrXaW1umRXeXUsHROSCOF0Gq/elsv6Ijdr7UuneOLREd+sbhsGB1FOnZ1r/vEHrWGZuoWsddhtNQmucXttqfrQID8DP6yIi2d5fYOa9cPIweNWAQW9A7OAL/35AHb86ZXpdeVKYFRHLpWWnEZceR1x6HAcyDhCXHkd8ejx7ju8p0eOf7P4kQ5oOKecqRaQqm/9HEuPnbj19hKuDabvWER7kw1MDWxa4a9/lMohLzSx0c1Z6Vl6h7+lht9E0LMAMrvXMm7Oa1w3Ax7OM1pi6nPDra7DkRcCA0FZw8zQIaXzR37pDaAfC/MJIyUwp8t0xGzbC/MLoENrhop/rYinMikiFSMtOIz49nrgMM6jGZ8Sb7fQ40nPSL+p7RwdGl1GVIlIdzf8jiZHTNxSKbIfSshgxfQPDezbAbrPxR2IaWxLSycguHFy9HHaa1Q04PdsaSOvIIJrVDcDbo5xujjpx2LzJa+/PZrv9nXD1q+DpWybf3mF3MK7LOMYsGYMNW4FAa8OcrR7bZazlN3+BwqyIlKEzgTU/qGbEcSD9AHEZcaRlp53zsaF+oUQHRlM/oD71A+sTHRBNZEAkD/74IIczD1f6mQERcU9Ol8H4uVuLPOXqTN9Hy/cX6PfysNMiPJDYiMD85QJNwwLw8rCXd7mmuBUwYzhkJIGnH1wzAdrdVuZP0ze6LxMum1BgNxmAML8wxnYZWym25QKFWREppfScdDOwnj3LejrA/nUXgb8K9QulfkB9M7QG1s8PrlEBUfh6FD2b8FiXx9xiZkBE3NOafamnlxacW/+WYfRtGUZsRBBNwmrg6aig4Ho2lwtWvA4/PguGE0Kawc1TIbRFuT1l3+i+9Inqw5rENSxauYh+3fuVeJ/viqIwKyKFZORk5C8B+Oss67HsY+d8bKhvKFGBUfmzrNGB0UQFRBEVEIWfp1+pa3GXmQERcS+GYbBmXyovz99WouuvaRPOde0iy7mqc8hMhdn/B7sWmu02t5gzst41yv2pHXYHncI6keKVQqewTpUqyILCrEi1lZGTUWDd6tk3Xp0vsNbxrVNgZvVMcL3QwHo+7jAzICLu4VSOk29/S2DKiv1sP5RR4seFBlzYFldl4sBa+PpuSD8IDm9zbWyHYeZmtKIwK1KZXOiRrcU5kXOiQGA983l8Rvx59xAM8Q0ptCTgzCxreQTW86nsMwMiUrkdSM1k+qo4vlh7gLRT5pZZPp52rmsXyY/bkjl6IqfIdbM2oG6QD11igiu0XgAMA1ZNgkVPgisPghuZywrqtq74WioxhVmRSqI0R7ae7WTuyYLLAc6aZS1pYD0zuxoV8OfyACsCq4hIWTIMgxV7jjJlxX5+3JaM63RajQr2ZVi3BtzcKYogP8/83QxsUCDQnpn3fGpgyxLtN1umTh2Hbx+E7fPMdsvrYdCb4BNYsXW4AYVZkUrgfEe2vtDrBRoFNfpzd4CzwuvRrKPn/N61fWoXnFkNjCI6wJxt9ff0L8+XJSJiiZPZeczamMC0FfvZlXIiv/+SxiHc1aMBlzcveBjCgNhwJt/R4ax9Zk11i9hntkIkboSv7oLjceDwgitfME/00rKCIinMilisJEe2Prb0sXN+j2Cf4IIzq2fWswbUp4ZX+d8cICJSGew/cpJpK+P4ev0BMk4fYuDn5WBwh3rc1SOaxqEBxT52QGw4/VrWZeXuFBYuXU3/Xl1LfAJYmTEMWPsBLPg3OHOgZn24aSpEavvBc1GYFbFYSY5sBQjwDKBRzUYFZlnPfK7AKiLVlctl8Ouuw0xdsZ8lOw9jnJ4XiAnxZ1j3aAZ3rEegT8mOt3bYbXSNCeboNoOuMcEVG2SzM2DO32DLLLPd7Bq4/m3wrVVxNbgphVkRi+08trNE1/2n23+4uuHV5VyNiIh7yMjKZcb6g0xbGce+Iyfz+/s0q8NdPRrQu0kd7BW9zvVCHfoDvr4Lju4Guwf0HQ/dH9SyghJSmBWxSOKJRN7f/D6zds0q0fV1/OqUc0UiIpXf7pQTTFu5n5nrD3IyxwlAgLcHQzrVY1j3BsSEuNG9AIYBGz+B7x+FvCwIjISbpkBUF6srcysKsyIV7EyI/Wb3N+S5zDVdXnYvclw5RV6vI1tFpLpzugx+3p7C1JX7WbrrSH5/49Aa3NU9mhs71MPf280iTc5J+O6fsOlzs924H9zwLvjXtrYuN+Rm/+VF3FfCiQTe//19vt39LXmGGWK7hXdjZNuRpGalMmbJGAAd2SoiclpaZi5frTvAJ6viiE/NBMx33q9oHsbdPRrQs3FtbO74VvzhHfDVMDi8HWx2uPw/0PMfYLfgiNwqQGFWpJydK8R2CPtztlVHtoqImHYcymDKiv18szGBU7nmUoIgX09u6RzFnd2iiQp2432wN30J80ZDbibUqAtDPoQGl1hdlVtTmBUpJwczDvLB5g8KhNju4d0Z2W4k7UPbF7peR7aKSHWW53SxeFsKU1bsY9XePw98aV43gLt6NOD6dpH4ernx78PcU/DDWNgw1WzHXAqDP4AaodbWVQUozIqUsdKG2LPpyFYRqW6Onczhi7UHmL4qjoTjpwBzi6z+LcO4q0cDusYEu+dSgrMd3WMegpC8GbDBZeOg96Og3/FlQmFWpIwczDjI+5vfZ87uOfkhtkdED0a2HUm70HbWFiciUslsSUxj6or9fPtbItl5LgCC/b24tXMUd3SLJqKmr8UVlpE/Zpn7x+ZkgF+IORvbqI/VVVUpCrMiF+lAxgE+2PyBQqyIyHnkOl0s2HKIqSv2s3b/sfz+2MhA7uregIFtI/DxrCKzlXnZsPA/sOY9sx3dEwZ/CIEVfDRuNaAwK3KBigqxPSN6MqLtCIVYEZGzHDmRzeer4/l0dTyH0rMA8LDbuKp1OHf3iKZD/Vruv5TgbMf2w9d3Q+JGs33JGOjzODgUu8qDRlWklA5kHOD9399nzp45OA3zLluFWBGRwjYdOM7UFfuZ93sSOU5zKUFIDW+Gdq3P7V3rExboY3GF5WD7d/DNSMhKM4+iveE9aNrf6qqqNIVZkRIqMsRG9mRk25G0rdPW4upERCqHnDwX329OYsqK/fx24Hh+f7uomtzdowFXtw7Hy6MK7qfqzIXFT8PKt8x2vc4w5GOoGWVpWdWBwqzIeRxIP8B7m99j7p65CrEiIsVITs/i09XxfLY6niMnsgHwcti5tk04d/VoQNuomtYWWJ7SDsLX98DBNWa7+0NwxVPg4WVtXdWEwqxIMYoKsZdEXsLItiNpU6eNxdWJiFjPMAw2xB9jyoo4fticRJ7LPMEwLNCbO7pGc1vX+oTU8La4ynK2axHMegBOpYJ3EFw/CVpca3VV1YrCrMhfxKfH897v7zFv7zyFWBGRImTlOpm7KZGpK/fzR0J6fn/nBrW4q0cDrmxVF09HFVxKcDZnHvz8PCybYLbD28FNUyA4xsqqqiWFWZHTFGJFRM4t8fgppq+K44u1B0g9mQOAt4ed69pFMKx7A2IjgyyusIKkJ8HMeyFuudnufD9c+Tx4VPFZ6EpKYVaqvfj0eN79/V2+2/tdfojtFdmLkW1H0rpOa4urExGxlmEYrN6XytQV+1m4NRnn6aUEkTV9uaNbNLd2jqKWfzVaG7p3Ccy8D04eBq8AGPQ6xA62uqpqTWFWqi2FWBGR4p3KcfLNbwlMXbGf7Ycy8vu7N6zNXT0a0LdFKB5VfSnB2VxO+PVVWPISYEBYLNw0FUIaW11ZtacwK9VOXHpc/nICl2Hue9i7Xm9GtBmhECsiVZ7TZc60rj9io/a+VLo3DsVh//PAggOpmXyyKo4v1x4g7VQuAL6eDm7oEMld3RvQrG6AVaVb58RhmHWfOSsL0GEYXPUKeFaRI3fdnMKsVBvFhdiRbUcSGxJrcXUiIuVv/h9JjJ+7laS0LMDBtF3rCA/y4clrWxLo68mUFftZvC0Zw1xJQP1gP4Z1j+amjlEE+XlaWnuFcDmxxS0jMnUltrhAaNgb4lfBjOFw4hB4+sG1/4O2t1pdqZxFYVaqvP1p+3nv9/f4bt93+SH20nqXMqLtCIVYEak25v+RxMjpGzD+0p+UlsXITzcU6OvVJIS7ezTgsmYFZ22rtK1zYP5YPNIT6QQQNxm8AyH7BOCCkGZw8zQIbW5xofJXCrNSZRUXYke2HUmrkFYWVyciUnGcLoPxc7cWCrJnswF3dKvPXT1iaBxao6JKqxy2zoGvhsFfRyj79LZj0T3h9q/By7/CS5PzU5iVKmdf2j7e+/09vt/3fX6IvazeZYxoO0IhVkSqpTX7Uk8vLSieAVzdOqL6BVmXE+aPpVCQPdux/eDhU1EVSSkpzEqVUWyIbTeCVrUVYkWk+toYf6xE16VknDvwVklxKyA98dzXpCeY18X0qpiapFQUZsXt7Uvbx7u/v8sP+374M8RGnZ6JVYgVkWpsY/wx3v55N4u3pZTo+tCAajj7eCK5bK+TCqcwK25rb9pe3vv9PYVYEZG/WL33KG/9vJulu44A5npYb087WbmuIq+3AXWDfOgSE1xxRVYWaQdLdl2NsPKtQy6Ywqy4nb1pe3l3kzkTa5xe49Qnqg8j2o6gZe2WFlcnImINwzD4ddcR3vppF2v3m8sKPOw2bmgfycjLGrEzOYOR081dC85eHXpmr4KnBrasPjsXAOTlwE/PwIo3z3OhDQIjILpHhZQlpacwK25DIVZEpDCXy2DRtmTe+mk3mxPSAPDysHNLpyj+79KG1KvlB0DDOjWYfEeHs/aZNdUN8uGpgS0ZEBtuSf2WOLrH3Ds26Tez3bgf7F58+otFRP0BL4HdUYEFSmkozEqlt/f4Xt75/R3m75ufH2Ivj7qcEW1H0KJ2C4urExGxhtNl8N3mJN7+aTc7ks3jZn09HdzetT73925IWGDh9a8DYsPp17IuK3ensHDpavr36lroBLAqb9OX8N0YyDkBvrXgureh+TX5+8wWuBksMMIMsi0HWVevnJfCrFRaCrEiIoXlOl3M3pjA5CV72HfkJAAB3h4M6xHN8J4x1K7hfc7HO+w2usYEc3SbQdeY4OoTZLMz4PtHYdPnZju6J9z4PgRFmu2Wg6D5NeTt/ZXfli6gXa8r8WjYWzOybkBhVizhdDlZl7yOTTmbCE0OpUtEFxynf2HsOb6Hdze9y/z9f4bYK+pfwYi2I2gerJNXRKR6ysp18vX6g7yzZA8Jx08BUNPPk3t7xjCsRwOCfKvBcbMXKnEjzLgXUveAzQ6XjoPejxQOqnYHRvQlJGxJp230JQqybsLyMDtp0iReffVVkpKSaNWqFRMnTqRXr+L3cfv000955ZVX2LVrF0FBQQwYMIDXXnuN2rVrV2DVcjEWxy3mpTUvkZxpbnPy9Y9fE+YXxt2t7ub3w78rxIqInCUzJ4/PVsfz3q97ScnIBiCkhjcP9I7h9q7R+Htb/k955eVywapJsPhpcOVCYD0Y/AFEd7e6MilDlv4/4Msvv2T06NFMmjSJnj178u6773LVVVexdetW6tevX+j6ZcuWMWzYMP73v/8xcOBAEhISGDFiBPfddx+zZ8+24BVIaS2OW8yYJWPyw+oZyZnJvLz25fx23/p9GdF2BM2Cm1V0iSIilUJ6Vi6frIzjw2X7SD2ZA0BEkA8jLmvEzZ2i8PHUrOE5nTgM34yE3YvMdvNrYdCb4FcNtx+r4iwNsxMmTODee+/lvvvuA2DixIksWLCAyZMn8+KLLxa6ftWqVTRo0IC//e1vAMTExPB///d/vPLKKxVat1wYp8vJS2teKhRkz+bt8GbaVdO0O4GIVFupJ3P4ePk+pqzYT0ZWHgDRtf148LLGXN8+Ei8Pu8UVuoE9P8Ps/zMPOvDwgStfgE7DwVZN1gdXM5aF2ZycHNavX8+4ceMK9Pfv358VK1YU+ZgePXrw+OOP8/3333PVVVeRkpLCjBkzuOaaa4p9nuzsbLKzs/Pb6enpAOTm5pKbm1sGr+T8zjxPRT1fZbUueV3+0oLiZDuzSTuVVq3HSj8vxdPYFE3jUjx3GpvDGdl8uHw/n689SGaOE4DGdfwZeWlDro4Nw8NhB8NJbq7zop/LncalVJy52H95EfvKN7FhYIQ0I++GDyC0BeTllehbVNmxuUgVPS6leR6bYRjFT5OVo8TERCIjI1m+fDk9evy5EfELL7zA1KlT2bFjR5GPmzFjBvfccw9ZWVnk5eUxaNAgZsyYgadn0Qvfn376acaPH1+o/7PPPsPPz69sXoyUyKacTXyd+fV5r7vJ7ybaerWtgIpERKyXmg0/JdhZmWIjzzBnDuv5G/SPdNE62KC6bDZwsfyyD9Nx/ySCM/cAsK92H7bUG4rTfu7dHaRyyszMZOjQoaSlpREYGHjOay1fNW77y5S/YRiF+s7YunUrf/vb33jyySe58sorSUpK4tFHH2XEiBF8+OGHRT7mscceY8yYMfnt9PR0oqKi6N+//3kHp6zk5uayaNEi+vXrV2zoruqOZR1j7vK5kHn+a/t170ensE7lX1QlpZ+X4mlsiqZxKV5lHpu4o5m8u3Qfs39LJM9lzit1qF+TUZfG0LtJSLH/FpaFyjwuF8K2ZRaOH57Glp2B4ROE85qJ1Gs+kHoX8L2q2tiUlYoelzPvpJeEZWE2JCQEh8PBoUOHCvSnpKQQFlb0+ccvvvgiPXv25NFHHwWgTZs2+Pv706tXL5577jnCwwufXuLt7Y23d+G/yjw9PSv8h9SK57SaYRh8s/sb/rv+v6Rlp53zWhs2wvzCCmzTVZ1Vx5+XktLYFE3jUrzKNDY7kzN4++fdzN2UyOkMS8/GtXmoTxO6NQwu1xD7V5VpXC5Izkn44V+wcbrZjuqGbfD7eNQsfBN5abn92JSTihqX0jyHZWHWy8uLjh07smjRIm644Yb8/kWLFnHdddcV+ZjMzEw8PAqW7HCYocei1RJyDvvS9vHsqmdZe2gtAM1qNePqmKuZuGEiQIEbwWynjwwc22WsgqyIVEmbD6bx1s+7WLDlz3sHLm8eyoN9GtMxupaFlbmppN/NI2mP7gJs0PtRuHQsOCx/01kqmKX/xceMGcOdd95Jp06d6N69O++99x7x8fGMGDECMJcIJCQkMG3aNAAGDhzI/fffz+TJk/OXGYwePZouXboQERFh5UuRs+Q4c/jwjw95//f3yXXl4uvhy6i2o7ij5R142D2oH1i/wD6zAGF+YYztMpa+0X0trFxEpOytj0vlzZ92s2THYcC8of6q2LqMuqwxsZFBFlfnhgwDVr8Li54AZw4EhJsnecUUv0e9VG2WhtlbbrmFo0eP8swzz5CUlERsbCzff/890dHRACQlJREfH59//d13301GRgZvvfUW//znP6lZsyaXX345L7/8cnFPIRVsffJ6xq8cz760fQBcEnkJ/+n2HyJrROZf0ze6L32i+rAmcQ2LVi6iX/d+WlogIlWKYRis2HOUt37azcq9RwGw2+C6dpGMuqwRTcICLK7QTZ08Ct8+CDt/MNtNr4Lr3gZ/HZxUnVk+Fz9q1ChGjRpV5NemTJlSqO/hhx/m4YcfLueqpLTSstP43/r/MXPXTABq+9RmXJdxXNngyiLXfznsDjqFdSLFK4VOYZ0UZEWkSjAMg5+2p/DWz7vZGH8cAE+HjSEd6zHi0kZE1/a3tkB3tu9XmPUAZCSBwwv6PwddHtDesWJ9mBX3ZhgG8/fP5+U1L3M0y5x9GNxkMP/o+A+CvPX2mYhUDy6Xwfwth3jrp91sTTLvwvb2sHNbl/o80LshETV9La7QjTnz4JeX4NfXAANCmsKQj6Bua6srk0pCYVYu2MGMgzy3+jmWJywHoGFQQ57s/iQdwzpaXJmISMXIc7qY+3sib/+8h90pJwDw93JwR/do7rukIXUCtMfpRTkeDzPvgwOrzXb7O+Gql8FLM9zyJ4VZKbVcVy7Tt05n0m+TyHJm4Wn35IE2DzA8djheDi+ryxMRKXfZeU5mbUhg8pI9xKeaG2gH+nhwd88Y7unRgFr++l140bZ8A3P/Bllp4B0IAydC7GCrq5JKSGFWSmXz4c2MXzmeHcfME9o61+3Mk92epEFQA2sLExGpAFm5Tr5YE8+7v+4lKS0LgGB/L+7rFcOd3aIJ8NG+pBctJxMWPAbrp5jtyE4w5EOo1cDKqqQSU5iVEjmRc4I3N77J59s/x8AgyDuIRzo9wnWNrqvQDb5FRKxwIjuP6avi+GDpXo6cyAEgLNCbB3o34rYuUfh56Z/TMpG8xdw79vB2wAaX/AP6/Bsc+iNBiqf/98l5/Rj/Iy+sfoGUzBQABjYcyCOdHyHYJ9jiykREyldaZi4fr9jHx8v3k3YqF4B6tXwZcWkjhnSsh4+ndmIpE4YB6z6EBY9DXhbUCIMb34OGl1ldmbgBhVkp1qGTh3hx9Yv8dOAnAKIConii2xN0j+hucWUiIuXryIlsPly2j09WxnEiOw+AhnX8GXVZY65rF4Gnw25xhVVIZirMeRi2zzPbTfrD9ZPBP8TausRtKMxKIU6Xky92fMGbG9/kZO5JPGwe3BN7Dw+0eQAfDx+ryxMRKTeH0rJ499c9fL4mnqxcFwDN6wbw0OWNuSo2HIddy6rKVNwKc7eC9ASwe0K/8dB1JNj1x4KUnMKsFLAjdQfjV45n85HNALSt05Ynuz9J01pNLa5MRKT8HEjNZPIve5ix7iA5TjPEtq0XxEOXN+GK5qHYFWLLlssJv74Kv7wMhguCG5l7x0a0s7oycUMKswLAqbxTTN40mWlbpuE0nNTwrMHoDqO5qdlN2G36C1lEqqbdKSeYtGQ33/6WiNNlANAlJpiHL2/MJY1DdINreUg7aJ7kFWfuUU7boXD1K+CtI37lwijMCssTlvPsqmdJOJEAQL/ofozrMo5Qv1CLKxMRuXBOl8HqfamsP2Kj9r5UujcOzV8msDUxnbeX7Ob7zUkYZoalV5MQHurTmK4Na1tYdRW3bR58+yBkHQevGnDt/6DNzVZXJW5OYbYaO3LqCK+sfYUf9v0AQF3/uvyn63+4NOpSiysTEbk48/9IYvzcraf3gnUwbdc6woN8uLNbNBvij7F4W0r+tf1ahvFQn8a0jappWb1VXu4pWPgfWPuB2Y5oD4M/hNqNrK1LqgSF2WrIZbiYvWs2/13/XzJyMrDb7Nze4nYeavcQfp5+VpcnInJR5v+RxMjpGzD+0p+UlsUrC8wDX2w2uKZ1OA/2aUyL8MCKL7I6Sdlu7h2bssVs9/gbXP4EeOiUNCkbCrPVzN7jexm/cjwbUjYA0CK4BU/1eIpWtVtZXJmIyMVzugzGz91aKMiezdfTwbcP9aRpmNZolivDgA1T4YdxkHcK/OvADe9A475WVyZVjMJsNZHtzOaDzR/wweYPyHPl4evhy0PtHmJoi6F42PVjICJVw5p9qfnHzBbnVK6ToydyIKyCiqqOTh2HuX+Hrd+Y7YZ94IZ3IUCDLmVPKaYaWHtoLc+sfIb96fsB6F2vN493fZyIGhHWFiYiUkYOZ2QzZ1MiHy/bV6LrUzLOHXjlIsSvNveOTYsHuwdc8SR0f1h7x0q5UZitwo5nHee/6//LN7u/ASDEN4RxXcbRP7q/tpsREbeXletk8bZkZm1I4Jedh/O31iqJ0AAdAFPmXE5YNgF+fhEMJ9RqYO4dG9nR6sqkilOYrYIMw2De3nm8tu41UrNSAbi56c38vePfCfTSjQ4i4r4Mw2Bd3DFmbTjIvN+TyMjKy/9au6ia3NA+gkk/7yElI7vIdbM2oG6QD11igius5mohPdHcO3b/UrPd+ia4ZgL46N8cKX8Ks1XMgfQDPLvqWVYmrQSgcc3GPNX9KdqFtrO2MBGRi7D/yElmbUxg9saDHEg9ld8fWdOXG9pHckOHSBrVqQFAWKAPI6dvwAYFAu2Z96OeGthSx9KWpR3z4ZuRcCoVPP3hmteg7W3mlhEiFUBhtorIdeUydctU3tn0DtnObLzsXoxoO4K7W92Np8PT6vJEREotLTOXeZsTmbUhgfVxx/L7/b0cXN06nBs71KNrTHCho2YHxIYz+Y4OZ+0za6ob5MNTA1syIDa8wl5DlZaXDYuehNXvmO26bcxlBSFNrK1Lqh2F2Spg0+FNjF85nl3HdgHQNbwrT3Z7kvqB9S2uTESkdHKdLn7ZcZhZGw+yeGsKOU4XAHYbXNKkDoM7RNK/ZV18vRzn/D4DYsPp17IuK3ensHDpavr36lrgBDC5SEd2wYx74NBms91tFPR9Gjy8LS1LqieFWTeWkZPB6xte56sdX2FgUNO7Jo92fpSBDQfqBi8RcRuGYfBHQjozNxxk7qZEjp7Myf9a87oBDO5Qj+vaRRAaWLqbthx2G11jgjm6zaBrTLCCbFkwDPjtU/j+UcjNBL/acP1kaHql1ZVJNaYw64YMw2Bx/GJeWv0SKafMIxkHNRrEI50eoZZPLYurExEpmaS0U3yzMZFZGw6yK+VEfn9IDW+ubxfBjR3q0TJCNxBVGllpMG8M/DHDbMf0hhveg0At2xBrKcy6mUMnD/H8qudZcnAJANGB0TzR7Qm6hne1tjARkRI4mZ3Hgi2HmLUhgeV7jmCcvkPL28NO/1Z1ubFDJL0ah+Dh0J6klcrB9eayguNxYHPA5Y9Dz9FgP/dyD5GKoDDrJpwuJ59t/4w3N77JqbxTeNg9GB47nAfaPIC3Q2uURKTycroMVu45yqwNB5m/5RCZOc78r3WJCWZwh0iuah1OoI9uVq10XC5Y8Qb89Cy48iCoPgz5EKK6WF2ZSD6FWTew7eg2xq8cz5ajWwBoH9qep7o/RaOajSyuTESkeLuSM5i5IYFvNiZwKP3PXQUa1Pbjxg71uKF9JFHBfhZWKOeUkQyzH4C9S8x2qxvg2ongW9PCokQKU5itxDJzM5n02ySmb5uO03AS4BnAPzr9g8FNBmO36S04Eal8jpzIZu4mczutzQlp+f1Bvp4MbGtup9U+qqZuUq3sdi2G2f8HmUfAwxeufgXa36m9Y6VSUpitpH49+CvPr3qexJOJAAxoMICxXcYS4hticWUiIgVl5Tr5aXsKszYcZMmOw+SdPlbWw26jT/NQBneIpE/zULw9tL6y0svLgR/Hw8q3zHZYrLl3bJ1m1tYlcg4Ks5XMkVNHeGnNSyzYvwCACP8IHu/2OL3r9ba4MhGRPxmGwfq4Y8zamMC8TYmkn3WsbNt6QdzYoR7Xtgmndg2t6a90XE5sccuITF2JLS4QGvY2b+Q6ugdmDIek38zrujwA/Z4Fz9JtiSZS0RRmKwmX4WLGzhlMXD+RjNwMHDYHd7S4g1HtRuHnqTVlIlI5xB/NZNbGg8zemEDc0cz8/vAgH25oH8mNHSJpHBpgYYVyTlvnwPyxeKQn0gkgbjIERkDzgeb+sTknwLcWXPc2NL/G6mpFSkRhthLYfWw3z6x6ho0pGwFoVbsVT3V/iha1W1hcmYgIpJ3K5fvNSczacJC1+/88VtbPy8FVseEM7hBJt4a1Cx0rK5XM1jnw1TDAKNifnghr3jU/j74EbnwPgiIrvDyRC6Uwa6FsZzbvbnqXj7d8TJ4rDz8PPx5u/zC3Nb8Nh/buExEL5TpdLN11mJkbEli0NZmcPPNYWZsNLmkcwo0dIrmyVV38vPTPiFtwOWH+WAoF2bN5B8Kds8HDq8LKEikL+i1UzpwuJ+uS17EpZxOhyaF0ieiCw+5gddJqnln5DPEZ8QBcFnUZj3d9nLr+dS2uWESqK8Mw2JKYzqwNCczZlMCRE38eK9s0rMbpY2UjqRukNZRuJ26FOQN7LtnpcGA1xPSqmJpEyojCbDlaHLeYl9a8RHJmMgBf//g1dXzrEB0YzbrkdQCE+obyWNfHuKL+FdqqRkQscSgti29+S2D2hgR2JGfk99f29+K6duY62FYRgfod5c5OJJftdSKViMJsOVkct5gxS8Zg/OUtncOnDnP41GEAbm12K3/r8DcCvHSzhIhUrMycP4+VXbb7z2NlvTzs9GsZxuAOkfRqUgdPHStbNdQIK9vrRCoRhdly4HQ5eWnNS4WC7NmCfYIZ12Wc1saKSIVxuQxW7T3KzA0JzP8jiZNnHSvbuUEtbuxQj6tbhxPkq2NlqxTDgMSN57nIZu5qEN2jQkoSKUsKs+VgQ8qG/KUFxUnNSmVDygY61+1cQVWJSFXkdBms3pfK+iM2au9LpXvjUBx/2VVgd0oGs04fK5uY9uexstG1/bixvXmsbP3a2gKwSspMhW9Gwc4fzuq0UfBGsNM/LwNeMvebFXEzCrPl4HDm4TK9TkSkKPP/SGL83K0kpWUBDqbtWkd4kA9PDWxJl5jap4+VPcimg38eKxvo48G1bSMY3CGSDvVraR1sVXZgjXkIQtoBcHjDgBfBPwTmjyt4M1hghBlkWw6yrlaRi6AwWw7q+NUp0+tERP5q/h9JjJy+odBipqS0LEZM34DdBqdPlcXDbuOyZnW4sUM9Lm8eio+nZt+qNJfLPI72x/HgyoPghnDTFAhva369+bXk7f2V35YuoF2vK/E4cwKYiJtSmC0HHUI7EOYXRkpmSpHrZm3YCPMLo0NoBwuqExF353QZjJ+79Vw7huIyIDYikMEd6zGwbQQhOla2eshMhW9Gws75ZrvVjTDwdfAJ/PMauwMj+hIStqTTNvoSBVlxe7pNtRw47A7GdRkHmMH1bGfaY7uM1c1fInJB1uxLPb204Nwev6Yl9/SMUZCtLuJXwzu9zCDr8IZr/wdDPioYZEWqIIXZctI3ui8TLptAqF9ogf4wvzAmXDaBvtF9LapMRNxd3NGTJbouJeP8gVeqAJcLlr8OH18F6QchuBHctxg6DTePbBOp4rTMoBz1je5Ln6g+rElcw6KVi+jXvV/+CWAiIqWVletk2sr9vL54V4muDw3QSV1V3smj8M0I2LXQbMcOgYETwVv7l0v1oTBbzhx2B53COpHilUKnsE4KsiJSak6XwcwNB5m4aGf+1loedht5rqJXzdqAukE+dIkJrsAqpcLFrzJ3K0hPMJcVXP0KdLhLs7FS7SjMiohUUoZhsHhbCq8u2M7O5BMARAT58I9+TfH38uDBzzaY1531mDMx5qmBLQvtNytVhMsFK16HH58Fwwm1G5u7FdRtbXVlIpZQmBURqYTW7U/lpR+2sy7uGABBvp481Kcxd3aPzt9aa7K9w1n7zJrqnt5ndkBsuCV1Szk7eRRm/x/sXmS2W99k3uilZQVSjSnMiohUIjuTM3hl/g4WbzNPEfTxtDO8Zwz/d2mjQsfMDogNp1/LuqzcncLCpavp36trkSeASRURt9JcVpCRCB4+cNUr0GGYlhVItacwKyJSCSQeP8X/Fu1k5oaDuAxw2G3c3CmK0X2bEBZY/I1cDruNrjHBHN1m0DUmWEG2KnK5YPlE+Om508sKmpxeVhBrdWUilYLCrIiIhY5n5jBpyR6mrNhPTp4LgAGt6vLIlc1oHFrD4urEciePnF5WsNhst7kFrpkA3vrZEDlDYVZExAKncpx8vGIfk5fsISMrD4CuMcGMvao5HerXsrg6qRTiVpxeVpBkLiu4+jVof4eWFYj8hcKsiEgFynO6mLH+IP9bvJPk9GwAmtcNYOxVzbmsaR1sCiricsGyCfDz82C4IKSpuawgrJXVlYlUSgqzIiIVwDAMFmxJ5tUF29lz2DzBK7KmL//s35Tr2kVqrauYThyG2Q/Anp/Mdptb4Zr/almByDkozIqIlLPVe4/y0vztbIw/DkAtP08eurwJd3Srj7eHDlKR0/Yvgxn3wolD4OEL17wG7W7XsgKR81CYFREpJ9uS0nll/nZ+3nEYAF9PB/f1iuH+3g0J9PE8z6Ol2nC5YNl/4ecXTi8raAY3T4XQFlZXJuIWFGZFRMrYwWOZTFi0k9kbEzAM8+jZW7tE8bfLmxB6jm22pBo6cRhm3Q97fzbbbYeaM7Je/tbWJeJGFGZFRMpI6skc3v55N5+sjCPHaW6zdU2bcB7p34yYEIUT+Yt9S2HmfWctK/gvtL/d6qpE3I7CrIjIRcrMyeOjZft495e9ZGSb22z1aFSbcVc1p029mtYWJ5WPywlL/wtLXjSXFdRpbu5WoGUFIhdEYVZE5ALlOl18ufYAr/+4i8MZ5jZbrSICGTugOb2ahGibLSnsRMrpZQVLzHa7O+DqV7SsQOQiKMyKiJSSYRh8v/kQry3cwb4j5jZbUcG+PNK/GQPbRGDXNltSlH2/nl5WkAyefuaygnZDra5KxO0pzIqIlMKK3Ud4ef52Nh1MA6C2vxd/u6IJt3Wpj5eH3eLqpFJyOeHX1+CXl04vK2hxellBc6srE6kSFGZFRErgj4Q0Xlmwg193mtts+Xs5uL93Q+7r1ZAa3vpVKsXISIZZ95mzsmAeR3vVq+DlZ21dIlWIfgOLiJxD/NFM/rtoB9/+lgiAp8PG7V2jeejyxoTU8La4OqnU9v5iLis4mWIuK7j2f9D2VqurEqlyFGZFRIpw5EQ2b/20m09Xx5HrNAAY1DaCf/ZvSnRt3awj5+Bywi+vwC8vAwaEtjSXFdRpZnVlIlWSwqyIyFlOZOfxwdK9vP/rXk7mOAHo1SSEsQOaExsZZHF1UullJMPMe2H/UrPdYRgMeFnLCkTKkcKsiAiQk+fi8zXxvPnTLo6cyAGgdWQQ465qTs/GIRZXJ25h7xKYef/pZQX+p5cV3GJ1VSJVnsKsiFRrLpfB3N8T+e/CncSnZgLQoLYfj1zZjKtjw7XNlpyfy2kuKfjlFcxlBa1OLytoanVlItWCwqyIVFtLdx3mpR+2syUxHYCQGt78vW8Tbu0chadD22xJCWQcMm/yyl9WcBdc9TJ4+lpbl0g1ojArItXO7weP8/L87SzffRSAGt4e/F/vhgy/JAZ/bbMlJbXnZ/M0r5OHzWUFAydCm5utrkqk2tFvbRGpNvYdOclrC3fw3e9JAHg57NzRzdxmK9jfy+LqxG24nLDkJfj1VfKXFdw8FUKaWF2ZSLWkMCsiVV5KRhZv/LiLL9YcIM9lYLPBDe0i+Ue/pkQF6y5zKYX0JHNZQdwys93xbhjwkpYViFhIYVZEqqyMrFze+3UvHyzdx6lcc5utPs3q8K8BzWkRHmhxdeJ2dv8Isx6AzCPgVQMGvg6th1hdlUi1pzArIlVOdp6TT1fF89bPu0k9aW6z1S6qJuOuak63hrUtrk7cjjMPlrwIS/8LGBDW2tytIKSx1ZWJCAqzIlKFOF0G3/6WwIRFOzl47BQADUP8+deAZlzZqi42m7bZklJKTzIPQYhbbrY73gMDXtSyApFKRGFWRNyC02Wwel8q64/YqL0vle6NQ3Gc3gPWMAyW7DzMyz9sZ/uhDABCA7z5R7+m3NSxHh7aZksuxO7FMOv/tKxApJJTmBWRSm/+H0mMn7uVpLQswMG0XesID/LhqYEtCQv04aUftrN6XyoAAT4ejLysEff0iMHXy2Ft4eKenHmw5IXTywowlxXcPBVqN7K2LhEpksKsiFRq8/9IYuT0DRh/6U9Ky2LE9A35bS8PO3f3aMDISxtRS9tsyYVKT4QZ90L8CrPd6V648gXw9LG2LhEplsKsiFRaTpfB+LlbCwXZvxrSIZJ/9G9GZE2tY5SLsGsxzH4AMo+CVwAMegNib7S6KhE5D4VZEam01uxLPb204NwGd4xSkJUL58yDn5+DZf8z23XbmLsVaFmBiFtQmBWRSutQ2qkSXZeScf7AK1KktARzt4L4lWa7833Q/3ktKxBxIwqzIlLpJKWd4os1B5i2cn+Jrg8NUPCQC7BrkXkIwqlUc1nBdW9CqxusrkpESklhVkQqBafL4Nedh/l0dTw/bU/GdXqhrN1G/ud/ZQPqBvnQJSa4wuqUKsCZCz89B8snmu3wtjDkYy0rEHFTCrMiYqmUjCy+XneQz1bHk3D8z2UFXWOCub1bNDYM/vb5bwAFbgQ7c/zBUwNb5u83K1KAy4ktbhmRqSuxxQVCw96QkQQzhsOB1eY1XR6A/s+Bh7e1tYrIBVOYFZEK53IZrNx7lE9Xx7FwSzJ5p6deA308GNIxiqFdo2gcGpB/vafDftY+s6a6p/eZHRAbXuH1ixvYOgfmj8UjPZFOAHGTwa825GVBzknwDoRBb0Kr6y0uVEQuluVhdtKkSbz66qskJSXRqlUrJk6cSK9evYq89u6772bq1KmF+lu2bMmWLVvKu1QRuUipJ3OYsf4An62OZ//RzPz+DvVrcnvXaK5pE46PZ+GDDgbEhtOvZV1W7k5h4dLV9O/VtcAJYCIFbJ0DXw2Dv27qlnnU/N+aDWDYbAhuWNGViUg5sDTMfvnll4wePZpJkybRs2dP3n33Xa666iq2bt1K/fr1C13/+uuv89JLL+W38/LyaNu2LTfddFNFli0ipWAYBmv3H+PT1XH8sPkQOU4XADW8PbihfSRDu9anRXjgeb+Pw26ja0wwR7cZdI0JVpCVormcMH8shYJsgWtyoGZ0hZUkIuXL0jA7YcIE7r33Xu677z4AJk6cyIIFC5g8eTIvvvhioeuDgoIICgrKb3/zzTccO3aMe+65p8JqFpGSScvMZdZGcy3srpQT+f2xkYHc3jWaQW0j8Pe2/M0hqWriVpineJ1LeqJ5XUzR7wKKiHux7F+SnJwc1q9fz7hx4wr09+/fnxUrVpToe3z44Yf07duX6Oji/8LOzs4mOzs7v52eng5Abm4uubm5F1B56Z15nop6PnehcSmaO4+LYRhsOpjG52sP8v0fh8jKNWdhfT3tDGwTzq2d69E68swfpEapX6M7j0150rj8yXY8oUT/sOWlJWBU4/HSz0zxNDZFq+hxKc3z2AzDON9JkeUiMTGRyMhIli9fTo8ePfL7X3jhBaZOncqOHTvO+fikpCSioqL47LPPuPnmm4u97umnn2b8+PGF+j/77DP8/Pwu/AWISL4sJ6w7bGNFsp2EzD/f/g/3NehZ10WnEANfTcJKOQvK3E+7uA+omRV/3muXNX6MowEtKqAqEbkQmZmZDB06lLS0NAIDz70UzfJ/Xmy2guveDMMo1FeUKVOmULNmTa6//vpzXvfYY48xZsyY/HZ6ejpRUVH079//vINTVnJzc1m0aBH9+vXD09OzQp7THWhciuZO47IlMZ0v1h1k7qYkTuY4AfDysHN1qzBu6xJF+6igEv3/uaTcaWwqUrUfl4xDOJa8gG3H59gw8lfLFvWTZ2CDwAi63jQa7IVvNqwuqv3PzDlobIpW0eNy5p30krAszIaEhOBwODh06FCB/pSUFMLCws75WMMw+Oijj7jzzjvx8vI657Xe3t54exfeP9DT07PCf0iteE53oHEpWmUdl1M5Tub+nsinq+PZdOB4fn/DEH+Gdq3P4A71qOV/7v9fXqzKOjZWq3bjkpMJK9+CZRMh96TZFzsEW4OeMO/MJEbB3YltAANewtNbp8ZBNfyZKQWNTdEqalxK8xyWhVkvLy86duzIokWLuOGGP48PXLRoEdddd905H/vLL7+we/du7r333vIuU0RO25mcwWer45m54SAZWXkAeDpsXNmqLrd3jaZbw+AynYUVKZbLBZu/hh/HQ3qC2VevC1z5AkR1Ntt+IeauBmffDBYYAQNegpaDKr5mESk3li4zGDNmDHfeeSedOnWie/fuvPfee8THxzNixAjAXCKQkJDAtGnTCjzuww8/pGvXrsTGxlpRtki1kZXrZP4fh/h0dRxr9x/L748K9mVol2hu6lSPkBo6OUkqUNxKWPBvSNxgtoPqQ7+nodWNcPYfUy0HQfNryNv7K78tXUC7Xlfi0bB3tV5aIFJVWRpmb7nlFo4ePcozzzxDUlISsbGxfP/99/m7EyQlJREfX3Ahf1paGjNnzuT111+3omSRamHv4RN8viaeGesPcizTvKPUYbfRt0UoQ7tG06txCHbt8yoVKXUfLH4Ktn5rtr0CoNcY6DYKPItZMmB3YERfQsKWdNpGX6IgK1JFWX4D2KhRoxg1alSRX5syZUqhvqCgIDIzMwtfLCIXJSfPxaKtyXy6Oo4Ve47m94cH+XBbl/rc0jmKsECtM5QKlpUGv74Gq98BZw7Y7NBhGPR5HGqEWl2diFQClodZEbHWgdRMPl8Tz1frDnDkRA5gvlvbp1koQ7vU57JmdfBw2C2uUqodZx6s/xiWvPjnMbQN+8CVz0NYK2trE5FKRWFWpBrKc7r4aXsKn66O59ddhzmz23SdAG9u6RTFrV2iqFdL+zCLRXYtggWPw5HT+42HNIX+z0OTfgXXxYqIoDArUq0kpZ3iizUH+HLtAQ6lZ+X392oSwtAu9enbMgxPzcKKVZK3wsL/wJ4fzbZvMPT5N3S8GxzaIklEiqYwK1LFOV0Gv+46zGer4/lxWzKu07Owwf5e3NSxHrd1qU+DEH9ri5Tq7cRh+Pl52DAVDBfYPaHr/0HvR8G3ptXViUgld0FhNi8vjyVLlrBnzx6GDh1KQEAAiYmJBAYGUqNGjbKuUUQuQEpGFl+vO8jna+I5eOxUfn+XmGBu71qfAbF18fbQ3d1iodwsWD0Zfv0v5GSYfS0GQb/xENzQ2tpExG2UOszGxcUxYMAA4uPjyc7Opl+/fgQEBPDKK6+QlZXFO++8Ux51ikgJuFwGK/ce5bPV8SzYcoi809OwgT4eDO5Yj9u71qdxaIDFVUq1ZxiwZba51dbx09svhrczDz1o0NPS0kTE/ZQ6zP7973+nU6dObNq0idq1a+f333DDDdx3331lWpyIlEzqyRxmrj/IZ2vi2XfkZH5/+/o1ub1rNNe0DsfXS7OwUgkcXA8LHoMDq812QAT0fQpa3wx2rdcWkdIrdZhdtmwZy5cvx8ur4Nnr0dHRJCQklFlhInJuhmGwdv8xPlsdx/ebD5HjdAFQw9uD69tHMLRLNC0jAi2uUuS04wfM42c3f222Pf2g52jo8RB4ac22iFy4UodZl8uF0+ks1H/w4EECAvT2pcjFcLoMVu9LZf0RG7X3pdK9cSiOv5y0lXYql9kbDvLp6nh2pZzI728VEcgd3aIZ1DYCf2/d2ymVRHYGLJsIK9+CvCzABu2GwuX/gcAIq6sTkSqg1P/i9evXj4kTJ/Lee+8BYLPZOHHiBE899RRXX311mRcoUl3M/yOJ8XO3kpSWBTiYtmsd4UE+PDWwJVe2qstvB47z2ep45v6eSFauOQvr6+lgUNsIhnatT5t6Qdi0B6dUFi4n/PYp/PQcnEg2+6IvMQ89iGhnaWkiUrWUOsxOmDCByy+/nJYtW5KVlcXQoUPZtWsXISEhfP755+VRo0iVN/+PJEZO34Dxl/5DaVmMmL6BejV9OXj8zx0JmoUFcHu3+lzfPpJAH+2/KZXM3iXmoQfJf5jt4IbQ71lofo0OPRCRMlfqMBsZGclvv/3GF198wfr163G5XNx7773cfvvt+Pr6lkeNIlWa02Uwfu7WQkEWyO87ePwUng4bA9uYs7Ado2tpFlYqnyO7YOETsPMHs+0TBJeOhc73g4fXuR8rInKBShVmc3NzadasGfPmzeOee+7hnnvuKa+6RKqNNftSTy8tOLdJQzvQr1XdCqhIpJQyU2HJS7DuQ3Dlgc0Bne+Dy8aBX7DV1YlIFVeqMOvp6Ul2drZmhETKUErG+YMsQGZu4RsvRSyVlwNr34dfXoasNLOv6VXQ7xmo09Ta2kSk2ij1pn4PP/wwL7/8Mnl5eeVRj0i1ExrgU6bXiZQ7w4Bt82BSV1jwbzPIhsXCnd/A0C8UZEWkQpV6zezq1av58ccfWbhwIa1bt8bfv+D+gLNmzSqz4kSqOsMwWB+fes5rbEDdIB+6xOjtWqkEEn+Dhf+B/UvNtn8oXPEEtLsd7DqYQ0QqXqnDbM2aNRk8eHB51CJSrWRk5fLI15tYsCU5v88GBW4EO7Og56mBLQvtNytSodKT4Kdn4bfPAAMc3uaBB5f8A7y1x7iIWKfUYfbjjz8ujzpEqpVdyRn83yfr2XvkJF4OO+Ova0UtP8+z9pk11T29z+yA2HALq5VqLeckrHgLlk+E3Eyzr/VNcMWTULO+paWJiMAFhNkzDh8+zI4dO7DZbDRt2pQ6deqUZV0iVda83xP514zfycxxEhHkw6Q7OtIuqiYA/VrWZeXuFBYuXU3/Xl2LPAFMpEK4XPD7l/DjM5CRaPbV6wJXvgBRna2tTUTkLKUOsydPnuThhx9m2rRpuFzmKUQOh4Nhw4bx5ptv4ufnV+ZFilQFeU4XL/2wnQ+W7QOgR6PavHlbe2rX8M6/xmG30TUmmKPbDLrGBCvIijXiVpg3diVuNNtB9aHf09DqRh16ICKVTql3MxgzZgy//PILc+fO5fjx4xw/fpxvv/2WX375hX/+85/lUaOI2zuckc3tH6zOD7IjLm3EtOFdCgRZEcul7oUv74SPrzKDrFcA9H0aHloLsYMVZEWkUir1zOzMmTOZMWMGl112WX7f1Vdfja+vLzfffDOTJ08uy/pE3N76uGOM+nQ9yenZ1PD24LWb2mgNrFQup47D0tdg9bvgzAGbHTrcBX3+DTVCra5OROScSh1mMzMzCQsLK9QfGhpKZmZmmRQlUhUYhsH0VXE8M28ruU6DxqE1eOeOjjQOrWF1aSImZx6s/xh+fgFOnd4irtHl0P95CGtpbW0iIiVU6jDbvXt3nnrqKaZNm4aPj7mJ+6lTpxg/fjzdu3cv8wJF3NGpHCePz97MrI0JAFzTOpyXh7ShhvcF33MpUnYMA3YtMveLPbLD7AtpBlc+D437ajmBiLiVUv/L+vrrrzNgwADq1atH27Ztsdls/Pbbb/j4+LBgwYLyqFHErcQfzeT/pq9nW1I6DruNcQOac1+vGB0DLZVD8hZY8Djs/dls+9WGyx6DjveAQ39siYj7KfVvrtjYWHbt2sX06dPZvn07hmFw6623cvvtt+Pr61seNYq4jZ+3p/D3LzaSnpVHbX8v3hzanh6NQqwuSwROpMDPz8OGaWC4wO4J3UZAr0fAt6bV1YmIXLAL+jPc19eX+++/v6xrEXFbLpfBGz/t4vUfd2EY0L5+TSbd3oHwIP2BJxbLzYJVk2DpBMjJMPtaDIJ+4yG4obW1iYiUgVKH2RdffJGwsDCGDx9eoP+jjz7i8OHDjB07tsyKE3EHaZm5jP5yIz/vOAzAHd3q88S1LfH20Dn1UgFcTmxxy4hMXYktLhAa9ga7w1wX+8dMWDwe0uLNayPam4ceRPewtmYRkTJU6jD77rvv8tlnnxXqb9WqFbfeeqvCrFQrWxPTGTF9PfGpmXh72Hn+htYM6VjP6rKkutg6B+aPxSM9kU4AcZMhMAI63w87voeDa83rAiKg71PQ+mawl3p7cRGRSq3UYfbQoUOEhxfeI7NOnTokJSWVSVEi7mD2xoM8NmszWbku6tXy5Z07OhIbGWR1WVJdbJ0DXw0DjIL96Ynw43jzc08/uOQf0P0h8NLpjCJSNZU6zEZFRbF8+XJiYmIK9C9fvpyIiIgyK0ykssrJc/Hcd1uZtjIOgEub1uH1W9tR08/L4sqk2nA5Yf5YCgXZs3n6wYNroabeKRCRqq3UYfa+++5j9OjR5ObmcvnllwPw448/8q9//UvH2UqVdygti1GfrmdD/HEA/nZFE/5+RRMcdm27JRUoboU5A3suuZlwbJ/CrIhUeaUOs//6179ITU1l1KhR5OTkAODj48PYsWN57LHHyrxAkcpi1d6jPPTZRo6cyCbAx4OJt7TjihaFT8MTKXcnksv2OhERN1bqMGuz2Xj55Zd54okn2LZtG76+vjRp0gRvb+/yqE/EcoZh8OGyfbz4w3acLoPmdQN4546ONAjxt7o0qa7SEkp2XQ39sSUiVd8FH/dSo0YNOnfuTFxcHHv27KF58+bYdZesVDEns/MYO/N35v1u3tx4fbsIXryxDb5e2nZLLJCVZh5Bu2HaeS60mbsaaAsuEakGSpw+p06dysSJEwv0PfDAAzRs2JDWrVsTGxvLgQMHyro+EcvsPXyCGyYtZ97vSXjYbYwf1Ir/3dJOQVassWsxTOr+Z5Bt3A+wnf442+n2gJfM/WZFRKq4EofZd955h6CgP7cdmj9/Ph9//DHTpk1j7dq11KxZk/Hjx5dLkSIVbcGWQwx6azk7k08QGuDNFw90464eDbDZdKOXVLBTx+HbB+HTwZCeALVi4O7v4I4ZcPM0CPzLVomBEWZ/y0GWlCsiUtFKvMxg586ddOrUKb/97bffMmjQIG6//XYAXnjhBe65556yr1CkAjldBv9duINJS/YA0KVBMG/d3p7QAB+LK5NqaedCmPt3yEgEbNB1BFzxBHidXq/dchA0v4a8vb/y29IFtOt1JR5nTgATEakmShxmT506RWBgYH57xYoVBY60bdiwIYcOHSrb6kQqUOrJHP72+UaW7T4CwPCeMTx2dXM8HVoLLhXs1DGY/2/YdPq0xeBGcN3bEN298LV2B0b0JSRsSadt9CUKsiJS7ZQ4zEZHR7N+/Xqio6M5cuQIW7Zs4ZJLLsn/+qFDhwosQxBxJ78fPM7I6RtIOH4KX08HLw9pw6C2OgRELLDjB5g7Gk4cAmzQ/UHo87hO8BIRKUaJw+ywYcN48MEH2bJlCz/99BPNmzenY8eO+V9fsWIFsbGx5VKkSHn6cm08T3y7hZw8FzEh/rxzR0ea1Q2wuiypbjJTYf5j8PsXZrt2Y7huEtTvam1dIiKVXInD7NixY8nMzGTWrFnUrVuXr7/+usDXly9fzm233VbmBYqUl6xcJ0/P2cIXa81dOPq2CGPCLW0J9PG0uDKpdrZ/B/P+YR5yYLND94egz7/B09fqykREKr0Sh1m73c6zzz7Ls88+W+TX/xpuRSqzhOOnGDl9Pb8fTMNmg0f6N2PkpY2w61haqUiZqfDDv2Dz6d+fIU3N2dioztbWJSLiRi740AQRd7Vs1xEe/nwDxzJzqennyRu3tqd30zpWlyXVzdY58N0YOHnYnI3t8Te47DHw1M4ZIiKloTAr1YZhGEz+ZQ+vLdiBy4DWkUFMur0DUcG6sUYq0Mkj8P2jsGWW2a7T3JyNrdfx3I8TEZEiKcxKtZCRlcsjX29iwZZkAG7uVI9nrovFx1PbGEkF2vINfPdPyDwCNgdcMhouHQse3lZXJiLithRmpcrbmZzBiE/Ws/fISbwcdsZf14pbO0fpNC+pOCcOw/ePwNZvzHZoS7h+EkS0t7QsEZGqQGFWqrR5vyfyrxm/k5njJDzIh8l3dKRdVE2ry5LqwjDM5QTfPwqZR83Z2F5joPejmo0VESkjZXa00YEDBwqcCCZipTyni+fmbeWhzzaSmeOkR6PazHv4EgVZqTgnUuCrO2HGcDPIhsXC/T/B5f9RkBURKUNlFmZTU1OZOnVqWX07kQt2OCOb2z9YzQfL9gEw4tJGTBvehdo1FCCkAhgGbJ4Bb3eBbXPB7gGXjoP7f4aIdlZXJyJS5ZR4mcGcOXPO+fW9e/dedDEiF2t93DFGfbqe5PRs/L0c/PfmtgyIDbe6LKkuMg7BvDGw4zuzHdbaXBsb3sbaukREqrASh9nrr78em82GYRjFXqMbasQqhmEwfVUcz8zbSq7ToHFoDd65oyONQ2tYXZpUB4YBv39lHoCQdRzsnua62F5jwKET5UREylOJlxmEh4czc+ZMXC5XkR8bNmwozzpFinUqx8k/v9rEE99uIddpcHXrunzzYE8FWakY6Unw+W0w+wEzyIa3hQeWwGVjFWRFRCpAiWdmO3bsyIYNG7j++uuL/Pr5Zm1FykP80Uz+b/p6tiWlY7fBuKuac3+vhnqXQMqfYcCmL2D+WMhKM2djLxsLPUcrxIqIVKASh9lHH32UkydPFvv1xo0b8/PPP5dJUSIl8fP2FP7+xUbSs/Ko7e/Fm0Pb06NRiNVlSXWQnghzR8OuBWY7vB1cPxnCWlpZlYhItVTiMNurV69zft3f359LL730ogsSOR+Xy+CNn3bx+o+7MAxoF1WTyXd0IDzI1+rSpKozDPjtU5j/b8hOA4cXXPYY9PgbOLRtt4iIFUr823fv3r3ExMTo7VuxVFpmLqO/3MjPOw4DcEe3+jxxbUu8PXQsrZSztIMw9++we7HZjuwI102C0ObW1iUiUs2V+AawJk2acPjw4fz2LbfcQnJycrkUJVKULYlpDHxrGT/vOIy3h53XbmrLc9e3VpCV8mUYsGEaTOpuBlmHN/QdD8MXKsiKiFQCJQ6zf7256/vvvz/nGlqRsjRrw0FunLSC+NRM6tXyZebIHgzpWM/qsqSqO34Apt8Icx6G7HSo1xlGLINLRmtZgYhIJaHfxlKp5eS5eO67rUxbGQfApU3r8Pqt7ajp52VxZVKlGQasnwILn4CcDPDwMY+h7TYK7HonQESkMilxmLXZbIXWy2r9rJSnQ2lZjPp0PRvijwPwt8sb8/e+TXHY9XMn5ehYHMz9G+xdYrajusJ1b0NIE0vLEhGRopU4zBqGwd133423t3m+fVZWFiNGjMDf37/AdbNmzSrbCqVaWrX3KA99toEjJ3II8PFg4i3tuKJFmNVlSVXmcsH6j2DRU5BzAjx84Yonoev/aTZWRKQSK3GYveuuuwq077jjjjIvRsQwDD5cto8Xf9iO02XQvG4A79zRkQYh/ud/sMiFOrYfvn0I9i812/W7m7OxtRtZWpaIiJxficPsxx9/XJ51SDXjdBms3pfK+iM2au9LpXvjULJynYyd+Tvzfk8C4Pp2Ebx4Yxt8vTQrJuXE5YJ1H5qzsbknwdMPrngKujwA9hLfHysiIhbSDWBS4eb/kcT4uVtJSssCHEzbtY46NbzwcNhJSsvCw27jP9e04K4eDbQuW8pP6l749mGIW2a2oy+B696E4IbW1iUiIqWiMCsVav4fSYycvgHjL/2HT+QAEOjjwUd3d6ZTg+CKL06qB5cL1rwHP46H3Ezw9Id+46HTvZqNFRFxQwqzUmGcLoPxc7cWCrJn8/Vy0L5+rQqrSaqZo3vMtbHxK8x2g14w6E0IjrG2LhERuWAKs1Jh1uxLPb20oHjJ6dms2ZdK90a1K6gqqRZcTlj9Lvz4DOSdMmdj+z8DHYdrNlZExM0pzEqFSck4d5At7XUiJXJkN3z7IBxYZbZjesOgt6BWtLV1iYhImVCYlQoTGuBTpteJnJPLCasmwU/PQV4WeNWA/s9Bx7tBNxaKiFQZCrNSYYL9vbDbwFXMolkbUDfIhy4xuvlLLtLhnfDtKDi41mw37AOD3oCa9a2tS0REypzCrFSITQeOc/fHa84ZZAGeGthSx9XKhXM5YeVb8NPz4MwGrwC48nnoMEyzsSIiVZTCrJS75buP8MC0dZzMcdKmXhB3dotmwqKdBW4Gqxvkw1MDWzIgNtzCSsWtpWw3Z2MT1pvtxn1h4OsQVM/aukREpFwpzEq5+mFzEn//4jdynC56NKrNe8M6UcPbgxs71GPl7hQWLl1N/15d6d44VDOycm4uJ7a4ZUSmrsQWFwgNe4PdAc48WPEGLHkRnDngHQQDXoB2t2s2VkSkGlCYlXLz+Zp4Hp+9GZcBA1rV5fXb2uHtYR5N67Db6BoTzNFtBl1jghVk5dy2zoH5Y/FIT6QTQNxkCIyA7g/D5q8gcaN5XZP+cO1ECIq0sFgREalICrNS5gzDYPIve3hl/g4AbusSxXPXt1ZglQuzdQ58NQz+etxGeiIseMz83CcIBrwMbW/VbKyISDWjMCtlyuUyeOH7bXywbB8Aoy5rxKNXNsOmgCEXwuWE+WMpFGTP5uEDI1ZATa2NFRGpjhRmpczkOV2MnbmZmRsOAvD41S24v3dDi6sStxa3wpyBPZe8LDi2T2FWRKSaUpiVMpGV6+ShzzayeFsyDruNlwe3YUhHhQu5SCeSy/Y6ERGpchRm5aKlZ+Vy39R1rNmXipeHnbeHdqBfyzCryxJ3l5f956EH51NDP28iItWVwqxclMMZ2dz10Rq2JqUT4O3BB3d1omvD2laXJe7MmQubPodfXoG0A+e52GbuahDdo0JKExGRykdhVi7YgdRM7vxwNfuPZhJSw4upw7vQKiLI6rLEXbmcsHmGuV/sMfMGQmrUhaZXwoZppy86+0aw0zcVDnjJ3G9WRESqJYVZuSA7DmVw54erScnIpl4tX6bf25UGIf5WlyXuyOWCbd/Czy/CEXM7N/xCoNcY6DQcPH3N07zmjy14M1hghBlkWw6ypm4REakU7FYXMGnSJGJiYvDx8aFjx44sXbr0nNdnZ2fz+OOPEx0djbe3N40aNeKjjz6qoGoFYH1cKje9s4KUjGyahQUwc2QPBVkpPcOAHT/Au73h67vNIOtTE654Ev6+Cbo/aAZZMAPr6D/Iu+Mb1kWPJO+Ob2D0ZgVZERGxdmb2yy+/ZPTo0UyaNImePXvy7rvvctVVV7F161bq169f5GNuvvlmkpOT+fDDD2ncuDEpKSnk5eVVcOXV1887Uhg5fT1ZuS46Rtfio7s6E+TnaXVZ4k4MA/b8BD8/DwnrzT6vADO8dh9lHoBQFLsDI/oSErak0zb6Ei0tEBERwOIwO2HCBO69917uu+8+ACZOnMiCBQuYPHkyL774YqHr58+fzy+//MLevXsJDg4GoEGDBhVZcrX27W8J/POrTeS5DC5rVodJt3fAz0srVaQU9i+Hn56D+BVm29MPujwAPf8OfsHW1iYiIm7JsiSSk5PD+vXrGTduXIH+/v37s2LFiiIfM2fOHDp16sQrr7zCJ598gr+/P4MGDeLZZ5/F19e3yMdkZ2eTnZ2d305PTwcgNzeX3NzcMno153bmeSrq+crDtFXxPPvddgAGtqnLyzfG4mkzLuo1VYVxKQ9VcVxsCeux//Ii9n1LADAc3rg63o2r+9+hRqh5UQleb1Ucm7KgcSmexqZoGpfiaWyKVtHjUprnsRmGcY5zIstPYmIikZGRLF++nB49/txW54UXXmDq1Kns2LGj0GMGDBjAkiVL6Nu3L08++SRHjhxh1KhRXH755cWum3366acZP358of7PPvsMPz+/sntBVZRhwA8H7Sw4aC6v7lXXxY0NXNh1Oq2UQFDmfponzaJu+m8AuHAQF3IpO8MGkeWlmVgRESlaZmYmQ4cOJS0tjcDAwHNea/l7xDZbwVRkGEahvjNcLhc2m41PP/2UoCBzXd2ECRMYMmQIb7/9dpGzs4899hhjxozJb6enpxMVFUX//v3POzhlJTc3l0WLFtGvXz88Pd1nfanLZfDMd9tZcNDc6/NvlzfiocsaFvvfp7TcdVzKW5UYl8M7cPz6MvYdcwAwbHaM1rfi7PVP6tWM5kLPhqsSY1MONC7F09gUTeNSPI1N0Sp6XM68k14SloXZkJAQHA4Hhw4dKtCfkpJCWFjRp/mEh4cTGRmZH2QBWrRogWEYHDx4kCZNmhR6jLe3N97e3oX6PT09K/yH1IrnvFA5eS4embWJuZsSsdngmUGtuLN7g3J5Lncal4rkluNydA8seQk2f425J6wNYgdju2wctpAmZbZ9iluOTQXQuBRPY1M0jUvxNDZFq6hxKc1zWLY1l5eXFx07dmTRokUF+hctWlRg2cHZevbsSWJiIidOnMjv27lzJ3a7nXr1LnSuR/4qMyeP+6atY+6mRDzsNl6/tX25BVmpIo7Hw7cPwVudYfNXgAEtBsLIFTDkQwgp/IemiIhIWbB0n9kxY8bwwQcf8NFHH7Ft2zb+8Y9/EB8fz4gRIwBzicCwYcPyrx86dCi1a9fmnnvuYevWrfz66688+uijDB8+vNgbwKR0jmfmcPsHq/l152F8PR18cFcnBrWNsLosqazSk+C7R+CNDrDxEzCc0KQ/PLAEbpkOYS2trlBERKo4S9fM3nLLLRw9epRnnnmGpKQkYmNj+f7774mOjgYgKSmJ+Pj4/Otr1KjBokWLePjhh+nUqRO1a9fm5ptv5rnnnrPqJVQph9KyGPbRanYmnyDI15OP7u5Mx+haVpclldGJw7B8Iqz9APKyzL6YS+Hy/0BUF0tLExGR6sXyG8BGjRrFqFGjivzalClTCvU1b9680NIEuXj7jpzkjg9Wk3D8FGGB3nxyb1eahgVYXZZUNpmpsPItWPUO5J40+6K6weWPQ0xva2sTEZFqyfIwK9b7IyGNuz5aw9GTOTSo7ccn93YlKljblslZstJh1WQzyGafvsM0vB1c/gQ0vgLKaIcLERGR0lKYreZW7jnK/dPWcSI7j1YRgUy5pwt1Agrv/iDVVM5JWPMeLH8dTh0z+0JbmTOxza5WiBUREcspzFZjC7cc4qHPN5KT56JrTDDv39WJQB9tQyJAbhas/xiW/hdOHjb7ajeBPo9ByxvAbum9oyIiIvkUZqupr9YdYNzM33EZ0K9lGG/e1h4fT4fVZYnV8nLMXQl+fQ0yEs2+mtFw2WPQ+iZw6FeGiIhULvqXqRp679c9vPD9dgCGdKzHSze2xsOhmbZqzZkHv38Jv7xk7hkLEBgJvR+F9neAQzP2IiJSOSnMViOGYfDy/B2888seAB7o3ZDHrmpeZsfTihtyuWDLLFjyIhzdbfb5h0LvR6DDXeDpY219IiIi56EwW03kOV08PvsPvlx3AIBxVzVnxKWNLK5KLGMYsH0e/PwCpGw1+3yD4ZLR0Pl+8NJuFiIi4h4UZquBrFwnf/9iIwu2JGO3wQs3tObWLvWtLkusYBiwezH89Bwk/Wb2eQdBj4eh2wjw1t7CIiLiXhRmq7iMrFwemLaelXuP4uWw88Zt7RgQG251WWKFvb+YIfbgGrPtVQO6joAeD4GvTnoTERH3pDBbhR09kc3dH69lc0Ia/l4O3h/WiR6NQ6wuSypa/CozxO5farY9fKDL/dBzNPjr50FERNybwmwVlXD8FHd+sJq9R04S7O/FlHs606ZeTavLkoqUuBF+eh52nz7+2e4Jne6BXv+EgLrW1iYiIlJGFGaroF3JGdz54RoOpWcREeTDJ/d1pVGdGlaXJRUleYt5Y9f2eWbb5jC31+r9KNSMsrY2ERGRMqYwW8VsjD/GPVPWcjwzl8ahNZg2vAsRNX2tLksqwpFd5hZbf8wCDMAGbW6BS/8FtbVzhYiIVE0Ks1XI0l2H+b9P1pOZ46RtVE2m3N2ZWv5eVpcl5S11H/zyCvz+BRgus6/VDeapXXWaWVubiIhIOVOYrSK++z2J0V9uJNdp0KtJCO/c0RF/b/3nrdLSDprHzm78BFx5Zl+zq6HPv6Fua2trExERqSBKO1XA9FVxPPHtHxgGXNM6nAm3tMXbw2F1WVJeMpJh2QRY9xE4c8y+RldAn8ehXkdraxMREalgCrNuzDAM3v55N68t3AnA0K71efa6WBx2HU/rtlxObHHLiExdiS0uEBr2BvvpP0xOHoUVr8Pq9yDvlNkX3RMu/w9E97CuZhEREQspzLopl8vgue+28dHyfQA8fHljxvRris2mIOu2ts6B+WPxSE+kE0DcZAiMgMufhNS9sGoS5Jwwr43sZIbYhpeB/puLiEg1pjDrhnKdLv4143dmb0wA4IlrW3LvJTEWVyUXZesc+GoY5i4EZ0lPhG9G/Nmu28YMsU36K8SKiIigMOt2TuU4efCzDfy0PQWH3carQ9pwY4d6VpclF8PlhPljKRRkz2b3gBs/hJaDwG6vsNJEREQqO4VZN5J2Kpf7pq5l7f5jeHvYmXR7B65oEWZ1WXKx4laYM7Dn4soD/9oKsiIiIn+hMOsmUjKyGPbhGrYfyiDAx4MP7+pMl5hgq8uSsnAiuWyvExERqUYUZt1A/NFM7vhwNfGpmYTU8Gba8C60jAi0uiwpKzVKOLte0utERESqEYXZSm5bUjrDPlrD4YxsooJ9mX5vV6Jr+1tdlpSl9ITzXGAzdzXQ9lsiIiKFKMxWYmv3pzJ8yloysvJoXjeAacO7EBroY3VZUlYMA359FX5+/qxOGwVvBDu9Y8GAl/7cb1ZERETy6W6SSuqn7cnc+eFqMrLy6BRdiy8f6K4gW5Xk5cA3o/4Msj3+BjdNg8DwgtcFRsDN08xdDERERKQQzcxWQrM3HuSRr3/H6TLo06wOk27viK+XZuWqjFPH4Ms7Yf9SsDngmteg03Dzay2uJW/vr/y2dAHtel2Jx9kngImIiEghCrOVzMfL9zF+7lYAbmgfyStD2uDp0AR6lZG6Dz69CY7uAq8AuGkKNOn759ftDozoS0jYkk7b6EsUZEVERM5DYbaSMAyD/y3ayRs/7Qbg7h4NePLaltjtOuWpyjiwFj6/FTKPQGAkDP0K6sZaXZWIiIhbU5itBJwugye//YNPV8cD8M9+TXno8sbYdFxp1bFlNsweAXlZ5pG0Q78qvD5WRERESk1h1mI5eS7+8dVvfPd7EjYbPHNdLHd2i7a6LCkrhgHLJ8Lip81206tg8AfgXcPKqkRERKoMhVkLnczOY8T09SzddQRPh43/3dKOa9tEWF2WlBVnLnz3T9gw1Wx3HQFXvqB1sCIiImVIYdYix07mcM+Utfx24Di+ng7evbMjvZvWsbosKStZafDVXbD3Z7DZ4coXodsIq6sSERGpchRmLZCUdoo7P1zD7pQT1PTz5KO7O9Ohfi2ry5KycvwAfHYzpGwFTz8Y8hE0u8rqqkRERKokhdly5nQZrN6XyvojNmrvSyUsyI+7P15LwvFT1A304ZN7u9AkLMDqMqWsJGwwdyw4kQw16sLQLyGindVViYiIVFkKs+Vo/h9JjJ+7laS0LMDBtF3rsNvAZUDDEH+m3duFerX8rC5Tysr272DGvZB3CkJbwe1fQVA9q6sSERGp0hRmy8n8P5IYOX0Dxl/6Xac7RlzWSEG2qjAMWDUZFvwbMKBxXxjyMfgEWl2ZiIhIlaejpcqB02Uwfu7WQkH2DBvwv0U7cbqKu0LchjMPvn8UFjwGGNDxHrjtSwVZERGRCqIwWw7W7Es9vbSgaAaQlJbFmn2pFVeUlL3sE/DFUFj7PmCDfs/Ctf8Dh97wEBERqSj6V7ccpGQUH2Qv5DqphNITzR0LDm0GDx+48T1oeZ3VVYmIiFQ7CrPlIDTAp0yvk0rm0Gb49GbISAT/OnDbF1Cvk9VViYiIVEtaZlAOusQEEx7kg62Yr9uA8CAfusQEV2RZUhZ2LoSPBphBNqQZ3PejgqyIiIiFFGbLgcNu46mBLQEKBdoz7acGtsRhLy7uSqW05n34/BbIOQExveHehVAr2uqqREREqjWF2XIyIDacyXd0oG5QwaUEdYN8mHxHBwbEhltUmZSaywkLHofvHwHDBe3ugNtngm9NqysTERGp9rRmthwNiA2nX8u6rNydwsKlq+nfqyvdG4dqRtad5JyEWQ/A9nlm+/InoNc/wab/hiIiIpWBwmw5c9htdI0J5ug2g64xwQqy7iQj2VxWkLgRHN5w/SRoPcTqqkREROQsCrMiRUneam69lXYAfIPhts+hfjerqxIREZG/UJgV+as9P8FXd0F2OgQ3gtu/htqNrK5KREREiqAwK3K2DdNg3j/AlQf1e8Ctn4KftlATERGprBRmRQBcLvjpGVj2P7Pd+ma47i3w8La2LhERETknhVmR3FPwzUjYMttsXzoOLhunHQtERETcgMKsVG8nj8Dnt8HBNWD3hEFvQrvbrK5KRERESkhhVqqvI7vg0yFwbD/4BMEtn0JML6urEhERkVJQmJXqaf8y+OJ2yDoOtRrA0K+hTlOrqxIREZFSUpiV6mfTF/DtQ+DKhXqd4bYvwD/E6qpERETkAijMSvVhGLDkJfjlJbPd8nq44R3w9LW0LBEREblwCrNSPeRlw5yH4fcvzfYl/4DLnwS73dq6RERE5KIozErVl5kKX94BccvB5oBr/wcd77K6KhERESkDCrNStR3dA5/dDEd3g3cg3DwVGl1udVUiIiJSRhRmpeqKXwVfDIXMoxAUBUO/grCWVlclIiIiZUhhVqqmP2bC7JHgzIaI9uaOBQF1ra5KREREypjCrFQthgFL/ws/PWu2m10Dg98HL39r6xIREZFyoTArVYczF+aNho3TzXb3h6DfM2B3WFqWiIiIlB+FWakaTh2Hr4bBvl/AZoerXoEu91tdlYiIiJQzhVlxf8fizB0LDm8HT3+46WNoeqXVVYmIiEgFUJgV93ZwPXx+C5w8DAHh5o4F4W2srkpEREQqiMKsuK9tc2Hm/ZB3CsJaw9AvISjS6qpERESkAinMivsxDFj5Fix8AjCgSX8Y8hF4B1hdmYiIiFQwhVlxL848+OFRWPeR2e58Pwx4CRz6URYREamOlADEfWSlw4x7YPdiwAZXPg/dRoHNZnVlIiIiYhGFWXEPaQfhs1sg+Q/w8IXBH0CLa62uSkRERCymMCuVX9ImM8hmJIF/qHmjV2QHq6sSERGRSkBhViq3HfNhxnDIPQl1WsDtX0HN+lZXJSIiIpWEwqxUXqvfhfnjwHBBwz5w81TwCbK6KhEREalEFGal8nE5YcHjsHqy2e4wDK6ZAA5Pa+sSERGRSkdhViqXnJMw8z7Y8b3Z7vs09BytHQtERESkSAqzYg2XE1vcMiJTV2KLC4SGvc0jaT+72bzhy+ENN74LrW6wulIRERGpxBRmpeJtnQPzx+KRnkgngLjJ5i4FLiecOgp+teG2LyCqi9WVioiISCWnMCsVa+sc+GoYYBTsP5li/m+NcBj+AwTHVHhpIiIi4n7sVhcg1YjLCfPHUijIns2Gtt4SERGRElOYlYoTtwLSE899TUaSeZ2IiIhICSjMSsU5kVy214mIiEi1pzArFadGWNleJyIiItWe5WF20qRJxMTE4OPjQ8eOHVm6dGmx1y5ZsgSbzVboY/v27RVYsVywyE7g4XOOC2wQGAnRPSqsJBEREXFvlobZL7/8ktGjR/P444+zceNGevXqxVVXXUV8fPw5H7djxw6SkpLyP5o0aVJBFcsFyz0FXw+DvKxiLjh9KMKAl8DuqLCyRERExL1ZGmYnTJjAvffey3333UeLFi2YOHEiUVFRTJ48+ZyPCw0NpW7duvkfDofCT6WWfcI8DGHXQvDwhd7/gsCIgtcERsDN06DlIGtqFBEREbdk2T6zOTk5rF+/nnHjxhXo79+/PytWnPtu9vbt25OVlUXLli35z3/+Q58+fYq9Njs7m+zs7Px2eno6ALm5ueTm5l7EKyi5M89TUc9XqWSl4fjyNuwH12B41cB5y+cY9btDz3/i3LeMP1YuJrZ7Xxwxl5gzstVxjP6iWv+8nIfGpmgal+JpbIqmcSmexqZoFT0upXkem2EY59j0s/wkJiYSGRnJ8uXL6dHjzzWSL7zwAlOnTmXHjh2FHrNjxw5+/fVXOnbsSHZ2Np988gnvvPMOS5YsoXfv3kU+z9NPP8348eML9X/22Wf4+fmV3QuSQrzyMui++1VqntpPjsOflY0e4bh/I6vLEhERkUouMzOToUOHkpaWRmBg4DmvtfwEMJvNVqBtGEahvjOaNWtGs2bN8tvdu3fnwIEDvPbaa8WG2ccee4wxY8bkt9PT04mKiqJ///7nHZyykpuby6JFi+jXrx+enp4V8pyWyziEx+dDsJ3aj+EXgm3oTHqEtSpwSbUclxLQuBRPY1M0jUvxNDZF07gUT2NTtIoelzPvpJeEZWE2JCQEh8PBoUOHCvSnpKQQFlbyrZm6devG9OnTi/26t7c33t7ehfo9PT0r/IfUiue0xPEDMH0QpO6FgHBsw+bgWadpsZdXm3EpJY1L8TQ2RdO4FE9jUzSNS/E0NkWrqHEpzXNYdgOYl5cXHTt2ZNGiRQX6Fy1aVGDZwfls3LiR8PDwsi5PLtTRPfDxVWaQrVkf7vkBzhFkRURERC6GpcsMxowZw5133kmnTp3o3r077733HvHx8YwYMQIwlwgkJCQwbdo0ACZOnEiDBg1o1aoVOTk5TJ8+nZkzZzJz5kwrX4ackbIdpl0HJw5B7cYwbA4ERVpdlYiIiFRhlobZW265haNHj/LMM8+QlJREbGws33//PdHR0QAkJSUV2HM2JyeHRx55hISEBHx9fWnVqhXfffcdV199tVUvQc5I2gSf3ACZRyG0FQz7BmqEWl2ViIiIVHGW3wA2atQoRo0aVeTXpkyZUqD9r3/9i3/9618VUJWUyoE1MH0IZKdBRAe4Yyb4BVtdlYiIiFQDlodZcXP7lsJnt0DuSajfHYZ+BT4Vs0uEiIiIiMKsXLhdi+DLO8wjahteBrd+Bl7+VlclIiIi1Yilx9mKG9s6Bz6/zQyyTa+C275UkBUREZEKpzArpff7V/D13eDKhVY3wi2fgKeP1VWJiIhINaQwK6WzfgrMegAMJ7S7HQZ/AA5tKi0iIiLWUJiVkls5Ceb+HTCg8/0w6C2wO6yuSkRERKoxhVkpmV9fhQWPmZ/3+Btc/SrY9eMjIiIi1tJuBnJuhgE/PgPLJpjty/4Nl/4LbDZr6xIRERFBYVbOxTBg/jhY/Y7Z7v8c9HjY2ppEREREzqIwK0VzOWHeaNgwzWxfMwE632tpSSIiIiJ/pTArhTlz4ZuRsPlrsNnhuknQ7jarqxIREREpRGFWCsrLhhnDYfs8sHuYW2+1usHqqkRERESKpDArf8rJNI+n3fMjOLzh5mnQbIDVVYmIiIgUS2FWTNkZ8NktELccPP3gts+h4WVWVyUiIiJyTgqzAqeOwfQhkLAOvAPh9q+hfjerqxIRERE5L4XZ6u7EYfjkBkjeDL614M7ZENHe6qpERERESkRhtjpLT4Rp18GRneAfCsO+hbCWVlclIiIiUmIKs9XVsTiYNgiO7YfASBg2B0IaW12ViIiISKkozFZHR3abQTY9AWo1MINsrWirqxIREREpNYXZ6iZ5q7m04GQKhDQzlxYEhltdlYiIiMgFUZitThI3mjd7nToGdVvDnd+Af4jVVYmIiIhcMIXZ6iJ+FXx6E2SnQ2QnuGOGuXuBiIiIiBtTmK0O9i6Bz2+D3EyI7glDvwTvAKurEhEREbloCrNV3Y758NUwcGZDoyvglung5Wd1VSIiIiJlwm51AVKOtsyGL283g2zza80jahVkRUREpApRmK2qfvscZgwHVx60vglumgIe3lZXJSIiIlKmFGarorUfwDcjwHBBh2Fww7vg8LS6KhEREZEypzBb1ax4E777p/l51xEw8A2wO6ytSURERKSc6AawqsIw4JeXYcmLZvuSMXDFk2CzWVuXiIiISDlSmK0KDAMWPQkr3jDblz8BvR+xtiYRERGRCqAw6+5cLvjhUXOdLMCVL0L3UdbWJCIiIlJBFGbdmcsJcx6G3z4FbDBwInS82+KiRERERCqOwqy7cubCrPvNvWRtDrjhHWhzs9VViYiIiFQohVl3lJsFX98NO38AuycM+QhaDrK6KhEREZEKpzDrbnJOwhdDYe8S8PAxj6dt0s/qqkREREQsoTDrTrLS4NOb4cAq8PSHoV9CTC+rqxIRERGxjMKsu8hMhek3QuJG8A6CO2ZCVGerqxIRERGxlMKsOziRAtOuh5Qt4Feb/2/nzoOiuvcsgJ9umqUBGyVGJUIRl9ACpUikVMAXX0ojVmKMqadx3DHqhCoSMVHzcEiEpFLl4BpNwLiB0VIxTyEhUWPMuIFGjSwqguKCxgXj6JMRxXGB7/zBsyc8G5/dcO/txvOp6ir43Qv33OOl6+ut7sa4HMAvTOtURERERJrjMOvo/ucSsGYocP004N0BGP8d0K6b1qmIiIiIHAKHWUf294r6QbbqN8AnoH6QfaaL1qmIiIiIHAaHWUf13+X1g2x1JeDbGRifC7QO0DoVERERkUPhMOuIrhyrf41szTXg2WBg/LdAqw5apyIiIiJyOBxmHc3FgvpPLfjfqvo3eY3NAbye0ToVERERkUPiMOtIzu0D1o8E7lUD/r2BMX8DjK21TkVERETksDjMOorT/wVkjQEe3AGe/xMwKgtw99Y6FREREZFD4zDrCE5sAf4WC9TeA14YBLy1BnA1ap2KiIiIyOFxmNXasU1A9r8DUgsEDwX+sgowuGmdioiIiMgp6LUO8FQrXAtsnlw/yPb4N2B4JgdZIiIiIhtwmNXKweVA7rsABOg1ERi2FHDhjXIiIiIiW3CY1UL+ImDbzPqv+8YDQxYBev5TEBEREdmKtwKVVlcL3fl8dPz7L9CdMwG/5QF5C+q3vfQh8PJ/ADqdthmJiIiInBSHWSWV5gI//hWGm5cRAQDnl/7/toEpQL/3NQpGRERE1DJwmFVKaS7wzXgAYn27bxdV4xARERG1RHyhphLqaoEf/4pGB1nogB8T6/cjIiIiIrtxmFXC+f3AzcuP2UGAm5fq9yMiIiIiu3GYVcKt35t3PyIiIiKyisOsErzbN+9+RERERGQVh1klBEYBpucANPaRWzrA1LF+PyIiIiKyG4dZJehdgMGp//jmnwfaf3w/+D/r9yMiIiIiu3GYVUrIUOCtNYDJr+G66bn69ZCh2uQiIiIiakH4ObNKChkKdHsND87uRXHedvT8UwwMnV/iHVkiIiKiZsI7s0rTu0AC++GSbyQksB8HWSIiIqJmxGGWiIiIiJwWh1kiIiIiclocZomIiIjIaXGYJSIiIiKnxWGWiIiIiJwWh1kiIiIiclocZomIiIjIaXGYJSIiIiKnxWGWiIiIiJwWh1kiIiIiclocZomIiIjIaXGYJSIiIiKnxWGWiIiIiJyWQesAahMRAMDNmzdVO+b9+/dRU1ODmzdvwtXVVbXjOjr2Yh17aRy7sY69NI7dWMdeGsdurFO7l4dz2sO57XGeumG2uroaABAQEKBxEiIiIiJ6nOrqavj4+Dx2H508ycjbgtTV1eHy5cto1aoVdDqdKse8efMmAgICcOHCBZhMJlWO6QzYi3XspXHsxjr20jh2Yx17aRy7sU7tXkQE1dXVeO6556DXP/5VsU/dnVm9Xg9/f39Njm0ymfiHYQV7sY69NI7dWMdeGsdurGMvjWM31qnZy7+6I/sQ3wBGRERERE6LwywREREROS0Osypwd3dHcnIy3N3dtY7iUNiLdeylcezGOvbSOHZjHXtpHLuxzpF7eereAEZERERELQfvzBIRERGR0+IwS0REREROi8MsERERETktDrNERERE5LQ4zDaD9PR0dOrUCR4eHujVqxfy8vIa3beyshKjR4+G2WyGXq/HtGnT1AuqAVu6yc7OxiuvvIJnn30WJpMJkZGR2L59u4pp1WNLL/n5+YiOjsYzzzwDo9GIbt26YdGiRSqmVZct3fzRvn37YDAY0LNnT2UDasSWXnbv3g2dTvfI48SJEyomVo+t18zdu3eRlJSEwMBAuLu7o0uXLsjIyFAprXps6SU2NtbqNRMaGqpiYvXYes2sW7cOYWFh8PT0hJ+fHyZOnIjr16+rlFY9tvaSlpaG4OBgGI1GmM1mrFmzRqWk/0SoSbKyssTV1VVWrFghpaWlkpCQIF5eXnL+/Hmr+1dUVMjUqVPl66+/lp49e0pCQoK6gVVkazcJCQmSmpoqhw4dkvLycpk1a5a4urpKYWGhysmVZWsvhYWFsn79eikpKZGKigpZu3ateHp6yrJly1ROrjxbu3moqqpKOnfuLIMGDZKwsDB1wqrI1l527dolAOTkyZNSWVlpeTx48EDl5Mqz55oZOnSo9OnTR3bs2CEVFRVy8OBB2bdvn4qplWdrL1VVVQ2ulQsXLoivr68kJyerG1wFtnaTl5cner1eFi9eLGfPnpW8vDwJDQ2VYcOGqZxcWbb2kp6eLq1atZKsrCw5c+aMbNiwQby9vSU3N1fl5CIcZpuod+/eEhcX12CtW7dukpiY+C9/tn///i16mG1KNw+FhITIJ5980tzRNNUcvbz55psyduzY5o6mOXu7GTlypHz00UeSnJzcIodZW3t5OMzeuHFDhXTasrWbbdu2iY+Pj1y/fl2NeJpp6vNMTk6O6HQ6OXfunBLxNGVrN/PmzZPOnTs3WFuyZIn4+/srllELtvYSGRkpM2bMaLCWkJAg0dHRimVsDF9m0AT37t1DQUEBBg0a1GB90KBB2L9/v0apHENzdFNXV4fq6mr4+voqEVETzdFLUVER9u/fj/79+ysRUTP2dpOZmYkzZ84gOTlZ6YiaaMo1Ex4eDj8/PwwYMAC7du1SMqYm7OkmNzcXERERmDt3Ljp27IigoCDMmDEDd+7cUSOyKprjeWbVqlUYOHAgAgMDlYioGXu6iYqKwsWLF7F161aICH7//Xds2rQJr732mhqRVWFPL3fv3oWHh0eDNaPRiEOHDuH+/fuKZbWGw2wTXLt2DbW1tWjfvn2D9fbt2+PKlSsapXIMzdHNggULcPv2bbz11ltKRNREU3rx9/eHu7s7IiIiEB8fj8mTJysZVXX2dHPq1CkkJiZi3bp1MBgMasRUnT29+Pn5Yfny5di8eTOys7NhNpsxYMAA7N27V43IqrGnm7NnzyI/Px8lJSXIycnB559/jk2bNiE+Pl6NyKpo6vNvZWUltm3b1uKeYwD7uomKisK6deswcuRIuLm5oUOHDmjdujW++OILNSKrwp5eYmJisHLlShQUFEBEcPjwYWRkZOD+/fu4du2aGrEtWuazv8p0Ol2D70XkkbWnlb3dbNiwASkpKfjuu+/Qrl07peJpxp5e8vLycOvWLRw4cACJiYno2rUrRo0apWRMTTxpN7W1tRg9ejQ++eQTBAUFqRVPM7ZcM2azGWaz2fJ9ZGQkLly4gPnz5+Oll15SNKcWbOmmrq4OOp0O69atg4+PDwBg4cKFGD58ONLS0mA0GhXPqxZ7n39Xr16N1q1bY9iwYQol054t3ZSWlmLq1KmYPXs2YmJiUFlZiZkzZyIuLg6rVq1SI65qbOnl448/xpUrV9C3b1+ICNq3b4/Y2FjMnTsXLi4uasS14J3ZJmjbti1cXFwe+V/L1atXH/nfzdOmKd1s3LgRkyZNwjfffIOBAwcqGVN1TemlU6dO6N69O6ZMmYL3338fKSkpCiZVn63dVFdX4/Dhw3j33XdhMBhgMBjw6aef4siRIzAYDNi5c6da0RXVXM8zffv2xalTp5o7nqbs6cbPzw8dO3a0DLIAEBwcDBHBxYsXFc2rlqZcMyKCjIwMjBs3Dm5ubkrG1IQ93cyZMwfR0dGYOXMmevTogZiYGKSnpyMjIwOVlZVqxFacPb0YjUZkZGSgpqYG586dw2+//Ybnn38erVq1Qtu2bdWIbcFhtgnc3NzQq1cv7Nixo8H6jh07EBUVpVEqx2BvNxs2bEBsbCzWr1/fol6P9FBzXTMigrt37zZ3PE3Z2o3JZMKxY8dQXFxsecTFxcFsNqO4uBh9+vRRK7qimuuaKSoqgp+fX3PH05Q93URHR+Py5cu4deuWZa28vBx6vR7+/v6K5lVLU66ZPXv24PTp05g0aZKSETVjTzc1NTXQ6xuOSw/vPIqIMkFV1pRrxtXVFf7+/nBxcUFWVhaGDBnySF+KU/0tZy3Mw4+yWLVqlZSWlsq0adPEy8vL8g7QxMREGTduXIOfKSoqkqKiIunVq5eMHj1aioqK5Pjx41rEV5St3axfv14MBoOkpaU1+IiYqqoqrU5BEbb28uWXX0pubq6Ul5dLeXm5ZGRkiMlkkqSkJK1OQTH2/D39UUv9NANbe1m0aJHk5ORIeXm5lJSUSGJiogCQzZs3a3UKirG1m+rqavH395fhw4fL8ePHZc+ePfLCCy/I5MmTtToFRdj7tzR27Fjp06eP2nFVZWs3mZmZYjAYJD09Xc6cOSP5+fkSEREhvXv31uoUFGFrLydPnpS1a9dKeXm5HDx4UEaOHCm+vr5SUVGhenYOs80gLS1NAgMDxc3NTV588UXZs2ePZduECROkf//+DfYH8MgjMDBQ3dAqsaWb/v37W+1mwoQJ6gdXmC29LFmyREJDQ8XT01NMJpOEh4dLenq61NbWapBcebb+Pf1RSx1mRWzrJTU1Vbp06SIeHh7Spk0b6devn2zZskWD1Oqw9ZopKyuTgQMHitFoFH9/f/nggw+kpqZG5dTKs7WXqqoqMRqNsnz5cpWTqs/WbpYsWSIhISFiNBrFz89PxowZIxcvXlQ5tfJs6aW0tFR69uwpRqNRTCaTvPHGG3LixAkNUovoRFrIPXIiIiIieurwNbNERERE5LQ4zBIRERGR0+IwS0REREROi8MsERERETktDrNERERE5LQ4zBIRERGR0+IwS0REREROi8MsERERETktDrNERAo7d+4cdDodiouLVT3u7t27odPpUFVV1aTfo9Pp8O233za6XavzIyICOMwSETWJTqd77CM2NlbriERELZpB6wBERM6ssrLS8vXGjRsxe/ZsnDx50rJmNBpx48YNm39vbW0tdDod9HrecyAiehw+SxIRNUGHDh0sDx8fH+h0ukfWHjp79ixefvlleHp6IiwsDL/88otl2+rVq9G6dWv88MMPCAkJgbu7O86fP4979+7hww8/RMeOHeHl5YU+ffpg9+7dlp87f/48Xn/9dbRp0wZeXl4IDQ3F1q1bG2QsKChAREQEPD09ERUV1WDYBoClS5eiS5cucHNzg9lsxtq1ax97zocOHUJ4eDg8PDwQERGBoqKiJjRIRNQ0HGaJiFSSlJSEGTNmoLi4GEFBQRg1ahQePHhg2V5TU4M5c+Zg5cqVOH78ONq1a4eJEydi3759yMrKwtGjRzFixAgMHjwYp06dAgDEx8fj7t272Lt3L44dO4bU1FR4e3s/ctwFCxbg8OHDMBgMePvtty3bcnJykJCQgOnTp6OkpATvvPMOJk6ciF27dlk9h9u3b2PIkCEwm80oKChASkoKZsyYoUBbRERPSIiIqFlkZmaKj4/PI+sVFRUCQFauXGlZO378uACQsrIyy88CkOLiYss+p0+fFp1OJ5cuXWrw+wYMGCCzZs0SEZHu3btLSkqK1Ty7du0SAPLzzz9b1rZs2SIA5M6dOyIiEhUVJVOmTGnwcyNGjJBXX33V8j0AycnJERGRZcuWia+vr9y+fduyfenSpQJAioqKGquGiEgxvDNLRKSSHj16WL728/MDAFy9etWy5ubm1mCfwsJCiAiCgoLg7e1teezZswdnzpwBAEydOhWfffYZoqOjkZycjKNHj9p03LKyMkRHRzfYPzo6GmVlZVbPoaysDGFhYfD09LSsRUZGPlkBREQK4BvAiIhU4urqavlap9MBAOrq6ixrRqPRsv5wm4uLCwoKCuDi4tLgdz18KcHkyZMRExODLVu24KeffsKcOXOwYMECvPfee0983D8eEwBE5JG1P24jInIkvDNLROSgwsPDUVtbi6tXr6Jr164NHh06dLDsFxAQgLi4OGRnZ2P69OlYsWLFEx8jODgY+fn5Ddb279+P4OBgq/uHhITgyJEjuHPnjmXtwIEDNp4ZEVHz4TBLROSggoKCMGbMGIwfPx7Z2dmoqKjAr7/+itTUVMsnFkybNg3bt29HRUUFCgsLsXPnzkYHUWtmzpyJ1atX46uvvsKpU6ewcOFCZGdnN/qmrtGjR0Ov12PSpEkoLS3F1q1bMX/+/GY5XyIie3CYJSJyYJmZmRg/fjymT58Os9mMoUOH4uDBgwgICABQ/3m08fHxCA4OxuDBg2E2m5Genv7Ev3/YsGFYvHgx5s2bh9DQUCxbtgyZmZn485//bHV/b29vfP/99ygtLUV4eDiSkpKQmpraHKdKRGQXnfAFUERERETkpHhnloiIiIicFodZIiIiInJaHGaJiIiIyGlxmCUiIiIip8VhloiIiIicFodZIiIiInJaHGaJiIiIyGlxmCUiIiIip8VhloiIiIicFodZIiIiInJaHGaJiIiIyGn9H98EdR1HuWorAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Score: 0.7335\n"
     ]
    }
   ],
   "source": [
    "#Plot the F1 curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, fold_f1_scores, marker='o', linestyle='-')\n",
    "plt.plot(thresholds, fold_half_scores, marker='o', linestyle='-')\n",
    "plt.plot(thresholds, fold_double_scores, marker='o', linestyle='-')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Curve')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Display the mean F1 score\n",
    "print(f\"Mean F1 Score: {mean_f1_scores:.4f}\")\n",
    "\n",
    "#pick 0.7 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.0099, 0.0098, 0.0097, 0.0096, 0.0095, 0.0094, 0.0093, 0.0092, 0.0091, 0.009000000000000001, 0.0089, 0.0088, 0.0087, 0.0086, 0.0085, 0.0084, 0.0083, 0.0082, 0.008100000000000001, 0.008, 0.0079, 0.0078000000000000005, 0.0077, 0.0076, 0.0075, 0.0074, 0.0073, 0.0072, 0.0070999999999999995, 0.006999999999999999, 0.0069, 0.0068, 0.006699999999999999, 0.006599999999999999, 0.006500000000000001, 0.0064, 0.0063, 0.0062, 0.0061, 0.006, 0.005900000000000001, 0.0058000000000000005, 0.005700000000000001, 0.005600000000000001, 0.0055000000000000005, 0.0054, 0.0053, 0.005200000000000001, 0.0051, 0.005, 0.0049, 0.0048, 0.0047, 0.0046, 0.0045, 0.004399999999999999, 0.004300000000000001, 0.004200000000000001, 0.0041, 0.004, 0.0039000000000000003, 0.0038, 0.0037, 0.0036, 0.0034999999999999996, 0.0034, 0.0032999999999999995, 0.0031999999999999997, 0.0031000000000000008, 0.0030000000000000005, 0.0029000000000000002, 0.0028000000000000004, 0.0027, 0.0026000000000000003, 0.0025, 0.0024, 0.0023, 0.0021999999999999997, 0.0021, 0.0019999999999999996, 0.0018999999999999996, 0.0018000000000000006, 0.0017000000000000003, 0.0016000000000000003, 0.0015000000000000002, 0.0014000000000000002, 0.0013000000000000002, 0.0012, 0.0010999999999999998, 0.0009999999999999998, 0.0008999999999999998, 0.0007999999999999996, 0.0006999999999999996, 0.0006000000000000006, 0.0005000000000000004, 0.00040000000000000034, 0.0003000000000000003, 0.00020000000000000017, 0.00010000000000000009]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning rate vs. epoch\n",
    "print(learning_rates)\n",
    "learning_rates.pop(0)\n",
    "learning_rates.insert(0, 0.01)\n",
    "plt.plot(range(1, 100 + 1), learning_rates)\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.9476\n",
      "Pseudo Test Loss: 0.23131117224693298\n",
      "Pseudo Test Accuracy: 0.947596549987793\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the pseudo-test set\n",
    "pseudo_test_loss, pseudo_test_accuracy = model.evaluate(np.expand_dims(X_val, -1), y_val)\n",
    "print(f\"Pseudo Test Loss: {pseudo_test_loss}\")\n",
    "print(f\"Pseudo Test Accuracy: {pseudo_test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) \n[GCC 12.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2df73002193cefbfa9243a6efa2b74af79e3047145117f20857a75b11408ac59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

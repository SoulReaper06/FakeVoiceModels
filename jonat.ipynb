{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define paths and parameters\n",
    "DATASET_PATH = r\"D:\\RediMinds\\prototypes\\datasets\\archive\\LA\\LA\\ASVspoof2019_LA_train\\flac\"\n",
    "LABEL_FILE_PATH = \"D:/RediMinds/prototypes/datasets/archive/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\"\n",
    "NUM_CLASSES = 2  # Number of classes (bonafide and spoof)\n",
    "SAMPLE_RATE = 16000  # Sample rate of your audio files\n",
    "DURATION = 5  # Duration of audio clips in seconds\n",
    "N_MELS = 128  # Number of Mel frequency bins\n",
    "\n",
    "labels = {}\n",
    "\n",
    "with open(LABEL_FILE_PATH, 'r') as label_file:\n",
    "    lines = label_file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split()\n",
    "    file_name = parts[1]\n",
    "    label = 1 if parts[-1] == \"bonafide\" else 0\n",
    "    labels[file_name] = label\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "max_time_steps = 109  # Define the maximum time steps for your model\n",
    "\n",
    "for file_name, label in labels.items():\n",
    "    file_path = os.path.join(DATASET_PATH, file_name + \".flac\")\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "\n",
    "    # Extract Mel spectrogram using librosa\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=SAMPLE_RATE, n_mels=N_MELS)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Ensure all spectrograms have the same width (time steps)\n",
    "    if mel_spectrogram.shape[1] < max_time_steps:\n",
    "        mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, max_time_steps - mel_spectrogram.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mel_spectrogram = mel_spectrogram[:, :max_time_steps]\n",
    "\n",
    "    X.append(mel_spectrogram)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X,y\n",
    "\n",
    "y_encoded = to_categorical(y, NUM_CLASSES)\n",
    "split_index = int(0.8 * len(X))\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y_encoded[:split_index], y_encoded[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model architecture\n",
    "input_shape = (N_MELS, X_train.shape[2], 1)  # Input shape for CNN (height, width, channels)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation='relu')(model_input)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "model_output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "#Save the Model\n",
    "model.save(\"fakeaudio.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 10:53:21.649682: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-09 10:53:22.482396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22843 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:1a:00.0, compute capability: 7.5\n",
      "2023-10-09 10:53:22.483095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22773 MB memory:  -> device: 1, name: NVIDIA TITAN RTX, pci bus id: 0000:68:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load both Model 1 and Model 2\n",
    "model1 = load_model('models/agamjeet-model.h5')  # Replace with the path to Model 1's saved file\n",
    "model2 = load_model('models/jonat-model.h5') \n",
    "model3 = load_model('models/gautham-model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to testing data for each model\n",
    "testing_dir_model1 = '/home/jonat/datasets/for-2seconds/testing'  # Adjust the path\n",
    "testing_dir_model2 = '/home/jonat/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_eval/flac'\n",
    "testing_dir_model3 = '/home/jonat/datasets/release_in_the_wild'\n",
    "LABEL_FILE_PATH_MODEL2 = '/home/jonat/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt'\n",
    "LABEL_FILE_PATH_MODEL3 = '/home/jonat/datasets/release_in_the_wild/meta.csv'\n",
    "\n",
    "#CONSTANT VARIABLES\n",
    "MAX_PAD_LENGTH = 86\n",
    "NUM_MFCC_COEFFS = 40\n",
    "NUM_CLASSES = 2  # Number of classes (bonafide and spoof)\n",
    "SAMPLE_RATE = 16000  # Sample rate of your audio files\n",
    "DURATION = 5  # Duration of audio clips in seconds\n",
    "N_MELS = 128  # Number of Mel frequency bins\n",
    "MAX_TIME_STEPS = 109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-2.76277771e+02, -2.49373566e+02, -1.99227371e+02, ...,\n",
       "          -2.27046265e+02, -1.34770493e+02, -1.03455429e+02],\n",
       "         [ 1.74620529e+02,  1.85464966e+02,  1.96909729e+02, ...,\n",
       "           7.07589569e+01,  1.54023010e+02,  1.65170990e+02],\n",
       "         [ 5.69737358e+01,  4.54773674e+01,  1.74491978e+01, ...,\n",
       "          -2.83980751e+01, -1.50940132e+01, -5.55561447e+00],\n",
       "         ...,\n",
       "         [ 2.46777916e+00,  7.45345497e+00,  5.94833279e+00, ...,\n",
       "           8.74664211e+00,  1.27606812e+01,  1.21703796e+01],\n",
       "         [ 4.85905141e-01, -2.36257339e+00,  1.46288171e-01, ...,\n",
       "           7.01033306e+00,  3.16514158e+00,  2.43539977e+00],\n",
       "         [-9.34749171e-02, -3.58693719e+00, -2.31290364e+00, ...,\n",
       "          -1.22441196e+00, -6.32507420e+00, -4.38854647e+00]],\n",
       " \n",
       "        [[-3.08881439e+02, -3.03552643e+02, -2.12761063e+02, ...,\n",
       "          -1.82072174e+02, -1.09421761e+02, -9.30665588e+01],\n",
       "         [ 1.54973816e+02,  1.56298920e+02,  1.57697021e+02, ...,\n",
       "           1.20053299e+02,  1.61675415e+02,  1.79663010e+02],\n",
       "         [ 4.44691315e+01,  3.99298630e+01, -1.46820087e+01, ...,\n",
       "          -2.81591072e+01, -5.40886536e+01, -5.90874252e+01],\n",
       "         ...,\n",
       "         [-5.07596397e+00, -6.44710922e+00, -1.13696623e+01, ...,\n",
       "           2.60362482e+00,  9.83487129e+00,  1.20643368e+01],\n",
       "         [-8.31093490e-01, -2.11534023e+00, -1.10132751e+01, ...,\n",
       "           1.70580406e+01,  1.98471527e+01,  1.40589962e+01],\n",
       "         [-3.53662086e+00, -4.03428936e+00, -7.36544609e+00, ...,\n",
       "           2.16578732e+01,  2.29628029e+01,  1.65289059e+01]],\n",
       " \n",
       "        [[-1.52683578e+02, -1.00014404e+02, -8.93416824e+01, ...,\n",
       "          -1.54003082e+02, -1.29320724e+02, -1.32199860e+02],\n",
       "         [ 2.81605110e+01,  4.47012711e+01,  8.25540848e+01, ...,\n",
       "           8.96567001e+01,  1.19450523e+02,  1.26100586e+02],\n",
       "         [-3.64352875e+01, -6.23426285e+01, -7.17549362e+01, ...,\n",
       "          -5.91172409e+01, -7.09159088e+01, -4.93900452e+01],\n",
       "         ...,\n",
       "         [-4.75099850e+00, -6.48921871e+00, -8.99948537e-01, ...,\n",
       "           2.67161322e+00,  2.60476732e+00,  1.42866850e-01],\n",
       "         [-4.22950459e+00,  1.92703831e+00,  7.77332401e+00, ...,\n",
       "           5.91316128e+00,  4.00051403e+00,  5.03842640e+00],\n",
       "         [-3.78465176e+00,  1.90988922e+00,  4.69052410e+00, ...,\n",
       "           1.57490039e+00,  2.22725844e+00,  1.07559621e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-9.56090851e+01, -7.27528763e+01, -8.31278458e+01, ...,\n",
       "          -1.03267456e+02, -9.10149231e+01, -9.12150497e+01],\n",
       "         [ 1.67156296e+02,  1.70431793e+02,  1.52494522e+02, ...,\n",
       "           2.01818649e+02,  1.83716614e+02,  1.85112686e+02],\n",
       "         [-6.71284027e+01, -8.15568848e+01, -9.35574646e+01, ...,\n",
       "          -6.26082840e+01, -7.29463348e+01, -5.81941299e+01],\n",
       "         ...,\n",
       "         [ 1.24215803e+01,  2.27925396e+01,  4.22394867e+01, ...,\n",
       "          -6.91330314e-01, -3.59406829e+00,  2.75636220e+00],\n",
       "         [ 1.02287598e+01,  2.29058571e+01,  3.52634125e+01, ...,\n",
       "          -3.11483097e+00, -1.04690895e+01, -7.51497030e+00],\n",
       "         [ 3.59858513e+00,  1.01962881e+01,  1.38039675e+01, ...,\n",
       "          -3.97474909e+00, -1.37468891e+01, -1.37868156e+01]],\n",
       " \n",
       "        [[-2.67743652e+02, -2.33248199e+02, -2.29770645e+02, ...,\n",
       "          -3.72496124e+02, -4.30678040e+02, -4.57802246e+02],\n",
       "         [-4.19966125e+01, -3.31964912e+01, -3.19975548e+01, ...,\n",
       "           8.68476410e+01,  7.41678848e+01,  5.78560028e+01],\n",
       "         [-1.46108866e+01, -3.19870720e+01, -3.89329185e+01, ...,\n",
       "           1.35820923e+01,  3.44838486e+01,  3.59962578e+01],\n",
       "         ...,\n",
       "         [-5.44681072e+00, -1.53993130e+00,  5.00383377e-02, ...,\n",
       "           2.12612557e+00,  5.64795303e+00,  6.81831741e+00],\n",
       "         [-3.31563187e+00,  1.24714124e+00,  2.21896577e+00, ...,\n",
       "           4.49995947e+00, -9.13560390e-03,  7.92069137e-01],\n",
       "         [-2.50125456e+00, -2.19588947e+00,  3.59929800e-02, ...,\n",
       "           5.93486309e+00,  1.24560225e+00,  1.44077945e+00]],\n",
       " \n",
       "        [[-2.93032013e+02, -2.81195129e+02, -2.18836182e+02, ...,\n",
       "          -9.32525024e+01, -8.84762115e+01, -1.12746086e+02],\n",
       "         [ 1.59387802e+02,  1.98381470e+02,  2.31005386e+02, ...,\n",
       "           1.84605133e+02,  1.63591034e+02,  1.57314636e+02],\n",
       "         [ 4.97581444e+01,  5.67651215e+01,  3.67251892e+01, ...,\n",
       "          -8.32153625e+01, -8.11981812e+01, -5.21557388e+01],\n",
       "         ...,\n",
       "         [-3.81007981e+00, -5.37445354e+00, -8.00673676e+00, ...,\n",
       "          -5.18182945e+00, -1.98433423e+00, -2.05609655e+00],\n",
       "         [-3.57079434e+00, -2.44243741e+00, -6.87644577e+00, ...,\n",
       "          -1.21909294e+01, -7.34762526e+00, -5.90226746e+00],\n",
       "         [-4.19720268e+00, -3.85836339e+00, -3.93513227e+00, ...,\n",
       "          -3.23514175e+00, -1.09895766e-02, -4.96950531e+00]]],\n",
       "       dtype=float32),\n",
       " array(['fake', 'fake', 'fake', ..., 'fake', 'real', 'fake'], dtype='<U4'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define functions for preprocessing the data for each model\n",
    "def preprocess_data_model1(file_path):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=NUM_MFCC_COEFFS)\n",
    "        pad_width = MAX_PAD_LENGTH - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, max(0, pad_width))), mode='constant')\n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while processing file: {file_path}\")\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# Process testing data for Model 1\n",
    "X_test_model1 = []\n",
    "y_test_model1 = []\n",
    "\n",
    "data = []\n",
    "for label in os.listdir(testing_dir_model1):\n",
    "    label_dir = os.path.join(testing_dir_model1, label)\n",
    "    if not os.path.isdir(label_dir):\n",
    "        continue\n",
    "    for file_name in os.listdir(label_dir):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(label_dir, file_name)\n",
    "            features = preprocess_data_model1(file_path)\n",
    "            if features is not None:\n",
    "                data.append([features, label])\n",
    "# Shuffle the data\n",
    "np.random.shuffle(data)\n",
    "\n",
    "X_test_model1 = np.array([x[0] for x in data])\n",
    "y_test_model1 = np.array([x[1] for x in data])  \n",
    "\n",
    "X_test_model1,y_test_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_model2 = []\n",
    "y_test_model2 = []\n",
    "\n",
    "labels = {}\n",
    "\n",
    "# Define a function to preprocess a single audio file\n",
    "def preprocess_data_model2(file_path, sample_rate, duration, n_mels, max_time_steps):\n",
    "    try:\n",
    "        audio, _ = librosa.load(file_path, sr=sample_rate, duration=duration)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n",
    "        mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "        \n",
    "        # Ensure all spectrograms have the same width (time steps)\n",
    "        if mel_spectrogram.shape[1] < max_time_steps:\n",
    "            mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, max_time_steps - mel_spectrogram.shape[1])), mode='constant')\n",
    "        else:\n",
    "            mel_spectrogram = mel_spectrogram[:, :max_time_steps]\n",
    "        \n",
    "        return mel_spectrogram\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while processing file: {file_path}\")\n",
    "        return None\n",
    "\n",
    "with open(LABEL_FILE_PATH_MODEL2, 'r') as label_file:\n",
    "    lines = label_file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split()\n",
    "    file_name = parts[1]\n",
    "    label = 1 if parts[-1] == \"bonafide\" else 0\n",
    "    labels[file_name] = label\n",
    "\n",
    "\n",
    "\n",
    "for file_name in os.listdir(testing_dir_model2):\n",
    "    if file_name.endswith('.flac'):\n",
    "        file_path = os.path.join(testing_dir_model2, file_name)\n",
    "        features = preprocess_data_model2(file_path, SAMPLE_RATE, DURATION, N_MELS, MAX_TIME_STEPS)\n",
    "        if features is not None:\n",
    "            X_test_model2.append(features)    \n",
    "        y_test_model2.append(label)\n",
    "\n",
    "\n",
    "X_test_model2 = np.array(X_test_model2)\n",
    "y_test_model2 = np.array(y_test_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_model3(file_path):\n",
    "    n_mfcc = 13\n",
    "    max_length = 100\n",
    "# Load the audio file\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Extract MFCC features\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "    # Ensure that the MFCCs have the same length as during training\n",
    "    if mfccs.shape[1] < max_length:\n",
    "        mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mfccs = mfccs[:, :max_length]\n",
    "\n",
    "    # Reshape the MFCCs to match the input shape expected by the model\n",
    "    input_shape = (1, n_mfcc, max_length, 1)\n",
    "    mfccs = mfccs.reshape(input_shape)\n",
    "\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(predictions_model1, predictions_model2,predictions_model3):\n",
    "    # Perform majority voting\n",
    "    combined_predictions = []\n",
    "    for pred1, pred2, pred3 in zip(predictions_model1, predictions_model2, predictions_model3):\n",
    "        # Choose the class with the majority of votes\n",
    "        combined_prediction = np.argmax(np.bincount([np.argmax(pred1), np.argmax(pred2), np.argmax(pred3)]))\n",
    "        combined_predictions.append(combined_prediction)\n",
    "    \n",
    "    return np.array(combined_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions from both models (e.g., using majority vote)\n",
    "ensemble_predictions = majority_vote(predictions_model1, predictions_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prediction from Model 1: fake\n",
      "Prediction from Model 2: real\n",
      "Prediction from Model 3: fake\n",
      "This audio sample is :  Fake\n"
     ]
    }
   ],
   "source": [
    "audio_sample_path = '/home/jonat/datasets/for-2seconds/testing/fake/file1040.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav'\n",
    "# Preprocess the audio sample for Model 1 (MFCC-based)\n",
    "# Ensure that the preprocessing matches what was done for Model 1\n",
    "preprocessed_audio_model1 = preprocess_data_model1(audio_sample_path)  # Implement this function\n",
    "\n",
    "# Preprocess the audio sample for Model 2 (Mel spectrogram-based)\n",
    "# Ensure that the preprocessing matches what was done for Model 2\n",
    "sample_rate = 16000  # Adjust to match the sample rate used during training\n",
    "duration = 5  # Adjust to match the duration used during training\n",
    "n_mels = 128  # Adjust to match the number of Mel frequency bins used during training\n",
    "max_time_steps = 109  # Adjust to match the maximum time steps used during training\n",
    "\n",
    "preprocessed_audio_model2 = preprocess_data_model2(audio_sample_path, sample_rate, duration, n_mels, max_time_steps)\n",
    "\n",
    "preprocessed_audio_model3 = preprocess_data_model3(audio_sample_path)\n",
    "\n",
    "# Make predictions for Model 1\n",
    "prediction_model1 = model1.predict(np.expand_dims(preprocessed_audio_model1, axis=0))\n",
    "\n",
    "# Make predictions for Model 2\n",
    "prediction_model2 = model2.predict(np.expand_dims(preprocessed_audio_model2, axis=0))\n",
    "\n",
    "prediction_model3 = model3.predict(preprocessed_audio_model3)\n",
    "\n",
    "# Interpret the predictions\n",
    "if prediction_model3[0][0] > 0.5:\n",
    "    result = \"fake\"\n",
    "else:\n",
    "    result = \"real\"\n",
    "\n",
    "# Combine predictions using ensemble strategy (e.g., majority voting)\n",
    "ensemble_prediction = majority_vote(prediction_model1, prediction_model2,prediction_model3)  # Implement this function\n",
    "\n",
    "# Define a mapping from binary values to class labels\n",
    "class_labels = {0: \"fake\", 1: \"real\"}\n",
    "\n",
    "# Convert the ensemble_prediction array to a single integer\n",
    "ensemble_prediction_int = int(ensemble_prediction[0])\n",
    "\n",
    "# Convert the predictions to class labels\n",
    "prediction_label_model1 = class_labels.get(int(prediction_model1[0][0]), \"Unknown\")\n",
    "prediction_label_model2 = class_labels.get(int(prediction_model2[0][0]), \"Unknown\")\n",
    "prediction_label_model3 = class_labels.get(int(prediction_model3[0][0]), \"Unknown\")\n",
    "\n",
    "# Print the predictions from both models\n",
    "print(f\"Prediction from Model 1: {prediction_label_model1}\")\n",
    "print(f\"Prediction from Model 2: {prediction_label_model2}\")\n",
    "print(f\"Prediction from Model 3: {result}\")\n",
    "\n",
    "fakeCount = 0\n",
    "realCount = 0\n",
    "\n",
    "if(prediction_label_model1 == \"fake\"):\n",
    "    fakeCount+=1\n",
    "if(prediction_label_model2 == \"fake\"):\n",
    "    fakeCount+=1\n",
    "if(result == \"fake\"):\n",
    "    fakeCount+=1\n",
    "\n",
    "if(prediction_label_model1 == \"real\"):\n",
    "    realCount+=1\n",
    "if(prediction_label_model2 == \"real\"):\n",
    "    realCount+=1\n",
    "if(result == \"real\"):\n",
    "    realCount+=1\n",
    "\n",
    "probability_index = {}\n",
    "\n",
    "probability_index[\"Real\"] = realCount\n",
    "probability_index[\"Fake\"] = fakeCount\n",
    "\n",
    "final_prediction = max(probability_index, key= probability_index.get)\n",
    "\n",
    "print(\"This audio sample is : \", final_prediction)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

import os
import librosa
import numpy as np
from keras.models import load_model

# Define the path to the trained model
model_path = '../jonat/gautham-model.h5'

# Load the trained model
model = load_model(model_path)

# Define the path to the audio file you want to test
audio_file_path_to_test = '/home/jonat/datasets/release_in_the_wild/5.wav'

# Define parameters for MFCC extraction (should match the parameters used during training)
n_mfcc = 13
max_length = 100

# Load and preprocess the sample audio file

# Load the audio file
audio, sr = librosa.load(audio_file_path_to_test, sr=None)

# Extract MFCC features
mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)

# Ensure that the MFCCs have the same length as during training
if mfccs.shape[1] < max_length:
    mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')
else:
    mfccs = mfccs[:, :max_length]

# Reshape the MFCCs to match the input shape expected by the model
input_shape = (1, n_mfcc, max_length, 1)
mfccs = mfccs.reshape(input_shape)

# Make predictions using the model
predictions = model.predict(mfccs)

# Interpret the predictions
if predictions[0][0] > 0.5:
    result = "Fake"
else:
    result = "Not Fake"

# Print the result
print(f"The audio is classified as: {result}")